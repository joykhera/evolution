{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.867896239845841, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.515970072922883, "policy_loss": -0.003952317346360475, "vf_loss": 6.519058433663908, "vf_explained_var": -0.0007094839262583899, "kl": 0.0043198403920560995, "entropy": 1.605187068792878, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1474321120472812, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.509613756654124, "policy_loss": -0.0017191034037048224, "vf_loss": 8.510760650685224, "vf_explained_var": -0.0010090816273260368, "kl": 0.002861066903407422, "entropy": 1.6066086286590213, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 1507.381269364841, "episode_reward_min": 439.92133433938045, "episode_reward_mean": 839.6677759323426, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": 5.959999999999974, "predator_policy": 0.592770149262007}, "policy_reward_max": {"prey_policy": 537.0062741555779, "predator_policy": 477.18496239477514}, "policy_reward_mean": {"prey_policy": 264.88009604406113, "predator_policy": 154.95379192211058}, "custom_metrics": {}, "hist_stats": {"episode_reward": [439.92133433938045, 613.4299999999978, 1207.5599999999986, 1048.3999999999987, 1507.381269364841, 1272.0286554642075, 451.1103894845694, 632.5688071183101, 664.1916520879302, 570.3579776073409, 692.9100000000001, 833.7199999999984, 986.093758515852, 902.4999999999995, 733.3252407854438, 894.179999999998, 537.1708820143007, 1127.169999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [83.08113943614111, 137.98947471769932, 267.21023249406846, 149.98959291733968, 429.80884135116884, 281.8548880587646, 268.8167045610231, 271.5425170187834, 293.7759802983288, 371.6301808675539, 470.9014091182684, 349.38810913630425, 329.5457850048913, 20.809999999999974, 154.04127952983174, 362.01594568018606, 263.50112987301566, 240.17228339161463, 165.55034232365728, 364.46776343051926, 328.66068687093946, 115.44199305953892, 135.2210180320988, 372.30152390673203, 445.8713202476139, 5.960000000000002, 313.1925232948914, 372.8051141229256, 76.8389484301088, 537.0062741555779, 461.28824085293377, 186.03603611425964, 315.2074210858399, 5.959999999999974, 256.0335377074821, 331.76522049610145], "policy_predator_policy_reward": [63.92643977542069, 154.92428041012053, 45.47040708265904, 150.75976750593068, 160.24511194123468, 335.65115864883103, 287.92748298121654, 220.11329543897722, 413.80285572271544, 428.1722524762427, 218.29100533389519, 233.44813187573925, 26.96100639448265, 73.79359808519709, 106.39546148874001, 10.116120419554298, 89.7443097733525, 70.77392904994859, 14.519829899221744, 25.820041953943786, 83.99800694046132, 164.80931312906046, 304.0984760932681, 22.098981967901885, 88.37552521065967, 445.8869130575798, 83.99747670510843, 132.50488587707426, 0.592770149262007, 118.88724805049692, 225.0246513598442, 21.831071672961393, 23.884003881121465, 192.11945704734154, 62.18627940164028, 477.18496239477514]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8082280343967424, "mean_inference_ms": 1.9786081986378106, "mean_action_processing_ms": 0.3317128072792155, "mean_env_wait_ms": 0.2858447254938389, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005696217219034831, "StateBufferConnector_ms": 0.003053082360161675, "ViewRequirementAgentConnector_ms": 0.09255276785956489}, "num_episodes": 18, "episode_return_max": 1507.381269364841, "episode_return_min": 439.92133433938045, "episode_return_mean": 839.6677759323426, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 274.43768031057107, "num_env_steps_trained_throughput_per_sec": 274.43768031057107, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 14575.266, "restore_workers_time_ms": 0.017, "training_step_time_ms": 14575.211, "sample_time_ms": 1613.802, "learn_time_ms": 12939.997, "learn_throughput": 309.119, "synch_weights_time_ms": 16.948}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "479e5_00000", "date": "2024-08-16_11-26-57", "timestamp": 1723787817, "time_this_iter_s": 14.625415802001953, "time_total_s": 14.625415802001953, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x325fdcd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14.625415802001953, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 61.69523809523809, "ram_util_percent": 82.75714285714285}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.078993243247113, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.5663336562101176, "policy_loss": -0.0067241687253708875, "vf_loss": 5.571755504103565, "vf_explained_var": 0.002991779456062922, "kl": 0.013023388518160532, "entropy": 1.5897225038715141, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9021352014844379, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.757774300297732, "policy_loss": -0.006136599162386523, "vf_loss": 7.7628850719916125, "vf_explained_var": 0.010132707679082477, "kl": 0.010258269706535974, "entropy": 1.5939368497126947, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 1507.381269364841, "episode_reward_min": 214.6017878244104, "episode_reward_mean": 761.7050535338483, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": 2.0000000000000013, "predator_policy": -7.441697644539177}, "policy_reward_max": {"prey_policy": 537.0062741555779, "predator_policy": 477.18496239477514}, "policy_reward_mean": {"prey_policy": 249.97051764610544, "predator_policy": 130.88200912081922}, "custom_metrics": {}, "hist_stats": {"episode_reward": [439.92133433938045, 613.4299999999978, 1207.5599999999986, 1048.3999999999987, 1507.381269364841, 1272.0286554642075, 451.1103894845694, 632.5688071183101, 664.1916520879302, 570.3579776073409, 692.9100000000001, 833.7199999999984, 986.093758515852, 902.4999999999995, 733.3252407854438, 894.179999999998, 537.1708820143007, 1127.169999999999, 363.6237707056459, 846.3668202832298, 939.618716410448, 464.84520508209573, 214.6017878244104, 585.9630216074952, 599.3099999999981, 301.1912218399857, 728.4359866536065, 628.4599999999979, 397.36999999999796, 839.2499999999982, 1069.5606569884578, 659.9329543264516, 713.6799999999986, 666.2115148588942, 955.3542381617139, 1333.5860656939476], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [83.08113943614111, 137.98947471769932, 267.21023249406846, 149.98959291733968, 429.80884135116884, 281.8548880587646, 268.8167045610231, 271.5425170187834, 293.7759802983288, 371.6301808675539, 470.9014091182684, 349.38810913630425, 329.5457850048913, 20.809999999999974, 154.04127952983174, 362.01594568018606, 263.50112987301566, 240.17228339161463, 165.55034232365728, 364.46776343051926, 328.66068687093946, 115.44199305953892, 135.2210180320988, 372.30152390673203, 445.8713202476139, 5.960000000000002, 313.1925232948914, 372.8051141229256, 76.8389484301088, 537.0062741555779, 461.28824085293377, 186.03603611425964, 315.2074210858399, 5.959999999999974, 256.0335377074821, 331.76522049610145, 7.981607828745645, 234.27756538820037, 144.14541427330465, 270.5067268746614, 419.31651586024736, 252.79263537098527, 309.9524167583224, 39.61999999999999, 2.0000000000000013, 133.54744588076343, 118.82000000000025, 299.0788298433338, 414.2871524706754, 78.09927677067097, 115.01018955373236, 105.31630729540886, 378.98268552249186, 133.35115484927599, 219.31452341465695, 216.85178952270056, 218.34169764453844, 102.82189917200216, 101.8290881616789, 456.6749954265844, 426.5089345255363, 306.97664912013624, 347.11093633934763, 136.92699619138813, 343.10286804794447, 145.8994653646845, 195.67350690389722, 171.672321195309, 353.8407575092764, 285.6424788327468, 473.4633171140901, 502.4556639060511], "policy_predator_policy_reward": [63.92643977542069, 154.92428041012053, 45.47040708265904, 150.75976750593068, 160.24511194123468, 335.65115864883103, 287.92748298121654, 220.11329543897722, 413.80285572271544, 428.1722524762427, 218.29100533389519, 233.44813187573925, 26.96100639448265, 73.79359808519709, 106.39546148874001, 10.116120419554298, 89.7443097733525, 70.77392904994859, 14.519829899221744, 25.820041953943786, 83.99800694046132, 164.80931312906046, 304.0984760932681, 22.098981967901885, 88.37552521065967, 445.8869130575798, 83.99747670510843, 132.50488587707426, 0.592770149262007, 118.88724805049692, 225.0246513598442, 21.831071672961393, 23.884003881121465, 192.11945704734154, 62.18627940164028, 477.18496239477514, 122.82243461179868, -1.4578371230973177, 250.89951335012313, 180.81516578514126, 261.08348413975216, 6.426081039463087, 42.79287754425195, 72.47991077952273, 78.15368101506593, 0.9006609285831049, 67.47021321859513, 100.59397854556741, 98.1928475293242, 8.730723229329609, 76.31540157166936, 4.549323419178085, 113.54638235197561, 102.55576392986438, 139.43821047729904, 52.855476585341975, -7.441697644539177, 83.64810082799828, 6.940911838321871, 273.8050045734152, 138.23982469061494, 197.83524865217154, 53.64929283620817, 122.24572895950799, 16.19817398343449, 208.47949260393526, 148.5997062833196, 150.2659804763694, 242.34204564023892, 73.52895617945181, 234.02833321299698, 123.63875146081007]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9112648037978848, "mean_inference_ms": 2.3830272108042476, "mean_action_processing_ms": 0.3954588302165301, "mean_env_wait_ms": 0.35161617017716845, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007331371307373047, "StateBufferConnector_ms": 0.0030931499269273546, "ViewRequirementAgentConnector_ms": 0.11896193027496338}, "num_episodes": 18, "episode_return_max": 1507.381269364841, "episode_return_min": 214.6017878244104, "episode_return_mean": 761.7050535338483, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 271.5075926475972, "num_env_steps_trained_throughput_per_sec": 271.5075926475972, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 14653.917, "restore_workers_time_ms": 0.152, "training_step_time_ms": 14653.72, "sample_time_ms": 2269.383, "learn_time_ms": 12364.572, "learn_throughput": 323.505, "synch_weights_time_ms": 16.223}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "479e5_00000", "date": "2024-08-16_11-27-14", "timestamp": 1723787834, "time_this_iter_s": 14.772563934326172, "time_total_s": 29.397979736328125, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78174c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 29.397979736328125, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 58.196000000000005, "ram_util_percent": 82.40800000000002}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3154075835432326, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.366894545883098, "policy_loss": -0.0070856129316977726, "vf_loss": 6.372821869673552, "vf_explained_var": -4.99775800755415e-05, "kl": 0.011582956179341823, "entropy": 1.581860978893502, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2068155704509644, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.931933745126875, "policy_loss": -0.007332947556170876, "vf_loss": 8.938086014197618, "vf_explained_var": 0.01798415193482051, "kl": 0.011806915147148909, "entropy": 1.5885532782822058, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 1507.381269364841, "episode_reward_min": 205.28396970386638, "episode_reward_mean": 749.0145553722332, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": 2.0000000000000013, "predator_policy": -7.441697644539177}, "policy_reward_max": {"prey_policy": 539.4511288916443, "predator_policy": 477.18496239477514}, "policy_reward_mean": {"prey_policy": 252.2187772509908, "predator_policy": 122.28850043512624}, "custom_metrics": {}, "hist_stats": {"episode_reward": [439.92133433938045, 613.4299999999978, 1207.5599999999986, 1048.3999999999987, 1507.381269364841, 1272.0286554642075, 451.1103894845694, 632.5688071183101, 664.1916520879302, 570.3579776073409, 692.9100000000001, 833.7199999999984, 986.093758515852, 902.4999999999995, 733.3252407854438, 894.179999999998, 537.1708820143007, 1127.169999999999, 363.6237707056459, 846.3668202832298, 939.618716410448, 464.84520508209573, 214.6017878244104, 585.9630216074952, 599.3099999999981, 301.1912218399857, 728.4359866536065, 628.4599999999979, 397.36999999999796, 839.2499999999982, 1069.5606569884578, 659.9329543264516, 713.6799999999986, 666.2115148588942, 955.3542381617139, 1333.5860656939476, 753.4500844112977, 1188.8246262828347, 686.1965299875368, 290.82006635822063, 1046.0649586142754, 597.2464779157727, 823.1389427430059, 991.9001626791569, 1026.8646102703985, 903.1842308700321, 205.28396970386638, 547.873708390827, 628.3999999999978, 553.359999999998, 600.5706526555256, 485.42772814101806, 323.42999999999824, 1373.3673138582908], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [83.08113943614111, 137.98947471769932, 267.21023249406846, 149.98959291733968, 429.80884135116884, 281.8548880587646, 268.8167045610231, 271.5425170187834, 293.7759802983288, 371.6301808675539, 470.9014091182684, 349.38810913630425, 329.5457850048913, 20.809999999999974, 154.04127952983174, 362.01594568018606, 263.50112987301566, 240.17228339161463, 165.55034232365728, 364.46776343051926, 328.66068687093946, 115.44199305953892, 135.2210180320988, 372.30152390673203, 445.8713202476139, 5.960000000000002, 313.1925232948914, 372.8051141229256, 76.8389484301088, 537.0062741555779, 461.28824085293377, 186.03603611425964, 315.2074210858399, 5.959999999999974, 256.0335377074821, 331.76522049610145, 7.981607828745645, 234.27756538820037, 144.14541427330465, 270.5067268746614, 419.31651586024736, 252.79263537098527, 309.9524167583224, 39.61999999999999, 2.0000000000000013, 133.54744588076343, 118.82000000000025, 299.0788298433338, 414.2871524706754, 78.09927677067097, 115.01018955373236, 105.31630729540886, 378.98268552249186, 133.35115484927599, 219.31452341465695, 216.85178952270056, 218.34169764453844, 102.82189917200216, 101.8290881616789, 456.6749954265844, 426.5089345255363, 306.97664912013624, 347.11093633934763, 136.92699619138813, 343.10286804794447, 145.8994653646845, 195.67350690389722, 171.672321195309, 353.8407575092764, 285.6424788327468, 473.4633171140901, 502.4556639060511, 325.6541387208085, 286.02226372599574, 320.8572970062904, 360.1479108739385, 196.15696479471515, 239.488036652008, 101.9900000000005, 164.33511473881381, 473.68767380500486, 401.34601972316733, 348.38579641472927, 58.42999999999997, 244.58175056272546, 341.86839036810613, 539.4511288916443, 172.35737640465712, 392.8713732818518, 342.1637686852444, 169.22298736716675, 442.34729189841397, 16.85000000000011, 152.9870937097313, 183.55429073316242, 218.48218071657328, 87.72365742684988, 280.4390458555099, 273.6726743341808, 188.3815400251916, 310.0549750861778, 70.31000000000003, 369.1194724494251, 95.49768944700476, 199.46722298436794, 40.391093345460746, 397.4904822923269, 435.96397026616995], "policy_predator_policy_reward": [63.92643977542069, 154.92428041012053, 45.47040708265904, 150.75976750593068, 160.24511194123468, 335.65115864883103, 287.92748298121654, 220.11329543897722, 413.80285572271544, 428.1722524762427, 218.29100533389519, 233.44813187573925, 26.96100639448265, 73.79359808519709, 106.39546148874001, 10.116120419554298, 89.7443097733525, 70.77392904994859, 14.519829899221744, 25.820041953943786, 83.99800694046132, 164.80931312906046, 304.0984760932681, 22.098981967901885, 88.37552521065967, 445.8869130575798, 83.99747670510843, 132.50488587707426, 0.592770149262007, 118.88724805049692, 225.0246513598442, 21.831071672961393, 23.884003881121465, 192.11945704734154, 62.18627940164028, 477.18496239477514, 122.82243461179868, -1.4578371230973177, 250.89951335012313, 180.81516578514126, 261.08348413975216, 6.426081039463087, 42.79287754425195, 72.47991077952273, 78.15368101506593, 0.9006609285831049, 67.47021321859513, 100.59397854556741, 98.1928475293242, 8.730723229329609, 76.31540157166936, 4.549323419178085, 113.54638235197561, 102.55576392986438, 139.43821047729904, 52.855476585341975, -7.441697644539177, 83.64810082799828, 6.940911838321871, 273.8050045734152, 138.23982469061494, 197.83524865217154, 53.64929283620817, 122.24572895950799, 16.19817398343449, 208.47949260393526, 148.5997062833196, 150.2659804763694, 242.34204564023892, 73.52895617945181, 234.02833321299698, 123.63875146081007, 127.65687990676648, 14.116802057727952, 196.95381949326628, 310.86559890933967, 58.57498601625825, 191.97654252455584, 21.198811567241762, 3.2961400521658897, 115.06442730169871, 55.96683778440454, 56.273455772090465, 134.15722572895294, 103.38410028685982, 133.30470152531493, 95.03335969322411, 185.05829768963196, 122.24308441014945, 169.58638389315303, 113.69401868720963, 177.91993291724137, 33.90209128103196, 1.5447847131045362, 3.4579304425015085, 142.37930649858964, 22.929413663839487, 237.30788305380037, 67.89845997480842, 23.40732566581817, 25.79336469681818, 194.41231287252984, 3.8104741563221456, 17.000092088268296, 42.43890665453924, 41.132777015631554, 297.406070733248, 242.5067905665456]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9628490008417002, "mean_inference_ms": 2.5365878900698666, "mean_action_processing_ms": 0.41208296129675837, "mean_env_wait_ms": 0.38006829147277116, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0071017830460159866, "StateBufferConnector_ms": 0.003126153239497432, "ViewRequirementAgentConnector_ms": 0.13531380229526097}, "num_episodes": 18, "episode_return_max": 1507.381269364841, "episode_return_min": 205.28396970386638, "episode_return_mean": 749.0145553722332, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 273.24799143650483, "num_env_steps_trained_throughput_per_sec": 273.24799143650483, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 14648.854, "restore_workers_time_ms": 0.107, "training_step_time_ms": 14648.696, "sample_time_ms": 2313.003, "learn_time_ms": 12309.82, "learn_throughput": 324.944, "synch_weights_time_ms": 22.052}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "479e5_00000", "date": "2024-08-16_11-27-29", "timestamp": 1723787849, "time_this_iter_s": 14.75730013847351, "time_total_s": 44.155279874801636, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7850310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 44.155279874801636, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 60.09047619047618, "ram_util_percent": 82.42857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.049701024300207, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.184059126919539, "policy_loss": -0.00821854860630261, "vf_loss": 4.1910978101548695, "vf_explained_var": 0.0018956209932054792, "kl": 0.011798701281293632, "entropy": 1.5732352409413253, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.720283323620993, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.846316432448291, "policy_loss": -0.0069484163758162625, "vf_loss": 7.852010461262294, "vf_explained_var": 0.01928174451545433, "kl": 0.012543618667200341, "entropy": 1.5674398118225985, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 1773.2989819678855, "episode_reward_min": 205.28396970386638, "episode_reward_mean": 740.0745813913175, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": 2.0000000000000013, "predator_policy": -7.441697644539177}, "policy_reward_max": {"prey_policy": 539.4511288916443, "predator_policy": 501.98425998770824}, "policy_reward_mean": {"prey_policy": 249.76018133986398, "predator_policy": 120.27710935579519}, "custom_metrics": {}, "hist_stats": {"episode_reward": [439.92133433938045, 613.4299999999978, 1207.5599999999986, 1048.3999999999987, 1507.381269364841, 1272.0286554642075, 451.1103894845694, 632.5688071183101, 664.1916520879302, 570.3579776073409, 692.9100000000001, 833.7199999999984, 986.093758515852, 902.4999999999995, 733.3252407854438, 894.179999999998, 537.1708820143007, 1127.169999999999, 363.6237707056459, 846.3668202832298, 939.618716410448, 464.84520508209573, 214.6017878244104, 585.9630216074952, 599.3099999999981, 301.1912218399857, 728.4359866536065, 628.4599999999979, 397.36999999999796, 839.2499999999982, 1069.5606569884578, 659.9329543264516, 713.6799999999986, 666.2115148588942, 955.3542381617139, 1333.5860656939476, 753.4500844112977, 1188.8246262828347, 686.1965299875368, 290.82006635822063, 1046.0649586142754, 597.2464779157727, 823.1389427430059, 991.9001626791569, 1026.8646102703985, 903.1842308700321, 205.28396970386638, 547.873708390827, 628.3999999999978, 553.359999999998, 600.5706526555256, 485.42772814101806, 323.42999999999824, 1373.3673138582908, 1227.141379385471, 389.96739430913124, 529.7188261655926, 714.4794784700559, 1773.2989819678855, 1019.4715696872636, 561.9306897500068, 422.0477736809684, 973.4615662013273, 336.24999999999795, 730.1454439177392, 559.6709514747001, 640.8999999999983, 612.4771717183315, 995.9385929556073, 261.3978100304875, 494.2605965562378, 596.0256438034596], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [83.08113943614111, 137.98947471769932, 267.21023249406846, 149.98959291733968, 429.80884135116884, 281.8548880587646, 268.8167045610231, 271.5425170187834, 293.7759802983288, 371.6301808675539, 470.9014091182684, 349.38810913630425, 329.5457850048913, 20.809999999999974, 154.04127952983174, 362.01594568018606, 263.50112987301566, 240.17228339161463, 165.55034232365728, 364.46776343051926, 328.66068687093946, 115.44199305953892, 135.2210180320988, 372.30152390673203, 445.8713202476139, 5.960000000000002, 313.1925232948914, 372.8051141229256, 76.8389484301088, 537.0062741555779, 461.28824085293377, 186.03603611425964, 315.2074210858399, 5.959999999999974, 256.0335377074821, 331.76522049610145, 7.981607828745645, 234.27756538820037, 144.14541427330465, 270.5067268746614, 419.31651586024736, 252.79263537098527, 309.9524167583224, 39.61999999999999, 2.0000000000000013, 133.54744588076343, 118.82000000000025, 299.0788298433338, 414.2871524706754, 78.09927677067097, 115.01018955373236, 105.31630729540886, 378.98268552249186, 133.35115484927599, 219.31452341465695, 216.85178952270056, 218.34169764453844, 102.82189917200216, 101.8290881616789, 456.6749954265844, 426.5089345255363, 306.97664912013624, 347.11093633934763, 136.92699619138813, 343.10286804794447, 145.8994653646845, 195.67350690389722, 171.672321195309, 353.8407575092764, 285.6424788327468, 473.4633171140901, 502.4556639060511, 325.6541387208085, 286.02226372599574, 320.8572970062904, 360.1479108739385, 196.15696479471515, 239.488036652008, 101.9900000000005, 164.33511473881381, 473.68767380500486, 401.34601972316733, 348.38579641472927, 58.42999999999997, 244.58175056272546, 341.86839036810613, 539.4511288916443, 172.35737640465712, 392.8713732818518, 342.1637686852444, 169.22298736716675, 442.34729189841397, 16.85000000000011, 152.9870937097313, 183.55429073316242, 218.48218071657328, 87.72365742684988, 280.4390458555099, 273.6726743341808, 188.3815400251916, 310.0549750861778, 70.31000000000003, 369.1194724494251, 95.49768944700476, 199.46722298436794, 40.391093345460746, 397.4904822923269, 435.96397026616995, 492.1107869405687, 465.3755159293736, 84.0156816252322, 195.42127454839533, 235.06560132295846, 217.4521534515595, 191.33314989743772, 338.14888467794435, 332.73426877349937, 460.3307426002673, 159.50723279596002, 405.12667048156, 477.71075415968096, 2.0000000000000013, 189.54517181126002, 176.24, 296.0816826859566, 237.62554093923168, 236.74178983030959, 42.60805456366836, 122.2125743164995, 457.4662616459531, 199.01, 224.59434369638973, 181.60886120678782, 211.77850377471077, 110.60387883115638, 378.09780196781713, 416.38914755988793, 342.0031866239509, 216.83082749353065, 2.0000000000000013, 29.0632056591962, 236.45573088383807, 102.16618612084632, 260.3827030179736], "policy_predator_policy_reward": [63.92643977542069, 154.92428041012053, 45.47040708265904, 150.75976750593068, 160.24511194123468, 335.65115864883103, 287.92748298121654, 220.11329543897722, 413.80285572271544, 428.1722524762427, 218.29100533389519, 233.44813187573925, 26.96100639448265, 73.79359808519709, 106.39546148874001, 10.116120419554298, 89.7443097733525, 70.77392904994859, 14.519829899221744, 25.820041953943786, 83.99800694046132, 164.80931312906046, 304.0984760932681, 22.098981967901885, 88.37552521065967, 445.8869130575798, 83.99747670510843, 132.50488587707426, 0.592770149262007, 118.88724805049692, 225.0246513598442, 21.831071672961393, 23.884003881121465, 192.11945704734154, 62.18627940164028, 477.18496239477514, 122.82243461179868, -1.4578371230973177, 250.89951335012313, 180.81516578514126, 261.08348413975216, 6.426081039463087, 42.79287754425195, 72.47991077952273, 78.15368101506593, 0.9006609285831049, 67.47021321859513, 100.59397854556741, 98.1928475293242, 8.730723229329609, 76.31540157166936, 4.549323419178085, 113.54638235197561, 102.55576392986438, 139.43821047729904, 52.855476585341975, -7.441697644539177, 83.64810082799828, 6.940911838321871, 273.8050045734152, 138.23982469061494, 197.83524865217154, 53.64929283620817, 122.24572895950799, 16.19817398343449, 208.47949260393526, 148.5997062833196, 150.2659804763694, 242.34204564023892, 73.52895617945181, 234.02833321299698, 123.63875146081007, 127.65687990676648, 14.116802057727952, 196.95381949326628, 310.86559890933967, 58.57498601625825, 191.97654252455584, 21.198811567241762, 3.2961400521658897, 115.06442730169871, 55.96683778440454, 56.273455772090465, 134.15722572895294, 103.38410028685982, 133.30470152531493, 95.03335969322411, 185.05829768963196, 122.24308441014945, 169.58638389315303, 113.69401868720963, 177.91993291724137, 33.90209128103196, 1.5447847131045362, 3.4579304425015085, 142.37930649858964, 22.929413663839487, 237.30788305380037, 67.89845997480842, 23.40732566581817, 25.79336469681818, 194.41231287252984, 3.8104741563221456, 17.000092088268296, 42.43890665453924, 41.132777015631554, 297.406070733248, 242.5067905665456, 115.26310642845482, 154.39197008707407, 16.856060901042227, 93.67437723446415, 10.698018069075623, 66.50305332199918, 168.631032512068, 16.36641138260594, 478.2497106064112, 501.98425998770824, 118.7494051839087, 336.08826122583486, 10.774387830883878, 71.44554775944323, 13.042452972065718, 43.22014889764258, 247.1270324988295, 192.62731007730952, 22.66821016969038, 34.23194543633128, 150.12001294523375, 0.3465950100534947, 79.18148744738183, 56.8851203309286, 134.51149622528803, 113.001138793212, 81.15031540686142, 42.62517551249912, 188.78443072372232, 48.761828048045224, -0.9621899695107459, 43.529172506468996, 52.48961773834996, 176.2520422748551, 67.6828346691131, 165.79391999552865]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0120940479064322, "mean_inference_ms": 2.6928721198447914, "mean_action_processing_ms": 0.4277939187295965, "mean_env_wait_ms": 0.3967850986988904, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007078382703993056, "StateBufferConnector_ms": 0.003214346037970649, "ViewRequirementAgentConnector_ms": 0.15246536996629503}, "num_episodes": 18, "episode_return_max": 1773.2989819678855, "episode_return_min": 205.28396970386638, "episode_return_mean": 740.0745813913175, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 271.1131954847864, "num_env_steps_trained_throughput_per_sec": 271.1131954847864, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 14675.143, "restore_workers_time_ms": 0.089, "training_step_time_ms": 14675.0, "sample_time_ms": 2508.361, "learn_time_ms": 12136.205, "learn_throughput": 329.592, "synch_weights_time_ms": 27.329}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "479e5_00000", "date": "2024-08-16_11-27-44", "timestamp": 1723787864, "time_this_iter_s": 14.770127058029175, "time_total_s": 58.92540693283081, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a789b8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 58.92540693283081, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 60.72857142857143, "ram_util_percent": 82.58571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1839440986908303, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.410562683539416, "policy_loss": -0.009889422963427567, "vf_loss": 6.419317392318968, "vf_explained_var": 0.002267491029053138, "kl": 0.0113471217043466, "entropy": 1.5608677046639579, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.63122379086005, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.972665929037428, "policy_loss": -0.00855723526316483, "vf_loss": 8.979573490001536, "vf_explained_var": 0.019521678030175505, "kl": 0.016496945681487893, "entropy": 1.5383511654283635, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 1773.2989819678855, "episode_reward_min": 155.556375514384, "episode_reward_mean": 774.0465758246204, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": 2.0000000000000013, "predator_policy": -7.441697644539177}, "policy_reward_max": {"prey_policy": 569.921344712396, "predator_policy": 523.7240453126414}, "policy_reward_mean": {"prey_policy": 260.7305436682973, "predator_policy": 126.29274424401346}, "custom_metrics": {}, "hist_stats": {"episode_reward": [439.92133433938045, 613.4299999999978, 1207.5599999999986, 1048.3999999999987, 1507.381269364841, 1272.0286554642075, 451.1103894845694, 632.5688071183101, 664.1916520879302, 570.3579776073409, 692.9100000000001, 833.7199999999984, 986.093758515852, 902.4999999999995, 733.3252407854438, 894.179999999998, 537.1708820143007, 1127.169999999999, 363.6237707056459, 846.3668202832298, 939.618716410448, 464.84520508209573, 214.6017878244104, 585.9630216074952, 599.3099999999981, 301.1912218399857, 728.4359866536065, 628.4599999999979, 397.36999999999796, 839.2499999999982, 1069.5606569884578, 659.9329543264516, 713.6799999999986, 666.2115148588942, 955.3542381617139, 1333.5860656939476, 753.4500844112977, 1188.8246262828347, 686.1965299875368, 290.82006635822063, 1046.0649586142754, 597.2464779157727, 823.1389427430059, 991.9001626791569, 1026.8646102703985, 903.1842308700321, 205.28396970386638, 547.873708390827, 628.3999999999978, 553.359999999998, 600.5706526555256, 485.42772814101806, 323.42999999999824, 1373.3673138582908, 1227.141379385471, 389.96739430913124, 529.7188261655926, 714.4794784700559, 1773.2989819678855, 1019.4715696872636, 561.9306897500068, 422.0477736809684, 973.4615662013273, 336.24999999999795, 730.1454439177392, 559.6709514747001, 640.8999999999983, 612.4771717183315, 995.9385929556073, 261.3978100304875, 494.2605965562378, 596.0256438034596, 720.3456370794653, 1402.6865686385327, 1321.8672685995311, 899.3538152281043, 952.5679487212916, 673.199999999998, 1407.1874653530515, 887.460259043669, 1169.8659799498791, 606.4635673240683, 469.2811808462114, 1123.0293899480012, 512.5196082616103, 155.556375514384, 754.1295207991045, 614.7663551926214, 1281.0717037097081, 1567.944001546976, 754.9215606813516, 508.1876143149367, 1539.1216951639728, 464.3199999999997, 1092.3233674627584, 191.5496269290999, 775.5147405279142, 543.509999999998, 956.4958956263424], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [83.08113943614111, 137.98947471769932, 267.21023249406846, 149.98959291733968, 429.80884135116884, 281.8548880587646, 268.8167045610231, 271.5425170187834, 293.7759802983288, 371.6301808675539, 470.9014091182684, 349.38810913630425, 329.5457850048913, 20.809999999999974, 154.04127952983174, 362.01594568018606, 263.50112987301566, 240.17228339161463, 165.55034232365728, 364.46776343051926, 328.66068687093946, 115.44199305953892, 135.2210180320988, 372.30152390673203, 445.8713202476139, 5.960000000000002, 313.1925232948914, 372.8051141229256, 76.8389484301088, 537.0062741555779, 461.28824085293377, 186.03603611425964, 315.2074210858399, 5.959999999999974, 256.0335377074821, 331.76522049610145, 7.981607828745645, 234.27756538820037, 144.14541427330465, 270.5067268746614, 419.31651586024736, 252.79263537098527, 309.9524167583224, 39.61999999999999, 2.0000000000000013, 133.54744588076343, 118.82000000000025, 299.0788298433338, 414.2871524706754, 78.09927677067097, 115.01018955373236, 105.31630729540886, 378.98268552249186, 133.35115484927599, 219.31452341465695, 216.85178952270056, 218.34169764453844, 102.82189917200216, 101.8290881616789, 456.6749954265844, 426.5089345255363, 306.97664912013624, 347.11093633934763, 136.92699619138813, 343.10286804794447, 145.8994653646845, 195.67350690389722, 171.672321195309, 353.8407575092764, 285.6424788327468, 473.4633171140901, 502.4556639060511, 325.6541387208085, 286.02226372599574, 320.8572970062904, 360.1479108739385, 196.15696479471515, 239.488036652008, 101.9900000000005, 164.33511473881381, 473.68767380500486, 401.34601972316733, 348.38579641472927, 58.42999999999997, 244.58175056272546, 341.86839036810613, 539.4511288916443, 172.35737640465712, 392.8713732818518, 342.1637686852444, 169.22298736716675, 442.34729189841397, 16.85000000000011, 152.9870937097313, 183.55429073316242, 218.48218071657328, 87.72365742684988, 280.4390458555099, 273.6726743341808, 188.3815400251916, 310.0549750861778, 70.31000000000003, 369.1194724494251, 95.49768944700476, 199.46722298436794, 40.391093345460746, 397.4904822923269, 435.96397026616995, 492.1107869405687, 465.3755159293736, 84.0156816252322, 195.42127454839533, 235.06560132295846, 217.4521534515595, 191.33314989743772, 338.14888467794435, 332.73426877349937, 460.3307426002673, 159.50723279596002, 405.12667048156, 477.71075415968096, 2.0000000000000013, 189.54517181126002, 176.24, 296.0816826859566, 237.62554093923168, 236.74178983030959, 42.60805456366836, 122.2125743164995, 457.4662616459531, 199.01, 224.59434369638973, 181.60886120678782, 211.77850377471077, 110.60387883115638, 378.09780196781713, 416.38914755988793, 342.0031866239509, 216.83082749353065, 2.0000000000000013, 29.0632056591962, 236.45573088383807, 102.16618612084632, 260.3827030179736, 236.60054428501275, 290.4067054685493, 398.8570433038092, 522.4133589391096, 487.82663901200317, 500.6174274277503, 334.18019749391595, 322.0524713609489, 351.3127888683907, 309.643127326731, 316.3182952583364, 223.64304776870608, 195.03771835405638, 331.5708048703038, 401.0141006022415, 76.66954263523809, 428.8754302381807, 343.349938694913, 333.9341434719787, 156.2357746124665, 332.7226579274785, 2.98999999999998, 496.03172638917164, 344.76240334356817, 185.4935753315842, 53.479999999999976, 149.49375475401263, 5.960000000000001, 19.820000000000004, 471.6947429382192, 279.4312860520628, 223.8716486336263, 359.76006949313324, 119.57317279264826, 473.8264557619137, 569.921344712396, 351.4911284896477, 246.93566914664822, 199.86924094334069, 206.74293547785356, 478.75846655200456, 470.07692546746483, 250.14724755345122, 208.1821701995099, 436.4694852859301, 409.62621739858406, 37.63999999999993, 100.68351323860355, 87.76034405174683, 371.9999675641248, 102.04482888517002, 344.4274203103148, 325.611777697072, 381.32225699852313], "policy_predator_policy_reward": [63.92643977542069, 154.92428041012053, 45.47040708265904, 150.75976750593068, 160.24511194123468, 335.65115864883103, 287.92748298121654, 220.11329543897722, 413.80285572271544, 428.1722524762427, 218.29100533389519, 233.44813187573925, 26.96100639448265, 73.79359808519709, 106.39546148874001, 10.116120419554298, 89.7443097733525, 70.77392904994859, 14.519829899221744, 25.820041953943786, 83.99800694046132, 164.80931312906046, 304.0984760932681, 22.098981967901885, 88.37552521065967, 445.8869130575798, 83.99747670510843, 132.50488587707426, 0.592770149262007, 118.88724805049692, 225.0246513598442, 21.831071672961393, 23.884003881121465, 192.11945704734154, 62.18627940164028, 477.18496239477514, 122.82243461179868, -1.4578371230973177, 250.89951335012313, 180.81516578514126, 261.08348413975216, 6.426081039463087, 42.79287754425195, 72.47991077952273, 78.15368101506593, 0.9006609285831049, 67.47021321859513, 100.59397854556741, 98.1928475293242, 8.730723229329609, 76.31540157166936, 4.549323419178085, 113.54638235197561, 102.55576392986438, 139.43821047729904, 52.855476585341975, -7.441697644539177, 83.64810082799828, 6.940911838321871, 273.8050045734152, 138.23982469061494, 197.83524865217154, 53.64929283620817, 122.24572895950799, 16.19817398343449, 208.47949260393526, 148.5997062833196, 150.2659804763694, 242.34204564023892, 73.52895617945181, 234.02833321299698, 123.63875146081007, 127.65687990676648, 14.116802057727952, 196.95381949326628, 310.86559890933967, 58.57498601625825, 191.97654252455584, 21.198811567241762, 3.2961400521658897, 115.06442730169871, 55.96683778440454, 56.273455772090465, 134.15722572895294, 103.38410028685982, 133.30470152531493, 95.03335969322411, 185.05829768963196, 122.24308441014945, 169.58638389315303, 113.69401868720963, 177.91993291724137, 33.90209128103196, 1.5447847131045362, 3.4579304425015085, 142.37930649858964, 22.929413663839487, 237.30788305380037, 67.89845997480842, 23.40732566581817, 25.79336469681818, 194.41231287252984, 3.8104741563221456, 17.000092088268296, 42.43890665453924, 41.132777015631554, 297.406070733248, 242.5067905665456, 115.26310642845482, 154.39197008707407, 16.856060901042227, 93.67437723446415, 10.698018069075623, 66.50305332199918, 168.631032512068, 16.36641138260594, 478.2497106064112, 501.98425998770824, 118.7494051839087, 336.08826122583486, 10.774387830883878, 71.44554775944323, 13.042452972065718, 43.22014889764258, 247.1270324988295, 192.62731007730952, 22.66821016969038, 34.23194543633128, 150.12001294523375, 0.3465950100534947, 79.18148744738183, 56.8851203309286, 134.51149622528803, 113.001138793212, 81.15031540686142, 42.62517551249912, 188.78443072372232, 48.761828048045224, -0.9621899695107459, 43.529172506468996, 52.48961773834996, 176.2520422748551, 67.6828346691131, 165.79391999552865, 14.487576829009019, 178.8508104968959, 200.30673835840057, 281.1094280372137, 39.94574632403911, 293.47745583573777, 239.6871854531231, 3.433960920116201, 174.56218654758405, 117.04984597858608, 24.766952231292777, 108.47170474166332, 523.7240453126414, 356.85489681605105, 127.0427238600123, 282.73389194617897, 191.7307282751984, 205.90988274158798, -7.335574319487764, 123.62922355911095, 18.65629677757914, 114.91222614115551, 52.873158463906094, 229.36210175135597, 125.17625897559468, 148.3697739544325, -2.0917483468039495, 2.194369107175037, 97.81761772293679, 164.79716013794987, 24.29822221913149, 87.16519828780064, 329.875989577734, 471.8624718461931, 267.83723574079244, 256.35896533187497, 12.445722042893578, 144.0490410021623, 54.41923378174633, 47.15620411199802, 309.26404855405815, 281.0222545904453, 0.0, 5.990582247038581, 42.907327555920205, 203.32033722232464, 28.328553071025993, 24.89756061946957, 8.58861003854189, 307.1658188735018, 29.29517111483022, 67.7425796896842, 192.05545880238984, 57.50640212835744]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0634651674194924, "mean_inference_ms": 2.8567242871198752, "mean_action_processing_ms": 0.44661519037095837, "mean_env_wait_ms": 0.4142891678272448, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007220952197758838, "StateBufferConnector_ms": 0.0032735593391187263, "ViewRequirementAgentConnector_ms": 0.1558798732179584}, "num_episodes": 27, "episode_return_max": 1773.2989819678855, "episode_return_min": 155.556375514384, "episode_return_mean": 774.0465758246204, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 262.1136808190765, "num_env_steps_trained_throughput_per_sec": 262.1136808190765, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 14792.228, "restore_workers_time_ms": 0.074, "training_step_time_ms": 14792.103, "sample_time_ms": 2634.966, "learn_time_ms": 12128.74, "learn_throughput": 329.795, "synch_weights_time_ms": 25.27}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "479e5_00000", "date": "2024-08-16_11-27-59", "timestamp": 1723787879, "time_this_iter_s": 15.337454080581665, "time_total_s": 74.26286101341248, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a789bb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 74.26286101341248, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 62.82272727272727, "ram_util_percent": 81.97727272727273}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.248984408410138, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.742752912814025, "policy_loss": -0.009535964375002082, "vf_loss": 7.751039401059428, "vf_explained_var": 0.0015477057802614081, "kl": 0.012494876848938598, "entropy": 1.5262054393531153, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.590783271587715, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.141483596519187, "policy_loss": -0.00800051896354903, "vf_loss": 9.148082860310872, "vf_explained_var": 0.03926841944613785, "kl": 0.014012377467426472, "entropy": 1.5251097818531056, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 1773.2989819678855, "episode_reward_min": 155.556375514384, "episode_reward_mean": 828.7834713819393, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 2.0000000000000013, "predator_policy": -7.441697644539177}, "policy_reward_max": {"prey_policy": 589.7863422505105, "predator_policy": 610.7246189176169}, "policy_reward_mean": {"prey_policy": 277.74323377634374, "predator_policy": 136.64850191462625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1127.169999999999, 363.6237707056459, 846.3668202832298, 939.618716410448, 464.84520508209573, 214.6017878244104, 585.9630216074952, 599.3099999999981, 301.1912218399857, 728.4359866536065, 628.4599999999979, 397.36999999999796, 839.2499999999982, 1069.5606569884578, 659.9329543264516, 713.6799999999986, 666.2115148588942, 955.3542381617139, 1333.5860656939476, 753.4500844112977, 1188.8246262828347, 686.1965299875368, 290.82006635822063, 1046.0649586142754, 597.2464779157727, 823.1389427430059, 991.9001626791569, 1026.8646102703985, 903.1842308700321, 205.28396970386638, 547.873708390827, 628.3999999999978, 553.359999999998, 600.5706526555256, 485.42772814101806, 323.42999999999824, 1373.3673138582908, 1227.141379385471, 389.96739430913124, 529.7188261655926, 714.4794784700559, 1773.2989819678855, 1019.4715696872636, 561.9306897500068, 422.0477736809684, 973.4615662013273, 336.24999999999795, 730.1454439177392, 559.6709514747001, 640.8999999999983, 612.4771717183315, 995.9385929556073, 261.3978100304875, 494.2605965562378, 596.0256438034596, 720.3456370794653, 1402.6865686385327, 1321.8672685995311, 899.3538152281043, 952.5679487212916, 673.199999999998, 1407.1874653530515, 887.460259043669, 1169.8659799498791, 606.4635673240683, 469.2811808462114, 1123.0293899480012, 512.5196082616103, 155.556375514384, 754.1295207991045, 614.7663551926214, 1281.0717037097081, 1567.944001546976, 754.9215606813516, 508.1876143149367, 1539.1216951639728, 464.3199999999997, 1092.3233674627584, 191.5496269290999, 775.5147405279142, 543.509999999998, 956.4958956263424, 1764.2013397225276, 1660.130744961304, 1102.1428820041583, 1070.6915837054405, 1144.3056210935965, 740.6788302211321, 1076.67487533332, 1308.7290787905144, 1228.39146382171, 1379.5791828327024, 896.4499999999991, 652.8445693792532, 1096.7602911604397, 1136.8454545750023, 1643.6985402079918, 807.9516036881499, 881.007495436631, 643.5025414047944], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [256.0335377074821, 331.76522049610145, 7.981607828745645, 234.27756538820037, 144.14541427330465, 270.5067268746614, 419.31651586024736, 252.79263537098527, 309.9524167583224, 39.61999999999999, 2.0000000000000013, 133.54744588076343, 118.82000000000025, 299.0788298433338, 414.2871524706754, 78.09927677067097, 115.01018955373236, 105.31630729540886, 378.98268552249186, 133.35115484927599, 219.31452341465695, 216.85178952270056, 218.34169764453844, 102.82189917200216, 101.8290881616789, 456.6749954265844, 426.5089345255363, 306.97664912013624, 347.11093633934763, 136.92699619138813, 343.10286804794447, 145.8994653646845, 195.67350690389722, 171.672321195309, 353.8407575092764, 285.6424788327468, 473.4633171140901, 502.4556639060511, 325.6541387208085, 286.02226372599574, 320.8572970062904, 360.1479108739385, 196.15696479471515, 239.488036652008, 101.9900000000005, 164.33511473881381, 473.68767380500486, 401.34601972316733, 348.38579641472927, 58.42999999999997, 244.58175056272546, 341.86839036810613, 539.4511288916443, 172.35737640465712, 392.8713732818518, 342.1637686852444, 169.22298736716675, 442.34729189841397, 16.85000000000011, 152.9870937097313, 183.55429073316242, 218.48218071657328, 87.72365742684988, 280.4390458555099, 273.6726743341808, 188.3815400251916, 310.0549750861778, 70.31000000000003, 369.1194724494251, 95.49768944700476, 199.46722298436794, 40.391093345460746, 397.4904822923269, 435.96397026616995, 492.1107869405687, 465.3755159293736, 84.0156816252322, 195.42127454839533, 235.06560132295846, 217.4521534515595, 191.33314989743772, 338.14888467794435, 332.73426877349937, 460.3307426002673, 159.50723279596002, 405.12667048156, 477.71075415968096, 2.0000000000000013, 189.54517181126002, 176.24, 296.0816826859566, 237.62554093923168, 236.74178983030959, 42.60805456366836, 122.2125743164995, 457.4662616459531, 199.01, 224.59434369638973, 181.60886120678782, 211.77850377471077, 110.60387883115638, 378.09780196781713, 416.38914755988793, 342.0031866239509, 216.83082749353065, 2.0000000000000013, 29.0632056591962, 236.45573088383807, 102.16618612084632, 260.3827030179736, 236.60054428501275, 290.4067054685493, 398.8570433038092, 522.4133589391096, 487.82663901200317, 500.6174274277503, 334.18019749391595, 322.0524713609489, 351.3127888683907, 309.643127326731, 316.3182952583364, 223.64304776870608, 195.03771835405638, 331.5708048703038, 401.0141006022415, 76.66954263523809, 428.8754302381807, 343.349938694913, 333.9341434719787, 156.2357746124665, 332.7226579274785, 2.98999999999998, 496.03172638917164, 344.76240334356817, 185.4935753315842, 53.479999999999976, 149.49375475401263, 5.960000000000001, 19.820000000000004, 471.6947429382192, 279.4312860520628, 223.8716486336263, 359.76006949313324, 119.57317279264826, 473.8264557619137, 569.921344712396, 351.4911284896477, 246.93566914664822, 199.86924094334069, 206.74293547785356, 478.75846655200456, 470.07692546746483, 250.14724755345122, 208.1821701995099, 436.4694852859301, 409.62621739858406, 37.63999999999993, 100.68351323860355, 87.76034405174683, 371.9999675641248, 102.04482888517002, 344.4274203103148, 325.611777697072, 381.32225699852313, 484.4554240499457, 536.8920557476764, 337.78309792483697, 290.653164590918, 323.27590122188354, 296.19047717722844, 308.13972413633115, 327.6383241502625, 565.2293677415612, 252.2029564606852, 66.34999999999997, 518.3683977626639, 487.1008670928031, 222.12648603402423, 476.2438214770311, 589.7863422505105, 472.91720637430984, 406.66303907461526, 446.0493902488982, 431.12222709637973, 407.03759841641585, 231.52538341697527, 145.72457175165286, 310.10180218983373, 318.18223184816287, 341.18891946935156, 326.2656728559866, 377.8411132913711, 545.814678944143, 401.4590178454854, 138.11457558468712, 428.07639640276403, 297.4648300619616, 266.67215803879714, 272.05767746025754, 225.16891013810735], "policy_predator_policy_reward": [62.18627940164028, 477.18496239477514, 122.82243461179868, -1.4578371230973177, 250.89951335012313, 180.81516578514126, 261.08348413975216, 6.426081039463087, 42.79287754425195, 72.47991077952273, 78.15368101506593, 0.9006609285831049, 67.47021321859513, 100.59397854556741, 98.1928475293242, 8.730723229329609, 76.31540157166936, 4.549323419178085, 113.54638235197561, 102.55576392986438, 139.43821047729904, 52.855476585341975, -7.441697644539177, 83.64810082799828, 6.940911838321871, 273.8050045734152, 138.23982469061494, 197.83524865217154, 53.64929283620817, 122.24572895950799, 16.19817398343449, 208.47949260393526, 148.5997062833196, 150.2659804763694, 242.34204564023892, 73.52895617945181, 234.02833321299698, 123.63875146081007, 127.65687990676648, 14.116802057727952, 196.95381949326628, 310.86559890933967, 58.57498601625825, 191.97654252455584, 21.198811567241762, 3.2961400521658897, 115.06442730169871, 55.96683778440454, 56.273455772090465, 134.15722572895294, 103.38410028685982, 133.30470152531493, 95.03335969322411, 185.05829768963196, 122.24308441014945, 169.58638389315303, 113.69401868720963, 177.91993291724137, 33.90209128103196, 1.5447847131045362, 3.4579304425015085, 142.37930649858964, 22.929413663839487, 237.30788305380037, 67.89845997480842, 23.40732566581817, 25.79336469681818, 194.41231287252984, 3.8104741563221456, 17.000092088268296, 42.43890665453924, 41.132777015631554, 297.406070733248, 242.5067905665456, 115.26310642845482, 154.39197008707407, 16.856060901042227, 93.67437723446415, 10.698018069075623, 66.50305332199918, 168.631032512068, 16.36641138260594, 478.2497106064112, 501.98425998770824, 118.7494051839087, 336.08826122583486, 10.774387830883878, 71.44554775944323, 13.042452972065718, 43.22014889764258, 247.1270324988295, 192.62731007730952, 22.66821016969038, 34.23194543633128, 150.12001294523375, 0.3465950100534947, 79.18148744738183, 56.8851203309286, 134.51149622528803, 113.001138793212, 81.15031540686142, 42.62517551249912, 188.78443072372232, 48.761828048045224, -0.9621899695107459, 43.529172506468996, 52.48961773834996, 176.2520422748551, 67.6828346691131, 165.79391999552865, 14.487576829009019, 178.8508104968959, 200.30673835840057, 281.1094280372137, 39.94574632403911, 293.47745583573777, 239.6871854531231, 3.433960920116201, 174.56218654758405, 117.04984597858608, 24.766952231292777, 108.47170474166332, 523.7240453126414, 356.85489681605105, 127.0427238600123, 282.73389194617897, 191.7307282751984, 205.90988274158798, -7.335574319487764, 123.62922355911095, 18.65629677757914, 114.91222614115551, 52.873158463906094, 229.36210175135597, 125.17625897559468, 148.3697739544325, -2.0917483468039495, 2.194369107175037, 97.81761772293679, 164.79716013794987, 24.29822221913149, 87.16519828780064, 329.875989577734, 471.8624718461931, 267.83723574079244, 256.35896533187497, 12.445722042893578, 144.0490410021623, 54.41923378174633, 47.15620411199802, 309.26404855405815, 281.0222545904453, 0.0, 5.990582247038581, 42.907327555920205, 203.32033722232464, 28.328553071025993, 24.89756061946957, 8.58861003854189, 307.1658188735018, 29.29517111483022, 67.7425796896842, 192.05545880238984, 57.50640212835744, 232.1918403646844, 510.6620195602218, 610.7246189176169, 420.9698635279328, 264.56180452017855, 218.1146990848682, 175.78493314153766, 259.1286022773089, 138.30180638154903, 188.57149050980115, 96.86130147292565, 59.099130985543326, 126.42055606407833, 241.02696614241523, 124.61742373297861, 118.08149132999465, 263.170764149163, 85.64045422362172, 380.1975115020069, 122.2100539854168, 172.25240158358392, 85.63461658302415, 76.07187305015083, 120.94632238761628, 311.3082953045726, 126.0808445383527, 326.2419274950919, 106.49674093255275, 241.97190576671744, 454.45293765164706, 123.66566726191915, 118.09496443877981, 206.44067427759325, 110.42983305827991, 111.40239055268776, 34.873563253741985]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.125947573965914, "mean_inference_ms": 3.061697837883587, "mean_action_processing_ms": 0.4737768157419658, "mean_env_wait_ms": 0.44124283829137867, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006972908973693848, "StateBufferConnector_ms": 0.012900471687316895, "ViewRequirementAgentConnector_ms": 0.1606159210205078}, "num_episodes": 18, "episode_return_max": 1773.2989819678855, "episode_return_min": 155.556375514384, "episode_return_mean": 828.7834713819393, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 281.48252219387376, "num_env_steps_trained_throughput_per_sec": 281.48252219387376, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 14695.273, "restore_workers_time_ms": 0.067, "training_step_time_ms": 14695.153, "sample_time_ms": 2529.419, "learn_time_ms": 12135.168, "learn_throughput": 329.62, "synch_weights_time_ms": 27.642}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "479e5_00000", "date": "2024-08-16_11-28-14", "timestamp": 1723787894, "time_this_iter_s": 14.256939888000488, "time_total_s": 88.51980090141296, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7884e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 88.51980090141296, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 60.21, "ram_util_percent": 81.54499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0521638532006552, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.210686622094856, "policy_loss": -0.009180964312944857, "vf_loss": 8.218790042968024, "vf_explained_var": -0.0007033601955131248, "kl": 0.010775433607615218, "entropy": 1.540032173023022, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4026421567750356, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.466644111512199, "policy_loss": -0.005644698768592977, "vf_loss": 9.471410675149746, "vf_explained_var": 0.026827919167816322, "kl": 0.008781397910042484, "entropy": 1.4873017867406209, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 1847.6297324737673, "episode_reward_min": 155.556375514384, "episode_reward_mean": 924.351453693782, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 2.0000000000000013, "predator_policy": -7.335574319487764}, "policy_reward_max": {"prey_policy": 619.7642804194087, "predator_policy": 610.7246189176169}, "policy_reward_mean": {"prey_policy": 305.1173524617384, "predator_policy": 157.05837438515294}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1333.5860656939476, 753.4500844112977, 1188.8246262828347, 686.1965299875368, 290.82006635822063, 1046.0649586142754, 597.2464779157727, 823.1389427430059, 991.9001626791569, 1026.8646102703985, 903.1842308700321, 205.28396970386638, 547.873708390827, 628.3999999999978, 553.359999999998, 600.5706526555256, 485.42772814101806, 323.42999999999824, 1373.3673138582908, 1227.141379385471, 389.96739430913124, 529.7188261655926, 714.4794784700559, 1773.2989819678855, 1019.4715696872636, 561.9306897500068, 422.0477736809684, 973.4615662013273, 336.24999999999795, 730.1454439177392, 559.6709514747001, 640.8999999999983, 612.4771717183315, 995.9385929556073, 261.3978100304875, 494.2605965562378, 596.0256438034596, 720.3456370794653, 1402.6865686385327, 1321.8672685995311, 899.3538152281043, 952.5679487212916, 673.199999999998, 1407.1874653530515, 887.460259043669, 1169.8659799498791, 606.4635673240683, 469.2811808462114, 1123.0293899480012, 512.5196082616103, 155.556375514384, 754.1295207991045, 614.7663551926214, 1281.0717037097081, 1567.944001546976, 754.9215606813516, 508.1876143149367, 1539.1216951639728, 464.3199999999997, 1092.3233674627584, 191.5496269290999, 775.5147405279142, 543.509999999998, 956.4958956263424, 1764.2013397225276, 1660.130744961304, 1102.1428820041583, 1070.6915837054405, 1144.3056210935965, 740.6788302211321, 1076.67487533332, 1308.7290787905144, 1228.39146382171, 1379.5791828327024, 896.4499999999991, 652.8445693792532, 1096.7602911604397, 1136.8454545750023, 1643.6985402079918, 807.9516036881499, 881.007495436631, 643.5025414047944, 1560.4198864638688, 1179.4506265283949, 1308.2319213401759, 1339.2597781715726, 1039.189155859038, 1040.5599999999986, 1515.887594948416, 806.755296560101, 1049.931600648412, 982.5104394515463, 1061.3342386732784, 818.7318520014239, 1847.6297324737673, 836.8994011253894, 876.202886603912, 1393.3004150312204, 1417.7236263523712, 1583.725673693803], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [473.4633171140901, 502.4556639060511, 325.6541387208085, 286.02226372599574, 320.8572970062904, 360.1479108739385, 196.15696479471515, 239.488036652008, 101.9900000000005, 164.33511473881381, 473.68767380500486, 401.34601972316733, 348.38579641472927, 58.42999999999997, 244.58175056272546, 341.86839036810613, 539.4511288916443, 172.35737640465712, 392.8713732818518, 342.1637686852444, 169.22298736716675, 442.34729189841397, 16.85000000000011, 152.9870937097313, 183.55429073316242, 218.48218071657328, 87.72365742684988, 280.4390458555099, 273.6726743341808, 188.3815400251916, 310.0549750861778, 70.31000000000003, 369.1194724494251, 95.49768944700476, 199.46722298436794, 40.391093345460746, 397.4904822923269, 435.96397026616995, 492.1107869405687, 465.3755159293736, 84.0156816252322, 195.42127454839533, 235.06560132295846, 217.4521534515595, 191.33314989743772, 338.14888467794435, 332.73426877349937, 460.3307426002673, 159.50723279596002, 405.12667048156, 477.71075415968096, 2.0000000000000013, 189.54517181126002, 176.24, 296.0816826859566, 237.62554093923168, 236.74178983030959, 42.60805456366836, 122.2125743164995, 457.4662616459531, 199.01, 224.59434369638973, 181.60886120678782, 211.77850377471077, 110.60387883115638, 378.09780196781713, 416.38914755988793, 342.0031866239509, 216.83082749353065, 2.0000000000000013, 29.0632056591962, 236.45573088383807, 102.16618612084632, 260.3827030179736, 236.60054428501275, 290.4067054685493, 398.8570433038092, 522.4133589391096, 487.82663901200317, 500.6174274277503, 334.18019749391595, 322.0524713609489, 351.3127888683907, 309.643127326731, 316.3182952583364, 223.64304776870608, 195.03771835405638, 331.5708048703038, 401.0141006022415, 76.66954263523809, 428.8754302381807, 343.349938694913, 333.9341434719787, 156.2357746124665, 332.7226579274785, 2.98999999999998, 496.03172638917164, 344.76240334356817, 185.4935753315842, 53.479999999999976, 149.49375475401263, 5.960000000000001, 19.820000000000004, 471.6947429382192, 279.4312860520628, 223.8716486336263, 359.76006949313324, 119.57317279264826, 473.8264557619137, 569.921344712396, 351.4911284896477, 246.93566914664822, 199.86924094334069, 206.74293547785356, 478.75846655200456, 470.07692546746483, 250.14724755345122, 208.1821701995099, 436.4694852859301, 409.62621739858406, 37.63999999999993, 100.68351323860355, 87.76034405174683, 371.9999675641248, 102.04482888517002, 344.4274203103148, 325.611777697072, 381.32225699852313, 484.4554240499457, 536.8920557476764, 337.78309792483697, 290.653164590918, 323.27590122188354, 296.19047717722844, 308.13972413633115, 327.6383241502625, 565.2293677415612, 252.2029564606852, 66.34999999999997, 518.3683977626639, 487.1008670928031, 222.12648603402423, 476.2438214770311, 589.7863422505105, 472.91720637430984, 406.66303907461526, 446.0493902488982, 431.12222709637973, 407.03759841641585, 231.52538341697527, 145.72457175165286, 310.10180218983373, 318.18223184816287, 341.18891946935156, 326.2656728559866, 377.8411132913711, 545.814678944143, 401.4590178454854, 138.11457558468712, 428.07639640276403, 297.4648300619616, 266.67215803879714, 272.05767746025754, 225.16891013810735, 336.44071623146175, 372.8092532778315, 453.99033588374766, 266.55702183111566, 212.86117624425597, 360.57872355571806, 392.38155960944005, 386.6441493045269, 511.0831960872318, 209.00877165605723, 270.30093797129746, 499.80542151430757, 422.79520107715604, 610.4389088749361, 305.2348570388607, 246.58117486737555, 150.62560232000112, 457.87658483753785, 367.6174509675801, 375.37628890988367, 126.56067097118358, 539.8220368634275, 482.17939843354395, 153.70065101692967, 399.2097897430412, 619.7642804194087, 390.8279289214426, 261.51228204992714, 219.9754699917135, 425.062015583268, 480.35937550247434, 464.9650293508407, 473.5669509547861, 346.8858637150178, 396.29343814562424, 559.2048134728018], "policy_predator_policy_reward": [234.02833321299698, 123.63875146081007, 127.65687990676648, 14.116802057727952, 196.95381949326628, 310.86559890933967, 58.57498601625825, 191.97654252455584, 21.198811567241762, 3.2961400521658897, 115.06442730169871, 55.96683778440454, 56.273455772090465, 134.15722572895294, 103.38410028685982, 133.30470152531493, 95.03335969322411, 185.05829768963196, 122.24308441014945, 169.58638389315303, 113.69401868720963, 177.91993291724137, 33.90209128103196, 1.5447847131045362, 3.4579304425015085, 142.37930649858964, 22.929413663839487, 237.30788305380037, 67.89845997480842, 23.40732566581817, 25.79336469681818, 194.41231287252984, 3.8104741563221456, 17.000092088268296, 42.43890665453924, 41.132777015631554, 297.406070733248, 242.5067905665456, 115.26310642845482, 154.39197008707407, 16.856060901042227, 93.67437723446415, 10.698018069075623, 66.50305332199918, 168.631032512068, 16.36641138260594, 478.2497106064112, 501.98425998770824, 118.7494051839087, 336.08826122583486, 10.774387830883878, 71.44554775944323, 13.042452972065718, 43.22014889764258, 247.1270324988295, 192.62731007730952, 22.66821016969038, 34.23194543633128, 150.12001294523375, 0.3465950100534947, 79.18148744738183, 56.8851203309286, 134.51149622528803, 113.001138793212, 81.15031540686142, 42.62517551249912, 188.78443072372232, 48.761828048045224, -0.9621899695107459, 43.529172506468996, 52.48961773834996, 176.2520422748551, 67.6828346691131, 165.79391999552865, 14.487576829009019, 178.8508104968959, 200.30673835840057, 281.1094280372137, 39.94574632403911, 293.47745583573777, 239.6871854531231, 3.433960920116201, 174.56218654758405, 117.04984597858608, 24.766952231292777, 108.47170474166332, 523.7240453126414, 356.85489681605105, 127.0427238600123, 282.73389194617897, 191.7307282751984, 205.90988274158798, -7.335574319487764, 123.62922355911095, 18.65629677757914, 114.91222614115551, 52.873158463906094, 229.36210175135597, 125.17625897559468, 148.3697739544325, -2.0917483468039495, 2.194369107175037, 97.81761772293679, 164.79716013794987, 24.29822221913149, 87.16519828780064, 329.875989577734, 471.8624718461931, 267.83723574079244, 256.35896533187497, 12.445722042893578, 144.0490410021623, 54.41923378174633, 47.15620411199802, 309.26404855405815, 281.0222545904453, 0.0, 5.990582247038581, 42.907327555920205, 203.32033722232464, 28.328553071025993, 24.89756061946957, 8.58861003854189, 307.1658188735018, 29.29517111483022, 67.7425796896842, 192.05545880238984, 57.50640212835744, 232.1918403646844, 510.6620195602218, 610.7246189176169, 420.9698635279328, 264.56180452017855, 218.1146990848682, 175.78493314153766, 259.1286022773089, 138.30180638154903, 188.57149050980115, 96.86130147292565, 59.099130985543326, 126.42055606407833, 241.02696614241523, 124.61742373297861, 118.08149132999465, 263.170764149163, 85.64045422362172, 380.1975115020069, 122.2100539854168, 172.25240158358392, 85.63461658302415, 76.07187305015083, 120.94632238761628, 311.3082953045726, 126.0808445383527, 326.2419274950919, 106.49674093255275, 241.97190576671744, 454.45293765164706, 123.66566726191915, 118.09496443877981, 206.44067427759325, 110.42983305827991, 111.40239055268776, 34.873563253741985, 491.1936582390238, 359.97625871555243, 372.00963571849536, 86.89363309503682, 138.7251512074284, 596.0668703327741, 384.6925811377966, 175.54148811980852, 86.06746439561081, 233.02972372013966, 255.674578485692, 14.779062028701567, 207.92654854814705, 274.72693644817855, 107.18983843720584, 147.74942621665883, 272.5765431105275, 168.8528703803469, 96.27937583540938, 143.23732373867318, 163.05561576797095, 231.89591507069898, 8.659139907055238, 174.19266264389512, 384.7600284921549, 443.89563381916315, 124.20005005425507, 60.35914009976487, 107.97671696530102, 123.18868406363082, 39.31293885738702, 408.6630713205186, 357.0520078047745, 240.21880387779382, 321.71615298817704, 306.51126908720033]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1423066469729906, "mean_inference_ms": 3.104095852462346, "mean_action_processing_ms": 0.47485515899939257, "mean_env_wait_ms": 0.4425284533816207, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0060405731201171875, "StateBufferConnector_ms": 0.01288902759552002, "ViewRequirementAgentConnector_ms": 0.15406107902526855}, "num_episodes": 18, "episode_return_max": 1847.6297324737673, "episode_return_min": 155.556375514384, "episode_return_mean": 924.351453693782, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 290.22978578681193, "num_env_steps_trained_throughput_per_sec": 290.22978578681193, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 14564.834, "restore_workers_time_ms": 0.06, "training_step_time_ms": 14564.723, "sample_time_ms": 2369.302, "learn_time_ms": 12165.286, "learn_throughput": 328.804, "synch_weights_time_ms": 27.009}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "479e5_00000", "date": "2024-08-16_11-28-28", "timestamp": 1723787908, "time_this_iter_s": 13.861299991607666, "time_total_s": 102.38110089302063, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a789baf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 102.38110089302063, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 62.075, "ram_util_percent": 81.73499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1099040124782178, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.401811311106202, "policy_loss": -0.008973208459084312, "vf_loss": 9.409484836538002, "vf_explained_var": -0.002625667008142623, "kl": 0.012996705093210695, "entropy": 1.5180867907231448, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4819276167917503, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.56195254452014, "policy_loss": -0.00499315140522504, "vf_loss": 9.566138736280815, "vf_explained_var": -0.006100267140322892, "kl": 0.008069450566936818, "entropy": 1.4529788750189323, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 1853.7322749079415, "episode_reward_min": 155.556375514384, "episode_reward_mean": 1061.9268447818615, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 2.0000000000000013, "predator_policy": -7.335574319487764}, "policy_reward_max": {"prey_policy": 649.6570787908902, "predator_policy": 610.7246189176169}, "policy_reward_mean": {"prey_policy": 338.2158065868524, "predator_policy": 192.7476158040785}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1373.3673138582908, 1227.141379385471, 389.96739430913124, 529.7188261655926, 714.4794784700559, 1773.2989819678855, 1019.4715696872636, 561.9306897500068, 422.0477736809684, 973.4615662013273, 336.24999999999795, 730.1454439177392, 559.6709514747001, 640.8999999999983, 612.4771717183315, 995.9385929556073, 261.3978100304875, 494.2605965562378, 596.0256438034596, 720.3456370794653, 1402.6865686385327, 1321.8672685995311, 899.3538152281043, 952.5679487212916, 673.199999999998, 1407.1874653530515, 887.460259043669, 1169.8659799498791, 606.4635673240683, 469.2811808462114, 1123.0293899480012, 512.5196082616103, 155.556375514384, 754.1295207991045, 614.7663551926214, 1281.0717037097081, 1567.944001546976, 754.9215606813516, 508.1876143149367, 1539.1216951639728, 464.3199999999997, 1092.3233674627584, 191.5496269290999, 775.5147405279142, 543.509999999998, 956.4958956263424, 1764.2013397225276, 1660.130744961304, 1102.1428820041583, 1070.6915837054405, 1144.3056210935965, 740.6788302211321, 1076.67487533332, 1308.7290787905144, 1228.39146382171, 1379.5791828327024, 896.4499999999991, 652.8445693792532, 1096.7602911604397, 1136.8454545750023, 1643.6985402079918, 807.9516036881499, 881.007495436631, 643.5025414047944, 1560.4198864638688, 1179.4506265283949, 1308.2319213401759, 1339.2597781715726, 1039.189155859038, 1040.5599999999986, 1515.887594948416, 806.755296560101, 1049.931600648412, 982.5104394515463, 1061.3342386732784, 818.7318520014239, 1847.6297324737673, 836.8994011253894, 876.202886603912, 1393.3004150312204, 1417.7236263523712, 1583.725673693803, 1316.5276085655607, 1714.2515287404956, 983.5622740640952, 1159.203730706597, 1470.68045577321, 1739.4286336476312, 1264.1863841747052, 1853.7322749079415, 1561.5199667042407, 1553.0494486560308, 1220.0326582401683, 1772.1786959105762, 1436.53635491879, 1407.2208522639023, 1486.276452594206, 1695.6842895873292, 1491.4621525125654, 1617.6281615575988], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [397.4904822923269, 435.96397026616995, 492.1107869405687, 465.3755159293736, 84.0156816252322, 195.42127454839533, 235.06560132295846, 217.4521534515595, 191.33314989743772, 338.14888467794435, 332.73426877349937, 460.3307426002673, 159.50723279596002, 405.12667048156, 477.71075415968096, 2.0000000000000013, 189.54517181126002, 176.24, 296.0816826859566, 237.62554093923168, 236.74178983030959, 42.60805456366836, 122.2125743164995, 457.4662616459531, 199.01, 224.59434369638973, 181.60886120678782, 211.77850377471077, 110.60387883115638, 378.09780196781713, 416.38914755988793, 342.0031866239509, 216.83082749353065, 2.0000000000000013, 29.0632056591962, 236.45573088383807, 102.16618612084632, 260.3827030179736, 236.60054428501275, 290.4067054685493, 398.8570433038092, 522.4133589391096, 487.82663901200317, 500.6174274277503, 334.18019749391595, 322.0524713609489, 351.3127888683907, 309.643127326731, 316.3182952583364, 223.64304776870608, 195.03771835405638, 331.5708048703038, 401.0141006022415, 76.66954263523809, 428.8754302381807, 343.349938694913, 333.9341434719787, 156.2357746124665, 332.7226579274785, 2.98999999999998, 496.03172638917164, 344.76240334356817, 185.4935753315842, 53.479999999999976, 149.49375475401263, 5.960000000000001, 19.820000000000004, 471.6947429382192, 279.4312860520628, 223.8716486336263, 359.76006949313324, 119.57317279264826, 473.8264557619137, 569.921344712396, 351.4911284896477, 246.93566914664822, 199.86924094334069, 206.74293547785356, 478.75846655200456, 470.07692546746483, 250.14724755345122, 208.1821701995099, 436.4694852859301, 409.62621739858406, 37.63999999999993, 100.68351323860355, 87.76034405174683, 371.9999675641248, 102.04482888517002, 344.4274203103148, 325.611777697072, 381.32225699852313, 484.4554240499457, 536.8920557476764, 337.78309792483697, 290.653164590918, 323.27590122188354, 296.19047717722844, 308.13972413633115, 327.6383241502625, 565.2293677415612, 252.2029564606852, 66.34999999999997, 518.3683977626639, 487.1008670928031, 222.12648603402423, 476.2438214770311, 589.7863422505105, 472.91720637430984, 406.66303907461526, 446.0493902488982, 431.12222709637973, 407.03759841641585, 231.52538341697527, 145.72457175165286, 310.10180218983373, 318.18223184816287, 341.18891946935156, 326.2656728559866, 377.8411132913711, 545.814678944143, 401.4590178454854, 138.11457558468712, 428.07639640276403, 297.4648300619616, 266.67215803879714, 272.05767746025754, 225.16891013810735, 336.44071623146175, 372.8092532778315, 453.99033588374766, 266.55702183111566, 212.86117624425597, 360.57872355571806, 392.38155960944005, 386.6441493045269, 511.0831960872318, 209.00877165605723, 270.30093797129746, 499.80542151430757, 422.79520107715604, 610.4389088749361, 305.2348570388607, 246.58117486737555, 150.62560232000112, 457.87658483753785, 367.6174509675801, 375.37628890988367, 126.56067097118358, 539.8220368634275, 482.17939843354395, 153.70065101692967, 399.2097897430412, 619.7642804194087, 390.8279289214426, 261.51228204992714, 219.9754699917135, 425.062015583268, 480.35937550247434, 464.9650293508407, 473.5669509547861, 346.8858637150178, 396.29343814562424, 559.2048134728018, 356.0608861075322, 415.8566964404822, 430.2021117627151, 491.1863339894417, 410.0434613065781, 294.7612465918191, 393.0669603330141, 426.79202772961185, 472.77652261301375, 442.32966110092883, 613.8162841651304, 521.0481537074902, 390.6558864442985, 482.86380165191997, 459.2972005866076, 570.5423263397109, 444.91591193360136, 386.7996966062451, 400.48143142321004, 496.0869865306314, 562.8483796031823, 159.4551640849706, 405.35504597673355, 527.7011355638925, 284.1933751988655, 430.95513832129745, 544.4389351209347, 350.10805354791404, 518.5777293507091, 459.77130521886534, 335.227495584666, 649.6570787908902, 466.31172119768786, 446.84532098052443, 496.48346006323555, 466.39310010352614], "policy_predator_policy_reward": [297.406070733248, 242.5067905665456, 115.26310642845482, 154.39197008707407, 16.856060901042227, 93.67437723446415, 10.698018069075623, 66.50305332199918, 168.631032512068, 16.36641138260594, 478.2497106064112, 501.98425998770824, 118.7494051839087, 336.08826122583486, 10.774387830883878, 71.44554775944323, 13.042452972065718, 43.22014889764258, 247.1270324988295, 192.62731007730952, 22.66821016969038, 34.23194543633128, 150.12001294523375, 0.3465950100534947, 79.18148744738183, 56.8851203309286, 134.51149622528803, 113.001138793212, 81.15031540686142, 42.62517551249912, 188.78443072372232, 48.761828048045224, -0.9621899695107459, 43.529172506468996, 52.48961773834996, 176.2520422748551, 67.6828346691131, 165.79391999552865, 14.487576829009019, 178.8508104968959, 200.30673835840057, 281.1094280372137, 39.94574632403911, 293.47745583573777, 239.6871854531231, 3.433960920116201, 174.56218654758405, 117.04984597858608, 24.766952231292777, 108.47170474166332, 523.7240453126414, 356.85489681605105, 127.0427238600123, 282.73389194617897, 191.7307282751984, 205.90988274158798, -7.335574319487764, 123.62922355911095, 18.65629677757914, 114.91222614115551, 52.873158463906094, 229.36210175135597, 125.17625897559468, 148.3697739544325, -2.0917483468039495, 2.194369107175037, 97.81761772293679, 164.79716013794987, 24.29822221913149, 87.16519828780064, 329.875989577734, 471.8624718461931, 267.83723574079244, 256.35896533187497, 12.445722042893578, 144.0490410021623, 54.41923378174633, 47.15620411199802, 309.26404855405815, 281.0222545904453, 0.0, 5.990582247038581, 42.907327555920205, 203.32033722232464, 28.328553071025993, 24.89756061946957, 8.58861003854189, 307.1658188735018, 29.29517111483022, 67.7425796896842, 192.05545880238984, 57.50640212835744, 232.1918403646844, 510.6620195602218, 610.7246189176169, 420.9698635279328, 264.56180452017855, 218.1146990848682, 175.78493314153766, 259.1286022773089, 138.30180638154903, 188.57149050980115, 96.86130147292565, 59.099130985543326, 126.42055606407833, 241.02696614241523, 124.61742373297861, 118.08149132999465, 263.170764149163, 85.64045422362172, 380.1975115020069, 122.2100539854168, 172.25240158358392, 85.63461658302415, 76.07187305015083, 120.94632238761628, 311.3082953045726, 126.0808445383527, 326.2419274950919, 106.49674093255275, 241.97190576671744, 454.45293765164706, 123.66566726191915, 118.09496443877981, 206.44067427759325, 110.42983305827991, 111.40239055268776, 34.873563253741985, 491.1936582390238, 359.97625871555243, 372.00963571849536, 86.89363309503682, 138.7251512074284, 596.0668703327741, 384.6925811377966, 175.54148811980852, 86.06746439561081, 233.02972372013966, 255.674578485692, 14.779062028701567, 207.92654854814705, 274.72693644817855, 107.18983843720584, 147.74942621665883, 272.5765431105275, 168.8528703803469, 96.27937583540938, 143.23732373867318, 163.05561576797095, 231.89591507069898, 8.659139907055238, 174.19266264389512, 384.7600284921549, 443.89563381916315, 124.20005005425507, 60.35914009976487, 107.97671696530102, 123.18868406363082, 39.31293885738702, 408.6630713205186, 357.0520078047745, 240.21880387779382, 321.71615298817704, 306.51126908720033, 294.8844596470275, 249.72556637051952, 474.33262686756353, 318.53045612077386, 170.04277972653378, 108.71478643916471, 192.0523061317876, 147.29243651218496, 349.83912678858843, 205.7351452706788, 327.3867252982454, 277.17747047676727, 23.106628587581344, 367.56006749090517, 473.7741988031758, 350.1185491784471, 331.3487600180125, 398.455598146382, 200.2543953660097, 456.2266353361797, 352.35923481338557, 145.3698797386304, 440.0808690836686, 399.04164528628274, 304.6701819732902, 416.7176594253377, 208.3996453983151, 304.2742181967389, 241.76936859752385, 266.15804942710844, 333.77839328090164, 377.021321930871, 186.93961724624342, 391.36549308811027, 329.0661338824602, 325.6854675083771]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1413127740265265, "mean_inference_ms": 3.1021863928915137, "mean_action_processing_ms": 0.47275027787788093, "mean_env_wait_ms": 0.43500806883317966, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0057610273361206055, "StateBufferConnector_ms": 0.012865424156188965, "ViewRequirementAgentConnector_ms": 0.14123857021331787}, "num_episodes": 18, "episode_return_max": 1853.7322749079415, "episode_return_min": 155.556375514384, "episode_return_mean": 1061.9268447818615, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 277.0171183378381, "num_env_steps_trained_throughput_per_sec": 277.0171183378381, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 14549.174, "restore_workers_time_ms": 0.054, "training_step_time_ms": 14549.066, "sample_time_ms": 2247.951, "learn_time_ms": 12272.29, "learn_throughput": 325.938, "synch_weights_time_ms": 25.8}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "479e5_00000", "date": "2024-08-16_11-28-42", "timestamp": 1723787922, "time_this_iter_s": 14.473896026611328, "time_total_s": 116.85499691963196, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a781d8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 116.85499691963196, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 65.7, "ram_util_percent": 82.39}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2004003000795527, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.499580719862035, "policy_loss": -0.010417380237153597, "vf_loss": 9.50877467614633, "vf_explained_var": 0.0001742097435804902, "kl": 0.012234342278682364, "entropy": 1.5128992491298252, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.475704141725939, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.762080034124788, "policy_loss": -0.0038356224013364345, "vf_loss": 9.765217430377133, "vf_explained_var": -0.04311807565588169, "kl": 0.006982352499732676, "entropy": 1.421412005941704, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 1890.091470647017, "episode_reward_min": 155.556375514384, "episode_reward_mean": 1223.166358729104, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 2.98999999999998, "predator_policy": -7.335574319487764}, "policy_reward_max": {"prey_policy": 649.6570787908902, "predator_policy": 610.7246189176169}, "policy_reward_mean": {"prey_policy": 378.38231860399634, "predator_policy": 233.20086076055588}, "custom_metrics": {}, "hist_stats": {"episode_reward": [899.3538152281043, 952.5679487212916, 673.199999999998, 1407.1874653530515, 887.460259043669, 1169.8659799498791, 606.4635673240683, 469.2811808462114, 1123.0293899480012, 512.5196082616103, 155.556375514384, 754.1295207991045, 614.7663551926214, 1281.0717037097081, 1567.944001546976, 754.9215606813516, 508.1876143149367, 1539.1216951639728, 464.3199999999997, 1092.3233674627584, 191.5496269290999, 775.5147405279142, 543.509999999998, 956.4958956263424, 1764.2013397225276, 1660.130744961304, 1102.1428820041583, 1070.6915837054405, 1144.3056210935965, 740.6788302211321, 1076.67487533332, 1308.7290787905144, 1228.39146382171, 1379.5791828327024, 896.4499999999991, 652.8445693792532, 1096.7602911604397, 1136.8454545750023, 1643.6985402079918, 807.9516036881499, 881.007495436631, 643.5025414047944, 1560.4198864638688, 1179.4506265283949, 1308.2319213401759, 1339.2597781715726, 1039.189155859038, 1040.5599999999986, 1515.887594948416, 806.755296560101, 1049.931600648412, 982.5104394515463, 1061.3342386732784, 818.7318520014239, 1847.6297324737673, 836.8994011253894, 876.202886603912, 1393.3004150312204, 1417.7236263523712, 1583.725673693803, 1316.5276085655607, 1714.2515287404956, 983.5622740640952, 1159.203730706597, 1470.68045577321, 1739.4286336476312, 1264.1863841747052, 1853.7322749079415, 1561.5199667042407, 1553.0494486560308, 1220.0326582401683, 1772.1786959105762, 1436.53635491879, 1407.2208522639023, 1486.276452594206, 1695.6842895873292, 1491.4621525125654, 1617.6281615575988, 1483.6959426596766, 1796.6716149981905, 1813.5195826384115, 1827.9500418770954, 1303.870227067024, 1502.7147034742602, 1626.6998899693476, 1581.802972786023, 1283.7114669384532, 1551.6427936343707, 1621.3827850664172, 1890.091470647017, 1015.6988349345434, 1527.7455283024367, 926.0845952965211, 1747.9216559699194, 1725.3292329004398, 1858.191911461919, 1209.9210422360607, 1599.5331056142884, 1536.0999728273416, 1350.52268167459], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [334.18019749391595, 322.0524713609489, 351.3127888683907, 309.643127326731, 316.3182952583364, 223.64304776870608, 195.03771835405638, 331.5708048703038, 401.0141006022415, 76.66954263523809, 428.8754302381807, 343.349938694913, 333.9341434719787, 156.2357746124665, 332.7226579274785, 2.98999999999998, 496.03172638917164, 344.76240334356817, 185.4935753315842, 53.479999999999976, 149.49375475401263, 5.960000000000001, 19.820000000000004, 471.6947429382192, 279.4312860520628, 223.8716486336263, 359.76006949313324, 119.57317279264826, 473.8264557619137, 569.921344712396, 351.4911284896477, 246.93566914664822, 199.86924094334069, 206.74293547785356, 478.75846655200456, 470.07692546746483, 250.14724755345122, 208.1821701995099, 436.4694852859301, 409.62621739858406, 37.63999999999993, 100.68351323860355, 87.76034405174683, 371.9999675641248, 102.04482888517002, 344.4274203103148, 325.611777697072, 381.32225699852313, 484.4554240499457, 536.8920557476764, 337.78309792483697, 290.653164590918, 323.27590122188354, 296.19047717722844, 308.13972413633115, 327.6383241502625, 565.2293677415612, 252.2029564606852, 66.34999999999997, 518.3683977626639, 487.1008670928031, 222.12648603402423, 476.2438214770311, 589.7863422505105, 472.91720637430984, 406.66303907461526, 446.0493902488982, 431.12222709637973, 407.03759841641585, 231.52538341697527, 145.72457175165286, 310.10180218983373, 318.18223184816287, 341.18891946935156, 326.2656728559866, 377.8411132913711, 545.814678944143, 401.4590178454854, 138.11457558468712, 428.07639640276403, 297.4648300619616, 266.67215803879714, 272.05767746025754, 225.16891013810735, 336.44071623146175, 372.8092532778315, 453.99033588374766, 266.55702183111566, 212.86117624425597, 360.57872355571806, 392.38155960944005, 386.6441493045269, 511.0831960872318, 209.00877165605723, 270.30093797129746, 499.80542151430757, 422.79520107715604, 610.4389088749361, 305.2348570388607, 246.58117486737555, 150.62560232000112, 457.87658483753785, 367.6174509675801, 375.37628890988367, 126.56067097118358, 539.8220368634275, 482.17939843354395, 153.70065101692967, 399.2097897430412, 619.7642804194087, 390.8279289214426, 261.51228204992714, 219.9754699917135, 425.062015583268, 480.35937550247434, 464.9650293508407, 473.5669509547861, 346.8858637150178, 396.29343814562424, 559.2048134728018, 356.0608861075322, 415.8566964404822, 430.2021117627151, 491.1863339894417, 410.0434613065781, 294.7612465918191, 393.0669603330141, 426.79202772961185, 472.77652261301375, 442.32966110092883, 613.8162841651304, 521.0481537074902, 390.6558864442985, 482.86380165191997, 459.2972005866076, 570.5423263397109, 444.91591193360136, 386.7996966062451, 400.48143142321004, 496.0869865306314, 562.8483796031823, 159.4551640849706, 405.35504597673355, 527.7011355638925, 284.1933751988655, 430.95513832129745, 544.4389351209347, 350.10805354791404, 518.5777293507091, 459.77130521886534, 335.227495584666, 649.6570787908902, 466.31172119768786, 446.84532098052443, 496.48346006323555, 466.39310010352614, 407.2387168135596, 311.2039294570815, 477.5231352819031, 500.77931962656663, 550.2985358271766, 388.9497473555964, 591.3889201597639, 492.43230519585376, 493.1726039376351, 307.7464713247117, 480.6701117006055, 587.2920349428226, 460.67450134438303, 605.3228297308606, 536.024468275855, 468.72007408609414, 490.60484597805697, 443.6009810053025, 439.8063988693491, 365.70318793532476, 387.7703875997529, 370.3517278647948, 550.280648513319, 588.2143326820803, 555.0607639061325, 15.17677276241436, 362.08589970098336, 385.39694947993416, 584.1504830266429, 189.79076292750278, 534.200363159652, 492.30875860007757, 514.7173331450656, 639.0576694980022, 553.0174589907137, 515.4475550315124, 517.8570791065507, 277.68082635369893, 359.11150251604676, 443.95754381848593, 380.4196946151265, 529.781257227803, 459.0446322277156, 425.2832226543951], "policy_predator_policy_reward": [239.6871854531231, 3.433960920116201, 174.56218654758405, 117.04984597858608, 24.766952231292777, 108.47170474166332, 523.7240453126414, 356.85489681605105, 127.0427238600123, 282.73389194617897, 191.7307282751984, 205.90988274158798, -7.335574319487764, 123.62922355911095, 18.65629677757914, 114.91222614115551, 52.873158463906094, 229.36210175135597, 125.17625897559468, 148.3697739544325, -2.0917483468039495, 2.194369107175037, 97.81761772293679, 164.79716013794987, 24.29822221913149, 87.16519828780064, 329.875989577734, 471.8624718461931, 267.83723574079244, 256.35896533187497, 12.445722042893578, 144.0490410021623, 54.41923378174633, 47.15620411199802, 309.26404855405815, 281.0222545904453, 0.0, 5.990582247038581, 42.907327555920205, 203.32033722232464, 28.328553071025993, 24.89756061946957, 8.58861003854189, 307.1658188735018, 29.29517111483022, 67.7425796896842, 192.05545880238984, 57.50640212835744, 232.1918403646844, 510.6620195602218, 610.7246189176169, 420.9698635279328, 264.56180452017855, 218.1146990848682, 175.78493314153766, 259.1286022773089, 138.30180638154903, 188.57149050980115, 96.86130147292565, 59.099130985543326, 126.42055606407833, 241.02696614241523, 124.61742373297861, 118.08149132999465, 263.170764149163, 85.64045422362172, 380.1975115020069, 122.2100539854168, 172.25240158358392, 85.63461658302415, 76.07187305015083, 120.94632238761628, 311.3082953045726, 126.0808445383527, 326.2419274950919, 106.49674093255275, 241.97190576671744, 454.45293765164706, 123.66566726191915, 118.09496443877981, 206.44067427759325, 110.42983305827991, 111.40239055268776, 34.873563253741985, 491.1936582390238, 359.97625871555243, 372.00963571849536, 86.89363309503682, 138.7251512074284, 596.0668703327741, 384.6925811377966, 175.54148811980852, 86.06746439561081, 233.02972372013966, 255.674578485692, 14.779062028701567, 207.92654854814705, 274.72693644817855, 107.18983843720584, 147.74942621665883, 272.5765431105275, 168.8528703803469, 96.27937583540938, 143.23732373867318, 163.05561576797095, 231.89591507069898, 8.659139907055238, 174.19266264389512, 384.7600284921549, 443.89563381916315, 124.20005005425507, 60.35914009976487, 107.97671696530102, 123.18868406363082, 39.31293885738702, 408.6630713205186, 357.0520078047745, 240.21880387779382, 321.71615298817704, 306.51126908720033, 294.8844596470275, 249.72556637051952, 474.33262686756353, 318.53045612077386, 170.04277972653378, 108.71478643916471, 192.0523061317876, 147.29243651218496, 349.83912678858843, 205.7351452706788, 327.3867252982454, 277.17747047676727, 23.106628587581344, 367.56006749090517, 473.7741988031758, 350.1185491784471, 331.3487600180125, 398.455598146382, 200.2543953660097, 456.2266353361797, 352.35923481338557, 145.3698797386304, 440.0808690836686, 399.04164528628274, 304.6701819732902, 416.7176594253377, 208.3996453983151, 304.2742181967389, 241.76936859752385, 266.15804942710844, 333.77839328090164, 377.021321930871, 186.93961724624342, 391.36549308811027, 329.0661338824602, 325.6854675083771, 443.3372441033612, 321.9160522856752, 417.2433771969107, 401.12578289280987, 606.0137822149125, 268.2575172407258, 367.931333142039, 376.19748337943713, 321.81638716532956, 181.1347646393486, 259.7200411391904, 175.03251569164067, 180.7614395089517, 379.9411193851522, 317.09288229618033, 259.9655481278938, 253.13652577740382, 96.36911417769028, 362.6476672753121, 383.4855395543852, 499.26831164467626, 363.99235795719363, 378.83085861436535, 372.76563083725244, 260.9616342865856, 184.49966397941168, 376.9431095538218, 403.3195695676987, 5.909179614418862, 146.23416972795727, 377.9143079040729, 343.4982263061167, 297.75934610267905, 273.79488415469535, 463.986010872516, 325.74088656717765, 182.0920873391412, 232.29104943666943, 388.7921854884475, 407.67187379130957, 320.60182881871424, 305.2971921656983, 431.213814190759, 34.98101260172005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1075879937891564, "mean_inference_ms": 3.003327169500175, "mean_action_processing_ms": 0.460627075714378, "mean_env_wait_ms": 0.4191134031652501, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0047299861907958984, "StateBufferConnector_ms": 0.012708425521850586, "ViewRequirementAgentConnector_ms": 0.12788844108581543}, "num_episodes": 22, "episode_return_max": 1890.091470647017, "episode_return_min": 155.556375514384, "episode_return_mean": 1223.166358729104, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 275.2691017389344, "num_env_steps_trained_throughput_per_sec": 275.2691017389344, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 14547.182, "restore_workers_time_ms": 0.049, "training_step_time_ms": 14547.08, "sample_time_ms": 2168.503, "learn_time_ms": 12350.893, "learn_throughput": 323.863, "synch_weights_time_ms": 24.833}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "479e5_00000", "date": "2024-08-16_11-28-57", "timestamp": 1723787937, "time_this_iter_s": 14.575309753417969, "time_total_s": 131.43030667304993, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a781daf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 131.43030667304993, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 59.37142857142857, "ram_util_percent": 82.21904761904763}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2447110747376446, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.631236595577663, "policy_loss": -0.013672499633246352, "vf_loss": 9.643015702565512, "vf_explained_var": -0.010605050678606386, "kl": 0.01893388544141443, "entropy": 1.4884995189924088, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4803274595548237, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.745821908920531, "policy_loss": 0.0014686164557046833, "vf_loss": 9.743243626690415, "vf_explained_var": -0.013936724107732218, "kl": 0.011097036748486102, "entropy": 1.42473076071058, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 1914.7625680547078, "episode_reward_min": 643.5025414047944, "episode_reward_mean": 1414.823037478005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 15.17677276241436, "predator_policy": -1.5007913335373537}, "policy_reward_max": {"prey_policy": 709.2383301167192, "predator_policy": 610.7246189176169}, "policy_reward_mean": {"prey_policy": 427.767234824312, "predator_policy": 279.64428391469033}, "custom_metrics": {}, "hist_stats": {"episode_reward": [956.4958956263424, 1764.2013397225276, 1660.130744961304, 1102.1428820041583, 1070.6915837054405, 1144.3056210935965, 740.6788302211321, 1076.67487533332, 1308.7290787905144, 1228.39146382171, 1379.5791828327024, 896.4499999999991, 652.8445693792532, 1096.7602911604397, 1136.8454545750023, 1643.6985402079918, 807.9516036881499, 881.007495436631, 643.5025414047944, 1560.4198864638688, 1179.4506265283949, 1308.2319213401759, 1339.2597781715726, 1039.189155859038, 1040.5599999999986, 1515.887594948416, 806.755296560101, 1049.931600648412, 982.5104394515463, 1061.3342386732784, 818.7318520014239, 1847.6297324737673, 836.8994011253894, 876.202886603912, 1393.3004150312204, 1417.7236263523712, 1583.725673693803, 1316.5276085655607, 1714.2515287404956, 983.5622740640952, 1159.203730706597, 1470.68045577321, 1739.4286336476312, 1264.1863841747052, 1853.7322749079415, 1561.5199667042407, 1553.0494486560308, 1220.0326582401683, 1772.1786959105762, 1436.53635491879, 1407.2208522639023, 1486.276452594206, 1695.6842895873292, 1491.4621525125654, 1617.6281615575988, 1483.6959426596766, 1796.6716149981905, 1813.5195826384115, 1827.9500418770954, 1303.870227067024, 1502.7147034742602, 1626.6998899693476, 1581.802972786023, 1283.7114669384532, 1551.6427936343707, 1621.3827850664172, 1890.091470647017, 1015.6988349345434, 1527.7455283024367, 926.0845952965211, 1747.9216559699194, 1725.3292329004398, 1858.191911461919, 1209.9210422360607, 1599.5331056142884, 1536.0999728273416, 1350.52268167459, 1849.2406148239947, 1441.8039089807485, 1599.723134451632, 1379.8338058110642, 1173.3384598929663, 1775.5374531824923, 1645.0938753176379, 1411.043518829287, 1678.1652984937375, 1914.7625680547078, 1906.3964037660662, 1711.5097026416965, 1222.0976444823652, 1863.709926945196, 1596.5879195100315, 1638.9887634960526, 1637.880434965926, 1843.416113017602, 1701.0378226848243, 1473.8413941629915, 1900.3509343264527, 1902.5808979057654, 1842.5730556655228], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [325.611777697072, 381.32225699852313, 484.4554240499457, 536.8920557476764, 337.78309792483697, 290.653164590918, 323.27590122188354, 296.19047717722844, 308.13972413633115, 327.6383241502625, 565.2293677415612, 252.2029564606852, 66.34999999999997, 518.3683977626639, 487.1008670928031, 222.12648603402423, 476.2438214770311, 589.7863422505105, 472.91720637430984, 406.66303907461526, 446.0493902488982, 431.12222709637973, 407.03759841641585, 231.52538341697527, 145.72457175165286, 310.10180218983373, 318.18223184816287, 341.18891946935156, 326.2656728559866, 377.8411132913711, 545.814678944143, 401.4590178454854, 138.11457558468712, 428.07639640276403, 297.4648300619616, 266.67215803879714, 272.05767746025754, 225.16891013810735, 336.44071623146175, 372.8092532778315, 453.99033588374766, 266.55702183111566, 212.86117624425597, 360.57872355571806, 392.38155960944005, 386.6441493045269, 511.0831960872318, 209.00877165605723, 270.30093797129746, 499.80542151430757, 422.79520107715604, 610.4389088749361, 305.2348570388607, 246.58117486737555, 150.62560232000112, 457.87658483753785, 367.6174509675801, 375.37628890988367, 126.56067097118358, 539.8220368634275, 482.17939843354395, 153.70065101692967, 399.2097897430412, 619.7642804194087, 390.8279289214426, 261.51228204992714, 219.9754699917135, 425.062015583268, 480.35937550247434, 464.9650293508407, 473.5669509547861, 346.8858637150178, 396.29343814562424, 559.2048134728018, 356.0608861075322, 415.8566964404822, 430.2021117627151, 491.1863339894417, 410.0434613065781, 294.7612465918191, 393.0669603330141, 426.79202772961185, 472.77652261301375, 442.32966110092883, 613.8162841651304, 521.0481537074902, 390.6558864442985, 482.86380165191997, 459.2972005866076, 570.5423263397109, 444.91591193360136, 386.7996966062451, 400.48143142321004, 496.0869865306314, 562.8483796031823, 159.4551640849706, 405.35504597673355, 527.7011355638925, 284.1933751988655, 430.95513832129745, 544.4389351209347, 350.10805354791404, 518.5777293507091, 459.77130521886534, 335.227495584666, 649.6570787908902, 466.31172119768786, 446.84532098052443, 496.48346006323555, 466.39310010352614, 407.2387168135596, 311.2039294570815, 477.5231352819031, 500.77931962656663, 550.2985358271766, 388.9497473555964, 591.3889201597639, 492.43230519585376, 493.1726039376351, 307.7464713247117, 480.6701117006055, 587.2920349428226, 460.67450134438303, 605.3228297308606, 536.024468275855, 468.72007408609414, 490.60484597805697, 443.6009810053025, 439.8063988693491, 365.70318793532476, 387.7703875997529, 370.3517278647948, 550.280648513319, 588.2143326820803, 555.0607639061325, 15.17677276241436, 362.08589970098336, 385.39694947993416, 584.1504830266429, 189.79076292750278, 534.200363159652, 492.30875860007757, 514.7173331450656, 639.0576694980022, 553.0174589907137, 515.4475550315124, 517.8570791065507, 277.68082635369893, 359.11150251604676, 443.95754381848593, 380.4196946151265, 529.781257227803, 459.0446322277156, 425.2832226543951, 579.3471366296347, 451.60143121949596, 391.1490164898306, 450.2876914571484, 510.32073487440516, 461.366082469462, 617.3989394790595, 293.0421421331466, 548.0608309595585, 115.73510819354252, 522.9449101444698, 425.2523873286562, 399.6617478000249, 418.98183372930833, 406.86533392311276, 450.96508776039764, 469.4330139075267, 547.6460626114432, 439.1900252908546, 709.2383301167192, 320.08689770931966, 509.19310267999685, 430.23442416166637, 667.0297941432506, 440.4236698485307, 438.87721831193466, 561.7265053800149, 588.9841898320816, 577.8330404276245, 595.3846321144879, 565.7345664932446, 392.4681570503215, 548.3093681883098, 440.49743422614137, 566.7243766384538, 397.20090418958387, 465.2507000148517, 529.2697246654996, 445.945463741692, 584.2861634715115, 487.71987760722646, 573.3251662378136, 507.2692957466142, 546.6167766292468, 497.01621287993527, 506.61351540661025], "policy_predator_policy_reward": [192.05545880238984, 57.50640212835744, 232.1918403646844, 510.6620195602218, 610.7246189176169, 420.9698635279328, 264.56180452017855, 218.1146990848682, 175.78493314153766, 259.1286022773089, 138.30180638154903, 188.57149050980115, 96.86130147292565, 59.099130985543326, 126.42055606407833, 241.02696614241523, 124.61742373297861, 118.08149132999465, 263.170764149163, 85.64045422362172, 380.1975115020069, 122.2100539854168, 172.25240158358392, 85.63461658302415, 76.07187305015083, 120.94632238761628, 311.3082953045726, 126.0808445383527, 326.2419274950919, 106.49674093255275, 241.97190576671744, 454.45293765164706, 123.66566726191915, 118.09496443877981, 206.44067427759325, 110.42983305827991, 111.40239055268776, 34.873563253741985, 491.1936582390238, 359.97625871555243, 372.00963571849536, 86.89363309503682, 138.7251512074284, 596.0668703327741, 384.6925811377966, 175.54148811980852, 86.06746439561081, 233.02972372013966, 255.674578485692, 14.779062028701567, 207.92654854814705, 274.72693644817855, 107.18983843720584, 147.74942621665883, 272.5765431105275, 168.8528703803469, 96.27937583540938, 143.23732373867318, 163.05561576797095, 231.89591507069898, 8.659139907055238, 174.19266264389512, 384.7600284921549, 443.89563381916315, 124.20005005425507, 60.35914009976487, 107.97671696530102, 123.18868406363082, 39.31293885738702, 408.6630713205186, 357.0520078047745, 240.21880387779382, 321.71615298817704, 306.51126908720033, 294.8844596470275, 249.72556637051952, 474.33262686756353, 318.53045612077386, 170.04277972653378, 108.71478643916471, 192.0523061317876, 147.29243651218496, 349.83912678858843, 205.7351452706788, 327.3867252982454, 277.17747047676727, 23.106628587581344, 367.56006749090517, 473.7741988031758, 350.1185491784471, 331.3487600180125, 398.455598146382, 200.2543953660097, 456.2266353361797, 352.35923481338557, 145.3698797386304, 440.0808690836686, 399.04164528628274, 304.6701819732902, 416.7176594253377, 208.3996453983151, 304.2742181967389, 241.76936859752385, 266.15804942710844, 333.77839328090164, 377.021321930871, 186.93961724624342, 391.36549308811027, 329.0661338824602, 325.6854675083771, 443.3372441033612, 321.9160522856752, 417.2433771969107, 401.12578289280987, 606.0137822149125, 268.2575172407258, 367.931333142039, 376.19748337943713, 321.81638716532956, 181.1347646393486, 259.7200411391904, 175.03251569164067, 180.7614395089517, 379.9411193851522, 317.09288229618033, 259.9655481278938, 253.13652577740382, 96.36911417769028, 362.6476672753121, 383.4855395543852, 499.26831164467626, 363.99235795719363, 378.83085861436535, 372.76563083725244, 260.9616342865856, 184.49966397941168, 376.9431095538218, 403.3195695676987, 5.909179614418862, 146.23416972795727, 377.9143079040729, 343.4982263061167, 297.75934610267905, 273.79488415469535, 463.986010872516, 325.74088656717765, 182.0920873391412, 232.29104943666943, 388.7921854884475, 407.67187379130957, 320.60182881871424, 305.2971921656983, 431.213814190759, 34.98101260172005, 528.9464749689662, 289.34557200589603, 361.30498937762405, 239.0622116561459, 256.2647000596538, 371.77161704811004, 202.1005778486127, 267.29214635024584, 326.8487912213843, 182.69372951848237, 456.1156991654318, 371.22445654393266, 487.5523187174835, 338.8979750708205, 262.7398359776156, 290.47326116816043, 377.7167284917414, 283.36949348302664, 438.2195354073888, 328.1146772397448, 527.923761913634, 549.1926414631164, 430.2029947335472, 184.04248960323386, 148.4947232811753, 194.3020330407243, 377.9425486227189, 335.05668311038164, -1.5007913335373537, 424.871038301455, 286.2146433349226, 394.5713966175647, 373.3809690346638, 275.6926635168108, 513.8926351339422, 365.5981970556195, 416.52975628542, 289.9876417190529, 269.6348968192713, 173.97487013051847, 382.33901474242884, 456.9668757389837, 406.86082327277086, 441.83400225713274, 490.64205967957173, 348.30126769940557]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0597123950658354, "mean_inference_ms": 2.853424992761823, "mean_action_processing_ms": 0.43968475837790855, "mean_env_wait_ms": 0.3975060618359742, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005090117454528809, "StateBufferConnector_ms": 0.013581037521362305, "ViewRequirementAgentConnector_ms": 0.12406742572784424}, "num_episodes": 23, "episode_return_max": 1914.7625680547078, "episode_return_min": 643.5025414047944, "episode_return_mean": 1414.823037478005, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 280.840593938153, "num_env_steps_trained_throughput_per_sec": 280.840593938153, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 14516.761, "restore_workers_time_ms": 0.046, "training_step_time_ms": 14516.663, "sample_time_ms": 2094.267, "learn_time_ms": 12395.882, "learn_throughput": 322.688, "synch_weights_time_ms": 23.8}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "479e5_00000", "date": "2024-08-16_11-29-11", "timestamp": 1723787951, "time_this_iter_s": 14.285851955413818, "time_total_s": 145.71615862846375, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78e5040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 145.71615862846375, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 58.839999999999996, "ram_util_percent": 82.00500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1806090022994098, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.667368116328324, "policy_loss": -0.00830240687035103, "vf_loss": 9.674459017395343, "vf_explained_var": -0.008611318642500216, "kl": 0.012114956019866886, "entropy": 1.4876135672841753, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2653865309146346, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.843803334109998, "policy_loss": -0.003363864127516983, "vf_loss": 9.845570609683083, "vf_explained_var": -0.027865548171694315, "kl": 0.015966046962321637, "entropy": 1.3939497217299446, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 1915.9379329658173, "episode_reward_min": 643.5025414047944, "episode_reward_mean": 1503.4664545360843, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 15.17677276241436, "predator_policy": -1.5007913335373537}, "policy_reward_max": {"prey_policy": 709.2383301167192, "predator_policy": 606.0137822149125}, "policy_reward_mean": {"prey_policy": 444.41536701405727, "predator_policy": 307.3178602539848}, "custom_metrics": {}, "hist_stats": {"episode_reward": [643.5025414047944, 1560.4198864638688, 1179.4506265283949, 1308.2319213401759, 1339.2597781715726, 1039.189155859038, 1040.5599999999986, 1515.887594948416, 806.755296560101, 1049.931600648412, 982.5104394515463, 1061.3342386732784, 818.7318520014239, 1847.6297324737673, 836.8994011253894, 876.202886603912, 1393.3004150312204, 1417.7236263523712, 1583.725673693803, 1316.5276085655607, 1714.2515287404956, 983.5622740640952, 1159.203730706597, 1470.68045577321, 1739.4286336476312, 1264.1863841747052, 1853.7322749079415, 1561.5199667042407, 1553.0494486560308, 1220.0326582401683, 1772.1786959105762, 1436.53635491879, 1407.2208522639023, 1486.276452594206, 1695.6842895873292, 1491.4621525125654, 1617.6281615575988, 1483.6959426596766, 1796.6716149981905, 1813.5195826384115, 1827.9500418770954, 1303.870227067024, 1502.7147034742602, 1626.6998899693476, 1581.802972786023, 1283.7114669384532, 1551.6427936343707, 1621.3827850664172, 1890.091470647017, 1015.6988349345434, 1527.7455283024367, 926.0845952965211, 1747.9216559699194, 1725.3292329004398, 1858.191911461919, 1209.9210422360607, 1599.5331056142884, 1536.0999728273416, 1350.52268167459, 1849.2406148239947, 1441.8039089807485, 1599.723134451632, 1379.8338058110642, 1173.3384598929663, 1775.5374531824923, 1645.0938753176379, 1411.043518829287, 1678.1652984937375, 1914.7625680547078, 1906.3964037660662, 1711.5097026416965, 1222.0976444823652, 1863.709926945196, 1596.5879195100315, 1638.9887634960526, 1637.880434965926, 1843.416113017602, 1701.0378226848243, 1473.8413941629915, 1900.3509343264527, 1902.5808979057654, 1842.5730556655228, 1797.5130537603184, 1677.748293641134, 1349.150195812877, 1541.3892315563924, 1484.4293238453386, 1802.4444178195338, 1567.0999975494626, 1844.5147723620337, 1915.9379329658173, 1624.530062034028, 1133.7019517711203, 1707.5609081957123, 1801.837877484541, 1722.5046132158784, 1739.6884417007175, 1626.9762145100194, 1598.1881325776212, 1476.7057375656125], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [272.05767746025754, 225.16891013810735, 336.44071623146175, 372.8092532778315, 453.99033588374766, 266.55702183111566, 212.86117624425597, 360.57872355571806, 392.38155960944005, 386.6441493045269, 511.0831960872318, 209.00877165605723, 270.30093797129746, 499.80542151430757, 422.79520107715604, 610.4389088749361, 305.2348570388607, 246.58117486737555, 150.62560232000112, 457.87658483753785, 367.6174509675801, 375.37628890988367, 126.56067097118358, 539.8220368634275, 482.17939843354395, 153.70065101692967, 399.2097897430412, 619.7642804194087, 390.8279289214426, 261.51228204992714, 219.9754699917135, 425.062015583268, 480.35937550247434, 464.9650293508407, 473.5669509547861, 346.8858637150178, 396.29343814562424, 559.2048134728018, 356.0608861075322, 415.8566964404822, 430.2021117627151, 491.1863339894417, 410.0434613065781, 294.7612465918191, 393.0669603330141, 426.79202772961185, 472.77652261301375, 442.32966110092883, 613.8162841651304, 521.0481537074902, 390.6558864442985, 482.86380165191997, 459.2972005866076, 570.5423263397109, 444.91591193360136, 386.7996966062451, 400.48143142321004, 496.0869865306314, 562.8483796031823, 159.4551640849706, 405.35504597673355, 527.7011355638925, 284.1933751988655, 430.95513832129745, 544.4389351209347, 350.10805354791404, 518.5777293507091, 459.77130521886534, 335.227495584666, 649.6570787908902, 466.31172119768786, 446.84532098052443, 496.48346006323555, 466.39310010352614, 407.2387168135596, 311.2039294570815, 477.5231352819031, 500.77931962656663, 550.2985358271766, 388.9497473555964, 591.3889201597639, 492.43230519585376, 493.1726039376351, 307.7464713247117, 480.6701117006055, 587.2920349428226, 460.67450134438303, 605.3228297308606, 536.024468275855, 468.72007408609414, 490.60484597805697, 443.6009810053025, 439.8063988693491, 365.70318793532476, 387.7703875997529, 370.3517278647948, 550.280648513319, 588.2143326820803, 555.0607639061325, 15.17677276241436, 362.08589970098336, 385.39694947993416, 584.1504830266429, 189.79076292750278, 534.200363159652, 492.30875860007757, 514.7173331450656, 639.0576694980022, 553.0174589907137, 515.4475550315124, 517.8570791065507, 277.68082635369893, 359.11150251604676, 443.95754381848593, 380.4196946151265, 529.781257227803, 459.0446322277156, 425.2832226543951, 579.3471366296347, 451.60143121949596, 391.1490164898306, 450.2876914571484, 510.32073487440516, 461.366082469462, 617.3989394790595, 293.0421421331466, 548.0608309595585, 115.73510819354252, 522.9449101444698, 425.2523873286562, 399.6617478000249, 418.98183372930833, 406.86533392311276, 450.96508776039764, 469.4330139075267, 547.6460626114432, 439.1900252908546, 709.2383301167192, 320.08689770931966, 509.19310267999685, 430.23442416166637, 667.0297941432506, 440.4236698485307, 438.87721831193466, 561.7265053800149, 588.9841898320816, 577.8330404276245, 595.3846321144879, 565.7345664932446, 392.4681570503215, 548.3093681883098, 440.49743422614137, 566.7243766384538, 397.20090418958387, 465.2507000148517, 529.2697246654996, 445.945463741692, 584.2861634715115, 487.71987760722646, 573.3251662378136, 507.2692957466142, 546.6167766292468, 497.01621287993527, 506.61351540661025, 410.6531523390907, 478.5811492001434, 489.3867613907624, 599.7130917122694, 497.64320574180095, 487.9925528555925, 645.8234386971047, 429.6590241304398, 527.069353224078, 316.82222535848774, 388.4722001935441, 296.8474756757134, 404.8669618532399, 578.8600323008462, 590.5442235932032, 626.4437438887554, 593.8684364945951, 411.73990198099676, 373.1804294140199, 380.2166720299533, 165.28127067315586, 491.07830234614534, 472.4210964531079, 466.5039221890926, 460.1271350534353, 558.511651425803, 398.9301009499888, 439.9653494291654, 493.6721017336116, 482.59061523456364, 435.04877032275834, 411.27661185229783, 312.5048380692564, 424.07075045281056, 417.87054955849743, 452.98059555646705], "policy_predator_policy_reward": [111.40239055268776, 34.873563253741985, 491.1936582390238, 359.97625871555243, 372.00963571849536, 86.89363309503682, 138.7251512074284, 596.0668703327741, 384.6925811377966, 175.54148811980852, 86.06746439561081, 233.02972372013966, 255.674578485692, 14.779062028701567, 207.92654854814705, 274.72693644817855, 107.18983843720584, 147.74942621665883, 272.5765431105275, 168.8528703803469, 96.27937583540938, 143.23732373867318, 163.05561576797095, 231.89591507069898, 8.659139907055238, 174.19266264389512, 384.7600284921549, 443.89563381916315, 124.20005005425507, 60.35914009976487, 107.97671696530102, 123.18868406363082, 39.31293885738702, 408.6630713205186, 357.0520078047745, 240.21880387779382, 321.71615298817704, 306.51126908720033, 294.8844596470275, 249.72556637051952, 474.33262686756353, 318.53045612077386, 170.04277972653378, 108.71478643916471, 192.0523061317876, 147.29243651218496, 349.83912678858843, 205.7351452706788, 327.3867252982454, 277.17747047676727, 23.106628587581344, 367.56006749090517, 473.7741988031758, 350.1185491784471, 331.3487600180125, 398.455598146382, 200.2543953660097, 456.2266353361797, 352.35923481338557, 145.3698797386304, 440.0808690836686, 399.04164528628274, 304.6701819732902, 416.7176594253377, 208.3996453983151, 304.2742181967389, 241.76936859752385, 266.15804942710844, 333.77839328090164, 377.021321930871, 186.93961724624342, 391.36549308811027, 329.0661338824602, 325.6854675083771, 443.3372441033612, 321.9160522856752, 417.2433771969107, 401.12578289280987, 606.0137822149125, 268.2575172407258, 367.931333142039, 376.19748337943713, 321.81638716532956, 181.1347646393486, 259.7200411391904, 175.03251569164067, 180.7614395089517, 379.9411193851522, 317.09288229618033, 259.9655481278938, 253.13652577740382, 96.36911417769028, 362.6476672753121, 383.4855395543852, 499.26831164467626, 363.99235795719363, 378.83085861436535, 372.76563083725244, 260.9616342865856, 184.49966397941168, 376.9431095538218, 403.3195695676987, 5.909179614418862, 146.23416972795727, 377.9143079040729, 343.4982263061167, 297.75934610267905, 273.79488415469535, 463.986010872516, 325.74088656717765, 182.0920873391412, 232.29104943666943, 388.7921854884475, 407.67187379130957, 320.60182881871424, 305.2971921656983, 431.213814190759, 34.98101260172005, 528.9464749689662, 289.34557200589603, 361.30498937762405, 239.0622116561459, 256.2647000596538, 371.77161704811004, 202.1005778486127, 267.29214635024584, 326.8487912213843, 182.69372951848237, 456.1156991654318, 371.22445654393266, 487.5523187174835, 338.8979750708205, 262.7398359776156, 290.47326116816043, 377.7167284917414, 283.36949348302664, 438.2195354073888, 328.1146772397448, 527.923761913634, 549.1926414631164, 430.2029947335472, 184.04248960323386, 148.4947232811753, 194.3020330407243, 377.9425486227189, 335.05668311038164, -1.5007913335373537, 424.871038301455, 286.2146433349226, 394.5713966175647, 373.3809690346638, 275.6926635168108, 513.8926351339422, 365.5981970556195, 416.52975628542, 289.9876417190529, 269.6348968192713, 173.97487013051847, 382.33901474242884, 456.9668757389837, 406.86082327277086, 441.83400225713274, 490.64205967957173, 348.30126769940557, 474.2116753205911, 434.06707690049217, 226.2885086307673, 362.3599319073372, 169.22963312263755, 194.28480409284592, 268.2246600033633, 197.68210872548605, 267.4854671608316, 373.05227810194145, 571.8748582130361, 545.2498837372428, 293.28248452162603, 290.0905188737475, 412.8959281423752, 214.63087673770053, 431.8896923529243, 478.43990213730035, 440.94725129668575, 430.1857092933682, 280.8302162359917, 196.51216251582733, 355.8565084495046, 412.7793811040069, 382.5090637479027, 400.69002725739983, 438.8824907516701, 444.7266720850536, 317.96031472439375, 445.46541000814904, 338.26474478630274, 442.38608754866124, 403.43435453459534, 458.17818952096064, 282.7951700921045, 323.0594223585449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.02066987763563, "mean_inference_ms": 2.7413986172385343, "mean_action_processing_ms": 0.4232007907950667, "mean_env_wait_ms": 0.3816978696389883, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005101919174194336, "StateBufferConnector_ms": 0.004319190979003906, "ViewRequirementAgentConnector_ms": 0.12035894393920898}, "num_episodes": 18, "episode_return_max": 1915.9379329658173, "episode_return_min": 643.5025414047944, "episode_return_mean": 1503.4664545360843, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 284.96343073005596, "num_env_steps_trained_throughput_per_sec": 284.96343073005596, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 14462.925, "restore_workers_time_ms": 0.046, "training_step_time_ms": 14462.827, "sample_time_ms": 2068.841, "learn_time_ms": 12367.859, "learn_throughput": 323.419, "synch_weights_time_ms": 23.77}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "479e5_00000", "date": "2024-08-16_11-29-25", "timestamp": 1723787965, "time_this_iter_s": 14.08864688873291, "time_total_s": 159.80480551719666, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78e5310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 159.80480551719666, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 59.295, "ram_util_percent": 81.845}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3431086762872322, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.596022461583374, "policy_loss": -0.009463682783294528, "vf_loss": 9.604212858311083, "vf_explained_var": -0.006599311948453308, "kl": 0.012733027294814894, "entropy": 1.4653965396855875, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4230991036961318, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.828027343245411, "policy_loss": -0.0030524261702325134, "vf_loss": 9.83030807303373, "vf_explained_var": -0.0010661343102732663, "kl": 0.0077169253707129026, "entropy": 1.4290068319865636, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 1984.9452339166853, "episode_reward_min": 926.0845952965211, "episode_reward_mean": 1582.732607008096, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 15.17677276241436, "predator_policy": -1.5007913335373537}, "policy_reward_max": {"prey_policy": 709.2383301167192, "predator_policy": 606.0137822149125}, "policy_reward_mean": {"prey_policy": 463.3559073358548, "predator_policy": 328.0103961681934}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1583.725673693803, 1316.5276085655607, 1714.2515287404956, 983.5622740640952, 1159.203730706597, 1470.68045577321, 1739.4286336476312, 1264.1863841747052, 1853.7322749079415, 1561.5199667042407, 1553.0494486560308, 1220.0326582401683, 1772.1786959105762, 1436.53635491879, 1407.2208522639023, 1486.276452594206, 1695.6842895873292, 1491.4621525125654, 1617.6281615575988, 1483.6959426596766, 1796.6716149981905, 1813.5195826384115, 1827.9500418770954, 1303.870227067024, 1502.7147034742602, 1626.6998899693476, 1581.802972786023, 1283.7114669384532, 1551.6427936343707, 1621.3827850664172, 1890.091470647017, 1015.6988349345434, 1527.7455283024367, 926.0845952965211, 1747.9216559699194, 1725.3292329004398, 1858.191911461919, 1209.9210422360607, 1599.5331056142884, 1536.0999728273416, 1350.52268167459, 1849.2406148239947, 1441.8039089807485, 1599.723134451632, 1379.8338058110642, 1173.3384598929663, 1775.5374531824923, 1645.0938753176379, 1411.043518829287, 1678.1652984937375, 1914.7625680547078, 1906.3964037660662, 1711.5097026416965, 1222.0976444823652, 1863.709926945196, 1596.5879195100315, 1638.9887634960526, 1637.880434965926, 1843.416113017602, 1701.0378226848243, 1473.8413941629915, 1900.3509343264527, 1902.5808979057654, 1842.5730556655228, 1797.5130537603184, 1677.748293641134, 1349.150195812877, 1541.3892315563924, 1484.4293238453386, 1802.4444178195338, 1567.0999975494626, 1844.5147723620337, 1915.9379329658173, 1624.530062034028, 1133.7019517711203, 1707.5609081957123, 1801.837877484541, 1722.5046132158784, 1739.6884417007175, 1626.9762145100194, 1598.1881325776212, 1476.7057375656125, 1439.642732474737, 1474.8335560775483, 1779.37129157314, 1512.5943432775607, 1516.500688692468, 1626.5125838767285, 1462.567876406653, 1055.1521542158991, 1984.9452339166853, 1722.6656013441375, 1650.890870512073, 1876.2677027855116, 1564.274176186461, 1690.592652153598, 1634.2410466446695, 1677.1135077386687, 1291.018594695643, 1684.9516282667446], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [396.29343814562424, 559.2048134728018, 356.0608861075322, 415.8566964404822, 430.2021117627151, 491.1863339894417, 410.0434613065781, 294.7612465918191, 393.0669603330141, 426.79202772961185, 472.77652261301375, 442.32966110092883, 613.8162841651304, 521.0481537074902, 390.6558864442985, 482.86380165191997, 459.2972005866076, 570.5423263397109, 444.91591193360136, 386.7996966062451, 400.48143142321004, 496.0869865306314, 562.8483796031823, 159.4551640849706, 405.35504597673355, 527.7011355638925, 284.1933751988655, 430.95513832129745, 544.4389351209347, 350.10805354791404, 518.5777293507091, 459.77130521886534, 335.227495584666, 649.6570787908902, 466.31172119768786, 446.84532098052443, 496.48346006323555, 466.39310010352614, 407.2387168135596, 311.2039294570815, 477.5231352819031, 500.77931962656663, 550.2985358271766, 388.9497473555964, 591.3889201597639, 492.43230519585376, 493.1726039376351, 307.7464713247117, 480.6701117006055, 587.2920349428226, 460.67450134438303, 605.3228297308606, 536.024468275855, 468.72007408609414, 490.60484597805697, 443.6009810053025, 439.8063988693491, 365.70318793532476, 387.7703875997529, 370.3517278647948, 550.280648513319, 588.2143326820803, 555.0607639061325, 15.17677276241436, 362.08589970098336, 385.39694947993416, 584.1504830266429, 189.79076292750278, 534.200363159652, 492.30875860007757, 514.7173331450656, 639.0576694980022, 553.0174589907137, 515.4475550315124, 517.8570791065507, 277.68082635369893, 359.11150251604676, 443.95754381848593, 380.4196946151265, 529.781257227803, 459.0446322277156, 425.2832226543951, 579.3471366296347, 451.60143121949596, 391.1490164898306, 450.2876914571484, 510.32073487440516, 461.366082469462, 617.3989394790595, 293.0421421331466, 548.0608309595585, 115.73510819354252, 522.9449101444698, 425.2523873286562, 399.6617478000249, 418.98183372930833, 406.86533392311276, 450.96508776039764, 469.4330139075267, 547.6460626114432, 439.1900252908546, 709.2383301167192, 320.08689770931966, 509.19310267999685, 430.23442416166637, 667.0297941432506, 440.4236698485307, 438.87721831193466, 561.7265053800149, 588.9841898320816, 577.8330404276245, 595.3846321144879, 565.7345664932446, 392.4681570503215, 548.3093681883098, 440.49743422614137, 566.7243766384538, 397.20090418958387, 465.2507000148517, 529.2697246654996, 445.945463741692, 584.2861634715115, 487.71987760722646, 573.3251662378136, 507.2692957466142, 546.6167766292468, 497.01621287993527, 506.61351540661025, 410.6531523390907, 478.5811492001434, 489.3867613907624, 599.7130917122694, 497.64320574180095, 487.9925528555925, 645.8234386971047, 429.6590241304398, 527.069353224078, 316.82222535848774, 388.4722001935441, 296.8474756757134, 404.8669618532399, 578.8600323008462, 590.5442235932032, 626.4437438887554, 593.8684364945951, 411.73990198099676, 373.1804294140199, 380.2166720299533, 165.28127067315586, 491.07830234614534, 472.4210964531079, 466.5039221890926, 460.1271350534353, 558.511651425803, 398.9301009499888, 439.9653494291654, 493.6721017336116, 482.59061523456364, 435.04877032275834, 411.27661185229783, 312.5048380692564, 424.07075045281056, 417.87054955849743, 452.98059555646705, 464.3763929891294, 478.0929126007631, 548.9458369268007, 334.2387426344535, 469.3747219902011, 552.682147554723, 440.3383292275685, 519.0035366492231, 436.7048358257103, 418.33329365610996, 478.1328921250901, 419.9304657457187, 305.259639890126, 656.8492059007124, 330.6134503394198, 478.44374805465117, 496.88870759723585, 608.2639013451709, 465.54559696480356, 459.0769972419569, 501.79409579650604, 531.091210977249, 495.1901628773769, 581.6153100324805, 436.71524336465865, 446.45117263100826, 442.91739397124866, 510.8227366951936, 552.3603980922684, 402.6437693418139, 323.7863441812164, 328.00681168994464, 525.2631404229304, 368.8343079088695, 502.89679979363603, 567.2494744992271], "policy_predator_policy_reward": [321.71615298817704, 306.51126908720033, 294.8844596470275, 249.72556637051952, 474.33262686756353, 318.53045612077386, 170.04277972653378, 108.71478643916471, 192.0523061317876, 147.29243651218496, 349.83912678858843, 205.7351452706788, 327.3867252982454, 277.17747047676727, 23.106628587581344, 367.56006749090517, 473.7741988031758, 350.1185491784471, 331.3487600180125, 398.455598146382, 200.2543953660097, 456.2266353361797, 352.35923481338557, 145.3698797386304, 440.0808690836686, 399.04164528628274, 304.6701819732902, 416.7176594253377, 208.3996453983151, 304.2742181967389, 241.76936859752385, 266.15804942710844, 333.77839328090164, 377.021321930871, 186.93961724624342, 391.36549308811027, 329.0661338824602, 325.6854675083771, 443.3372441033612, 321.9160522856752, 417.2433771969107, 401.12578289280987, 606.0137822149125, 268.2575172407258, 367.931333142039, 376.19748337943713, 321.81638716532956, 181.1347646393486, 259.7200411391904, 175.03251569164067, 180.7614395089517, 379.9411193851522, 317.09288229618033, 259.9655481278938, 253.13652577740382, 96.36911417769028, 362.6476672753121, 383.4855395543852, 499.26831164467626, 363.99235795719363, 378.83085861436535, 372.76563083725244, 260.9616342865856, 184.49966397941168, 376.9431095538218, 403.3195695676987, 5.909179614418862, 146.23416972795727, 377.9143079040729, 343.4982263061167, 297.75934610267905, 273.79488415469535, 463.986010872516, 325.74088656717765, 182.0920873391412, 232.29104943666943, 388.7921854884475, 407.67187379130957, 320.60182881871424, 305.2971921656983, 431.213814190759, 34.98101260172005, 528.9464749689662, 289.34557200589603, 361.30498937762405, 239.0622116561459, 256.2647000596538, 371.77161704811004, 202.1005778486127, 267.29214635024584, 326.8487912213843, 182.69372951848237, 456.1156991654318, 371.22445654393266, 487.5523187174835, 338.8979750708205, 262.7398359776156, 290.47326116816043, 377.7167284917414, 283.36949348302664, 438.2195354073888, 328.1146772397448, 527.923761913634, 549.1926414631164, 430.2029947335472, 184.04248960323386, 148.4947232811753, 194.3020330407243, 377.9425486227189, 335.05668311038164, -1.5007913335373537, 424.871038301455, 286.2146433349226, 394.5713966175647, 373.3809690346638, 275.6926635168108, 513.8926351339422, 365.5981970556195, 416.52975628542, 289.9876417190529, 269.6348968192713, 173.97487013051847, 382.33901474242884, 456.9668757389837, 406.86082327277086, 441.83400225713274, 490.64205967957173, 348.30126769940557, 474.2116753205911, 434.06707690049217, 226.2885086307673, 362.3599319073372, 169.22963312263755, 194.28480409284592, 268.2246600033633, 197.68210872548605, 267.4854671608316, 373.05227810194145, 571.8748582130361, 545.2498837372428, 293.28248452162603, 290.0905188737475, 412.8959281423752, 214.63087673770053, 431.8896923529243, 478.43990213730035, 440.94725129668575, 430.1857092933682, 280.8302162359917, 196.51216251582733, 355.8565084495046, 412.7793811040069, 382.5090637479027, 400.69002725739983, 438.8824907516701, 444.7266720850536, 317.96031472439375, 445.46541000814904, 338.26474478630274, 442.38608754866124, 403.43435453459534, 458.17818952096064, 282.7951700921045, 323.0594223585449, 249.8164449256066, 247.35698195923612, 214.26164049894234, 377.38733601735225, 344.00034152171344, 413.31408050650157, 307.4106532825627, 245.84182411820532, 372.32163335704854, 289.1409258535995, 374.130319778643, 354.31890622727485, 174.30510083238082, 326.15392978343215, 100.08673752266294, 146.00821829916558, 428.9525700125666, 450.840054961711, 450.2976055166322, 347.74540162074453, 300.9187784922917, 317.0867852460278, 331.5388329630408, 467.9233969126139, 260.1857067646227, 420.9220534261708, 403.0062880947862, 333.8462333923704, 382.7750185195568, 296.46186069103067, 440.526379045069, 584.7939728224379, 117.56326581875338, 279.35788054508924, 302.59255069918163, 312.21280327469924]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9892099661827543, "mean_inference_ms": 2.6522976422485685, "mean_action_processing_ms": 0.4093615439252447, "mean_env_wait_ms": 0.3695272093997371, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005138039588928223, "StateBufferConnector_ms": 0.004301190376281738, "ViewRequirementAgentConnector_ms": 0.11804342269897461}, "num_episodes": 18, "episode_return_max": 1984.9452339166853, "episode_return_min": 926.0845952965211, "episode_return_mean": 1582.732607008096, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 294.3887028065777, "num_env_steps_trained_throughput_per_sec": 294.3887028065777, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 14348.417, "restore_workers_time_ms": 0.018, "training_step_time_ms": 14348.348, "sample_time_ms": 1913.24, "learn_time_ms": 12409.018, "learn_throughput": 322.346, "synch_weights_time_ms": 23.661}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "479e5_00000", "date": "2024-08-16_11-29-39", "timestamp": 1723787979, "time_this_iter_s": 13.623185157775879, "time_total_s": 173.42799067497253, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78e5e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 173.42799067497253, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 60.53500000000001, "ram_util_percent": 82.27000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1253021877121043, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.763062671378806, "policy_loss": -0.009819596763774162, "vf_loss": 9.771342053993669, "vf_explained_var": -0.01151720714316797, "kl": 0.015402042058790451, "entropy": 1.4695450990919083, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4195423039809736, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.801924254906872, "policy_loss": -0.006135435325275889, "vf_loss": 9.806312966220593, "vf_explained_var": 0.0018523945064141006, "kl": 0.017467136408977135, "entropy": 1.4615204981395176, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 1984.9452339166853, "episode_reward_min": 926.0845952965211, "episode_reward_mean": 1608.291781408054, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 15.17677276241436, "predator_policy": -1.5007913335373537}, "policy_reward_max": {"prey_policy": 709.2383301167192, "predator_policy": 606.0137822149125}, "policy_reward_mean": {"prey_policy": 467.36236147113306, "predator_policy": 336.7835292328939}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1617.6281615575988, 1483.6959426596766, 1796.6716149981905, 1813.5195826384115, 1827.9500418770954, 1303.870227067024, 1502.7147034742602, 1626.6998899693476, 1581.802972786023, 1283.7114669384532, 1551.6427936343707, 1621.3827850664172, 1890.091470647017, 1015.6988349345434, 1527.7455283024367, 926.0845952965211, 1747.9216559699194, 1725.3292329004398, 1858.191911461919, 1209.9210422360607, 1599.5331056142884, 1536.0999728273416, 1350.52268167459, 1849.2406148239947, 1441.8039089807485, 1599.723134451632, 1379.8338058110642, 1173.3384598929663, 1775.5374531824923, 1645.0938753176379, 1411.043518829287, 1678.1652984937375, 1914.7625680547078, 1906.3964037660662, 1711.5097026416965, 1222.0976444823652, 1863.709926945196, 1596.5879195100315, 1638.9887634960526, 1637.880434965926, 1843.416113017602, 1701.0378226848243, 1473.8413941629915, 1900.3509343264527, 1902.5808979057654, 1842.5730556655228, 1797.5130537603184, 1677.748293641134, 1349.150195812877, 1541.3892315563924, 1484.4293238453386, 1802.4444178195338, 1567.0999975494626, 1844.5147723620337, 1915.9379329658173, 1624.530062034028, 1133.7019517711203, 1707.5609081957123, 1801.837877484541, 1722.5046132158784, 1739.6884417007175, 1626.9762145100194, 1598.1881325776212, 1476.7057375656125, 1439.642732474737, 1474.8335560775483, 1779.37129157314, 1512.5943432775607, 1516.500688692468, 1626.5125838767285, 1462.567876406653, 1055.1521542158991, 1984.9452339166853, 1722.6656013441375, 1650.890870512073, 1876.2677027855116, 1564.274176186461, 1690.592652153598, 1634.2410466446695, 1677.1135077386687, 1291.018594695643, 1684.9516282667446, 1445.4509800187423, 1800.7946308951675, 1235.600493735, 1807.0301113604678, 1574.9018382149052, 1263.1345979211844, 1662.8239233977934, 1829.617952625295, 1802.7110113587892, 1629.348413548807, 1232.7168928469048, 1805.3529252504557, 1775.615570099642, 1836.499395773484, 1597.2162061568872, 1727.8662487351837, 1504.5318520271699, 1733.963831691718], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [496.48346006323555, 466.39310010352614, 407.2387168135596, 311.2039294570815, 477.5231352819031, 500.77931962656663, 550.2985358271766, 388.9497473555964, 591.3889201597639, 492.43230519585376, 493.1726039376351, 307.7464713247117, 480.6701117006055, 587.2920349428226, 460.67450134438303, 605.3228297308606, 536.024468275855, 468.72007408609414, 490.60484597805697, 443.6009810053025, 439.8063988693491, 365.70318793532476, 387.7703875997529, 370.3517278647948, 550.280648513319, 588.2143326820803, 555.0607639061325, 15.17677276241436, 362.08589970098336, 385.39694947993416, 584.1504830266429, 189.79076292750278, 534.200363159652, 492.30875860007757, 514.7173331450656, 639.0576694980022, 553.0174589907137, 515.4475550315124, 517.8570791065507, 277.68082635369893, 359.11150251604676, 443.95754381848593, 380.4196946151265, 529.781257227803, 459.0446322277156, 425.2832226543951, 579.3471366296347, 451.60143121949596, 391.1490164898306, 450.2876914571484, 510.32073487440516, 461.366082469462, 617.3989394790595, 293.0421421331466, 548.0608309595585, 115.73510819354252, 522.9449101444698, 425.2523873286562, 399.6617478000249, 418.98183372930833, 406.86533392311276, 450.96508776039764, 469.4330139075267, 547.6460626114432, 439.1900252908546, 709.2383301167192, 320.08689770931966, 509.19310267999685, 430.23442416166637, 667.0297941432506, 440.4236698485307, 438.87721831193466, 561.7265053800149, 588.9841898320816, 577.8330404276245, 595.3846321144879, 565.7345664932446, 392.4681570503215, 548.3093681883098, 440.49743422614137, 566.7243766384538, 397.20090418958387, 465.2507000148517, 529.2697246654996, 445.945463741692, 584.2861634715115, 487.71987760722646, 573.3251662378136, 507.2692957466142, 546.6167766292468, 497.01621287993527, 506.61351540661025, 410.6531523390907, 478.5811492001434, 489.3867613907624, 599.7130917122694, 497.64320574180095, 487.9925528555925, 645.8234386971047, 429.6590241304398, 527.069353224078, 316.82222535848774, 388.4722001935441, 296.8474756757134, 404.8669618532399, 578.8600323008462, 590.5442235932032, 626.4437438887554, 593.8684364945951, 411.73990198099676, 373.1804294140199, 380.2166720299533, 165.28127067315586, 491.07830234614534, 472.4210964531079, 466.5039221890926, 460.1271350534353, 558.511651425803, 398.9301009499888, 439.9653494291654, 493.6721017336116, 482.59061523456364, 435.04877032275834, 411.27661185229783, 312.5048380692564, 424.07075045281056, 417.87054955849743, 452.98059555646705, 464.3763929891294, 478.0929126007631, 548.9458369268007, 334.2387426344535, 469.3747219902011, 552.682147554723, 440.3383292275685, 519.0035366492231, 436.7048358257103, 418.33329365610996, 478.1328921250901, 419.9304657457187, 305.259639890126, 656.8492059007124, 330.6134503394198, 478.44374805465117, 496.88870759723585, 608.2639013451709, 465.54559696480356, 459.0769972419569, 501.79409579650604, 531.091210977249, 495.1901628773769, 581.6153100324805, 436.71524336465865, 446.45117263100826, 442.91739397124866, 510.8227366951936, 552.3603980922684, 402.6437693418139, 323.7863441812164, 328.00681168994464, 525.2631404229304, 368.8343079088695, 502.89679979363603, 567.2494744992271, 398.8275689540081, 331.8282125891172, 391.8852523236349, 551.3263413286345, 278.8703686934377, 523.6889164173365, 485.26005421748647, 454.79700723110204, 394.14083416220234, 525.1491566180366, 364.3826140005224, 545.3422967980581, 541.8197878396951, 259.7346215824314, 617.1353070451719, 439.00671811064694, 513.5635985037209, 459.7859106985708, 503.83088323154743, 393.3166097390659, 428.1349229800423, 492.9300117269167, 600.5798833746051, 521.5395689880505, 418.1246758710136, 532.2642158771716, 642.759086008207, 562.1996545758619, 472.39984946056563, 317.0914363251998, 442.6507378325307, 464.3029369919342, 610.0125484979071, 510.01176767487044, 478.73923928033645, 330.38594902955214], "policy_predator_policy_reward": [329.0661338824602, 325.6854675083771, 443.3372441033612, 321.9160522856752, 417.2433771969107, 401.12578289280987, 606.0137822149125, 268.2575172407258, 367.931333142039, 376.19748337943713, 321.81638716532956, 181.1347646393486, 259.7200411391904, 175.03251569164067, 180.7614395089517, 379.9411193851522, 317.09288229618033, 259.9655481278938, 253.13652577740382, 96.36911417769028, 362.6476672753121, 383.4855395543852, 499.26831164467626, 363.99235795719363, 378.83085861436535, 372.76563083725244, 260.9616342865856, 184.49966397941168, 376.9431095538218, 403.3195695676987, 5.909179614418862, 146.23416972795727, 377.9143079040729, 343.4982263061167, 297.75934610267905, 273.79488415469535, 463.986010872516, 325.74088656717765, 182.0920873391412, 232.29104943666943, 388.7921854884475, 407.67187379130957, 320.60182881871424, 305.2971921656983, 431.213814190759, 34.98101260172005, 528.9464749689662, 289.34557200589603, 361.30498937762405, 239.0622116561459, 256.2647000596538, 371.77161704811004, 202.1005778486127, 267.29214635024584, 326.8487912213843, 182.69372951848237, 456.1156991654318, 371.22445654393266, 487.5523187174835, 338.8979750708205, 262.7398359776156, 290.47326116816043, 377.7167284917414, 283.36949348302664, 438.2195354073888, 328.1146772397448, 527.923761913634, 549.1926414631164, 430.2029947335472, 184.04248960323386, 148.4947232811753, 194.3020330407243, 377.9425486227189, 335.05668311038164, -1.5007913335373537, 424.871038301455, 286.2146433349226, 394.5713966175647, 373.3809690346638, 275.6926635168108, 513.8926351339422, 365.5981970556195, 416.52975628542, 289.9876417190529, 269.6348968192713, 173.97487013051847, 382.33901474242884, 456.9668757389837, 406.86082327277086, 441.83400225713274, 490.64205967957173, 348.30126769940557, 474.2116753205911, 434.06707690049217, 226.2885086307673, 362.3599319073372, 169.22963312263755, 194.28480409284592, 268.2246600033633, 197.68210872548605, 267.4854671608316, 373.05227810194145, 571.8748582130361, 545.2498837372428, 293.28248452162603, 290.0905188737475, 412.8959281423752, 214.63087673770053, 431.8896923529243, 478.43990213730035, 440.94725129668575, 430.1857092933682, 280.8302162359917, 196.51216251582733, 355.8565084495046, 412.7793811040069, 382.5090637479027, 400.69002725739983, 438.8824907516701, 444.7266720850536, 317.96031472439375, 445.46541000814904, 338.26474478630274, 442.38608754866124, 403.43435453459534, 458.17818952096064, 282.7951700921045, 323.0594223585449, 249.8164449256066, 247.35698195923612, 214.26164049894234, 377.38733601735225, 344.00034152171344, 413.31408050650157, 307.4106532825627, 245.84182411820532, 372.32163335704854, 289.1409258535995, 374.130319778643, 354.31890622727485, 174.30510083238082, 326.15392978343215, 100.08673752266294, 146.00821829916558, 428.9525700125666, 450.840054961711, 450.2976055166322, 347.74540162074453, 300.9187784922917, 317.0867852460278, 331.5388329630408, 467.9233969126139, 260.1857067646227, 420.9220534261708, 403.0062880947862, 333.8462333923704, 382.7750185195568, 296.46186069103067, 440.526379045069, 584.7939728224379, 117.56326581875338, 279.35788054508924, 302.59255069918163, 312.21280327469924, 320.7805156737388, 394.0146828018789, 391.47670214746887, 466.1063350954277, 157.0737241936621, 275.96748443056487, 365.0569840500108, 501.9160658618677, 225.43538253339972, 430.17646490126515, 190.48553958245685, 162.9241475401454, 495.10345618474213, 366.16605779092555, 506.90377529625357, 266.57215217322374, 446.99843779269855, 382.363064363801, 388.10451796668417, 344.0964026115097, 176.12069085130997, 135.5312672886368, 425.0577915633438, 258.17568132445524, 329.8657622892641, 495.3609160621916, 375.8647084319441, 255.67594675746886, 406.19837567913254, 401.52654469199024, 336.04371314639985, 484.86886076431847, 118.79077536154652, 265.71676049284605, 483.28667976041294, 441.5519636214186]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9641022555669565, "mean_inference_ms": 2.582125718233092, "mean_action_processing_ms": 0.39937894459477086, "mean_env_wait_ms": 0.36019239682939386, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004929542541503906, "StateBufferConnector_ms": 0.004310727119445801, "ViewRequirementAgentConnector_ms": 0.1282057762145996}, "num_episodes": 18, "episode_return_max": 1984.9452339166853, "episode_return_min": 926.0845952965211, "episode_return_mean": 1608.291781408054, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 294.4676132884922, "num_env_steps_trained_throughput_per_sec": 294.4676132884922, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 14242.929, "restore_workers_time_ms": 0.018, "training_step_time_ms": 14242.86, "sample_time_ms": 1825.713, "learn_time_ms": 12392.887, "learn_throughput": 322.766, "synch_weights_time_ms": 21.941}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "479e5_00000", "date": "2024-08-16_11-29-52", "timestamp": 1723787992, "time_this_iter_s": 13.63838005065918, "time_total_s": 187.0663707256317, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7817550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 187.0663707256317, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 62.68947368421053, "ram_util_percent": 82.39473684210526}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4533814303458683, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.428853384653728, "policy_loss": -0.010242800921246055, "vf_loss": 9.4373726970935, "vf_explained_var": -0.004982637286816955, "kl": 0.017234883982378147, "entropy": 1.4462803677276328, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7390092659564245, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.590717103241612, "policy_loss": -0.00489880613250924, "vf_loss": 9.593597752202756, "vf_explained_var": 0.00020561905765028858, "kl": 0.0201811868438312, "entropy": 1.4689084054931763, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 1985.3172883348832, "episode_reward_min": 1055.1521542158991, "episode_reward_mean": 1646.1729498704694, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 115.73510819354252, "predator_policy": -1.5007913335373537}, "policy_reward_max": {"prey_policy": 709.2383301167192, "predator_policy": 622.6685449585667}, "policy_reward_mean": {"prey_policy": 463.31932990377123, "predator_policy": 359.76714503146343}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1173.3384598929663, 1775.5374531824923, 1645.0938753176379, 1411.043518829287, 1678.1652984937375, 1914.7625680547078, 1906.3964037660662, 1711.5097026416965, 1222.0976444823652, 1863.709926945196, 1596.5879195100315, 1638.9887634960526, 1637.880434965926, 1843.416113017602, 1701.0378226848243, 1473.8413941629915, 1900.3509343264527, 1902.5808979057654, 1842.5730556655228, 1797.5130537603184, 1677.748293641134, 1349.150195812877, 1541.3892315563924, 1484.4293238453386, 1802.4444178195338, 1567.0999975494626, 1844.5147723620337, 1915.9379329658173, 1624.530062034028, 1133.7019517711203, 1707.5609081957123, 1801.837877484541, 1722.5046132158784, 1739.6884417007175, 1626.9762145100194, 1598.1881325776212, 1476.7057375656125, 1439.642732474737, 1474.8335560775483, 1779.37129157314, 1512.5943432775607, 1516.500688692468, 1626.5125838767285, 1462.567876406653, 1055.1521542158991, 1984.9452339166853, 1722.6656013441375, 1650.890870512073, 1876.2677027855116, 1564.274176186461, 1690.592652153598, 1634.2410466446695, 1677.1135077386687, 1291.018594695643, 1684.9516282667446, 1445.4509800187423, 1800.7946308951675, 1235.600493735, 1807.0301113604678, 1574.9018382149052, 1263.1345979211844, 1662.8239233977934, 1829.617952625295, 1802.7110113587892, 1629.348413548807, 1232.7168928469048, 1805.3529252504557, 1775.615570099642, 1836.499395773484, 1597.2162061568872, 1727.8662487351837, 1504.5318520271699, 1733.963831691718, 1859.716749264427, 1471.537182355339, 1439.3854191660478, 1821.846497523609, 1368.5342267389167, 1651.977110766485, 1817.085821795034, 1786.562624262481, 1352.8540363114482, 1895.8412696014323, 1716.8080916311073, 1619.4112565015275, 1939.298126920208, 1764.8044196320134, 1744.9356996386298, 1561.1286214591319, 1624.605693328783, 1704.6369403500146, 1406.1126948088206, 1928.4327092481817, 1444.5656549339494, 1636.5133536704477, 1670.7489618547716, 1507.8229558658052, 1807.8083819784426, 1928.8567368989948, 1985.3172883348832], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [548.0608309595585, 115.73510819354252, 522.9449101444698, 425.2523873286562, 399.6617478000249, 418.98183372930833, 406.86533392311276, 450.96508776039764, 469.4330139075267, 547.6460626114432, 439.1900252908546, 709.2383301167192, 320.08689770931966, 509.19310267999685, 430.23442416166637, 667.0297941432506, 440.4236698485307, 438.87721831193466, 561.7265053800149, 588.9841898320816, 577.8330404276245, 595.3846321144879, 565.7345664932446, 392.4681570503215, 548.3093681883098, 440.49743422614137, 566.7243766384538, 397.20090418958387, 465.2507000148517, 529.2697246654996, 445.945463741692, 584.2861634715115, 487.71987760722646, 573.3251662378136, 507.2692957466142, 546.6167766292468, 497.01621287993527, 506.61351540661025, 410.6531523390907, 478.5811492001434, 489.3867613907624, 599.7130917122694, 497.64320574180095, 487.9925528555925, 645.8234386971047, 429.6590241304398, 527.069353224078, 316.82222535848774, 388.4722001935441, 296.8474756757134, 404.8669618532399, 578.8600323008462, 590.5442235932032, 626.4437438887554, 593.8684364945951, 411.73990198099676, 373.1804294140199, 380.2166720299533, 165.28127067315586, 491.07830234614534, 472.4210964531079, 466.5039221890926, 460.1271350534353, 558.511651425803, 398.9301009499888, 439.9653494291654, 493.6721017336116, 482.59061523456364, 435.04877032275834, 411.27661185229783, 312.5048380692564, 424.07075045281056, 417.87054955849743, 452.98059555646705, 464.3763929891294, 478.0929126007631, 548.9458369268007, 334.2387426344535, 469.3747219902011, 552.682147554723, 440.3383292275685, 519.0035366492231, 436.7048358257103, 418.33329365610996, 478.1328921250901, 419.9304657457187, 305.259639890126, 656.8492059007124, 330.6134503394198, 478.44374805465117, 496.88870759723585, 608.2639013451709, 465.54559696480356, 459.0769972419569, 501.79409579650604, 531.091210977249, 495.1901628773769, 581.6153100324805, 436.71524336465865, 446.45117263100826, 442.91739397124866, 510.8227366951936, 552.3603980922684, 402.6437693418139, 323.7863441812164, 328.00681168994464, 525.2631404229304, 368.8343079088695, 502.89679979363603, 567.2494744992271, 398.8275689540081, 331.8282125891172, 391.8852523236349, 551.3263413286345, 278.8703686934377, 523.6889164173365, 485.26005421748647, 454.79700723110204, 394.14083416220234, 525.1491566180366, 364.3826140005224, 545.3422967980581, 541.8197878396951, 259.7346215824314, 617.1353070451719, 439.00671811064694, 513.5635985037209, 459.7859106985708, 503.83088323154743, 393.3166097390659, 428.1349229800423, 492.9300117269167, 600.5798833746051, 521.5395689880505, 418.1246758710136, 532.2642158771716, 642.759086008207, 562.1996545758619, 472.39984946056563, 317.0914363251998, 442.6507378325307, 464.3029369919342, 610.0125484979071, 510.01176767487044, 478.73923928033645, 330.38594902955214, 406.9714158260439, 518.518204019355, 252.31940686423542, 316.67401372126346, 465.5323080292692, 368.3994806425622, 473.76934451828333, 442.79790446753714, 353.58262286392, 555.6218379888074, 465.5257196507795, 384.8470429602671, 490.1307488827887, 385.29998346832724, 536.4581332087046, 646.3872091808419, 474.2748010174714, 387.4642827829782, 596.4155155829327, 427.0166878306849, 271.2145364043235, 447.8914111177411, 527.5924900722877, 280.5754800041943, 386.34271966306824, 356.7708614060545, 440.4593581886015, 504.95746726395157, 526.2375065665541, 537.7237417011678, 333.52458135027166, 603.5191892864067, 395.2180855075894, 562.6529284085336, 574.3766419644428, 465.3334762695095, 282.9992191751022, 329.3894735824998, 347.08253243258105, 503.39432876417135, 418.4841880197379, 372.940202477685, 393.86425218621287, 470.0492616985345, 545.2845582459997, 310.7725202649008, 403.78720634820246, 419.9531396677386, 516.8963626590954, 576.107114700422, 321.3422016671263, 522.8224974575025, 576.2602658633633, 464.27370181085166], "policy_predator_policy_reward": [326.8487912213843, 182.69372951848237, 456.1156991654318, 371.22445654393266, 487.5523187174835, 338.8979750708205, 262.7398359776156, 290.47326116816043, 377.7167284917414, 283.36949348302664, 438.2195354073888, 328.1146772397448, 527.923761913634, 549.1926414631164, 430.2029947335472, 184.04248960323386, 148.4947232811753, 194.3020330407243, 377.9425486227189, 335.05668311038164, -1.5007913335373537, 424.871038301455, 286.2146433349226, 394.5713966175647, 373.3809690346638, 275.6926635168108, 513.8926351339422, 365.5981970556195, 416.52975628542, 289.9876417190529, 269.6348968192713, 173.97487013051847, 382.33901474242884, 456.9668757389837, 406.86082327277086, 441.83400225713274, 490.64205967957173, 348.30126769940557, 474.2116753205911, 434.06707690049217, 226.2885086307673, 362.3599319073372, 169.22963312263755, 194.28480409284592, 268.2246600033633, 197.68210872548605, 267.4854671608316, 373.05227810194145, 571.8748582130361, 545.2498837372428, 293.28248452162603, 290.0905188737475, 412.8959281423752, 214.63087673770053, 431.8896923529243, 478.43990213730035, 440.94725129668575, 430.1857092933682, 280.8302162359917, 196.51216251582733, 355.8565084495046, 412.7793811040069, 382.5090637479027, 400.69002725739983, 438.8824907516701, 444.7266720850536, 317.96031472439375, 445.46541000814904, 338.26474478630274, 442.38608754866124, 403.43435453459534, 458.17818952096064, 282.7951700921045, 323.0594223585449, 249.8164449256066, 247.35698195923612, 214.26164049894234, 377.38733601735225, 344.00034152171344, 413.31408050650157, 307.4106532825627, 245.84182411820532, 372.32163335704854, 289.1409258535995, 374.130319778643, 354.31890622727485, 174.30510083238082, 326.15392978343215, 100.08673752266294, 146.00821829916558, 428.9525700125666, 450.840054961711, 450.2976055166322, 347.74540162074453, 300.9187784922917, 317.0867852460278, 331.5388329630408, 467.9233969126139, 260.1857067646227, 420.9220534261708, 403.0062880947862, 333.8462333923704, 382.7750185195568, 296.46186069103067, 440.526379045069, 584.7939728224379, 117.56326581875338, 279.35788054508924, 302.59255069918163, 312.21280327469924, 320.7805156737388, 394.0146828018789, 391.47670214746887, 466.1063350954277, 157.0737241936621, 275.96748443056487, 365.0569840500108, 501.9160658618677, 225.43538253339972, 430.17646490126515, 190.48553958245685, 162.9241475401454, 495.10345618474213, 366.16605779092555, 506.90377529625357, 266.57215217322374, 446.99843779269855, 382.363064363801, 388.10451796668417, 344.0964026115097, 176.12069085130997, 135.5312672886368, 425.0577915633438, 258.17568132445524, 329.8657622892641, 495.3609160621916, 375.8647084319441, 255.67594675746886, 406.19837567913254, 401.52654469199024, 336.04371314639985, 484.86886076431847, 118.79077536154652, 265.71676049284605, 483.28667976041294, 441.5519636214186, 475.9246738691709, 458.30245554985817, 431.9340583779665, 470.609703391874, 418.9076265858615, 186.5460039083542, 435.4781292858311, 469.8011192519584, 256.53892391519884, 202.79084197099084, 399.8264859825008, 401.7778621729367, 465.54178954220606, 476.1132999017116, 344.82243276338284, 258.89484910955076, 219.79854149517797, 271.3164110158208, 488.1612272362301, 384.24783895158595, 375.0335991504771, 622.6685449585667, 391.01126662691973, 420.2320197981266, 606.6865920640593, 589.4979537870236, 504.83982471233287, 314.5477694671259, 324.66400812908364, 356.31044324182415, 301.0378939978267, 323.0469568246261, 257.49332752433844, 409.2413518883229, 433.4531211172435, 231.47370099881906, 361.1807445611679, 432.5432574900505, 476.0048204689635, 601.9510275824657, 272.733138414558, 380.408126021969, 434.957410947756, 337.64242883794685, 304.2359155062918, 510.45596783757924, 415.17022118438354, 268.9123886654814, 382.22466841041575, 332.58023620850844, 542.7221214396844, 541.9699163346841, 512.8649997944408, 431.91832086622594]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9343888463638982, "mean_inference_ms": 2.4963071206405782, "mean_action_processing_ms": 0.3869893222633406, "mean_env_wait_ms": 0.3476761997407465, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0050852298736572266, "StateBufferConnector_ms": 0.004459500312805176, "ViewRequirementAgentConnector_ms": 0.12017309665679932}, "num_episodes": 27, "episode_return_max": 1985.3172883348832, "episode_return_min": 1055.1521542158991, "episode_return_mean": 1646.1729498704694, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 287.8345810894137, "num_env_steps_trained_throughput_per_sec": 287.8345810894137, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 14157.216, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14157.152, "sample_time_ms": 1654.507, "learn_time_ms": 12480.65, "learn_throughput": 320.496, "synch_weights_time_ms": 19.443}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "479e5_00000", "date": "2024-08-16_11-30-06", "timestamp": 1723788006, "time_this_iter_s": 13.951403141021729, "time_total_s": 201.01777386665344, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78a0550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 201.01777386665344, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 62.44, "ram_util_percent": 82.435}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3345642700870202, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.701172005688703, "policy_loss": -0.010131692510743738, "vf_loss": 9.709568080195675, "vf_explained_var": -0.0040851903340173145, "kl": 0.01735615527692187, "entropy": 1.4429052814604744, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4868752147627886, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.789498771687665, "policy_loss": -0.005556603884398346, "vf_loss": 9.793298272733335, "vf_explained_var": 0.003832358657998383, "kl": 0.011714097988302846, "entropy": 1.4906263839000116, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 1985.3172883348832, "episode_reward_min": 1055.1521542158991, "episode_reward_mean": 1647.52258936392, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 165.28127067315586, "predator_policy": 100.08673752266294}, "policy_reward_max": {"prey_policy": 691.9377112768749, "predator_policy": 622.6685449585667}, "policy_reward_mean": {"prey_policy": 458.6639996389112, "predator_policy": 365.09729504304863}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1842.5730556655228, 1797.5130537603184, 1677.748293641134, 1349.150195812877, 1541.3892315563924, 1484.4293238453386, 1802.4444178195338, 1567.0999975494626, 1844.5147723620337, 1915.9379329658173, 1624.530062034028, 1133.7019517711203, 1707.5609081957123, 1801.837877484541, 1722.5046132158784, 1739.6884417007175, 1626.9762145100194, 1598.1881325776212, 1476.7057375656125, 1439.642732474737, 1474.8335560775483, 1779.37129157314, 1512.5943432775607, 1516.500688692468, 1626.5125838767285, 1462.567876406653, 1055.1521542158991, 1984.9452339166853, 1722.6656013441375, 1650.890870512073, 1876.2677027855116, 1564.274176186461, 1690.592652153598, 1634.2410466446695, 1677.1135077386687, 1291.018594695643, 1684.9516282667446, 1445.4509800187423, 1800.7946308951675, 1235.600493735, 1807.0301113604678, 1574.9018382149052, 1263.1345979211844, 1662.8239233977934, 1829.617952625295, 1802.7110113587892, 1629.348413548807, 1232.7168928469048, 1805.3529252504557, 1775.615570099642, 1836.499395773484, 1597.2162061568872, 1727.8662487351837, 1504.5318520271699, 1733.963831691718, 1859.716749264427, 1471.537182355339, 1439.3854191660478, 1821.846497523609, 1368.5342267389167, 1651.977110766485, 1817.085821795034, 1786.562624262481, 1352.8540363114482, 1895.8412696014323, 1716.8080916311073, 1619.4112565015275, 1939.298126920208, 1764.8044196320134, 1744.9356996386298, 1561.1286214591319, 1624.605693328783, 1704.6369403500146, 1406.1126948088206, 1928.4327092481817, 1444.5656549339494, 1636.5133536704477, 1670.7489618547716, 1507.8229558658052, 1807.8083819784426, 1928.8567368989948, 1985.3172883348832, 1481.0703086828064, 1680.0636812818364, 1653.9099611747572, 1839.3533697713258, 1658.774509281829, 1455.353704093864, 1547.4616735712168, 1653.611376163862, 1433.0250171912132, 1765.9424694087193, 1564.8256328580694, 1848.0691824297849, 1707.559841821865, 1798.5170312890057, 1875.0782596677511, 1661.0070081891267, 1567.8034036199276, 1939.87665052385], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [497.01621287993527, 506.61351540661025, 410.6531523390907, 478.5811492001434, 489.3867613907624, 599.7130917122694, 497.64320574180095, 487.9925528555925, 645.8234386971047, 429.6590241304398, 527.069353224078, 316.82222535848774, 388.4722001935441, 296.8474756757134, 404.8669618532399, 578.8600323008462, 590.5442235932032, 626.4437438887554, 593.8684364945951, 411.73990198099676, 373.1804294140199, 380.2166720299533, 165.28127067315586, 491.07830234614534, 472.4210964531079, 466.5039221890926, 460.1271350534353, 558.511651425803, 398.9301009499888, 439.9653494291654, 493.6721017336116, 482.59061523456364, 435.04877032275834, 411.27661185229783, 312.5048380692564, 424.07075045281056, 417.87054955849743, 452.98059555646705, 464.3763929891294, 478.0929126007631, 548.9458369268007, 334.2387426344535, 469.3747219902011, 552.682147554723, 440.3383292275685, 519.0035366492231, 436.7048358257103, 418.33329365610996, 478.1328921250901, 419.9304657457187, 305.259639890126, 656.8492059007124, 330.6134503394198, 478.44374805465117, 496.88870759723585, 608.2639013451709, 465.54559696480356, 459.0769972419569, 501.79409579650604, 531.091210977249, 495.1901628773769, 581.6153100324805, 436.71524336465865, 446.45117263100826, 442.91739397124866, 510.8227366951936, 552.3603980922684, 402.6437693418139, 323.7863441812164, 328.00681168994464, 525.2631404229304, 368.8343079088695, 502.89679979363603, 567.2494744992271, 398.8275689540081, 331.8282125891172, 391.8852523236349, 551.3263413286345, 278.8703686934377, 523.6889164173365, 485.26005421748647, 454.79700723110204, 394.14083416220234, 525.1491566180366, 364.3826140005224, 545.3422967980581, 541.8197878396951, 259.7346215824314, 617.1353070451719, 439.00671811064694, 513.5635985037209, 459.7859106985708, 503.83088323154743, 393.3166097390659, 428.1349229800423, 492.9300117269167, 600.5798833746051, 521.5395689880505, 418.1246758710136, 532.2642158771716, 642.759086008207, 562.1996545758619, 472.39984946056563, 317.0914363251998, 442.6507378325307, 464.3029369919342, 610.0125484979071, 510.01176767487044, 478.73923928033645, 330.38594902955214, 406.9714158260439, 518.518204019355, 252.31940686423542, 316.67401372126346, 465.5323080292692, 368.3994806425622, 473.76934451828333, 442.79790446753714, 353.58262286392, 555.6218379888074, 465.5257196507795, 384.8470429602671, 490.1307488827887, 385.29998346832724, 536.4581332087046, 646.3872091808419, 474.2748010174714, 387.4642827829782, 596.4155155829327, 427.0166878306849, 271.2145364043235, 447.8914111177411, 527.5924900722877, 280.5754800041943, 386.34271966306824, 356.7708614060545, 440.4593581886015, 504.95746726395157, 526.2375065665541, 537.7237417011678, 333.52458135027166, 603.5191892864067, 395.2180855075894, 562.6529284085336, 574.3766419644428, 465.3334762695095, 282.9992191751022, 329.3894735824998, 347.08253243258105, 503.39432876417135, 418.4841880197379, 372.940202477685, 393.86425218621287, 470.0492616985345, 545.2845582459997, 310.7725202649008, 403.78720634820246, 419.9531396677386, 516.8963626590954, 576.107114700422, 321.3422016671263, 522.8224974575025, 576.2602658633633, 464.27370181085166, 456.2544587375914, 323.68656678199784, 421.16972829847975, 411.3058152949848, 454.50726455378344, 656.9952380890493, 497.22333499189205, 468.92788415093236, 339.69348410784477, 530.6928148581443, 436.97928006287884, 691.9377112768749, 348.7355827473831, 428.11789357302104, 544.328292234593, 473.69381763683987, 467.12004159000065, 298.9832009252612, 532.4901908674472, 474.9422597786339, 626.0946595210614, 464.07848864618126, 490.10884949327715, 452.8698328432951, 514.4071117886954, 368.4494854860174, 491.06687288025967, 481.06551713379565, 496.37305978884234, 349.5833463338597, 615.6589806102432, 275.06483821591576, 326.3671053991725, 485.43058243002696, 447.94515309820343, 560.9513240765588], "policy_predator_policy_reward": [490.64205967957173, 348.30126769940557, 474.2116753205911, 434.06707690049217, 226.2885086307673, 362.3599319073372, 169.22963312263755, 194.28480409284592, 268.2246600033633, 197.68210872548605, 267.4854671608316, 373.05227810194145, 571.8748582130361, 545.2498837372428, 293.28248452162603, 290.0905188737475, 412.8959281423752, 214.63087673770053, 431.8896923529243, 478.43990213730035, 440.94725129668575, 430.1857092933682, 280.8302162359917, 196.51216251582733, 355.8565084495046, 412.7793811040069, 382.5090637479027, 400.69002725739983, 438.8824907516701, 444.7266720850536, 317.96031472439375, 445.46541000814904, 338.26474478630274, 442.38608754866124, 403.43435453459534, 458.17818952096064, 282.7951700921045, 323.0594223585449, 249.8164449256066, 247.35698195923612, 214.26164049894234, 377.38733601735225, 344.00034152171344, 413.31408050650157, 307.4106532825627, 245.84182411820532, 372.32163335704854, 289.1409258535995, 374.130319778643, 354.31890622727485, 174.30510083238082, 326.15392978343215, 100.08673752266294, 146.00821829916558, 428.9525700125666, 450.840054961711, 450.2976055166322, 347.74540162074453, 300.9187784922917, 317.0867852460278, 331.5388329630408, 467.9233969126139, 260.1857067646227, 420.9220534261708, 403.0062880947862, 333.8462333923704, 382.7750185195568, 296.46186069103067, 440.526379045069, 584.7939728224379, 117.56326581875338, 279.35788054508924, 302.59255069918163, 312.21280327469924, 320.7805156737388, 394.0146828018789, 391.47670214746887, 466.1063350954277, 157.0737241936621, 275.96748443056487, 365.0569840500108, 501.9160658618677, 225.43538253339972, 430.17646490126515, 190.48553958245685, 162.9241475401454, 495.10345618474213, 366.16605779092555, 506.90377529625357, 266.57215217322374, 446.99843779269855, 382.363064363801, 388.10451796668417, 344.0964026115097, 176.12069085130997, 135.5312672886368, 425.0577915633438, 258.17568132445524, 329.8657622892641, 495.3609160621916, 375.8647084319441, 255.67594675746886, 406.19837567913254, 401.52654469199024, 336.04371314639985, 484.86886076431847, 118.79077536154652, 265.71676049284605, 483.28667976041294, 441.5519636214186, 475.9246738691709, 458.30245554985817, 431.9340583779665, 470.609703391874, 418.9076265858615, 186.5460039083542, 435.4781292858311, 469.8011192519584, 256.53892391519884, 202.79084197099084, 399.8264859825008, 401.7778621729367, 465.54178954220606, 476.1132999017116, 344.82243276338284, 258.89484910955076, 219.79854149517797, 271.3164110158208, 488.1612272362301, 384.24783895158595, 375.0335991504771, 622.6685449585667, 391.01126662691973, 420.2320197981266, 606.6865920640593, 589.4979537870236, 504.83982471233287, 314.5477694671259, 324.66400812908364, 356.31044324182415, 301.0378939978267, 323.0469568246261, 257.49332752433844, 409.2413518883229, 433.4531211172435, 231.47370099881906, 361.1807445611679, 432.5432574900505, 476.0048204689635, 601.9510275824657, 272.733138414558, 380.408126021969, 434.957410947756, 337.64242883794685, 304.2359155062918, 510.45596783757924, 415.17022118438354, 268.9123886654814, 382.22466841041575, 332.58023620850844, 542.7221214396844, 541.9699163346841, 512.8649997944408, 431.91832086622594, 357.63300357451175, 343.4962795887044, 467.2137851198818, 380.3743525684943, 338.7911776100857, 203.61628092183943, 421.2698856231373, 451.9322650053625, 394.58283937497146, 393.8053709408689, 222.73846355190722, 103.69824920220115, 370.90679448249017, 399.70140276832205, 305.18954534875377, 330.3997209436767, 328.94906997201906, 337.9727047039327, 417.58014993851674, 340.92986882412305, 240.8254595967467, 233.82702509407812, 488.76576275256747, 416.3247373406479, 565.7307731549195, 258.9724713922355, 461.2190619897793, 365.16557928517074, 563.1430265175106, 465.9788270275386, 303.90529570449974, 466.37789365847107, 364.10930419905776, 391.8964115916729, 478.1895591004203, 452.79061424866757]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9128782023101449, "mean_inference_ms": 2.448860144885305, "mean_action_processing_ms": 0.381304929307781, "mean_env_wait_ms": 0.3419711651018407, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003995060920715332, "StateBufferConnector_ms": 0.0035134553909301758, "ViewRequirementAgentConnector_ms": 0.1271597146987915}, "num_episodes": 18, "episode_return_max": 1985.3172883348832, "episode_return_min": 1055.1521542158991, "episode_return_mean": 1647.52258936392, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 291.74894117382735, "num_env_steps_trained_throughput_per_sec": 291.74894117382735, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 14002.203, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14002.137, "sample_time_ms": 1488.406, "learn_time_ms": 12491.694, "learn_throughput": 320.213, "synch_weights_time_ms": 19.512}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "479e5_00000", "date": "2024-08-16_11-30-20", "timestamp": 1723788020, "time_this_iter_s": 13.76720404624939, "time_total_s": 214.78497791290283, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a781d940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 214.78497791290283, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 62.710000000000015, "ram_util_percent": 82.415}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2990114224020135, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.65884796778361, "policy_loss": -0.010523178269002566, "vf_loss": 9.667695746346126, "vf_explained_var": -0.007292377791076741, "kl": 0.016754082128631966, "entropy": 1.4340397643664526, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.413067447555759, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.81069267666529, "policy_loss": -0.006337916041187272, "vf_loss": 9.815028105337152, "vf_explained_var": -0.009070629575265148, "kl": 0.013349748139662212, "entropy": 1.488926112651825, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 1985.3172883348832, "episode_reward_min": 1055.1521542158991, "episode_reward_mean": 1657.8619352055916, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 252.31940686423542, "predator_policy": 0.7481705161082468}, "policy_reward_max": {"prey_policy": 691.9377112768749, "predator_policy": 629.0794857354323}, "policy_reward_mean": {"prey_policy": 454.216017940276, "predator_policy": 374.7149496625198}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1476.7057375656125, 1439.642732474737, 1474.8335560775483, 1779.37129157314, 1512.5943432775607, 1516.500688692468, 1626.5125838767285, 1462.567876406653, 1055.1521542158991, 1984.9452339166853, 1722.6656013441375, 1650.890870512073, 1876.2677027855116, 1564.274176186461, 1690.592652153598, 1634.2410466446695, 1677.1135077386687, 1291.018594695643, 1684.9516282667446, 1445.4509800187423, 1800.7946308951675, 1235.600493735, 1807.0301113604678, 1574.9018382149052, 1263.1345979211844, 1662.8239233977934, 1829.617952625295, 1802.7110113587892, 1629.348413548807, 1232.7168928469048, 1805.3529252504557, 1775.615570099642, 1836.499395773484, 1597.2162061568872, 1727.8662487351837, 1504.5318520271699, 1733.963831691718, 1859.716749264427, 1471.537182355339, 1439.3854191660478, 1821.846497523609, 1368.5342267389167, 1651.977110766485, 1817.085821795034, 1786.562624262481, 1352.8540363114482, 1895.8412696014323, 1716.8080916311073, 1619.4112565015275, 1939.298126920208, 1764.8044196320134, 1744.9356996386298, 1561.1286214591319, 1624.605693328783, 1704.6369403500146, 1406.1126948088206, 1928.4327092481817, 1444.5656549339494, 1636.5133536704477, 1670.7489618547716, 1507.8229558658052, 1807.8083819784426, 1928.8567368989948, 1985.3172883348832, 1481.0703086828064, 1680.0636812818364, 1653.9099611747572, 1839.3533697713258, 1658.774509281829, 1455.353704093864, 1547.4616735712168, 1653.611376163862, 1433.0250171912132, 1765.9424694087193, 1564.8256328580694, 1848.0691824297849, 1707.559841821865, 1798.5170312890057, 1875.0782596677511, 1661.0070081891267, 1567.8034036199276, 1939.87665052385, 1943.3100302215412, 1202.0124816897544, 1720.4969481106075, 1542.324107253059, 1820.5221903622662, 1902.5971605985833, 1866.3860066672216, 1846.7725310347269, 1720.6701978530614, 1729.9198917803153, 1748.3720179848422, 1682.0154853031065, 1749.6606108833244, 1765.121642500964, 1794.5910382291695, 1678.677667613173, 1754.9745276268395, 1343.298524922713], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [417.87054955849743, 452.98059555646705, 464.3763929891294, 478.0929126007631, 548.9458369268007, 334.2387426344535, 469.3747219902011, 552.682147554723, 440.3383292275685, 519.0035366492231, 436.7048358257103, 418.33329365610996, 478.1328921250901, 419.9304657457187, 305.259639890126, 656.8492059007124, 330.6134503394198, 478.44374805465117, 496.88870759723585, 608.2639013451709, 465.54559696480356, 459.0769972419569, 501.79409579650604, 531.091210977249, 495.1901628773769, 581.6153100324805, 436.71524336465865, 446.45117263100826, 442.91739397124866, 510.8227366951936, 552.3603980922684, 402.6437693418139, 323.7863441812164, 328.00681168994464, 525.2631404229304, 368.8343079088695, 502.89679979363603, 567.2494744992271, 398.8275689540081, 331.8282125891172, 391.8852523236349, 551.3263413286345, 278.8703686934377, 523.6889164173365, 485.26005421748647, 454.79700723110204, 394.14083416220234, 525.1491566180366, 364.3826140005224, 545.3422967980581, 541.8197878396951, 259.7346215824314, 617.1353070451719, 439.00671811064694, 513.5635985037209, 459.7859106985708, 503.83088323154743, 393.3166097390659, 428.1349229800423, 492.9300117269167, 600.5798833746051, 521.5395689880505, 418.1246758710136, 532.2642158771716, 642.759086008207, 562.1996545758619, 472.39984946056563, 317.0914363251998, 442.6507378325307, 464.3029369919342, 610.0125484979071, 510.01176767487044, 478.73923928033645, 330.38594902955214, 406.9714158260439, 518.518204019355, 252.31940686423542, 316.67401372126346, 465.5323080292692, 368.3994806425622, 473.76934451828333, 442.79790446753714, 353.58262286392, 555.6218379888074, 465.5257196507795, 384.8470429602671, 490.1307488827887, 385.29998346832724, 536.4581332087046, 646.3872091808419, 474.2748010174714, 387.4642827829782, 596.4155155829327, 427.0166878306849, 271.2145364043235, 447.8914111177411, 527.5924900722877, 280.5754800041943, 386.34271966306824, 356.7708614060545, 440.4593581886015, 504.95746726395157, 526.2375065665541, 537.7237417011678, 333.52458135027166, 603.5191892864067, 395.2180855075894, 562.6529284085336, 574.3766419644428, 465.3334762695095, 282.9992191751022, 329.3894735824998, 347.08253243258105, 503.39432876417135, 418.4841880197379, 372.940202477685, 393.86425218621287, 470.0492616985345, 545.2845582459997, 310.7725202649008, 403.78720634820246, 419.9531396677386, 516.8963626590954, 576.107114700422, 321.3422016671263, 522.8224974575025, 576.2602658633633, 464.27370181085166, 456.2544587375914, 323.68656678199784, 421.16972829847975, 411.3058152949848, 454.50726455378344, 656.9952380890493, 497.22333499189205, 468.92788415093236, 339.69348410784477, 530.6928148581443, 436.97928006287884, 691.9377112768749, 348.7355827473831, 428.11789357302104, 544.328292234593, 473.69381763683987, 467.12004159000065, 298.9832009252612, 532.4901908674472, 474.9422597786339, 626.0946595210614, 464.07848864618126, 490.10884949327715, 452.8698328432951, 514.4071117886954, 368.4494854860174, 491.06687288025967, 481.06551713379565, 496.37305978884234, 349.5833463338597, 615.6589806102432, 275.06483821591576, 326.3671053991725, 485.43058243002696, 447.94515309820343, 560.9513240765588, 607.510637984759, 520.4881987260837, 424.7672662859899, 393.2217772863575, 513.1383775423459, 389.67994341992585, 490.8694694961508, 443.19618520972284, 499.06011712769845, 421.6299269525155, 460.68902001070137, 480.92918435599734, 501.9393841342446, 553.9380503856491, 384.81374972376693, 303.3033426716107, 429.5342164068661, 264.49551236047085, 453.9562256400144, 446.7999206342318, 298.55029667546626, 635.1311086920786, 364.64406848149343, 399.10307899858947, 352.18507076874033, 473.23448708218297, 361.9483298006009, 677.613204466086, 406.2309940789677, 462.3512269692125, 468.3248529997987, 282.03283981345146, 320.93445524889904, 456.1313460388903, 320.08842653614073, 391.93564381362927], "policy_predator_policy_reward": [282.7951700921045, 323.0594223585449, 249.8164449256066, 247.35698195923612, 214.26164049894234, 377.38733601735225, 344.00034152171344, 413.31408050650157, 307.4106532825627, 245.84182411820532, 372.32163335704854, 289.1409258535995, 374.130319778643, 354.31890622727485, 174.30510083238082, 326.15392978343215, 100.08673752266294, 146.00821829916558, 428.9525700125666, 450.840054961711, 450.2976055166322, 347.74540162074453, 300.9187784922917, 317.0867852460278, 331.5388329630408, 467.9233969126139, 260.1857067646227, 420.9220534261708, 403.0062880947862, 333.8462333923704, 382.7750185195568, 296.46186069103067, 440.526379045069, 584.7939728224379, 117.56326581875338, 279.35788054508924, 302.59255069918163, 312.21280327469924, 320.7805156737388, 394.0146828018789, 391.47670214746887, 466.1063350954277, 157.0737241936621, 275.96748443056487, 365.0569840500108, 501.9160658618677, 225.43538253339972, 430.17646490126515, 190.48553958245685, 162.9241475401454, 495.10345618474213, 366.16605779092555, 506.90377529625357, 266.57215217322374, 446.99843779269855, 382.363064363801, 388.10451796668417, 344.0964026115097, 176.12069085130997, 135.5312672886368, 425.0577915633438, 258.17568132445524, 329.8657622892641, 495.3609160621916, 375.8647084319441, 255.67594675746886, 406.19837567913254, 401.52654469199024, 336.04371314639985, 484.86886076431847, 118.79077536154652, 265.71676049284605, 483.28667976041294, 441.5519636214186, 475.9246738691709, 458.30245554985817, 431.9340583779665, 470.609703391874, 418.9076265858615, 186.5460039083542, 435.4781292858311, 469.8011192519584, 256.53892391519884, 202.79084197099084, 399.8264859825008, 401.7778621729367, 465.54178954220606, 476.1132999017116, 344.82243276338284, 258.89484910955076, 219.79854149517797, 271.3164110158208, 488.1612272362301, 384.24783895158595, 375.0335991504771, 622.6685449585667, 391.01126662691973, 420.2320197981266, 606.6865920640593, 589.4979537870236, 504.83982471233287, 314.5477694671259, 324.66400812908364, 356.31044324182415, 301.0378939978267, 323.0469568246261, 257.49332752433844, 409.2413518883229, 433.4531211172435, 231.47370099881906, 361.1807445611679, 432.5432574900505, 476.0048204689635, 601.9510275824657, 272.733138414558, 380.408126021969, 434.957410947756, 337.64242883794685, 304.2359155062918, 510.45596783757924, 415.17022118438354, 268.9123886654814, 382.22466841041575, 332.58023620850844, 542.7221214396844, 541.9699163346841, 512.8649997944408, 431.91832086622594, 357.63300357451175, 343.4962795887044, 467.2137851198818, 380.3743525684943, 338.7911776100857, 203.61628092183943, 421.2698856231373, 451.9322650053625, 394.58283937497146, 393.8053709408689, 222.73846355190722, 103.69824920220115, 370.90679448249017, 399.70140276832205, 305.18954534875377, 330.3997209436767, 328.94906997201906, 337.9727047039327, 417.58014993851674, 340.92986882412305, 240.8254595967467, 233.82702509407812, 488.76576275256747, 416.3247373406479, 565.7307731549195, 258.9724713922355, 461.2190619897793, 365.16557928517074, 563.1430265175106, 465.9788270275386, 303.90529570449974, 466.37789365847107, 364.10930419905776, 391.8964115916729, 478.1895591004203, 452.79061424866757, 382.2089369896139, 433.1022565210855, 0.7481705161082468, 383.2752676012997, 436.7837506469744, 380.8948765013611, 302.4138389429665, 305.8446136042179, 585.4650381559813, 314.3671081260713, 493.0969126976672, 467.8820435342179, 482.0344198923491, 328.47415225498014, 629.0794857354323, 529.5759529039167, 451.2410048913023, 575.3994641944228, 497.1150126792063, 332.0487328268642, 465.40848009328977, 349.28213252400775, 514.4000995872792, 403.8682382357442, 363.40615721669536, 560.8348958157064, 374.9172295527242, 350.6428786815516, 502.0142585637692, 423.994558617219, 516.6606706487107, 411.6593041512134, 471.486130374535, 506.4225959645149, 281.16805716846767, 350.1063974044767]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8970027826257734, "mean_inference_ms": 2.4063578143576154, "mean_action_processing_ms": 0.3757654462428387, "mean_env_wait_ms": 0.33610124559803883, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003930091857910156, "StateBufferConnector_ms": 0.003191828727722168, "ViewRequirementAgentConnector_ms": 0.13136732578277588}, "num_episodes": 18, "episode_return_max": 1985.3172883348832, "episode_return_min": 1055.1521542158991, "episode_return_mean": 1657.8619352055916, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 293.3850061085095, "num_env_steps_trained_throughput_per_sec": 293.3850061085095, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 13944.551, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13944.489, "sample_time_ms": 1424.471, "learn_time_ms": 12500.58, "learn_throughput": 319.985, "synch_weights_time_ms": 16.959}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "479e5_00000", "date": "2024-08-16_11-30-34", "timestamp": 1723788034, "time_this_iter_s": 13.676820993423462, "time_total_s": 228.4617989063263, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78e88b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 228.4617989063263, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 62.215789473684204, "ram_util_percent": 82.36842105263156}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4194701165118546, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.56989253008807, "policy_loss": -0.012131012618423455, "vf_loss": 9.580328994327122, "vf_explained_var": -0.011732477296597113, "kl": 0.01694576198746038, "entropy": 1.444671708566171, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3172940034241902, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.841281912061904, "policy_loss": -0.006719902517747075, "vf_loss": 9.845834145217976, "vf_explained_var": -0.003962128439908305, "kl": 0.014451111641577898, "entropy": 1.477697768350127, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 2008.4169316622692, "episode_reward_min": 1202.0124816897544, "episode_reward_mean": 1690.6482422067559, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 252.31940686423542, "predator_policy": 0.7481705161082468}, "policy_reward_max": {"prey_policy": 691.9377112768749, "predator_policy": 629.0794857354323}, "policy_reward_mean": {"prey_policy": 462.1529824533647, "predator_policy": 383.1711386500136}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1684.9516282667446, 1445.4509800187423, 1800.7946308951675, 1235.600493735, 1807.0301113604678, 1574.9018382149052, 1263.1345979211844, 1662.8239233977934, 1829.617952625295, 1802.7110113587892, 1629.348413548807, 1232.7168928469048, 1805.3529252504557, 1775.615570099642, 1836.499395773484, 1597.2162061568872, 1727.8662487351837, 1504.5318520271699, 1733.963831691718, 1859.716749264427, 1471.537182355339, 1439.3854191660478, 1821.846497523609, 1368.5342267389167, 1651.977110766485, 1817.085821795034, 1786.562624262481, 1352.8540363114482, 1895.8412696014323, 1716.8080916311073, 1619.4112565015275, 1939.298126920208, 1764.8044196320134, 1744.9356996386298, 1561.1286214591319, 1624.605693328783, 1704.6369403500146, 1406.1126948088206, 1928.4327092481817, 1444.5656549339494, 1636.5133536704477, 1670.7489618547716, 1507.8229558658052, 1807.8083819784426, 1928.8567368989948, 1985.3172883348832, 1481.0703086828064, 1680.0636812818364, 1653.9099611747572, 1839.3533697713258, 1658.774509281829, 1455.353704093864, 1547.4616735712168, 1653.611376163862, 1433.0250171912132, 1765.9424694087193, 1564.8256328580694, 1848.0691824297849, 1707.559841821865, 1798.5170312890057, 1875.0782596677511, 1661.0070081891267, 1567.8034036199276, 1939.87665052385, 1943.3100302215412, 1202.0124816897544, 1720.4969481106075, 1542.324107253059, 1820.5221903622662, 1902.5971605985833, 1866.3860066672216, 1846.7725310347269, 1720.6701978530614, 1729.9198917803153, 1748.3720179848422, 1682.0154853031065, 1749.6606108833244, 1765.121642500964, 1794.5910382291695, 1678.677667613173, 1754.9745276268395, 1343.298524922713, 1899.4412874819247, 1811.0366465230568, 1707.0346920721179, 1531.86506385507, 1613.8367962207565, 1743.2051174278981, 1792.8688011591346, 1785.5560128521088, 1874.1670360608969, 1453.8015880141647, 1855.7017077327039, 1798.0780220395475, 1899.599744929791, 1649.4359212655197, 1892.3972088150304, 2008.4169316622692, 1769.1730004392523, 1628.9054717030124], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [502.89679979363603, 567.2494744992271, 398.8275689540081, 331.8282125891172, 391.8852523236349, 551.3263413286345, 278.8703686934377, 523.6889164173365, 485.26005421748647, 454.79700723110204, 394.14083416220234, 525.1491566180366, 364.3826140005224, 545.3422967980581, 541.8197878396951, 259.7346215824314, 617.1353070451719, 439.00671811064694, 513.5635985037209, 459.7859106985708, 503.83088323154743, 393.3166097390659, 428.1349229800423, 492.9300117269167, 600.5798833746051, 521.5395689880505, 418.1246758710136, 532.2642158771716, 642.759086008207, 562.1996545758619, 472.39984946056563, 317.0914363251998, 442.6507378325307, 464.3029369919342, 610.0125484979071, 510.01176767487044, 478.73923928033645, 330.38594902955214, 406.9714158260439, 518.518204019355, 252.31940686423542, 316.67401372126346, 465.5323080292692, 368.3994806425622, 473.76934451828333, 442.79790446753714, 353.58262286392, 555.6218379888074, 465.5257196507795, 384.8470429602671, 490.1307488827887, 385.29998346832724, 536.4581332087046, 646.3872091808419, 474.2748010174714, 387.4642827829782, 596.4155155829327, 427.0166878306849, 271.2145364043235, 447.8914111177411, 527.5924900722877, 280.5754800041943, 386.34271966306824, 356.7708614060545, 440.4593581886015, 504.95746726395157, 526.2375065665541, 537.7237417011678, 333.52458135027166, 603.5191892864067, 395.2180855075894, 562.6529284085336, 574.3766419644428, 465.3334762695095, 282.9992191751022, 329.3894735824998, 347.08253243258105, 503.39432876417135, 418.4841880197379, 372.940202477685, 393.86425218621287, 470.0492616985345, 545.2845582459997, 310.7725202649008, 403.78720634820246, 419.9531396677386, 516.8963626590954, 576.107114700422, 321.3422016671263, 522.8224974575025, 576.2602658633633, 464.27370181085166, 456.2544587375914, 323.68656678199784, 421.16972829847975, 411.3058152949848, 454.50726455378344, 656.9952380890493, 497.22333499189205, 468.92788415093236, 339.69348410784477, 530.6928148581443, 436.97928006287884, 691.9377112768749, 348.7355827473831, 428.11789357302104, 544.328292234593, 473.69381763683987, 467.12004159000065, 298.9832009252612, 532.4901908674472, 474.9422597786339, 626.0946595210614, 464.07848864618126, 490.10884949327715, 452.8698328432951, 514.4071117886954, 368.4494854860174, 491.06687288025967, 481.06551713379565, 496.37305978884234, 349.5833463338597, 615.6589806102432, 275.06483821591576, 326.3671053991725, 485.43058243002696, 447.94515309820343, 560.9513240765588, 607.510637984759, 520.4881987260837, 424.7672662859899, 393.2217772863575, 513.1383775423459, 389.67994341992585, 490.8694694961508, 443.19618520972284, 499.06011712769845, 421.6299269525155, 460.68902001070137, 480.92918435599734, 501.9393841342446, 553.9380503856491, 384.81374972376693, 303.3033426716107, 429.5342164068661, 264.49551236047085, 453.9562256400144, 446.7999206342318, 298.55029667546626, 635.1311086920786, 364.64406848149343, 399.10307899858947, 352.18507076874033, 473.23448708218297, 361.9483298006009, 677.613204466086, 406.2309940789677, 462.3512269692125, 468.3248529997987, 282.03283981345146, 320.93445524889904, 456.1313460388903, 320.08842653614073, 391.93564381362927, 422.2707980554426, 571.5333171858912, 426.12180775231457, 673.0777870566855, 449.56555436862345, 489.7145011783774, 473.6880156384747, 473.5938932075251, 458.96135767955394, 491.08750027845883, 380.87327984344813, 457.35350887724803, 629.3835108900945, 558.3224135256996, 504.8689210088395, 534.7015143046542, 327.31564341589194, 452.7390803655092, 445.2449166110136, 422.46751730293363, 603.3426500550638, 525.0205984215236, 547.5968195155679, 550.2648731814381, 531.6110951924155, 531.4384559829414, 616.3007009552846, 438.05113140885663, 562.0141680451405, 651.403118123974, 507.692447373609, 473.40736508623917, 493.3409789718113, 550.7956128322005, 638.4990617306836, 403.1675855515942], "policy_predator_policy_reward": [302.59255069918163, 312.21280327469924, 320.7805156737388, 394.0146828018789, 391.47670214746887, 466.1063350954277, 157.0737241936621, 275.96748443056487, 365.0569840500108, 501.9160658618677, 225.43538253339972, 430.17646490126515, 190.48553958245685, 162.9241475401454, 495.10345618474213, 366.16605779092555, 506.90377529625357, 266.57215217322374, 446.99843779269855, 382.363064363801, 388.10451796668417, 344.0964026115097, 176.12069085130997, 135.5312672886368, 425.0577915633438, 258.17568132445524, 329.8657622892641, 495.3609160621916, 375.8647084319441, 255.67594675746886, 406.19837567913254, 401.52654469199024, 336.04371314639985, 484.86886076431847, 118.79077536154652, 265.71676049284605, 483.28667976041294, 441.5519636214186, 475.9246738691709, 458.30245554985817, 431.9340583779665, 470.609703391874, 418.9076265858615, 186.5460039083542, 435.4781292858311, 469.8011192519584, 256.53892391519884, 202.79084197099084, 399.8264859825008, 401.7778621729367, 465.54178954220606, 476.1132999017116, 344.82243276338284, 258.89484910955076, 219.79854149517797, 271.3164110158208, 488.1612272362301, 384.24783895158595, 375.0335991504771, 622.6685449585667, 391.01126662691973, 420.2320197981266, 606.6865920640593, 589.4979537870236, 504.83982471233287, 314.5477694671259, 324.66400812908364, 356.31044324182415, 301.0378939978267, 323.0469568246261, 257.49332752433844, 409.2413518883229, 433.4531211172435, 231.47370099881906, 361.1807445611679, 432.5432574900505, 476.0048204689635, 601.9510275824657, 272.733138414558, 380.408126021969, 434.957410947756, 337.64242883794685, 304.2359155062918, 510.45596783757924, 415.17022118438354, 268.9123886654814, 382.22466841041575, 332.58023620850844, 542.7221214396844, 541.9699163346841, 512.8649997944408, 431.91832086622594, 357.63300357451175, 343.4962795887044, 467.2137851198818, 380.3743525684943, 338.7911776100857, 203.61628092183943, 421.2698856231373, 451.9322650053625, 394.58283937497146, 393.8053709408689, 222.73846355190722, 103.69824920220115, 370.90679448249017, 399.70140276832205, 305.18954534875377, 330.3997209436767, 328.94906997201906, 337.9727047039327, 417.58014993851674, 340.92986882412305, 240.8254595967467, 233.82702509407812, 488.76576275256747, 416.3247373406479, 565.7307731549195, 258.9724713922355, 461.2190619897793, 365.16557928517074, 563.1430265175106, 465.9788270275386, 303.90529570449974, 466.37789365847107, 364.10930419905776, 391.8964115916729, 478.1895591004203, 452.79061424866757, 382.2089369896139, 433.1022565210855, 0.7481705161082468, 383.2752676012997, 436.7837506469744, 380.8948765013611, 302.4138389429665, 305.8446136042179, 585.4650381559813, 314.3671081260713, 493.0969126976672, 467.8820435342179, 482.0344198923491, 328.47415225498014, 629.0794857354323, 529.5759529039167, 451.2410048913023, 575.3994641944228, 497.1150126792063, 332.0487328268642, 465.40848009328977, 349.28213252400775, 514.4000995872792, 403.8682382357442, 363.40615721669536, 560.8348958157064, 374.9172295527242, 350.6428786815516, 502.0142585637692, 423.994558617219, 516.6606706487107, 411.6593041512134, 471.486130374535, 506.4225959645149, 281.16805716846767, 350.1063974044767, 454.9732419465495, 450.6639302940423, 371.21927616140783, 340.61777555264825, 374.81081691550287, 392.9438196096131, 237.29839472683537, 347.2847602822343, 335.0633568623733, 328.7245814003692, 392.2481771567941, 512.7301515504081, 402.2778097779184, 202.8850669654229, 424.4189692181448, 321.5666083204713, 499.85554632848215, 594.2567659510139, 293.2712831644297, 292.81787093578754, 364.2726070630772, 363.0658521930389, 402.5826532911325, 297.6336760514102, 445.0970231779494, 391.45317057648555, 307.8576954221973, 287.2263934791807, 355.3516867314489, 323.628235914467, 510.140391215462, 517.1767279869606, 310.4932283080012, 414.543180327239, 288.26364342972266, 298.97518099101376]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.883789573782104, "mean_inference_ms": 2.3688163335074433, "mean_action_processing_ms": 0.3709665226220777, "mean_env_wait_ms": 0.33068816946622753, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003876805305480957, "StateBufferConnector_ms": 0.003245711326599121, "ViewRequirementAgentConnector_ms": 0.12972033023834229}, "num_episodes": 18, "episode_return_max": 2008.4169316622692, "episode_return_min": 1202.0124816897544, "episode_return_mean": 1690.6482422067559, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 295.577516447575, "num_env_steps_trained_throughput_per_sec": 295.577516447575, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 13919.615, "restore_workers_time_ms": 0.013, "training_step_time_ms": 13919.554, "sample_time_ms": 1415.996, "learn_time_ms": 12485.225, "learn_throughput": 320.379, "synch_weights_time_ms": 16.176}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "479e5_00000", "date": "2024-08-16_11-30-48", "timestamp": 1723788048, "time_this_iter_s": 13.572744131088257, "time_total_s": 242.03454303741455, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78e80d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 242.03454303741455, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 61.54210526315789, "ram_util_percent": 81.61052631578947}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.469618668710744, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.606632768035565, "policy_loss": -0.010946126767094173, "vf_loss": 9.616085639327922, "vf_explained_var": -0.01785016416241883, "kl": 0.014932630109227133, "entropy": 1.4436243461553382, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3401068336512676, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.839125435440629, "policy_loss": -0.002825332439391228, "vf_loss": 9.840415184081547, "vf_explained_var": 0.003796896638062896, "kl": 0.010237177230421257, "entropy": 1.4683324224734433, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 2008.4169316622692, "episode_reward_min": 1202.0124816897544, "episode_reward_mean": 1712.126801397756, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 176.1973973998847, "predator_policy": 0.7481705161082468}, "policy_reward_max": {"prey_policy": 706.985360146876, "predator_policy": 629.0794857354323}, "policy_reward_mean": {"prey_policy": 470.80542269538245, "predator_policy": 385.25797800349557}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1821.846497523609, 1368.5342267389167, 1651.977110766485, 1817.085821795034, 1786.562624262481, 1352.8540363114482, 1895.8412696014323, 1716.8080916311073, 1619.4112565015275, 1939.298126920208, 1764.8044196320134, 1744.9356996386298, 1561.1286214591319, 1624.605693328783, 1704.6369403500146, 1406.1126948088206, 1928.4327092481817, 1444.5656549339494, 1636.5133536704477, 1670.7489618547716, 1507.8229558658052, 1807.8083819784426, 1928.8567368989948, 1985.3172883348832, 1481.0703086828064, 1680.0636812818364, 1653.9099611747572, 1839.3533697713258, 1658.774509281829, 1455.353704093864, 1547.4616735712168, 1653.611376163862, 1433.0250171912132, 1765.9424694087193, 1564.8256328580694, 1848.0691824297849, 1707.559841821865, 1798.5170312890057, 1875.0782596677511, 1661.0070081891267, 1567.8034036199276, 1939.87665052385, 1943.3100302215412, 1202.0124816897544, 1720.4969481106075, 1542.324107253059, 1820.5221903622662, 1902.5971605985833, 1866.3860066672216, 1846.7725310347269, 1720.6701978530614, 1729.9198917803153, 1748.3720179848422, 1682.0154853031065, 1749.6606108833244, 1765.121642500964, 1794.5910382291695, 1678.677667613173, 1754.9745276268395, 1343.298524922713, 1899.4412874819247, 1811.0366465230568, 1707.0346920721179, 1531.86506385507, 1613.8367962207565, 1743.2051174278981, 1792.8688011591346, 1785.5560128521088, 1874.1670360608969, 1453.8015880141647, 1855.7017077327039, 1798.0780220395475, 1899.599744929791, 1649.4359212655197, 1892.3972088150304, 2008.4169316622692, 1769.1730004392523, 1628.9054717030124, 1533.1523998455507, 1722.1491202431466, 1707.0201786249015, 1956.76284744494, 1802.2716203623472, 1819.728225617367, 1812.5365126903819, 1790.0587910732954, 1698.7275922049055, 1440.713221540388, 1669.3194309698008, 1844.5993642966916, 1775.8919763231363, 1775.2780224142666, 1527.000913060342, 1521.8276437281813, 1896.0478123183236, 1765.768845577199, 1568.8508688822574, 1751.8200029153832, 1779.714630756391, 1709.3837529209134], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [473.76934451828333, 442.79790446753714, 353.58262286392, 555.6218379888074, 465.5257196507795, 384.8470429602671, 490.1307488827887, 385.29998346832724, 536.4581332087046, 646.3872091808419, 474.2748010174714, 387.4642827829782, 596.4155155829327, 427.0166878306849, 271.2145364043235, 447.8914111177411, 527.5924900722877, 280.5754800041943, 386.34271966306824, 356.7708614060545, 440.4593581886015, 504.95746726395157, 526.2375065665541, 537.7237417011678, 333.52458135027166, 603.5191892864067, 395.2180855075894, 562.6529284085336, 574.3766419644428, 465.3334762695095, 282.9992191751022, 329.3894735824998, 347.08253243258105, 503.39432876417135, 418.4841880197379, 372.940202477685, 393.86425218621287, 470.0492616985345, 545.2845582459997, 310.7725202649008, 403.78720634820246, 419.9531396677386, 516.8963626590954, 576.107114700422, 321.3422016671263, 522.8224974575025, 576.2602658633633, 464.27370181085166, 456.2544587375914, 323.68656678199784, 421.16972829847975, 411.3058152949848, 454.50726455378344, 656.9952380890493, 497.22333499189205, 468.92788415093236, 339.69348410784477, 530.6928148581443, 436.97928006287884, 691.9377112768749, 348.7355827473831, 428.11789357302104, 544.328292234593, 473.69381763683987, 467.12004159000065, 298.9832009252612, 532.4901908674472, 474.9422597786339, 626.0946595210614, 464.07848864618126, 490.10884949327715, 452.8698328432951, 514.4071117886954, 368.4494854860174, 491.06687288025967, 481.06551713379565, 496.37305978884234, 349.5833463338597, 615.6589806102432, 275.06483821591576, 326.3671053991725, 485.43058243002696, 447.94515309820343, 560.9513240765588, 607.510637984759, 520.4881987260837, 424.7672662859899, 393.2217772863575, 513.1383775423459, 389.67994341992585, 490.8694694961508, 443.19618520972284, 499.06011712769845, 421.6299269525155, 460.68902001070137, 480.92918435599734, 501.9393841342446, 553.9380503856491, 384.81374972376693, 303.3033426716107, 429.5342164068661, 264.49551236047085, 453.9562256400144, 446.7999206342318, 298.55029667546626, 635.1311086920786, 364.64406848149343, 399.10307899858947, 352.18507076874033, 473.23448708218297, 361.9483298006009, 677.613204466086, 406.2309940789677, 462.3512269692125, 468.3248529997987, 282.03283981345146, 320.93445524889904, 456.1313460388903, 320.08842653614073, 391.93564381362927, 422.2707980554426, 571.5333171858912, 426.12180775231457, 673.0777870566855, 449.56555436862345, 489.7145011783774, 473.6880156384747, 473.5938932075251, 458.96135767955394, 491.08750027845883, 380.87327984344813, 457.35350887724803, 629.3835108900945, 558.3224135256996, 504.8689210088395, 534.7015143046542, 327.31564341589194, 452.7390803655092, 445.2449166110136, 422.46751730293363, 603.3426500550638, 525.0205984215236, 547.5968195155679, 550.2648731814381, 531.6110951924155, 531.4384559829414, 616.3007009552846, 438.05113140885663, 562.0141680451405, 651.403118123974, 507.692447373609, 473.40736508623917, 493.3409789718113, 550.7956128322005, 638.4990617306836, 403.1675855515942, 603.0707074410095, 401.5891534741224, 381.9282427094055, 457.58554657662586, 434.55849391351217, 531.443784722985, 409.1678419220611, 546.2994593074634, 343.94774625760203, 570.0816173926768, 528.9931567972221, 516.3790689827302, 669.8547584039368, 508.9566836588273, 504.0099443882713, 466.1362887725999, 511.10728056815594, 362.4728771143763, 441.67212074736443, 417.6180981671936, 693.2821340167401, 583.4139274240515, 605.5509814639902, 494.04073617784894, 561.8969383651812, 616.0932346726877, 407.32634007828625, 486.48066850523344, 526.3885366627925, 176.1973973998847, 488.6499636611932, 412.86960197708856, 656.8363872039222, 706.985360146876, 558.9835281229866, 454.23795623858575, 445.7774650465385, 588.9323159927218, 512.5994231361431, 443.3933035518114, 399.0684035958581, 528.1854539668634, 424.56157253710694, 548.2431951158031], "policy_predator_policy_reward": [435.4781292858311, 469.8011192519584, 256.53892391519884, 202.79084197099084, 399.8264859825008, 401.7778621729367, 465.54178954220606, 476.1132999017116, 344.82243276338284, 258.89484910955076, 219.79854149517797, 271.3164110158208, 488.1612272362301, 384.24783895158595, 375.0335991504771, 622.6685449585667, 391.01126662691973, 420.2320197981266, 606.6865920640593, 589.4979537870236, 504.83982471233287, 314.5477694671259, 324.66400812908364, 356.31044324182415, 301.0378939978267, 323.0469568246261, 257.49332752433844, 409.2413518883229, 433.4531211172435, 231.47370099881906, 361.1807445611679, 432.5432574900505, 476.0048204689635, 601.9510275824657, 272.733138414558, 380.408126021969, 434.957410947756, 337.64242883794685, 304.2359155062918, 510.45596783757924, 415.17022118438354, 268.9123886654814, 382.22466841041575, 332.58023620850844, 542.7221214396844, 541.9699163346841, 512.8649997944408, 431.91832086622594, 357.63300357451175, 343.4962795887044, 467.2137851198818, 380.3743525684943, 338.7911776100857, 203.61628092183943, 421.2698856231373, 451.9322650053625, 394.58283937497146, 393.8053709408689, 222.73846355190722, 103.69824920220115, 370.90679448249017, 399.70140276832205, 305.18954534875377, 330.3997209436767, 328.94906997201906, 337.9727047039327, 417.58014993851674, 340.92986882412305, 240.8254595967467, 233.82702509407812, 488.76576275256747, 416.3247373406479, 565.7307731549195, 258.9724713922355, 461.2190619897793, 365.16557928517074, 563.1430265175106, 465.9788270275386, 303.90529570449974, 466.37789365847107, 364.10930419905776, 391.8964115916729, 478.1895591004203, 452.79061424866757, 382.2089369896139, 433.1022565210855, 0.7481705161082468, 383.2752676012997, 436.7837506469744, 380.8948765013611, 302.4138389429665, 305.8446136042179, 585.4650381559813, 314.3671081260713, 493.0969126976672, 467.8820435342179, 482.0344198923491, 328.47415225498014, 629.0794857354323, 529.5759529039167, 451.2410048913023, 575.3994641944228, 497.1150126792063, 332.0487328268642, 465.40848009328977, 349.28213252400775, 514.4000995872792, 403.8682382357442, 363.40615721669536, 560.8348958157064, 374.9172295527242, 350.6428786815516, 502.0142585637692, 423.994558617219, 516.6606706487107, 411.6593041512134, 471.486130374535, 506.4225959645149, 281.16805716846767, 350.1063974044767, 454.9732419465495, 450.6639302940423, 371.21927616140783, 340.61777555264825, 374.81081691550287, 392.9438196096131, 237.29839472683537, 347.2847602822343, 335.0633568623733, 328.7245814003692, 392.2481771567941, 512.7301515504081, 402.2778097779184, 202.8850669654229, 424.4189692181448, 321.5666083204713, 499.85554632848215, 594.2567659510139, 293.2712831644297, 292.81787093578754, 364.2726070630772, 363.0658521930389, 402.5826532911325, 297.6336760514102, 445.0970231779494, 391.45317057648555, 307.8576954221973, 287.2263934791807, 355.3516867314489, 323.628235914467, 510.140391215462, 517.1767279869606, 310.4932283080012, 414.543180327239, 288.26364342972266, 298.97518099101376, 124.49891806600576, 403.9936208644132, 425.0687312027013, 457.56659975441397, 312.4997256109923, 428.51817437741323, 546.8340405212238, 454.4615056941929, 442.0576933621324, 446.1845633499363, 342.3970091068869, 431.95899073052624, 275.4432196745542, 358.28185095306395, 414.5378653610828, 405.374692551341, 340.1224177717817, 485.0250167505913, 280.65544831119604, 300.76755431463425, 247.34705234267122, 145.27631718633856, 437.1517492887514, 307.85589736610166, 311.61962181473365, 286.2821814705347, 443.68134080889183, 437.78967302185686, 413.03430926856157, 411.3806697291032, 263.11566870933717, 357.19240938056237, 324.4733410812335, 207.75272388629173, 232.37522357093462, 520.1721376446926, 373.9830789901466, 160.15800885285165, 385.9954979811949, 409.8317782462337, 395.1161963867968, 457.3445768068708, 351.53016551714495, 385.04881975085885]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8689523223952378, "mean_inference_ms": 2.3292124608983436, "mean_action_processing_ms": 0.3654491811640531, "mean_env_wait_ms": 0.3249522891155886, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004030108451843262, "StateBufferConnector_ms": 0.0032815933227539062, "ViewRequirementAgentConnector_ms": 0.12252521514892578}, "num_episodes": 22, "episode_return_max": 2008.4169316622692, "episode_return_min": 1202.0124816897544, "episode_return_mean": 1712.126801397756, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 287.896993336687, "num_env_steps_trained_throughput_per_sec": 287.896993336687, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 13865.047, "restore_workers_time_ms": 0.013, "training_step_time_ms": 13864.989, "sample_time_ms": 1422.794, "learn_time_ms": 12423.947, "learn_throughput": 321.959, "synch_weights_time_ms": 16.165}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "479e5_00000", "date": "2024-08-16_11-31-02", "timestamp": 1723788062, "time_this_iter_s": 13.942528009414673, "time_total_s": 255.97707104682922, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a79008b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 255.97707104682922, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 62.93500000000002, "ram_util_percent": 82.13500000000002}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4041854997633627, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.682150535987168, "policy_loss": -0.013934763671002454, "vf_loss": 9.694148962838309, "vf_explained_var": -0.013800374256870734, "kl": 0.01936352900360404, "entropy": 1.410463429001904, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.356729615901513, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.80310807051482, "policy_loss": -0.0055421727596136625, "vf_loss": 9.806815402217643, "vf_explained_var": -0.002142078441286844, "kl": 0.012232230283511046, "entropy": 1.4164342528928524, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 2008.4169316622692, "episode_reward_min": 1202.0124816897544, "episode_reward_mean": 1730.659629183517, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 176.1973973998847, "predator_policy": 0.7481705161082468}, "policy_reward_max": {"prey_policy": 706.985360146876, "predator_policy": 629.0794857354323}, "policy_reward_mean": {"prey_policy": 484.7782527630131, "predator_policy": 380.55156182874555}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1985.3172883348832, 1481.0703086828064, 1680.0636812818364, 1653.9099611747572, 1839.3533697713258, 1658.774509281829, 1455.353704093864, 1547.4616735712168, 1653.611376163862, 1433.0250171912132, 1765.9424694087193, 1564.8256328580694, 1848.0691824297849, 1707.559841821865, 1798.5170312890057, 1875.0782596677511, 1661.0070081891267, 1567.8034036199276, 1939.87665052385, 1943.3100302215412, 1202.0124816897544, 1720.4969481106075, 1542.324107253059, 1820.5221903622662, 1902.5971605985833, 1866.3860066672216, 1846.7725310347269, 1720.6701978530614, 1729.9198917803153, 1748.3720179848422, 1682.0154853031065, 1749.6606108833244, 1765.121642500964, 1794.5910382291695, 1678.677667613173, 1754.9745276268395, 1343.298524922713, 1899.4412874819247, 1811.0366465230568, 1707.0346920721179, 1531.86506385507, 1613.8367962207565, 1743.2051174278981, 1792.8688011591346, 1785.5560128521088, 1874.1670360608969, 1453.8015880141647, 1855.7017077327039, 1798.0780220395475, 1899.599744929791, 1649.4359212655197, 1892.3972088150304, 2008.4169316622692, 1769.1730004392523, 1628.9054717030124, 1533.1523998455507, 1722.1491202431466, 1707.0201786249015, 1956.76284744494, 1802.2716203623472, 1819.728225617367, 1812.5365126903819, 1790.0587910732954, 1698.7275922049055, 1440.713221540388, 1669.3194309698008, 1844.5993642966916, 1775.8919763231363, 1775.2780224142666, 1527.000913060342, 1521.8276437281813, 1896.0478123183236, 1765.768845577199, 1568.8508688822574, 1751.8200029153832, 1779.714630756391, 1709.3837529209134, 1775.795184631195, 1701.837096969041, 1472.1787784993733, 1750.4780727333305, 1789.1602941797735, 1856.5249410052909, 1774.8276324821823, 1814.7341814678546, 1779.1914826883371, 1821.164924815714, 1857.6714315969377, 1608.5945239078835, 1792.9690284059866, 1890.353477961651, 1560.2383447871875, 1797.739149774666, 1703.7134044063262, 1777.7997590587863, 1918.8128155131851, 1815.030895486743, 1801.1429164418194, 1648.3922856930778, 1846.1240417900135], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [576.2602658633633, 464.27370181085166, 456.2544587375914, 323.68656678199784, 421.16972829847975, 411.3058152949848, 454.50726455378344, 656.9952380890493, 497.22333499189205, 468.92788415093236, 339.69348410784477, 530.6928148581443, 436.97928006287884, 691.9377112768749, 348.7355827473831, 428.11789357302104, 544.328292234593, 473.69381763683987, 467.12004159000065, 298.9832009252612, 532.4901908674472, 474.9422597786339, 626.0946595210614, 464.07848864618126, 490.10884949327715, 452.8698328432951, 514.4071117886954, 368.4494854860174, 491.06687288025967, 481.06551713379565, 496.37305978884234, 349.5833463338597, 615.6589806102432, 275.06483821591576, 326.3671053991725, 485.43058243002696, 447.94515309820343, 560.9513240765588, 607.510637984759, 520.4881987260837, 424.7672662859899, 393.2217772863575, 513.1383775423459, 389.67994341992585, 490.8694694961508, 443.19618520972284, 499.06011712769845, 421.6299269525155, 460.68902001070137, 480.92918435599734, 501.9393841342446, 553.9380503856491, 384.81374972376693, 303.3033426716107, 429.5342164068661, 264.49551236047085, 453.9562256400144, 446.7999206342318, 298.55029667546626, 635.1311086920786, 364.64406848149343, 399.10307899858947, 352.18507076874033, 473.23448708218297, 361.9483298006009, 677.613204466086, 406.2309940789677, 462.3512269692125, 468.3248529997987, 282.03283981345146, 320.93445524889904, 456.1313460388903, 320.08842653614073, 391.93564381362927, 422.2707980554426, 571.5333171858912, 426.12180775231457, 673.0777870566855, 449.56555436862345, 489.7145011783774, 473.6880156384747, 473.5938932075251, 458.96135767955394, 491.08750027845883, 380.87327984344813, 457.35350887724803, 629.3835108900945, 558.3224135256996, 504.8689210088395, 534.7015143046542, 327.31564341589194, 452.7390803655092, 445.2449166110136, 422.46751730293363, 603.3426500550638, 525.0205984215236, 547.5968195155679, 550.2648731814381, 531.6110951924155, 531.4384559829414, 616.3007009552846, 438.05113140885663, 562.0141680451405, 651.403118123974, 507.692447373609, 473.40736508623917, 493.3409789718113, 550.7956128322005, 638.4990617306836, 403.1675855515942, 603.0707074410095, 401.5891534741224, 381.9282427094055, 457.58554657662586, 434.55849391351217, 531.443784722985, 409.1678419220611, 546.2994593074634, 343.94774625760203, 570.0816173926768, 528.9931567972221, 516.3790689827302, 669.8547584039368, 508.9566836588273, 504.0099443882713, 466.1362887725999, 511.10728056815594, 362.4728771143763, 441.67212074736443, 417.6180981671936, 693.2821340167401, 583.4139274240515, 605.5509814639902, 494.04073617784894, 561.8969383651812, 616.0932346726877, 407.32634007828625, 486.48066850523344, 526.3885366627925, 176.1973973998847, 488.6499636611932, 412.86960197708856, 656.8363872039222, 706.985360146876, 558.9835281229866, 454.23795623858575, 445.7774650465385, 588.9323159927218, 512.5994231361431, 443.3933035518114, 399.0684035958581, 528.1854539668634, 424.56157253710694, 548.2431951158031, 459.8552166811131, 583.3430326069748, 565.7990295761583, 463.7989332806664, 583.1445339656548, 399.23842788525667, 379.23007873847143, 552.948385016917, 476.0253924168162, 519.6710270714899, 666.17769746386, 648.0654570320161, 537.1631856042753, 551.7680566128445, 476.52893866441326, 530.7122251301245, 297.2279788547444, 515.6080979462351, 496.3186519719282, 443.98863905021216, 457.3042222687952, 415.6183441760873, 484.7940129164375, 553.0825661818392, 436.741309966214, 436.53673689837336, 622.976889764915, 570.7420324519684, 540.7128409114093, 595.4490799874831, 488.9566868692187, 540.0409777794382, 463.4507674418391, 465.69542469075304, 456.74491427773114, 540.5535255246641, 650.9735920178274, 470.86811917534413, 419.87623887437695, 386.38283872177516, 582.3743195165571, 566.5974452312635, 570.7631112311841, 484.15197521728453, 512.4678519873721, 503.24857280234266], "policy_predator_policy_reward": [512.8649997944408, 431.91832086622594, 357.63300357451175, 343.4962795887044, 467.2137851198818, 380.3743525684943, 338.7911776100857, 203.61628092183943, 421.2698856231373, 451.9322650053625, 394.58283937497146, 393.8053709408689, 222.73846355190722, 103.69824920220115, 370.90679448249017, 399.70140276832205, 305.18954534875377, 330.3997209436767, 328.94906997201906, 337.9727047039327, 417.58014993851674, 340.92986882412305, 240.8254595967467, 233.82702509407812, 488.76576275256747, 416.3247373406479, 565.7307731549195, 258.9724713922355, 461.2190619897793, 365.16557928517074, 563.1430265175106, 465.9788270275386, 303.90529570449974, 466.37789365847107, 364.10930419905776, 391.8964115916729, 478.1895591004203, 452.79061424866757, 382.2089369896139, 433.1022565210855, 0.7481705161082468, 383.2752676012997, 436.7837506469744, 380.8948765013611, 302.4138389429665, 305.8446136042179, 585.4650381559813, 314.3671081260713, 493.0969126976672, 467.8820435342179, 482.0344198923491, 328.47415225498014, 629.0794857354323, 529.5759529039167, 451.2410048913023, 575.3994641944228, 497.1150126792063, 332.0487328268642, 465.40848009328977, 349.28213252400775, 514.4000995872792, 403.8682382357442, 363.40615721669536, 560.8348958157064, 374.9172295527242, 350.6428786815516, 502.0142585637692, 423.994558617219, 516.6606706487107, 411.6593041512134, 471.486130374535, 506.4225959645149, 281.16805716846767, 350.1063974044767, 454.9732419465495, 450.6639302940423, 371.21927616140783, 340.61777555264825, 374.81081691550287, 392.9438196096131, 237.29839472683537, 347.2847602822343, 335.0633568623733, 328.7245814003692, 392.2481771567941, 512.7301515504081, 402.2778097779184, 202.8850669654229, 424.4189692181448, 321.5666083204713, 499.85554632848215, 594.2567659510139, 293.2712831644297, 292.81787093578754, 364.2726070630772, 363.0658521930389, 402.5826532911325, 297.6336760514102, 445.0970231779494, 391.45317057648555, 307.8576954221973, 287.2263934791807, 355.3516867314489, 323.628235914467, 510.140391215462, 517.1767279869606, 310.4932283080012, 414.543180327239, 288.26364342972266, 298.97518099101376, 124.49891806600576, 403.9936208644132, 425.0687312027013, 457.56659975441397, 312.4997256109923, 428.51817437741323, 546.8340405212238, 454.4615056941929, 442.0576933621324, 446.1845633499363, 342.3970091068869, 431.95899073052624, 275.4432196745542, 358.28185095306395, 414.5378653610828, 405.374692551341, 340.1224177717817, 485.0250167505913, 280.65544831119604, 300.76755431463425, 247.34705234267122, 145.27631718633856, 437.1517492887514, 307.85589736610166, 311.61962181473365, 286.2821814705347, 443.68134080889183, 437.78967302185686, 413.03430926856157, 411.3806697291032, 263.11566870933717, 357.19240938056237, 324.4733410812335, 207.75272388629173, 232.37522357093462, 520.1721376446926, 373.9830789901466, 160.15800885285165, 385.9954979811949, 409.8317782462337, 395.1161963867968, 457.3445768068708, 351.53016551714495, 385.04881975085885, 460.2403502325295, 272.35658511057886, 355.74767356876816, 316.4914605434494, 208.21877386869318, 281.57704277976933, 441.2575358700652, 377.04207310787683, 418.50569920501687, 374.9581754864511, 204.08714975288004, 338.194636756534, 283.3214998256101, 402.57489043945276, 358.04405107585126, 449.44896659746746, 509.4864231878952, 456.86898269946363, 389.32994173854235, 491.5276920550314, 455.7970935973295, 528.9517715547263, 375.0252439718407, 195.69270083776667, 425.1258668841334, 494.5651146572657, 362.3465693384902, 334.28798640627656, 189.62242449385712, 234.45399939443888, 377.72690810121304, 391.0145770247973, 365.04950903062166, 409.5177032431122, 428.692359112776, 351.80896014361656, 454.02006415292, 342.95104016709405, 476.77501131604487, 531.9968065745456, 346.32797006827485, 305.84318162572544, 216.78805578232115, 376.68914346228803, 396.56312201267264, 433.84449498762643]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.856910379516208, "mean_inference_ms": 2.2928514482933027, "mean_action_processing_ms": 0.35927941437157174, "mean_env_wait_ms": 0.3196556202487622, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004264473915100098, "StateBufferConnector_ms": 0.003431081771850586, "ViewRequirementAgentConnector_ms": 0.14598965644836426}, "num_episodes": 23, "episode_return_max": 2008.4169316622692, "episode_return_min": 1202.0124816897544, "episode_return_mean": 1730.659629183517, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 299.1656458337338, "num_env_steps_trained_throughput_per_sec": 299.1656458337338, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 13748.975, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13748.916, "sample_time_ms": 1410.678, "learn_time_ms": 12319.421, "learn_throughput": 324.691, "synch_weights_time_ms": 16.213}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "479e5_00000", "date": "2024-08-16_11-31-15", "timestamp": 1723788075, "time_this_iter_s": 13.40538215637207, "time_total_s": 269.3824532032013, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7884b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 269.3824532032013, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 61.8157894736842, "ram_util_percent": 82.03157894736843}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.286234891777316, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.824679953963669, "policy_loss": -0.00960383655949343, "vf_loss": 9.832698099449198, "vf_explained_var": -0.010299695894200966, "kl": 0.015856927457005614, "entropy": 1.4269490206052386, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4027391874285602, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.73444440730665, "policy_loss": -0.007854057984948946, "vf_loss": 9.739727282650255, "vf_explained_var": -0.005736282862052715, "kl": 0.0171410981444164, "entropy": 1.3283406257629395, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 2008.4169316622692, "episode_reward_min": 1202.0124816897544, "episode_reward_mean": 1744.584053750622, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 85.06171581981488, "predator_policy": 0.7481705161082468}, "policy_reward_max": {"prey_policy": 706.985360146876, "predator_policy": 759.0733550191949}, "policy_reward_mean": {"prey_policy": 473.36753196450735, "predator_policy": 398.92449491080384}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1939.87665052385, 1943.3100302215412, 1202.0124816897544, 1720.4969481106075, 1542.324107253059, 1820.5221903622662, 1902.5971605985833, 1866.3860066672216, 1846.7725310347269, 1720.6701978530614, 1729.9198917803153, 1748.3720179848422, 1682.0154853031065, 1749.6606108833244, 1765.121642500964, 1794.5910382291695, 1678.677667613173, 1754.9745276268395, 1343.298524922713, 1899.4412874819247, 1811.0366465230568, 1707.0346920721179, 1531.86506385507, 1613.8367962207565, 1743.2051174278981, 1792.8688011591346, 1785.5560128521088, 1874.1670360608969, 1453.8015880141647, 1855.7017077327039, 1798.0780220395475, 1899.599744929791, 1649.4359212655197, 1892.3972088150304, 2008.4169316622692, 1769.1730004392523, 1628.9054717030124, 1533.1523998455507, 1722.1491202431466, 1707.0201786249015, 1956.76284744494, 1802.2716203623472, 1819.728225617367, 1812.5365126903819, 1790.0587910732954, 1698.7275922049055, 1440.713221540388, 1669.3194309698008, 1844.5993642966916, 1775.8919763231363, 1775.2780224142666, 1527.000913060342, 1521.8276437281813, 1896.0478123183236, 1765.768845577199, 1568.8508688822574, 1751.8200029153832, 1779.714630756391, 1709.3837529209134, 1775.795184631195, 1701.837096969041, 1472.1787784993733, 1750.4780727333305, 1789.1602941797735, 1856.5249410052909, 1774.8276324821823, 1814.7341814678546, 1779.1914826883371, 1821.164924815714, 1857.6714315969377, 1608.5945239078835, 1792.9690284059866, 1890.353477961651, 1560.2383447871875, 1797.739149774666, 1703.7134044063262, 1777.7997590587863, 1918.8128155131851, 1815.030895486743, 1801.1429164418194, 1648.3922856930778, 1846.1240417900135, 1891.8175250772333, 1772.9534384979493, 1924.2575021955354, 1617.7675193968453, 1848.10218610471, 1814.4070862175868, 1817.4703783230493, 1648.9408985811338, 1814.7793040807012, 1687.0801838542511, 1523.7833871126072, 1750.5858874976846, 1542.0146120809882, 1812.9807794240546, 1740.468046583777, 1790.6800415050502, 1832.63570434963, 1738.4616946595825], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [447.94515309820343, 560.9513240765588, 607.510637984759, 520.4881987260837, 424.7672662859899, 393.2217772863575, 513.1383775423459, 389.67994341992585, 490.8694694961508, 443.19618520972284, 499.06011712769845, 421.6299269525155, 460.68902001070137, 480.92918435599734, 501.9393841342446, 553.9380503856491, 384.81374972376693, 303.3033426716107, 429.5342164068661, 264.49551236047085, 453.9562256400144, 446.7999206342318, 298.55029667546626, 635.1311086920786, 364.64406848149343, 399.10307899858947, 352.18507076874033, 473.23448708218297, 361.9483298006009, 677.613204466086, 406.2309940789677, 462.3512269692125, 468.3248529997987, 282.03283981345146, 320.93445524889904, 456.1313460388903, 320.08842653614073, 391.93564381362927, 422.2707980554426, 571.5333171858912, 426.12180775231457, 673.0777870566855, 449.56555436862345, 489.7145011783774, 473.6880156384747, 473.5938932075251, 458.96135767955394, 491.08750027845883, 380.87327984344813, 457.35350887724803, 629.3835108900945, 558.3224135256996, 504.8689210088395, 534.7015143046542, 327.31564341589194, 452.7390803655092, 445.2449166110136, 422.46751730293363, 603.3426500550638, 525.0205984215236, 547.5968195155679, 550.2648731814381, 531.6110951924155, 531.4384559829414, 616.3007009552846, 438.05113140885663, 562.0141680451405, 651.403118123974, 507.692447373609, 473.40736508623917, 493.3409789718113, 550.7956128322005, 638.4990617306836, 403.1675855515942, 603.0707074410095, 401.5891534741224, 381.9282427094055, 457.58554657662586, 434.55849391351217, 531.443784722985, 409.1678419220611, 546.2994593074634, 343.94774625760203, 570.0816173926768, 528.9931567972221, 516.3790689827302, 669.8547584039368, 508.9566836588273, 504.0099443882713, 466.1362887725999, 511.10728056815594, 362.4728771143763, 441.67212074736443, 417.6180981671936, 693.2821340167401, 583.4139274240515, 605.5509814639902, 494.04073617784894, 561.8969383651812, 616.0932346726877, 407.32634007828625, 486.48066850523344, 526.3885366627925, 176.1973973998847, 488.6499636611932, 412.86960197708856, 656.8363872039222, 706.985360146876, 558.9835281229866, 454.23795623858575, 445.7774650465385, 588.9323159927218, 512.5994231361431, 443.3933035518114, 399.0684035958581, 528.1854539668634, 424.56157253710694, 548.2431951158031, 459.8552166811131, 583.3430326069748, 565.7990295761583, 463.7989332806664, 583.1445339656548, 399.23842788525667, 379.23007873847143, 552.948385016917, 476.0253924168162, 519.6710270714899, 666.17769746386, 648.0654570320161, 537.1631856042753, 551.7680566128445, 476.52893866441326, 530.7122251301245, 297.2279788547444, 515.6080979462351, 496.3186519719282, 443.98863905021216, 457.3042222687952, 415.6183441760873, 484.7940129164375, 553.0825661818392, 436.741309966214, 436.53673689837336, 622.976889764915, 570.7420324519684, 540.7128409114093, 595.4490799874831, 488.9566868692187, 540.0409777794382, 463.4507674418391, 465.69542469075304, 456.74491427773114, 540.5535255246641, 650.9735920178274, 470.86811917534413, 419.87623887437695, 386.38283872177516, 582.3743195165571, 566.5974452312635, 570.7631112311841, 484.15197521728453, 512.4678519873721, 503.24857280234266, 437.1480370284899, 536.6636350865134, 297.307527551738, 429.0958558072874, 385.32650225521536, 491.1723041277541, 345.86227454044155, 320.2574512129259, 581.5044240979704, 521.4789273919724, 513.0756438905953, 470.88278591846216, 516.0872365445291, 517.0985988675865, 376.009994662812, 422.614574006197, 397.01989593683896, 457.9631269553804, 531.1820558469428, 401.5247742408417, 372.309152636744, 269.719558087614, 472.15788703748166, 245.38158189503824, 171.37774875088726, 85.06171581981488, 268.8773440429544, 361.2738036393446, 412.7509137636108, 433.4722936155867, 416.85188564020604, 387.53528074950015, 450.427014099296, 426.03162491978406, 402.4911360984146, 327.79883233458054], "policy_predator_policy_reward": [478.1895591004203, 452.79061424866757, 382.2089369896139, 433.1022565210855, 0.7481705161082468, 383.2752676012997, 436.7837506469744, 380.8948765013611, 302.4138389429665, 305.8446136042179, 585.4650381559813, 314.3671081260713, 493.0969126976672, 467.8820435342179, 482.0344198923491, 328.47415225498014, 629.0794857354323, 529.5759529039167, 451.2410048913023, 575.3994641944228, 497.1150126792063, 332.0487328268642, 465.40848009328977, 349.28213252400775, 514.4000995872792, 403.8682382357442, 363.40615721669536, 560.8348958157064, 374.9172295527242, 350.6428786815516, 502.0142585637692, 423.994558617219, 516.6606706487107, 411.6593041512134, 471.486130374535, 506.4225959645149, 281.16805716846767, 350.1063974044767, 454.9732419465495, 450.6639302940423, 371.21927616140783, 340.61777555264825, 374.81081691550287, 392.9438196096131, 237.29839472683537, 347.2847602822343, 335.0633568623733, 328.7245814003692, 392.2481771567941, 512.7301515504081, 402.2778097779184, 202.8850669654229, 424.4189692181448, 321.5666083204713, 499.85554632848215, 594.2567659510139, 293.2712831644297, 292.81787093578754, 364.2726070630772, 363.0658521930389, 402.5826532911325, 297.6336760514102, 445.0970231779494, 391.45317057648555, 307.8576954221973, 287.2263934791807, 355.3516867314489, 323.628235914467, 510.140391215462, 517.1767279869606, 310.4932283080012, 414.543180327239, 288.26364342972266, 298.97518099101376, 124.49891806600576, 403.9936208644132, 425.0687312027013, 457.56659975441397, 312.4997256109923, 428.51817437741323, 546.8340405212238, 454.4615056941929, 442.0576933621324, 446.1845633499363, 342.3970091068869, 431.95899073052624, 275.4432196745542, 358.28185095306395, 414.5378653610828, 405.374692551341, 340.1224177717817, 485.0250167505913, 280.65544831119604, 300.76755431463425, 247.34705234267122, 145.27631718633856, 437.1517492887514, 307.85589736610166, 311.61962181473365, 286.2821814705347, 443.68134080889183, 437.78967302185686, 413.03430926856157, 411.3806697291032, 263.11566870933717, 357.19240938056237, 324.4733410812335, 207.75272388629173, 232.37522357093462, 520.1721376446926, 373.9830789901466, 160.15800885285165, 385.9954979811949, 409.8317782462337, 395.1161963867968, 457.3445768068708, 351.53016551714495, 385.04881975085885, 460.2403502325295, 272.35658511057886, 355.74767356876816, 316.4914605434494, 208.21877386869318, 281.57704277976933, 441.2575358700652, 377.04207310787683, 418.50569920501687, 374.9581754864511, 204.08714975288004, 338.194636756534, 283.3214998256101, 402.57489043945276, 358.04405107585126, 449.44896659746746, 509.4864231878952, 456.86898269946363, 389.32994173854235, 491.5276920550314, 455.7970935973295, 528.9517715547263, 375.0252439718407, 195.69270083776667, 425.1258668841334, 494.5651146572657, 362.3465693384902, 334.28798640627656, 189.62242449385712, 234.45399939443888, 377.72690810121304, 391.0145770247973, 365.04950903062166, 409.5177032431122, 428.692359112776, 351.80896014361656, 454.02006415292, 342.95104016709405, 476.77501131604487, 531.9968065745456, 346.32797006827485, 305.84318162572544, 216.78805578232115, 376.68914346228803, 396.56312201267264, 433.84449498762643, 492.13037766257867, 425.8754752996502, 541.7804947976135, 504.7695603413101, 537.3475154003308, 510.4111804122354, 404.3051225731399, 547.3426710703392, 397.6060975741013, 347.51273704066625, 313.206541896626, 517.2421145119054, 417.2652618505949, 367.01928106033836, 428.45720348907537, 421.85912642305107, 561.2647520129702, 398.5315291755108, 349.7552007667778, 404.6181529996895, 468.4804570132087, 413.27421937504135, 407.97184161041434, 625.07457695475, 526.5017924910918, 759.0733550191949, 605.0677952403983, 577.7618365013567, 484.51990631435285, 409.72493289022697, 521.496051711369, 464.7968234039759, 520.6624325900625, 435.5146327404893, 597.3557095123257, 410.816016714263]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8478566116823265, "mean_inference_ms": 2.265651936816685, "mean_action_processing_ms": 0.3550374150370774, "mean_env_wait_ms": 0.3160859884561866, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004309535026550293, "StateBufferConnector_ms": 0.003480672836303711, "ViewRequirementAgentConnector_ms": 0.13508963584899902}, "num_episodes": 18, "episode_return_max": 2008.4169316622692, "episode_return_min": 1202.0124816897544, "episode_return_mean": 1744.584053750622, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 307.4679741783007, "num_env_steps_trained_throughput_per_sec": 307.4679741783007, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 13625.628, "restore_workers_time_ms": 0.013, "training_step_time_ms": 13625.569, "sample_time_ms": 1413.466, "learn_time_ms": 12193.11, "learn_throughput": 328.054, "synch_weights_time_ms": 16.388}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "479e5_00000", "date": "2024-08-16_11-31-28", "timestamp": 1723788088, "time_this_iter_s": 13.054178953170776, "time_total_s": 282.43663215637207, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78500d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 282.43663215637207, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 61.65263157894737, "ram_util_percent": 82.02631578947368}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2416903606482914, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.855971970633854, "policy_loss": -0.01606207870774799, "vf_loss": 9.87018818981433, "vf_explained_var": -0.005649589010016628, "kl": 0.018458572218398875, "entropy": 1.3845417482512339, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.470865350583243, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.682572586826547, "policy_loss": -0.002316958073368937, "vf_loss": 9.683857285030305, "vf_explained_var": -0.005164280139579975, "kl": 0.006881742870328231, "entropy": 1.3363967504450884, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 2008.4169316622692, "episode_reward_min": 1050.3563663749305, "episode_reward_mean": 1676.2207582168676, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -280.85859048600247, "predator_policy": 124.49891806600576}, "policy_reward_max": {"prey_policy": 706.985360146876, "predator_policy": 967.2349087273044}, "policy_reward_mean": {"prey_policy": 408.3582941401104, "predator_policy": 429.7520849683237}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1343.298524922713, 1899.4412874819247, 1811.0366465230568, 1707.0346920721179, 1531.86506385507, 1613.8367962207565, 1743.2051174278981, 1792.8688011591346, 1785.5560128521088, 1874.1670360608969, 1453.8015880141647, 1855.7017077327039, 1798.0780220395475, 1899.599744929791, 1649.4359212655197, 1892.3972088150304, 2008.4169316622692, 1769.1730004392523, 1628.9054717030124, 1533.1523998455507, 1722.1491202431466, 1707.0201786249015, 1956.76284744494, 1802.2716203623472, 1819.728225617367, 1812.5365126903819, 1790.0587910732954, 1698.7275922049055, 1440.713221540388, 1669.3194309698008, 1844.5993642966916, 1775.8919763231363, 1775.2780224142666, 1527.000913060342, 1521.8276437281813, 1896.0478123183236, 1765.768845577199, 1568.8508688822574, 1751.8200029153832, 1779.714630756391, 1709.3837529209134, 1775.795184631195, 1701.837096969041, 1472.1787784993733, 1750.4780727333305, 1789.1602941797735, 1856.5249410052909, 1774.8276324821823, 1814.7341814678546, 1779.1914826883371, 1821.164924815714, 1857.6714315969377, 1608.5945239078835, 1792.9690284059866, 1890.353477961651, 1560.2383447871875, 1797.739149774666, 1703.7134044063262, 1777.7997590587863, 1918.8128155131851, 1815.030895486743, 1801.1429164418194, 1648.3922856930778, 1846.1240417900135, 1891.8175250772333, 1772.9534384979493, 1924.2575021955354, 1617.7675193968453, 1848.10218610471, 1814.4070862175868, 1817.4703783230493, 1648.9408985811338, 1814.7793040807012, 1687.0801838542511, 1523.7833871126072, 1750.5858874976846, 1542.0146120809882, 1812.9807794240546, 1740.468046583777, 1790.6800415050502, 1832.63570434963, 1738.4616946595825, 1414.788229920073, 1541.5483808281583, 1434.1692024288025, 1166.0247812437822, 1378.166592974635, 1055.061098115146, 1278.7985946930698, 1269.260009444211, 1050.3563663749305, 1603.3973117695687, 1449.7056922145637, 1334.6253339747745, 1440.6240549865618, 1261.344371987764, 1248.9327196997524, 1521.342972116413, 1563.1868091613455, 1560.6391109274084], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [320.08842653614073, 391.93564381362927, 422.2707980554426, 571.5333171858912, 426.12180775231457, 673.0777870566855, 449.56555436862345, 489.7145011783774, 473.6880156384747, 473.5938932075251, 458.96135767955394, 491.08750027845883, 380.87327984344813, 457.35350887724803, 629.3835108900945, 558.3224135256996, 504.8689210088395, 534.7015143046542, 327.31564341589194, 452.7390803655092, 445.2449166110136, 422.46751730293363, 603.3426500550638, 525.0205984215236, 547.5968195155679, 550.2648731814381, 531.6110951924155, 531.4384559829414, 616.3007009552846, 438.05113140885663, 562.0141680451405, 651.403118123974, 507.692447373609, 473.40736508623917, 493.3409789718113, 550.7956128322005, 638.4990617306836, 403.1675855515942, 603.0707074410095, 401.5891534741224, 381.9282427094055, 457.58554657662586, 434.55849391351217, 531.443784722985, 409.1678419220611, 546.2994593074634, 343.94774625760203, 570.0816173926768, 528.9931567972221, 516.3790689827302, 669.8547584039368, 508.9566836588273, 504.0099443882713, 466.1362887725999, 511.10728056815594, 362.4728771143763, 441.67212074736443, 417.6180981671936, 693.2821340167401, 583.4139274240515, 605.5509814639902, 494.04073617784894, 561.8969383651812, 616.0932346726877, 407.32634007828625, 486.48066850523344, 526.3885366627925, 176.1973973998847, 488.6499636611932, 412.86960197708856, 656.8363872039222, 706.985360146876, 558.9835281229866, 454.23795623858575, 445.7774650465385, 588.9323159927218, 512.5994231361431, 443.3933035518114, 399.0684035958581, 528.1854539668634, 424.56157253710694, 548.2431951158031, 459.8552166811131, 583.3430326069748, 565.7990295761583, 463.7989332806664, 583.1445339656548, 399.23842788525667, 379.23007873847143, 552.948385016917, 476.0253924168162, 519.6710270714899, 666.17769746386, 648.0654570320161, 537.1631856042753, 551.7680566128445, 476.52893866441326, 530.7122251301245, 297.2279788547444, 515.6080979462351, 496.3186519719282, 443.98863905021216, 457.3042222687952, 415.6183441760873, 484.7940129164375, 553.0825661818392, 436.741309966214, 436.53673689837336, 622.976889764915, 570.7420324519684, 540.7128409114093, 595.4490799874831, 488.9566868692187, 540.0409777794382, 463.4507674418391, 465.69542469075304, 456.74491427773114, 540.5535255246641, 650.9735920178274, 470.86811917534413, 419.87623887437695, 386.38283872177516, 582.3743195165571, 566.5974452312635, 570.7631112311841, 484.15197521728453, 512.4678519873721, 503.24857280234266, 437.1480370284899, 536.6636350865134, 297.307527551738, 429.0958558072874, 385.32650225521536, 491.1723041277541, 345.86227454044155, 320.2574512129259, 581.5044240979704, 521.4789273919724, 513.0756438905953, 470.88278591846216, 516.0872365445291, 517.0985988675865, 376.009994662812, 422.614574006197, 397.01989593683896, 457.9631269553804, 531.1820558469428, 401.5247742408417, 372.309152636744, 269.719558087614, 472.15788703748166, 245.38158189503824, 171.37774875088726, 85.06171581981488, 268.8773440429544, 361.2738036393446, 412.7509137636108, 433.4722936155867, 416.85188564020604, 387.53528074950015, 450.427014099296, 426.03162491978406, 402.4911360984146, 327.79883233458054, 88.88147936409871, -19.22446457022757, 136.29883293692012, 150.2071015984398, 106.04864079362116, 161.15779550197982, -130.814845785667, -164.5574386556343, 188.15979381137834, 29.022862912221584, 75.19721473648104, -202.855005210906, 100.66009364173158, 59.78290955814148, -217.6744899027496, -94.53595617672629, -74.99165511935841, -171.6035098982212, 228.21181757895738, 228.33483348840875, 106.26525971329683, 169.4017919084478, 131.18664156843062, 180.13233519136077, 164.15025134124838, 249.71137727855847, 114.84358494440741, 230.58210717419422, -280.85859048600247, -27.625120003330608, 182.0142500861362, 305.04772679548546, 188.23278714154765, 198.11214798922146, 372.0713135473684, 190.4509039716532], "policy_predator_policy_reward": [281.16805716846767, 350.1063974044767, 454.9732419465495, 450.6639302940423, 371.21927616140783, 340.61777555264825, 374.81081691550287, 392.9438196096131, 237.29839472683537, 347.2847602822343, 335.0633568623733, 328.7245814003692, 392.2481771567941, 512.7301515504081, 402.2778097779184, 202.8850669654229, 424.4189692181448, 321.5666083204713, 499.85554632848215, 594.2567659510139, 293.2712831644297, 292.81787093578754, 364.2726070630772, 363.0658521930389, 402.5826532911325, 297.6336760514102, 445.0970231779494, 391.45317057648555, 307.8576954221973, 287.2263934791807, 355.3516867314489, 323.628235914467, 510.140391215462, 517.1767279869606, 310.4932283080012, 414.543180327239, 288.26364342972266, 298.97518099101376, 124.49891806600576, 403.9936208644132, 425.0687312027013, 457.56659975441397, 312.4997256109923, 428.51817437741323, 546.8340405212238, 454.4615056941929, 442.0576933621324, 446.1845633499363, 342.3970091068869, 431.95899073052624, 275.4432196745542, 358.28185095306395, 414.5378653610828, 405.374692551341, 340.1224177717817, 485.0250167505913, 280.65544831119604, 300.76755431463425, 247.34705234267122, 145.27631718633856, 437.1517492887514, 307.85589736610166, 311.61962181473365, 286.2821814705347, 443.68134080889183, 437.78967302185686, 413.03430926856157, 411.3806697291032, 263.11566870933717, 357.19240938056237, 324.4733410812335, 207.75272388629173, 232.37522357093462, 520.1721376446926, 373.9830789901466, 160.15800885285165, 385.9954979811949, 409.8317782462337, 395.1161963867968, 457.3445768068708, 351.53016551714495, 385.04881975085885, 460.2403502325295, 272.35658511057886, 355.74767356876816, 316.4914605434494, 208.21877386869318, 281.57704277976933, 441.2575358700652, 377.04207310787683, 418.50569920501687, 374.9581754864511, 204.08714975288004, 338.194636756534, 283.3214998256101, 402.57489043945276, 358.04405107585126, 449.44896659746746, 509.4864231878952, 456.86898269946363, 389.32994173854235, 491.5276920550314, 455.7970935973295, 528.9517715547263, 375.0252439718407, 195.69270083776667, 425.1258668841334, 494.5651146572657, 362.3465693384902, 334.28798640627656, 189.62242449385712, 234.45399939443888, 377.72690810121304, 391.0145770247973, 365.04950903062166, 409.5177032431122, 428.692359112776, 351.80896014361656, 454.02006415292, 342.95104016709405, 476.77501131604487, 531.9968065745456, 346.32797006827485, 305.84318162572544, 216.78805578232115, 376.68914346228803, 396.56312201267264, 433.84449498762643, 492.13037766257867, 425.8754752996502, 541.7804947976135, 504.7695603413101, 537.3475154003308, 510.4111804122354, 404.3051225731399, 547.3426710703392, 397.6060975741013, 347.51273704066625, 313.206541896626, 517.2421145119054, 417.2652618505949, 367.01928106033836, 428.45720348907537, 421.85912642305107, 561.2647520129702, 398.5315291755108, 349.7552007667778, 404.6181529996895, 468.4804570132087, 413.27421937504135, 407.97184161041434, 625.07457695475, 526.5017924910918, 759.0733550191949, 605.0677952403983, 577.7618365013567, 484.51990631435285, 409.72493289022697, 521.496051711369, 464.7968234039759, 520.6624325900625, 435.5146327404893, 597.3557095123257, 410.816016714263, 821.800738274094, 523.3304768521073, 494.08564516069646, 760.9568011321011, 585.7437263159197, 581.2190398172822, 577.2038640132471, 884.1932016718354, 360.5565631849824, 800.4273730660534, 463.3694848397157, 719.3494037498554, 497.342668560988, 621.0129229322099, 614.2355467963808, 967.2349087273044, 538.4956552268766, 758.4558761656333, 422.9113035611043, 723.9393571410986, 426.87666545948645, 747.1619751333334, 746.4542646750056, 276.852092539977, 468.0440193947405, 558.7184069720164, 440.1594109793255, 475.759268889837, 619.4909773848497, 937.9254528042347, 574.789810769219, 459.49118446557173, 534.4853244763002, 642.356549554277, 573.5701706672206, 424.5467227411668]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8396105607441524, "mean_inference_ms": 2.2422067435735706, "mean_action_processing_ms": 0.3513768299207251, "mean_env_wait_ms": 0.31295930232813074, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004268646240234375, "StateBufferConnector_ms": 0.003437519073486328, "ViewRequirementAgentConnector_ms": 0.12330746650695801}, "num_episodes": 18, "episode_return_max": 2008.4169316622692, "episode_return_min": 1050.3563663749305, "episode_return_mean": 1676.2207582168676, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 292.207850339674, "num_env_steps_trained_throughput_per_sec": 292.207850339674, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 13590.828, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13590.768, "sample_time_ms": 1417.373, "learn_time_ms": 12154.585, "learn_throughput": 329.094, "synch_weights_time_ms": 16.065}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "479e5_00000", "date": "2024-08-16_11-31-42", "timestamp": 1723788102, "time_this_iter_s": 13.73356008529663, "time_total_s": 296.1701922416687, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78a04c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 296.1701922416687, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 64.06842105263158, "ram_util_percent": 82.01578947368421}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1858929964915785, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.935869678618415, "policy_loss": -0.010319113227041073, "vf_loss": 9.944798292937103, "vf_explained_var": -0.005866812492804552, "kl": 0.013905005010470456, "entropy": 1.3552467698773378, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3411371498669267, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.792044936790669, "policy_loss": -0.006897937298491203, "vf_loss": 9.79745095924095, "vf_explained_var": -0.000693918504412212, "kl": 0.009946009691767692, "entropy": 1.3910970524505333, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 1956.76284744494, "episode_reward_min": 732.1409556873142, "episode_reward_mean": 1586.5083925328938, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -934.8985840327526, "predator_policy": 124.49891806600576}, "policy_reward_max": {"prey_policy": 706.985360146876, "predator_policy": 1337.3494664141203}, "policy_reward_mean": {"prey_policy": 291.4049224300072, "predator_policy": 501.84927383644}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1628.9054717030124, 1533.1523998455507, 1722.1491202431466, 1707.0201786249015, 1956.76284744494, 1802.2716203623472, 1819.728225617367, 1812.5365126903819, 1790.0587910732954, 1698.7275922049055, 1440.713221540388, 1669.3194309698008, 1844.5993642966916, 1775.8919763231363, 1775.2780224142666, 1527.000913060342, 1521.8276437281813, 1896.0478123183236, 1765.768845577199, 1568.8508688822574, 1751.8200029153832, 1779.714630756391, 1709.3837529209134, 1775.795184631195, 1701.837096969041, 1472.1787784993733, 1750.4780727333305, 1789.1602941797735, 1856.5249410052909, 1774.8276324821823, 1814.7341814678546, 1779.1914826883371, 1821.164924815714, 1857.6714315969377, 1608.5945239078835, 1792.9690284059866, 1890.353477961651, 1560.2383447871875, 1797.739149774666, 1703.7134044063262, 1777.7997590587863, 1918.8128155131851, 1815.030895486743, 1801.1429164418194, 1648.3922856930778, 1846.1240417900135, 1891.8175250772333, 1772.9534384979493, 1924.2575021955354, 1617.7675193968453, 1848.10218610471, 1814.4070862175868, 1817.4703783230493, 1648.9408985811338, 1814.7793040807012, 1687.0801838542511, 1523.7833871126072, 1750.5858874976846, 1542.0146120809882, 1812.9807794240546, 1740.468046583777, 1790.6800415050502, 1832.63570434963, 1738.4616946595825, 1414.788229920073, 1541.5483808281583, 1434.1692024288025, 1166.0247812437822, 1378.166592974635, 1055.061098115146, 1278.7985946930698, 1269.260009444211, 1050.3563663749305, 1603.3973117695687, 1449.7056922145637, 1334.6253339747745, 1440.6240549865618, 1261.344371987764, 1248.9327196997524, 1521.342972116413, 1563.1868091613455, 1560.6391109274084, 1645.6771275176552, 1547.4406618524927, 1386.3941845091958, 741.1053726722511, 1229.1578706406433, 1471.7596448010313, 1235.501810011178, 1261.3386192990997, 1565.9269700518198, 942.5442497047366, 1368.5802687525359, 1614.103034258841, 1200.409045755231, 913.1895956205312, 1401.2968657741771, 1071.8859862944244, 1129.2252718734444, 732.1409556873142], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [638.4990617306836, 403.1675855515942, 603.0707074410095, 401.5891534741224, 381.9282427094055, 457.58554657662586, 434.55849391351217, 531.443784722985, 409.1678419220611, 546.2994593074634, 343.94774625760203, 570.0816173926768, 528.9931567972221, 516.3790689827302, 669.8547584039368, 508.9566836588273, 504.0099443882713, 466.1362887725999, 511.10728056815594, 362.4728771143763, 441.67212074736443, 417.6180981671936, 693.2821340167401, 583.4139274240515, 605.5509814639902, 494.04073617784894, 561.8969383651812, 616.0932346726877, 407.32634007828625, 486.48066850523344, 526.3885366627925, 176.1973973998847, 488.6499636611932, 412.86960197708856, 656.8363872039222, 706.985360146876, 558.9835281229866, 454.23795623858575, 445.7774650465385, 588.9323159927218, 512.5994231361431, 443.3933035518114, 399.0684035958581, 528.1854539668634, 424.56157253710694, 548.2431951158031, 459.8552166811131, 583.3430326069748, 565.7990295761583, 463.7989332806664, 583.1445339656548, 399.23842788525667, 379.23007873847143, 552.948385016917, 476.0253924168162, 519.6710270714899, 666.17769746386, 648.0654570320161, 537.1631856042753, 551.7680566128445, 476.52893866441326, 530.7122251301245, 297.2279788547444, 515.6080979462351, 496.3186519719282, 443.98863905021216, 457.3042222687952, 415.6183441760873, 484.7940129164375, 553.0825661818392, 436.741309966214, 436.53673689837336, 622.976889764915, 570.7420324519684, 540.7128409114093, 595.4490799874831, 488.9566868692187, 540.0409777794382, 463.4507674418391, 465.69542469075304, 456.74491427773114, 540.5535255246641, 650.9735920178274, 470.86811917534413, 419.87623887437695, 386.38283872177516, 582.3743195165571, 566.5974452312635, 570.7631112311841, 484.15197521728453, 512.4678519873721, 503.24857280234266, 437.1480370284899, 536.6636350865134, 297.307527551738, 429.0958558072874, 385.32650225521536, 491.1723041277541, 345.86227454044155, 320.2574512129259, 581.5044240979704, 521.4789273919724, 513.0756438905953, 470.88278591846216, 516.0872365445291, 517.0985988675865, 376.009994662812, 422.614574006197, 397.01989593683896, 457.9631269553804, 531.1820558469428, 401.5247742408417, 372.309152636744, 269.719558087614, 472.15788703748166, 245.38158189503824, 171.37774875088726, 85.06171581981488, 268.8773440429544, 361.2738036393446, 412.7509137636108, 433.4722936155867, 416.85188564020604, 387.53528074950015, 450.427014099296, 426.03162491978406, 402.4911360984146, 327.79883233458054, 88.88147936409871, -19.22446457022757, 136.29883293692012, 150.2071015984398, 106.04864079362116, 161.15779550197982, -130.814845785667, -164.5574386556343, 188.15979381137834, 29.022862912221584, 75.19721473648104, -202.855005210906, 100.66009364173158, 59.78290955814148, -217.6744899027496, -94.53595617672629, -74.99165511935841, -171.6035098982212, 228.21181757895738, 228.33483348840875, 106.26525971329683, 169.4017919084478, 131.18664156843062, 180.13233519136077, 164.15025134124838, 249.71137727855847, 114.84358494440741, 230.58210717419422, -280.85859048600247, -27.625120003330608, 182.0142500861362, 305.04772679548546, 188.23278714154765, 198.11214798922146, 372.0713135473684, 190.4509039716532, 242.31404434399838, 200.47250592646503, 68.90217369411884, 142.34403896728503, 186.13317758845125, 71.85240992800401, -545.8492236187535, -934.8985840327526, -52.0428290438648, 35.228790865297384, 162.9437286748144, 79.86301113081531, -53.44854197181046, -143.16345189113036, -411.6696356540971, -283.6548624285183, -123.45439658198639, 109.1316220821671, -380.88175403097824, -515.7263484166693, 46.696766980989864, 87.96030029041762, 138.3213800484678, 135.6333873001855, -231.9924505409581, -307.0473689960792, -595.5631470158129, -379.83647683162684, -14.471111534643569, -50.46830460770963, -455.49398791619325, -312.40967168907656, -151.9067390085318, -119.71764194771829, -640.5607136506167, -457.0255143900549], "policy_predator_policy_reward": [288.26364342972266, 298.97518099101376, 124.49891806600576, 403.9936208644132, 425.0687312027013, 457.56659975441397, 312.4997256109923, 428.51817437741323, 546.8340405212238, 454.4615056941929, 442.0576933621324, 446.1845633499363, 342.3970091068869, 431.95899073052624, 275.4432196745542, 358.28185095306395, 414.5378653610828, 405.374692551341, 340.1224177717817, 485.0250167505913, 280.65544831119604, 300.76755431463425, 247.34705234267122, 145.27631718633856, 437.1517492887514, 307.85589736610166, 311.61962181473365, 286.2821814705347, 443.68134080889183, 437.78967302185686, 413.03430926856157, 411.3806697291032, 263.11566870933717, 357.19240938056237, 324.4733410812335, 207.75272388629173, 232.37522357093462, 520.1721376446926, 373.9830789901466, 160.15800885285165, 385.9954979811949, 409.8317782462337, 395.1161963867968, 457.3445768068708, 351.53016551714495, 385.04881975085885, 460.2403502325295, 272.35658511057886, 355.74767356876816, 316.4914605434494, 208.21877386869318, 281.57704277976933, 441.2575358700652, 377.04207310787683, 418.50569920501687, 374.9581754864511, 204.08714975288004, 338.194636756534, 283.3214998256101, 402.57489043945276, 358.04405107585126, 449.44896659746746, 509.4864231878952, 456.86898269946363, 389.32994173854235, 491.5276920550314, 455.7970935973295, 528.9517715547263, 375.0252439718407, 195.69270083776667, 425.1258668841334, 494.5651146572657, 362.3465693384902, 334.28798640627656, 189.62242449385712, 234.45399939443888, 377.72690810121304, 391.0145770247973, 365.04950903062166, 409.5177032431122, 428.692359112776, 351.80896014361656, 454.02006415292, 342.95104016709405, 476.77501131604487, 531.9968065745456, 346.32797006827485, 305.84318162572544, 216.78805578232115, 376.68914346228803, 396.56312201267264, 433.84449498762643, 492.13037766257867, 425.8754752996502, 541.7804947976135, 504.7695603413101, 537.3475154003308, 510.4111804122354, 404.3051225731399, 547.3426710703392, 397.6060975741013, 347.51273704066625, 313.206541896626, 517.2421145119054, 417.2652618505949, 367.01928106033836, 428.45720348907537, 421.85912642305107, 561.2647520129702, 398.5315291755108, 349.7552007667778, 404.6181529996895, 468.4804570132087, 413.27421937504135, 407.97184161041434, 625.07457695475, 526.5017924910918, 759.0733550191949, 605.0677952403983, 577.7618365013567, 484.51990631435285, 409.72493289022697, 521.496051711369, 464.7968234039759, 520.6624325900625, 435.5146327404893, 597.3557095123257, 410.816016714263, 821.800738274094, 523.3304768521073, 494.08564516069646, 760.9568011321011, 585.7437263159197, 581.2190398172822, 577.2038640132471, 884.1932016718354, 360.5565631849824, 800.4273730660534, 463.3694848397157, 719.3494037498554, 497.342668560988, 621.0129229322099, 614.2355467963808, 967.2349087273044, 538.4956552268766, 758.4558761656333, 422.9113035611043, 723.9393571410986, 426.87666545948645, 747.1619751333334, 746.4542646750056, 276.852092539977, 468.0440193947405, 558.7184069720164, 440.1594109793255, 475.759268889837, 619.4909773848497, 937.9254528042347, 574.789810769219, 459.49118446557173, 534.4853244763002, 642.356549554277, 573.5701706672206, 424.5467227411668, 608.9253059481592, 593.9652712990329, 711.8085177458528, 624.3859314452353, 627.855729317579, 500.5528676751617, 884.5037139096368, 1337.3494664141203, 566.2445812639462, 679.7273275552643, 573.5712255023722, 655.3816794930287, 558.1395299798987, 873.9742738942198, 1045.3621917783582, 911.3009256033564, 846.3125184854784, 733.9372260661604, 791.4195595259182, 1047.732792626466, 544.1366121651738, 689.786589315955, 675.5209460701302, 664.627320840058, 697.4611740106882, 1041.9876912815798, 1117.4000694271754, 771.189150040796, 843.9235626798518, 622.312719236678, 882.8049981293714, 956.9846477703223, 653.3314451064291, 747.5182077232644, 1019.3119199771461, 810.4152637508398]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8333774357230714, "mean_inference_ms": 2.2230357525755524, "mean_action_processing_ms": 0.3483276447976197, "mean_env_wait_ms": 0.3104968710188138, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004523515701293945, "StateBufferConnector_ms": 0.0034922361373901367, "ViewRequirementAgentConnector_ms": 0.12985122203826904}, "num_episodes": 18, "episode_return_max": 1956.76284744494, "episode_return_min": 732.1409556873142, "episode_return_mean": 1586.5083925328938, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 296.60104738051007, "num_env_steps_trained_throughput_per_sec": 296.60104738051007, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 13580.693, "restore_workers_time_ms": 0.013, "training_step_time_ms": 13580.634, "sample_time_ms": 1453.278, "learn_time_ms": 12108.791, "learn_throughput": 330.339, "synch_weights_time_ms": 16.022}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "479e5_00000", "date": "2024-08-16_11-31-55", "timestamp": 1723788115, "time_this_iter_s": 13.528110027313232, "time_total_s": 309.69830226898193, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78e5e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 309.69830226898193, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 65.33684210526314, "ram_util_percent": 82.21578947368421}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2426944454747533, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.83019833438611, "policy_loss": -0.004622086886779736, "vf_loss": 9.833809916178385, "vf_explained_var": 0.0035117608529550057, "kl": 0.010105403311408604, "entropy": 1.2989452104719859, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.331986978279535, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.820683509584457, "policy_loss": -0.007961884167331158, "vf_loss": 9.826779599669118, "vf_explained_var": -0.0025095366296314058, "kl": 0.012438705377302848, "entropy": 1.4190713271262154, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 1924.2575021955354, "episode_reward_min": 581.4318622591875, "episode_reward_mean": 1431.1035001082391, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1063.241698490454, "predator_policy": 189.62242449385712}, "policy_reward_max": {"prey_policy": 666.17769746386, "predator_policy": 1432.6093206909522}, "policy_reward_mean": {"prey_policy": 38.70835790984383, "predator_policy": 676.843392144276}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1789.1602941797735, 1856.5249410052909, 1774.8276324821823, 1814.7341814678546, 1779.1914826883371, 1821.164924815714, 1857.6714315969377, 1608.5945239078835, 1792.9690284059866, 1890.353477961651, 1560.2383447871875, 1797.739149774666, 1703.7134044063262, 1777.7997590587863, 1918.8128155131851, 1815.030895486743, 1801.1429164418194, 1648.3922856930778, 1846.1240417900135, 1891.8175250772333, 1772.9534384979493, 1924.2575021955354, 1617.7675193968453, 1848.10218610471, 1814.4070862175868, 1817.4703783230493, 1648.9408985811338, 1814.7793040807012, 1687.0801838542511, 1523.7833871126072, 1750.5858874976846, 1542.0146120809882, 1812.9807794240546, 1740.468046583777, 1790.6800415050502, 1832.63570434963, 1738.4616946595825, 1414.788229920073, 1541.5483808281583, 1434.1692024288025, 1166.0247812437822, 1378.166592974635, 1055.061098115146, 1278.7985946930698, 1269.260009444211, 1050.3563663749305, 1603.3973117695687, 1449.7056922145637, 1334.6253339747745, 1440.6240549865618, 1261.344371987764, 1248.9327196997524, 1521.342972116413, 1563.1868091613455, 1560.6391109274084, 1645.6771275176552, 1547.4406618524927, 1386.3941845091958, 741.1053726722511, 1229.1578706406433, 1471.7596448010313, 1235.501810011178, 1261.3386192990997, 1565.9269700518198, 942.5442497047366, 1368.5802687525359, 1614.103034258841, 1200.409045755231, 913.1895956205312, 1401.2968657741771, 1071.8859862944244, 1129.2252718734444, 732.1409556873142, 1315.208123934638, 1005.2109633127026, 1198.3570458161475, 581.4318622591875, 1175.5689428379126, 1126.8153199640367, 942.4061826141738, 1283.0907978542834, 1079.8847145199447, 1128.7458671582308, 972.4549171464586, 1146.6502761631407, 1491.8506952526836, 967.8453481423251, 705.2908765328784, 1180.2458602523238, 1586.150913042187, 802.0501677655086, 1086.3788896068706, 1440.8636632840473, 1146.462220480258, 996.7152230349338, 1325.5142491650265, 1263.2584350481031, 1249.174528397537, 1452.9713188964947, 1006.7317333985507], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [476.0253924168162, 519.6710270714899, 666.17769746386, 648.0654570320161, 537.1631856042753, 551.7680566128445, 476.52893866441326, 530.7122251301245, 297.2279788547444, 515.6080979462351, 496.3186519719282, 443.98863905021216, 457.3042222687952, 415.6183441760873, 484.7940129164375, 553.0825661818392, 436.741309966214, 436.53673689837336, 622.976889764915, 570.7420324519684, 540.7128409114093, 595.4490799874831, 488.9566868692187, 540.0409777794382, 463.4507674418391, 465.69542469075304, 456.74491427773114, 540.5535255246641, 650.9735920178274, 470.86811917534413, 419.87623887437695, 386.38283872177516, 582.3743195165571, 566.5974452312635, 570.7631112311841, 484.15197521728453, 512.4678519873721, 503.24857280234266, 437.1480370284899, 536.6636350865134, 297.307527551738, 429.0958558072874, 385.32650225521536, 491.1723041277541, 345.86227454044155, 320.2574512129259, 581.5044240979704, 521.4789273919724, 513.0756438905953, 470.88278591846216, 516.0872365445291, 517.0985988675865, 376.009994662812, 422.614574006197, 397.01989593683896, 457.9631269553804, 531.1820558469428, 401.5247742408417, 372.309152636744, 269.719558087614, 472.15788703748166, 245.38158189503824, 171.37774875088726, 85.06171581981488, 268.8773440429544, 361.2738036393446, 412.7509137636108, 433.4722936155867, 416.85188564020604, 387.53528074950015, 450.427014099296, 426.03162491978406, 402.4911360984146, 327.79883233458054, 88.88147936409871, -19.22446457022757, 136.29883293692012, 150.2071015984398, 106.04864079362116, 161.15779550197982, -130.814845785667, -164.5574386556343, 188.15979381137834, 29.022862912221584, 75.19721473648104, -202.855005210906, 100.66009364173158, 59.78290955814148, -217.6744899027496, -94.53595617672629, -74.99165511935841, -171.6035098982212, 228.21181757895738, 228.33483348840875, 106.26525971329683, 169.4017919084478, 131.18664156843062, 180.13233519136077, 164.15025134124838, 249.71137727855847, 114.84358494440741, 230.58210717419422, -280.85859048600247, -27.625120003330608, 182.0142500861362, 305.04772679548546, 188.23278714154765, 198.11214798922146, 372.0713135473684, 190.4509039716532, 242.31404434399838, 200.47250592646503, 68.90217369411884, 142.34403896728503, 186.13317758845125, 71.85240992800401, -545.8492236187535, -934.8985840327526, -52.0428290438648, 35.228790865297384, 162.9437286748144, 79.86301113081531, -53.44854197181046, -143.16345189113036, -411.6696356540971, -283.6548624285183, -123.45439658198639, 109.1316220821671, -380.88175403097824, -515.7263484166693, 46.696766980989864, 87.96030029041762, 138.3213800484678, 135.6333873001855, -231.9924505409581, -307.0473689960792, -595.5631470158129, -379.83647683162684, -14.471111534643569, -50.46830460770963, -455.49398791619325, -312.40967168907656, -151.9067390085318, -119.71764194771829, -640.5607136506167, -457.0255143900549, -215.22258798040653, -264.5102058645104, -661.6120370415281, -608.1099393952597, -667.4909180937219, -440.47031150182687, -1063.241698490454, -856.5373619967287, -650.0318535089866, -267.79099986700743, -197.6507107891684, -346.3481119472087, -675.7347015515304, -483.8889029725247, -349.9122695559216, -390.7409939673006, -316.60620824994845, -947.7189526093675, -91.48374052119183, -451.13132005408596, -759.2538506708739, -333.80977859680036, -382.7928780534387, -643.8418785488548, -72.30385763503098, 79.92790157610101, -595.5555622268719, -303.58146946602994, -721.9888518124891, -684.6764241235987, -481.35918161430226, -392.95635251552136, 74.5680853064548, -295.16529085370246, -543.8084278318476, -670.375900723571, -453.6412969809927, -293.60358559909616, -425.1460876501891, -60.49362439540896, -248.40710812164343, -544.6610821752614, -658.9228478711459, -332.4981828986125, -258.89373062895424, -493.6009155792116, -735.1150121190049, -176.6981385101097, -353.81407590483695, -241.79385822587042, -321.04539701838905, -82.95024027107837, -479.3714438227249, -749.5567510992598], "policy_predator_policy_reward": [418.50569920501687, 374.9581754864511, 204.08714975288004, 338.194636756534, 283.3214998256101, 402.57489043945276, 358.04405107585126, 449.44896659746746, 509.4864231878952, 456.86898269946363, 389.32994173854235, 491.5276920550314, 455.7970935973295, 528.9517715547263, 375.0252439718407, 195.69270083776667, 425.1258668841334, 494.5651146572657, 362.3465693384902, 334.28798640627656, 189.62242449385712, 234.45399939443888, 377.72690810121304, 391.0145770247973, 365.04950903062166, 409.5177032431122, 428.692359112776, 351.80896014361656, 454.02006415292, 342.95104016709405, 476.77501131604487, 531.9968065745456, 346.32797006827485, 305.84318162572544, 216.78805578232115, 376.68914346228803, 396.56312201267264, 433.84449498762643, 492.13037766257867, 425.8754752996502, 541.7804947976135, 504.7695603413101, 537.3475154003308, 510.4111804122354, 404.3051225731399, 547.3426710703392, 397.6060975741013, 347.51273704066625, 313.206541896626, 517.2421145119054, 417.2652618505949, 367.01928106033836, 428.45720348907537, 421.85912642305107, 561.2647520129702, 398.5315291755108, 349.7552007667778, 404.6181529996895, 468.4804570132087, 413.27421937504135, 407.97184161041434, 625.07457695475, 526.5017924910918, 759.0733550191949, 605.0677952403983, 577.7618365013567, 484.51990631435285, 409.72493289022697, 521.496051711369, 464.7968234039759, 520.6624325900625, 435.5146327404893, 597.3557095123257, 410.816016714263, 821.800738274094, 523.3304768521073, 494.08564516069646, 760.9568011321011, 585.7437263159197, 581.2190398172822, 577.2038640132471, 884.1932016718354, 360.5565631849824, 800.4273730660534, 463.3694848397157, 719.3494037498554, 497.342668560988, 621.0129229322099, 614.2355467963808, 967.2349087273044, 538.4956552268766, 758.4558761656333, 422.9113035611043, 723.9393571410986, 426.87666545948645, 747.1619751333334, 746.4542646750056, 276.852092539977, 468.0440193947405, 558.7184069720164, 440.1594109793255, 475.759268889837, 619.4909773848497, 937.9254528042347, 574.789810769219, 459.49118446557173, 534.4853244763002, 642.356549554277, 573.5701706672206, 424.5467227411668, 608.9253059481592, 593.9652712990329, 711.8085177458528, 624.3859314452353, 627.855729317579, 500.5528676751617, 884.5037139096368, 1337.3494664141203, 566.2445812639462, 679.7273275552643, 573.5712255023722, 655.3816794930287, 558.1395299798987, 873.9742738942198, 1045.3621917783582, 911.3009256033564, 846.3125184854784, 733.9372260661604, 791.4195595259182, 1047.732792626466, 544.1366121651738, 689.786589315955, 675.5209460701302, 664.627320840058, 697.4611740106882, 1041.9876912815798, 1117.4000694271754, 771.189150040796, 843.9235626798518, 622.312719236678, 882.8049981293714, 956.9846477703223, 653.3314451064291, 747.5182077232644, 1019.3119199771461, 810.4152637508398, 911.8467285284185, 883.0941892511357, 1150.031095279419, 1124.901844470072, 1303.738513650044, 1002.5797617616523, 1111.1218870509904, 1390.0890356953794, 1168.7929430029224, 924.5988532109845, 688.1801473736496, 982.6339953267648, 850.1489948214767, 1251.8807923167524, 1020.9470391549477, 1002.7970222225575, 911.6005546883089, 1432.6093206909522, 874.0022842755221, 797.3586434579857, 864.338045001667, 1201.180501412466, 1187.3017137533827, 985.9833190120512, 862.7579117793148, 621.4687395322998, 982.9616535182797, 884.0207263169476, 796.3429457855281, 1315.6132066834375, 1116.2167761247572, 938.34461825739, 895.3361982115307, 911.4119203779038, 1007.9871587246392, 1008.2473375962884, 988.7965263620241, 844.8272458249352, 993.8354141320286, 932.667961197617, 1032.0891670713565, 907.4412437058063, 989.2984315408055, 998.8378222638866, 1226.932642658321, 851.0762527148714, 1110.1602926151518, 1064.9112930620656, 952.1873719473648, 892.5950905808796, 926.9136826408837, 930.0532735450781, 1149.6949385286052, 1085.9649897919303]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.833458600649209, "mean_inference_ms": 2.2117396070041853, "mean_action_processing_ms": 0.3460008556381154, "mean_env_wait_ms": 0.3097747081587226, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004835724830627441, "StateBufferConnector_ms": 0.0048683881759643555, "ViewRequirementAgentConnector_ms": 0.13204526901245117}, "num_episodes": 27, "episode_return_max": 1924.2575021955354, "episode_return_min": 581.4318622591875, "episode_return_mean": 1431.1035001082391, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 288.22073992013037, "num_env_steps_trained_throughput_per_sec": 288.22073992013037, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 13610.134, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13610.078, "sample_time_ms": 1553.304, "learn_time_ms": 12036.437, "learn_throughput": 332.324, "synch_weights_time_ms": 18.029}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "479e5_00000", "date": "2024-08-16_11-32-09", "timestamp": 1723788129, "time_this_iter_s": 13.93038821220398, "time_total_s": 323.6286904811859, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78e5dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 323.6286904811859, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 61.03000000000001, "ram_util_percent": 81.86000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.210827154204959, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.869080398700856, "policy_loss": -0.0036594095474808777, "vf_loss": 9.871886987534781, "vf_explained_var": 0.008108387643067294, "kl": 0.008528352004866364, "entropy": 1.3099717873744863, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.510855523004103, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.718389739687481, "policy_loss": -0.012544478276971156, "vf_loss": 9.72819761044134, "vf_explained_var": -0.006699928152498114, "kl": 0.018243919076151846, "entropy": 1.4569089557127979, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 1924.2575021955354, "episode_reward_min": 581.4318622591875, "episode_reward_mean": 1393.8210591865497, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1063.241698490454, "predator_policy": 276.852092539977}, "policy_reward_max": {"prey_policy": 581.5044240979704, "predator_policy": 1432.6093206909522}, "policy_reward_mean": {"prey_policy": -97.05508263206342, "predator_policy": 793.9656122253381}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1846.1240417900135, 1891.8175250772333, 1772.9534384979493, 1924.2575021955354, 1617.7675193968453, 1848.10218610471, 1814.4070862175868, 1817.4703783230493, 1648.9408985811338, 1814.7793040807012, 1687.0801838542511, 1523.7833871126072, 1750.5858874976846, 1542.0146120809882, 1812.9807794240546, 1740.468046583777, 1790.6800415050502, 1832.63570434963, 1738.4616946595825, 1414.788229920073, 1541.5483808281583, 1434.1692024288025, 1166.0247812437822, 1378.166592974635, 1055.061098115146, 1278.7985946930698, 1269.260009444211, 1050.3563663749305, 1603.3973117695687, 1449.7056922145637, 1334.6253339747745, 1440.6240549865618, 1261.344371987764, 1248.9327196997524, 1521.342972116413, 1563.1868091613455, 1560.6391109274084, 1645.6771275176552, 1547.4406618524927, 1386.3941845091958, 741.1053726722511, 1229.1578706406433, 1471.7596448010313, 1235.501810011178, 1261.3386192990997, 1565.9269700518198, 942.5442497047366, 1368.5802687525359, 1614.103034258841, 1200.409045755231, 913.1895956205312, 1401.2968657741771, 1071.8859862944244, 1129.2252718734444, 732.1409556873142, 1315.208123934638, 1005.2109633127026, 1198.3570458161475, 581.4318622591875, 1175.5689428379126, 1126.8153199640367, 942.4061826141738, 1283.0907978542834, 1079.8847145199447, 1128.7458671582308, 972.4549171464586, 1146.6502761631407, 1491.8506952526836, 967.8453481423251, 705.2908765328784, 1180.2458602523238, 1586.150913042187, 802.0501677655086, 1086.3788896068706, 1440.8636632840473, 1146.462220480258, 996.7152230349338, 1325.5142491650265, 1263.2584350481031, 1249.174528397537, 1452.9713188964947, 1006.7317333985507, 1713.5046185368374, 1599.1758142357016, 1772.6556602574194, 1701.4631932553345, 1357.624873072953, 1720.6172654825612, 1729.4773770199474, 1357.47472467017, 1405.4556629677172, 1644.562787672127, 1481.9338202012166, 1699.3503073078173, 1752.7711890764967, 1651.241872687901, 1451.8300650610963, 1446.5351494551553, 1478.5689828251377, 1315.574033718809], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [512.4678519873721, 503.24857280234266, 437.1480370284899, 536.6636350865134, 297.307527551738, 429.0958558072874, 385.32650225521536, 491.1723041277541, 345.86227454044155, 320.2574512129259, 581.5044240979704, 521.4789273919724, 513.0756438905953, 470.88278591846216, 516.0872365445291, 517.0985988675865, 376.009994662812, 422.614574006197, 397.01989593683896, 457.9631269553804, 531.1820558469428, 401.5247742408417, 372.309152636744, 269.719558087614, 472.15788703748166, 245.38158189503824, 171.37774875088726, 85.06171581981488, 268.8773440429544, 361.2738036393446, 412.7509137636108, 433.4722936155867, 416.85188564020604, 387.53528074950015, 450.427014099296, 426.03162491978406, 402.4911360984146, 327.79883233458054, 88.88147936409871, -19.22446457022757, 136.29883293692012, 150.2071015984398, 106.04864079362116, 161.15779550197982, -130.814845785667, -164.5574386556343, 188.15979381137834, 29.022862912221584, 75.19721473648104, -202.855005210906, 100.66009364173158, 59.78290955814148, -217.6744899027496, -94.53595617672629, -74.99165511935841, -171.6035098982212, 228.21181757895738, 228.33483348840875, 106.26525971329683, 169.4017919084478, 131.18664156843062, 180.13233519136077, 164.15025134124838, 249.71137727855847, 114.84358494440741, 230.58210717419422, -280.85859048600247, -27.625120003330608, 182.0142500861362, 305.04772679548546, 188.23278714154765, 198.11214798922146, 372.0713135473684, 190.4509039716532, 242.31404434399838, 200.47250592646503, 68.90217369411884, 142.34403896728503, 186.13317758845125, 71.85240992800401, -545.8492236187535, -934.8985840327526, -52.0428290438648, 35.228790865297384, 162.9437286748144, 79.86301113081531, -53.44854197181046, -143.16345189113036, -411.6696356540971, -283.6548624285183, -123.45439658198639, 109.1316220821671, -380.88175403097824, -515.7263484166693, 46.696766980989864, 87.96030029041762, 138.3213800484678, 135.6333873001855, -231.9924505409581, -307.0473689960792, -595.5631470158129, -379.83647683162684, -14.471111534643569, -50.46830460770963, -455.49398791619325, -312.40967168907656, -151.9067390085318, -119.71764194771829, -640.5607136506167, -457.0255143900549, -215.22258798040653, -264.5102058645104, -661.6120370415281, -608.1099393952597, -667.4909180937219, -440.47031150182687, -1063.241698490454, -856.5373619967287, -650.0318535089866, -267.79099986700743, -197.6507107891684, -346.3481119472087, -675.7347015515304, -483.8889029725247, -349.9122695559216, -390.7409939673006, -316.60620824994845, -947.7189526093675, -91.48374052119183, -451.13132005408596, -759.2538506708739, -333.80977859680036, -382.7928780534387, -643.8418785488548, -72.30385763503098, 79.92790157610101, -595.5555622268719, -303.58146946602994, -721.9888518124891, -684.6764241235987, -481.35918161430226, -392.95635251552136, 74.5680853064548, -295.16529085370246, -543.8084278318476, -670.375900723571, -453.6412969809927, -293.60358559909616, -425.1460876501891, -60.49362439540896, -248.40710812164343, -544.6610821752614, -658.9228478711459, -332.4981828986125, -258.89373062895424, -493.6009155792116, -735.1150121190049, -176.6981385101097, -353.81407590483695, -241.79385822587042, -321.04539701838905, -82.95024027107837, -479.3714438227249, -749.5567510992598, -37.63160830077036, -387.31578660294906, -34.921670348531194, -161.1707371903486, -293.14257951453413, -2.5794112096675734, -132.02132137519706, -268.84673406189313, -395.4703059886681, -480.9792380614956, -271.9771676259975, -350.55744978772566, 156.15946058672017, -255.8145358381839, -581.9931754739324, -597.5096263149418, -157.0848379308552, -337.0435665021231, 111.82692259200978, -715.7659445711419, -212.5985839495654, -543.5611381108762, -509.6675763995955, 203.08956307002933, -240.59422754831076, 247.30997355301338, -576.1966754626931, -136.96186703586812, -168.2238072020546, -237.56180198095075, -487.071904268365, -455.1208441844387, -66.05751599963237, 8.428360090701167, -64.8997752091098, -358.5176543117699], "policy_predator_policy_reward": [396.56312201267264, 433.84449498762643, 492.13037766257867, 425.8754752996502, 541.7804947976135, 504.7695603413101, 537.3475154003308, 510.4111804122354, 404.3051225731399, 547.3426710703392, 397.6060975741013, 347.51273704066625, 313.206541896626, 517.2421145119054, 417.2652618505949, 367.01928106033836, 428.45720348907537, 421.85912642305107, 561.2647520129702, 398.5315291755108, 349.7552007667778, 404.6181529996895, 468.4804570132087, 413.27421937504135, 407.97184161041434, 625.07457695475, 526.5017924910918, 759.0733550191949, 605.0677952403983, 577.7618365013567, 484.51990631435285, 409.72493289022697, 521.496051711369, 464.7968234039759, 520.6624325900625, 435.5146327404893, 597.3557095123257, 410.816016714263, 821.800738274094, 523.3304768521073, 494.08564516069646, 760.9568011321011, 585.7437263159197, 581.2190398172822, 577.2038640132471, 884.1932016718354, 360.5565631849824, 800.4273730660534, 463.3694848397157, 719.3494037498554, 497.342668560988, 621.0129229322099, 614.2355467963808, 967.2349087273044, 538.4956552268766, 758.4558761656333, 422.9113035611043, 723.9393571410986, 426.87666545948645, 747.1619751333334, 746.4542646750056, 276.852092539977, 468.0440193947405, 558.7184069720164, 440.1594109793255, 475.759268889837, 619.4909773848497, 937.9254528042347, 574.789810769219, 459.49118446557173, 534.4853244763002, 642.356549554277, 573.5701706672206, 424.5467227411668, 608.9253059481592, 593.9652712990329, 711.8085177458528, 624.3859314452353, 627.855729317579, 500.5528676751617, 884.5037139096368, 1337.3494664141203, 566.2445812639462, 679.7273275552643, 573.5712255023722, 655.3816794930287, 558.1395299798987, 873.9742738942198, 1045.3621917783582, 911.3009256033564, 846.3125184854784, 733.9372260661604, 791.4195595259182, 1047.732792626466, 544.1366121651738, 689.786589315955, 675.5209460701302, 664.627320840058, 697.4611740106882, 1041.9876912815798, 1117.4000694271754, 771.189150040796, 843.9235626798518, 622.312719236678, 882.8049981293714, 956.9846477703223, 653.3314451064291, 747.5182077232644, 1019.3119199771461, 810.4152637508398, 911.8467285284185, 883.0941892511357, 1150.031095279419, 1124.901844470072, 1303.738513650044, 1002.5797617616523, 1111.1218870509904, 1390.0890356953794, 1168.7929430029224, 924.5988532109845, 688.1801473736496, 982.6339953267648, 850.1489948214767, 1251.8807923167524, 1020.9470391549477, 1002.7970222225575, 911.6005546883089, 1432.6093206909522, 874.0022842755221, 797.3586434579857, 864.338045001667, 1201.180501412466, 1187.3017137533827, 985.9833190120512, 862.7579117793148, 621.4687395322998, 982.9616535182797, 884.0207263169476, 796.3429457855281, 1315.6132066834375, 1116.2167761247572, 938.34461825739, 895.3361982115307, 911.4119203779038, 1007.9871587246392, 1008.2473375962884, 988.7965263620241, 844.8272458249352, 993.8354141320286, 932.667961197617, 1032.0891670713565, 907.4412437058063, 989.2984315408055, 998.8378222638866, 1226.932642658321, 851.0762527148714, 1110.1602926151518, 1064.9112930620656, 952.1873719473648, 892.5950905808796, 926.9136826408837, 930.0532735450781, 1149.6949385286052, 1085.9649897919303, 1021.2027022307702, 1117.2493112097864, 822.2560830299354, 973.0121387446461, 982.5425574971068, 1085.8350934845148, 987.7891931319734, 1114.542055560452, 1115.3751616983423, 1118.6992554247736, 1207.1343082061196, 1136.0175746901646, 978.4325558249734, 850.6998964464385, 1279.474379767346, 1257.5031466916987, 791.3190008005845, 1108.2650666001111, 1127.8128451810726, 1120.688964470186, 1177.835074133141, 1060.2584681285173, 1013.9133031921867, 992.0150174451965, 842.0044785531685, 904.0509645186254, 1109.9309339902638, 1254.469481196199, 965.434170246097, 892.1815039980036, 1261.395448677762, 1127.3324492301967, 721.1536229801676, 815.0445157539015, 818.1123074083596, 920.8791558313294]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8327197849483627, "mean_inference_ms": 2.210362563776355, "mean_action_processing_ms": 0.346469423544631, "mean_env_wait_ms": 0.3116752145874684, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005021452903747559, "StateBufferConnector_ms": 0.004723906517028809, "ViewRequirementAgentConnector_ms": 0.12572264671325684}, "num_episodes": 18, "episode_return_max": 1924.2575021955354, "episode_return_min": 581.4318622591875, "episode_return_mean": 1393.8210591865497, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 286.3376036802024, "num_env_steps_trained_throughput_per_sec": 286.3376036802024, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 13617.401, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13617.341, "sample_time_ms": 1616.63, "learn_time_ms": 11980.644, "learn_throughput": 333.872, "synch_weights_time_ms": 17.843}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "479e5_00000", "date": "2024-08-16_11-32-23", "timestamp": 1723788143, "time_this_iter_s": 14.012474060058594, "time_total_s": 337.6411645412445, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7daa430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 337.6411645412445, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 63.40500000000001, "ram_util_percent": 81.07}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2268459162305272, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.932829441595329, "policy_loss": -0.010748268307615367, "vf_loss": 9.94108242912898, "vf_explained_var": 0.011881639623137378, "kl": 0.024952852905393664, "entropy": 1.3792625550870543, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.535023829908598, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.624157801128568, "policy_loss": -0.02383382007634888, "vf_loss": 9.64402291131398, "vf_explained_var": -0.013500175179627837, "kl": 0.026458088707656306, "entropy": 1.485961133336264, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 1859.8232248544866, "episode_reward_min": 581.4318622591875, "episode_reward_mean": 1387.0060680837655, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1063.241698490454, "predator_policy": 276.852092539977}, "policy_reward_max": {"prey_policy": 402.4911360984146, "predator_policy": 1432.6093206909522}, "policy_reward_mean": {"prey_policy": -159.58285458299534, "predator_policy": 853.0858886248778}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1738.4616946595825, 1414.788229920073, 1541.5483808281583, 1434.1692024288025, 1166.0247812437822, 1378.166592974635, 1055.061098115146, 1278.7985946930698, 1269.260009444211, 1050.3563663749305, 1603.3973117695687, 1449.7056922145637, 1334.6253339747745, 1440.6240549865618, 1261.344371987764, 1248.9327196997524, 1521.342972116413, 1563.1868091613455, 1560.6391109274084, 1645.6771275176552, 1547.4406618524927, 1386.3941845091958, 741.1053726722511, 1229.1578706406433, 1471.7596448010313, 1235.501810011178, 1261.3386192990997, 1565.9269700518198, 942.5442497047366, 1368.5802687525359, 1614.103034258841, 1200.409045755231, 913.1895956205312, 1401.2968657741771, 1071.8859862944244, 1129.2252718734444, 732.1409556873142, 1315.208123934638, 1005.2109633127026, 1198.3570458161475, 581.4318622591875, 1175.5689428379126, 1126.8153199640367, 942.4061826141738, 1283.0907978542834, 1079.8847145199447, 1128.7458671582308, 972.4549171464586, 1146.6502761631407, 1491.8506952526836, 967.8453481423251, 705.2908765328784, 1180.2458602523238, 1586.150913042187, 802.0501677655086, 1086.3788896068706, 1440.8636632840473, 1146.462220480258, 996.7152230349338, 1325.5142491650265, 1263.2584350481031, 1249.174528397537, 1452.9713188964947, 1006.7317333985507, 1713.5046185368374, 1599.1758142357016, 1772.6556602574194, 1701.4631932553345, 1357.624873072953, 1720.6172654825612, 1729.4773770199474, 1357.47472467017, 1405.4556629677172, 1644.562787672127, 1481.9338202012166, 1699.3503073078173, 1752.7711890764967, 1651.241872687901, 1451.8300650610963, 1446.5351494551553, 1478.5689828251377, 1315.574033718809, 1749.0778321209764, 1263.3262006792713, 1799.3725910069263, 1849.5672719590627, 1812.9824738524298, 1737.2637103482666, 1846.3247069312526, 1639.8958374180447, 1669.6088738033811, 1704.3684078774684, 1649.046298629302, 1843.989993211949, 1795.1244814946047, 1620.2525513717362, 1812.5894226852026, 1585.0885214894988, 1859.8232248544866, 1757.6470126605388], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [402.4911360984146, 327.79883233458054, 88.88147936409871, -19.22446457022757, 136.29883293692012, 150.2071015984398, 106.04864079362116, 161.15779550197982, -130.814845785667, -164.5574386556343, 188.15979381137834, 29.022862912221584, 75.19721473648104, -202.855005210906, 100.66009364173158, 59.78290955814148, -217.6744899027496, -94.53595617672629, -74.99165511935841, -171.6035098982212, 228.21181757895738, 228.33483348840875, 106.26525971329683, 169.4017919084478, 131.18664156843062, 180.13233519136077, 164.15025134124838, 249.71137727855847, 114.84358494440741, 230.58210717419422, -280.85859048600247, -27.625120003330608, 182.0142500861362, 305.04772679548546, 188.23278714154765, 198.11214798922146, 372.0713135473684, 190.4509039716532, 242.31404434399838, 200.47250592646503, 68.90217369411884, 142.34403896728503, 186.13317758845125, 71.85240992800401, -545.8492236187535, -934.8985840327526, -52.0428290438648, 35.228790865297384, 162.9437286748144, 79.86301113081531, -53.44854197181046, -143.16345189113036, -411.6696356540971, -283.6548624285183, -123.45439658198639, 109.1316220821671, -380.88175403097824, -515.7263484166693, 46.696766980989864, 87.96030029041762, 138.3213800484678, 135.6333873001855, -231.9924505409581, -307.0473689960792, -595.5631470158129, -379.83647683162684, -14.471111534643569, -50.46830460770963, -455.49398791619325, -312.40967168907656, -151.9067390085318, -119.71764194771829, -640.5607136506167, -457.0255143900549, -215.22258798040653, -264.5102058645104, -661.6120370415281, -608.1099393952597, -667.4909180937219, -440.47031150182687, -1063.241698490454, -856.5373619967287, -650.0318535089866, -267.79099986700743, -197.6507107891684, -346.3481119472087, -675.7347015515304, -483.8889029725247, -349.9122695559216, -390.7409939673006, -316.60620824994845, -947.7189526093675, -91.48374052119183, -451.13132005408596, -759.2538506708739, -333.80977859680036, -382.7928780534387, -643.8418785488548, -72.30385763503098, 79.92790157610101, -595.5555622268719, -303.58146946602994, -721.9888518124891, -684.6764241235987, -481.35918161430226, -392.95635251552136, 74.5680853064548, -295.16529085370246, -543.8084278318476, -670.375900723571, -453.6412969809927, -293.60358559909616, -425.1460876501891, -60.49362439540896, -248.40710812164343, -544.6610821752614, -658.9228478711459, -332.4981828986125, -258.89373062895424, -493.6009155792116, -735.1150121190049, -176.6981385101097, -353.81407590483695, -241.79385822587042, -321.04539701838905, -82.95024027107837, -479.3714438227249, -749.5567510992598, -37.63160830077036, -387.31578660294906, -34.921670348531194, -161.1707371903486, -293.14257951453413, -2.5794112096675734, -132.02132137519706, -268.84673406189313, -395.4703059886681, -480.9792380614956, -271.9771676259975, -350.55744978772566, 156.15946058672017, -255.8145358381839, -581.9931754739324, -597.5096263149418, -157.0848379308552, -337.0435665021231, 111.82692259200978, -715.7659445711419, -212.5985839495654, -543.5611381108762, -509.6675763995955, 203.08956307002933, -240.59422754831076, 247.30997355301338, -576.1966754626931, -136.96186703586812, -168.2238072020546, -237.56180198095075, -487.071904268365, -455.1208441844387, -66.05751599963237, 8.428360090701167, -64.8997752091098, -358.5176543117699, -113.76656562731993, 15.872068812129545, -60.656486822699065, 20.882102863023647, -110.23247055958164, 238.56414734711663, -342.2610079355672, -93.88021540385587, 115.95285377272242, 387.3112702917861, -67.20184846612406, 115.89579146177176, 24.736288211216362, 236.3574421570142, 133.19299169169284, -152.84169162408833, 39.6592342586098, 50.38111272359244, 151.71086806512884, 204.0267679772916, 215.41762986269936, -162.41479819764373, 96.57155585494446, 333.36848829459626, 174.3955908162161, -18.280201027031154, -37.498787019450674, -55.6756085545442, 301.1449838701533, -121.13837175895044, 67.28189375143144, 184.55117725034407, 244.79859050623156, -19.863277803102715, 44.617847679836295, 191.68609855210147], "policy_predator_policy_reward": [597.3557095123257, 410.816016714263, 821.800738274094, 523.3304768521073, 494.08564516069646, 760.9568011321011, 585.7437263159197, 581.2190398172822, 577.2038640132471, 884.1932016718354, 360.5565631849824, 800.4273730660534, 463.3694848397157, 719.3494037498554, 497.342668560988, 621.0129229322099, 614.2355467963808, 967.2349087273044, 538.4956552268766, 758.4558761656333, 422.9113035611043, 723.9393571410986, 426.87666545948645, 747.1619751333334, 746.4542646750056, 276.852092539977, 468.0440193947405, 558.7184069720164, 440.1594109793255, 475.759268889837, 619.4909773848497, 937.9254528042347, 574.789810769219, 459.49118446557173, 534.4853244763002, 642.356549554277, 573.5701706672206, 424.5467227411668, 608.9253059481592, 593.9652712990329, 711.8085177458528, 624.3859314452353, 627.855729317579, 500.5528676751617, 884.5037139096368, 1337.3494664141203, 566.2445812639462, 679.7273275552643, 573.5712255023722, 655.3816794930287, 558.1395299798987, 873.9742738942198, 1045.3621917783582, 911.3009256033564, 846.3125184854784, 733.9372260661604, 791.4195595259182, 1047.732792626466, 544.1366121651738, 689.786589315955, 675.5209460701302, 664.627320840058, 697.4611740106882, 1041.9876912815798, 1117.4000694271754, 771.189150040796, 843.9235626798518, 622.312719236678, 882.8049981293714, 956.9846477703223, 653.3314451064291, 747.5182077232644, 1019.3119199771461, 810.4152637508398, 911.8467285284185, 883.0941892511357, 1150.031095279419, 1124.901844470072, 1303.738513650044, 1002.5797617616523, 1111.1218870509904, 1390.0890356953794, 1168.7929430029224, 924.5988532109845, 688.1801473736496, 982.6339953267648, 850.1489948214767, 1251.8807923167524, 1020.9470391549477, 1002.7970222225575, 911.6005546883089, 1432.6093206909522, 874.0022842755221, 797.3586434579857, 864.338045001667, 1201.180501412466, 1187.3017137533827, 985.9833190120512, 862.7579117793148, 621.4687395322998, 982.9616535182797, 884.0207263169476, 796.3429457855281, 1315.6132066834375, 1116.2167761247572, 938.34461825739, 895.3361982115307, 911.4119203779038, 1007.9871587246392, 1008.2473375962884, 988.7965263620241, 844.8272458249352, 993.8354141320286, 932.667961197617, 1032.0891670713565, 907.4412437058063, 989.2984315408055, 998.8378222638866, 1226.932642658321, 851.0762527148714, 1110.1602926151518, 1064.9112930620656, 952.1873719473648, 892.5950905808796, 926.9136826408837, 930.0532735450781, 1149.6949385286052, 1085.9649897919303, 1021.2027022307702, 1117.2493112097864, 822.2560830299354, 973.0121387446461, 982.5425574971068, 1085.8350934845148, 987.7891931319734, 1114.542055560452, 1115.3751616983423, 1118.6992554247736, 1207.1343082061196, 1136.0175746901646, 978.4325558249734, 850.6998964464385, 1279.474379767346, 1257.5031466916987, 791.3190008005845, 1108.2650666001111, 1127.8128451810726, 1120.688964470186, 1177.835074133141, 1060.2584681285173, 1013.9133031921867, 992.0150174451965, 842.0044785531685, 904.0509645186254, 1109.9309339902638, 1254.469481196199, 965.434170246097, 892.1815039980036, 1261.395448677762, 1127.3324492301967, 721.1536229801676, 815.0445157539015, 818.1123074083596, 920.8791558313294, 849.8750428542205, 997.0972860819455, 663.0644534115028, 640.036131227444, 805.9580056474233, 865.0829085719681, 1127.5621933258446, 1158.1463019726395, 609.9853331157867, 699.7330166721355, 816.5263042485527, 872.0434631040664, 849.3953938179696, 735.8355827450515, 812.8030780048076, 846.7414593456336, 671.0309982547747, 908.5375285664051, 670.4414690699393, 678.1893027651082, 819.2806977875242, 776.7627691767219, 716.9883173902656, 697.0616316721432, 825.7303111463993, 813.2787805590211, 703.4858763626752, 1009.9410705830544, 865.661127949855, 766.9216826241444, 619.6232518056476, 713.6321986820759, 813.6290251553222, 821.2588869960355, 716.8253785098294, 804.5176879187705]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8342781625289305, "mean_inference_ms": 2.212527477470228, "mean_action_processing_ms": 0.3545001536496127, "mean_env_wait_ms": 0.3131005028543156, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0058890581130981445, "StateBufferConnector_ms": 0.004976868629455566, "ViewRequirementAgentConnector_ms": 0.13846075534820557}, "num_episodes": 18, "episode_return_max": 1859.8232248544866, "episode_return_min": 581.4318622591875, "episode_return_mean": 1387.0060680837655, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 276.62108097219857, "num_env_steps_trained_throughput_per_sec": 276.62108097219857, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 13692.38, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13692.321, "sample_time_ms": 1684.627, "learn_time_ms": 11987.914, "learn_throughput": 333.669, "synch_weights_time_ms": 17.702}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "479e5_00000", "date": "2024-08-16_11-32-38", "timestamp": 1723788158, "time_this_iter_s": 14.532063961029053, "time_total_s": 352.17322850227356, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78e5dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 352.17322850227356, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 66.05714285714286, "ram_util_percent": 81.12380952380951}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2887614025798424, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.867554191811374, "policy_loss": -0.004927089865560885, "vf_loss": 9.87103071818276, "vf_explained_var": 0.009419097913005365, "kl": 0.009670346480118034, "entropy": 1.373373532925964, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4984854318635175, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.70607003358306, "policy_loss": -0.0179893667624879, "vf_loss": 9.719846416655042, "vf_explained_var": -0.029167665438677267, "kl": 0.018724365247703285, "entropy": 1.472524419537297, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 2044.8974307827798, "episode_reward_min": 581.4318622591875, "episode_reward_mean": 1463.8200807365083, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1063.241698490454, "predator_policy": 333.55784827332496}, "policy_reward_max": {"prey_policy": 647.4792996586658, "predator_policy": 1432.6093206909522}, "policy_reward_mean": {"prey_policy": -117.34306518225537, "predator_policy": 849.2531055505093}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1560.6391109274084, 1645.6771275176552, 1547.4406618524927, 1386.3941845091958, 741.1053726722511, 1229.1578706406433, 1471.7596448010313, 1235.501810011178, 1261.3386192990997, 1565.9269700518198, 942.5442497047366, 1368.5802687525359, 1614.103034258841, 1200.409045755231, 913.1895956205312, 1401.2968657741771, 1071.8859862944244, 1129.2252718734444, 732.1409556873142, 1315.208123934638, 1005.2109633127026, 1198.3570458161475, 581.4318622591875, 1175.5689428379126, 1126.8153199640367, 942.4061826141738, 1283.0907978542834, 1079.8847145199447, 1128.7458671582308, 972.4549171464586, 1146.6502761631407, 1491.8506952526836, 967.8453481423251, 705.2908765328784, 1180.2458602523238, 1586.150913042187, 802.0501677655086, 1086.3788896068706, 1440.8636632840473, 1146.462220480258, 996.7152230349338, 1325.5142491650265, 1263.2584350481031, 1249.174528397537, 1452.9713188964947, 1006.7317333985507, 1713.5046185368374, 1599.1758142357016, 1772.6556602574194, 1701.4631932553345, 1357.624873072953, 1720.6172654825612, 1729.4773770199474, 1357.47472467017, 1405.4556629677172, 1644.562787672127, 1481.9338202012166, 1699.3503073078173, 1752.7711890764967, 1651.241872687901, 1451.8300650610963, 1446.5351494551553, 1478.5689828251377, 1315.574033718809, 1749.0778321209764, 1263.3262006792713, 1799.3725910069263, 1849.5672719590627, 1812.9824738524298, 1737.2637103482666, 1846.3247069312526, 1639.8958374180447, 1669.6088738033811, 1704.3684078774684, 1649.046298629302, 1843.989993211949, 1795.1244814946047, 1620.2525513717362, 1812.5894226852026, 1585.0885214894988, 1859.8232248544866, 1757.6470126605388, 1515.7039565017499, 1954.942374108556, 1662.2362690134705, 1863.7609486099211, 1894.0630532537969, 1762.8339258937121, 1590.7297391298314, 1852.4602585787543, 1895.2099785386317, 1571.0411638315866, 1614.7517251833056, 1918.3039891228048, 1979.9254451864172, 1876.842076881833, 1674.2703865670487, 1883.5608489061308, 2044.8974307827798, 1875.6619117770854], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [372.0713135473684, 190.4509039716532, 242.31404434399838, 200.47250592646503, 68.90217369411884, 142.34403896728503, 186.13317758845125, 71.85240992800401, -545.8492236187535, -934.8985840327526, -52.0428290438648, 35.228790865297384, 162.9437286748144, 79.86301113081531, -53.44854197181046, -143.16345189113036, -411.6696356540971, -283.6548624285183, -123.45439658198639, 109.1316220821671, -380.88175403097824, -515.7263484166693, 46.696766980989864, 87.96030029041762, 138.3213800484678, 135.6333873001855, -231.9924505409581, -307.0473689960792, -595.5631470158129, -379.83647683162684, -14.471111534643569, -50.46830460770963, -455.49398791619325, -312.40967168907656, -151.9067390085318, -119.71764194771829, -640.5607136506167, -457.0255143900549, -215.22258798040653, -264.5102058645104, -661.6120370415281, -608.1099393952597, -667.4909180937219, -440.47031150182687, -1063.241698490454, -856.5373619967287, -650.0318535089866, -267.79099986700743, -197.6507107891684, -346.3481119472087, -675.7347015515304, -483.8889029725247, -349.9122695559216, -390.7409939673006, -316.60620824994845, -947.7189526093675, -91.48374052119183, -451.13132005408596, -759.2538506708739, -333.80977859680036, -382.7928780534387, -643.8418785488548, -72.30385763503098, 79.92790157610101, -595.5555622268719, -303.58146946602994, -721.9888518124891, -684.6764241235987, -481.35918161430226, -392.95635251552136, 74.5680853064548, -295.16529085370246, -543.8084278318476, -670.375900723571, -453.6412969809927, -293.60358559909616, -425.1460876501891, -60.49362439540896, -248.40710812164343, -544.6610821752614, -658.9228478711459, -332.4981828986125, -258.89373062895424, -493.6009155792116, -735.1150121190049, -176.6981385101097, -353.81407590483695, -241.79385822587042, -321.04539701838905, -82.95024027107837, -479.3714438227249, -749.5567510992598, -37.63160830077036, -387.31578660294906, -34.921670348531194, -161.1707371903486, -293.14257951453413, -2.5794112096675734, -132.02132137519706, -268.84673406189313, -395.4703059886681, -480.9792380614956, -271.9771676259975, -350.55744978772566, 156.15946058672017, -255.8145358381839, -581.9931754739324, -597.5096263149418, -157.0848379308552, -337.0435665021231, 111.82692259200978, -715.7659445711419, -212.5985839495654, -543.5611381108762, -509.6675763995955, 203.08956307002933, -240.59422754831076, 247.30997355301338, -576.1966754626931, -136.96186703586812, -168.2238072020546, -237.56180198095075, -487.071904268365, -455.1208441844387, -66.05751599963237, 8.428360090701167, -64.8997752091098, -358.5176543117699, -113.76656562731993, 15.872068812129545, -60.656486822699065, 20.882102863023647, -110.23247055958164, 238.56414734711663, -342.2610079355672, -93.88021540385587, 115.95285377272242, 387.3112702917861, -67.20184846612406, 115.89579146177176, 24.736288211216362, 236.3574421570142, 133.19299169169284, -152.84169162408833, 39.6592342586098, 50.38111272359244, 151.71086806512884, 204.0267679772916, 215.41762986269936, -162.41479819764373, 96.57155585494446, 333.36848829459626, 174.3955908162161, -18.280201027031154, -37.498787019450674, -55.6756085545442, 301.1449838701533, -121.13837175895044, 67.28189375143144, 184.55117725034407, 244.79859050623156, -19.863277803102715, 44.617847679836295, 191.68609855210147, 249.98927746134095, 183.75791493066242, 383.9575777216572, 380.61763911906917, 285.31613081632514, 375.16333382818334, 647.4792996586658, 385.9464841358338, 380.2744084556035, 235.37571523796757, 449.885293780215, 389.5774506949712, 50.612234509856364, 159.39516891014995, 493.02007537417757, 490.8042338085567, 278.8635764753025, -57.41473164742288, 405.096117313308, 146.92220725156727, 122.23069767236427, 440.465249013746, 96.52222553149429, 486.1491456125832, 2.576297148509628, 370.4047352327207, 402.8259160405499, 552.1303279168005, 304.7525880333646, 552.0526640196075, 287.13639336387996, 188.3522449359496, 468.2703479193208, 249.06792791284727, 331.23287685168054, 396.34136478546077], "policy_predator_policy_reward": [573.5701706672206, 424.5467227411668, 608.9253059481592, 593.9652712990329, 711.8085177458528, 624.3859314452353, 627.855729317579, 500.5528676751617, 884.5037139096368, 1337.3494664141203, 566.2445812639462, 679.7273275552643, 573.5712255023722, 655.3816794930287, 558.1395299798987, 873.9742738942198, 1045.3621917783582, 911.3009256033564, 846.3125184854784, 733.9372260661604, 791.4195595259182, 1047.732792626466, 544.1366121651738, 689.786589315955, 675.5209460701302, 664.627320840058, 697.4611740106882, 1041.9876912815798, 1117.4000694271754, 771.189150040796, 843.9235626798518, 622.312719236678, 882.8049981293714, 956.9846477703223, 653.3314451064291, 747.5182077232644, 1019.3119199771461, 810.4152637508398, 911.8467285284185, 883.0941892511357, 1150.031095279419, 1124.901844470072, 1303.738513650044, 1002.5797617616523, 1111.1218870509904, 1390.0890356953794, 1168.7929430029224, 924.5988532109845, 688.1801473736496, 982.6339953267648, 850.1489948214767, 1251.8807923167524, 1020.9470391549477, 1002.7970222225575, 911.6005546883089, 1432.6093206909522, 874.0022842755221, 797.3586434579857, 864.338045001667, 1201.180501412466, 1187.3017137533827, 985.9833190120512, 862.7579117793148, 621.4687395322998, 982.9616535182797, 884.0207263169476, 796.3429457855281, 1315.6132066834375, 1116.2167761247572, 938.34461825739, 895.3361982115307, 911.4119203779038, 1007.9871587246392, 1008.2473375962884, 988.7965263620241, 844.8272458249352, 993.8354141320286, 932.667961197617, 1032.0891670713565, 907.4412437058063, 989.2984315408055, 998.8378222638866, 1226.932642658321, 851.0762527148714, 1110.1602926151518, 1064.9112930620656, 952.1873719473648, 892.5950905808796, 926.9136826408837, 930.0532735450781, 1149.6949385286052, 1085.9649897919303, 1021.2027022307702, 1117.2493112097864, 822.2560830299354, 973.0121387446461, 982.5425574971068, 1085.8350934845148, 987.7891931319734, 1114.542055560452, 1115.3751616983423, 1118.6992554247736, 1207.1343082061196, 1136.0175746901646, 978.4325558249734, 850.6998964464385, 1279.474379767346, 1257.5031466916987, 791.3190008005845, 1108.2650666001111, 1127.8128451810726, 1120.688964470186, 1177.835074133141, 1060.2584681285173, 1013.9133031921867, 992.0150174451965, 842.0044785531685, 904.0509645186254, 1109.9309339902638, 1254.469481196199, 965.434170246097, 892.1815039980036, 1261.395448677762, 1127.3324492301967, 721.1536229801676, 815.0445157539015, 818.1123074083596, 920.8791558313294, 849.8750428542205, 997.0972860819455, 663.0644534115028, 640.036131227444, 805.9580056474233, 865.0829085719681, 1127.5621933258446, 1158.1463019726395, 609.9853331157867, 699.7330166721355, 816.5263042485527, 872.0434631040664, 849.3953938179696, 735.8355827450515, 812.8030780048076, 846.7414593456336, 671.0309982547747, 908.5375285664051, 670.4414690699393, 678.1893027651082, 819.2806977875242, 776.7627691767219, 716.9883173902656, 697.0616316721432, 825.7303111463993, 813.2787805590211, 703.4858763626752, 1009.9410705830544, 865.661127949855, 766.9216826241444, 619.6232518056476, 713.6321986820759, 813.6290251553222, 821.2588869960355, 716.8253785098294, 804.5176879187705, 560.716677890735, 521.2400862190103, 591.5345196715076, 598.8326375963201, 452.46631511310096, 549.2904892558612, 496.77731654209634, 333.55784827332496, 624.9737015918333, 653.4392279683915, 456.758373965228, 466.61280745329617, 582.6014837396211, 798.120851970204, 429.3708742080132, 439.2650751880065, 780.5436631294966, 893.2174705812542, 544.5368149141702, 474.4860243525398, 501.8194938762128, 550.2362846209817, 684.5697015363723, 651.0629164423549, 833.0831509740783, 773.861261831109, 440.4071455687462, 481.4786873557368, 395.94063724642155, 421.5244972676548, 702.061584575288, 706.0106260310129, 689.9872977648237, 637.5718571857877, 643.1945067560794, 504.8931633838631]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8360926151929229, "mean_inference_ms": 2.2152455921398677, "mean_action_processing_ms": 0.3620859583582521, "mean_env_wait_ms": 0.31451966382241126, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007584095001220703, "StateBufferConnector_ms": 0.005033969879150391, "ViewRequirementAgentConnector_ms": 0.14093971252441406}, "num_episodes": 18, "episode_return_max": 2044.8974307827798, "episode_return_min": 581.4318622591875, "episode_return_mean": 1463.8200807365083, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 297.04288645977965, "num_env_steps_trained_throughput_per_sec": 297.04288645977965, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 13675.591, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13675.532, "sample_time_ms": 1683.648, "learn_time_ms": 11971.817, "learn_throughput": 334.118, "synch_weights_time_ms": 17.968}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "479e5_00000", "date": "2024-08-16_11-32-52", "timestamp": 1723788172, "time_this_iter_s": 13.526286125183105, "time_total_s": 365.69951462745667, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78e5e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 365.69951462745667, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 63.04210526315791, "ram_util_percent": 81.60526315789474}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7904750452312843, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.3410201405722, "policy_loss": -0.004988068659548406, "vf_loss": 9.344820524649645, "vf_explained_var": -0.05838106460672207, "kl": 0.007917898265986963, "entropy": 1.3844429205965112, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4255827713738043, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.761783538293587, "policy_loss": -0.009568394984552272, "vf_loss": 9.76815050518702, "vf_explained_var": -0.011666553676443757, "kl": 0.014228692141614055, "entropy": 1.4304046785389934, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 2044.8974307827798, "episode_reward_min": 581.4318622591875, "episode_reward_mean": 1543.7837742412812, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1063.241698490454, "predator_policy": 145.8120535807448}, "policy_reward_max": {"prey_policy": 767.2590711226935, "predator_policy": 1432.6093206909522}, "policy_reward_mean": {"prey_policy": 31.829252326714048, "predator_policy": 740.0626347939262}, "custom_metrics": {}, "hist_stats": {"episode_reward": [581.4318622591875, 1175.5689428379126, 1126.8153199640367, 942.4061826141738, 1283.0907978542834, 1079.8847145199447, 1128.7458671582308, 972.4549171464586, 1146.6502761631407, 1491.8506952526836, 967.8453481423251, 705.2908765328784, 1180.2458602523238, 1586.150913042187, 802.0501677655086, 1086.3788896068706, 1440.8636632840473, 1146.462220480258, 996.7152230349338, 1325.5142491650265, 1263.2584350481031, 1249.174528397537, 1452.9713188964947, 1006.7317333985507, 1713.5046185368374, 1599.1758142357016, 1772.6556602574194, 1701.4631932553345, 1357.624873072953, 1720.6172654825612, 1729.4773770199474, 1357.47472467017, 1405.4556629677172, 1644.562787672127, 1481.9338202012166, 1699.3503073078173, 1752.7711890764967, 1651.241872687901, 1451.8300650610963, 1446.5351494551553, 1478.5689828251377, 1315.574033718809, 1749.0778321209764, 1263.3262006792713, 1799.3725910069263, 1849.5672719590627, 1812.9824738524298, 1737.2637103482666, 1846.3247069312526, 1639.8958374180447, 1669.6088738033811, 1704.3684078774684, 1649.046298629302, 1843.989993211949, 1795.1244814946047, 1620.2525513717362, 1812.5894226852026, 1585.0885214894988, 1859.8232248544866, 1757.6470126605388, 1515.7039565017499, 1954.942374108556, 1662.2362690134705, 1863.7609486099211, 1894.0630532537969, 1762.8339258937121, 1590.7297391298314, 1852.4602585787543, 1895.2099785386317, 1571.0411638315866, 1614.7517251833056, 1918.3039891228048, 1979.9254451864172, 1876.842076881833, 1674.2703865670487, 1883.5608489061308, 2044.8974307827798, 1875.6619117770854, 1422.395276606957, 1428.4402232718405, 1693.0670262624378, 1878.6177358483096, 1813.1107855802636, 1680.1038161095846, 1738.2739671628592, 1466.9236629195427, 1313.6393202692668, 1771.784630673316, 1885.119048987752, 1484.9745183035752, 1536.7114648126578, 1605.0644041040557, 1796.7486188359512, 1697.2455033897163, 1730.3402185676914, 1525.326423369294, 1744.9592071469178, 1204.1167450690316, 1229.8202792857896, 1886.679252967992], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-1063.241698490454, -856.5373619967287, -650.0318535089866, -267.79099986700743, -197.6507107891684, -346.3481119472087, -675.7347015515304, -483.8889029725247, -349.9122695559216, -390.7409939673006, -316.60620824994845, -947.7189526093675, -91.48374052119183, -451.13132005408596, -759.2538506708739, -333.80977859680036, -382.7928780534387, -643.8418785488548, -72.30385763503098, 79.92790157610101, -595.5555622268719, -303.58146946602994, -721.9888518124891, -684.6764241235987, -481.35918161430226, -392.95635251552136, 74.5680853064548, -295.16529085370246, -543.8084278318476, -670.375900723571, -453.6412969809927, -293.60358559909616, -425.1460876501891, -60.49362439540896, -248.40710812164343, -544.6610821752614, -658.9228478711459, -332.4981828986125, -258.89373062895424, -493.6009155792116, -735.1150121190049, -176.6981385101097, -353.81407590483695, -241.79385822587042, -321.04539701838905, -82.95024027107837, -479.3714438227249, -749.5567510992598, -37.63160830077036, -387.31578660294906, -34.921670348531194, -161.1707371903486, -293.14257951453413, -2.5794112096675734, -132.02132137519706, -268.84673406189313, -395.4703059886681, -480.9792380614956, -271.9771676259975, -350.55744978772566, 156.15946058672017, -255.8145358381839, -581.9931754739324, -597.5096263149418, -157.0848379308552, -337.0435665021231, 111.82692259200978, -715.7659445711419, -212.5985839495654, -543.5611381108762, -509.6675763995955, 203.08956307002933, -240.59422754831076, 247.30997355301338, -576.1966754626931, -136.96186703586812, -168.2238072020546, -237.56180198095075, -487.071904268365, -455.1208441844387, -66.05751599963237, 8.428360090701167, -64.8997752091098, -358.5176543117699, -113.76656562731993, 15.872068812129545, -60.656486822699065, 20.882102863023647, -110.23247055958164, 238.56414734711663, -342.2610079355672, -93.88021540385587, 115.95285377272242, 387.3112702917861, -67.20184846612406, 115.89579146177176, 24.736288211216362, 236.3574421570142, 133.19299169169284, -152.84169162408833, 39.6592342586098, 50.38111272359244, 151.71086806512884, 204.0267679772916, 215.41762986269936, -162.41479819764373, 96.57155585494446, 333.36848829459626, 174.3955908162161, -18.280201027031154, -37.498787019450674, -55.6756085545442, 301.1449838701533, -121.13837175895044, 67.28189375143144, 184.55117725034407, 244.79859050623156, -19.863277803102715, 44.617847679836295, 191.68609855210147, 249.98927746134095, 183.75791493066242, 383.9575777216572, 380.61763911906917, 285.31613081632514, 375.16333382818334, 647.4792996586658, 385.9464841358338, 380.2744084556035, 235.37571523796757, 449.885293780215, 389.5774506949712, 50.612234509856364, 159.39516891014995, 493.02007537417757, 490.8042338085567, 278.8635764753025, -57.41473164742288, 405.096117313308, 146.92220725156727, 122.23069767236427, 440.465249013746, 96.52222553149429, 486.1491456125832, 2.576297148509628, 370.4047352327207, 402.8259160405499, 552.1303279168005, 304.7525880333646, 552.0526640196075, 287.13639336387996, 188.3522449359496, 468.2703479193208, 249.06792791284727, 331.23287685168054, 396.34136478546077, 684.0556072084003, 395.23490059412825, 422.3946569647586, 576.6238998382828, 426.80746131658844, 516.1506716927399, 642.1851300604558, 481.95878017905886, 562.1550393201761, 615.6969338183272, 674.8315372874297, 542.0090699171521, 405.8915974998344, 455.0422362885791, 575.002654539008, 428.45060172804233, 391.4053859546451, 409.82217798024584, 311.88768198837636, 445.3562952408783, 536.3967236875678, 550.0494582148721, 520.869668036816, 353.7221098294987, 543.5644005203214, 546.7140570969256, 566.0951228362626, 548.7788838740278, 767.2590711226935, 306.3792279296096, 541.0381991830244, 584.2893673337144, 517.1555667999944, 714.4657171764343, 432.49988969867087, 444.6385212562328, 454.91540071161586, 309.04544281641864, 436.41490713842734, 429.02477731910955, 397.1140821165791, 372.01558111995047, 663.3840217146883, 587.2917845069967], "policy_predator_policy_reward": [1111.1218870509904, 1390.0890356953794, 1168.7929430029224, 924.5988532109845, 688.1801473736496, 982.6339953267648, 850.1489948214767, 1251.8807923167524, 1020.9470391549477, 1002.7970222225575, 911.6005546883089, 1432.6093206909522, 874.0022842755221, 797.3586434579857, 864.338045001667, 1201.180501412466, 1187.3017137533827, 985.9833190120512, 862.7579117793148, 621.4687395322998, 982.9616535182797, 884.0207263169476, 796.3429457855281, 1315.6132066834375, 1116.2167761247572, 938.34461825739, 895.3361982115307, 911.4119203779038, 1007.9871587246392, 1008.2473375962884, 988.7965263620241, 844.8272458249352, 993.8354141320286, 932.667961197617, 1032.0891670713565, 907.4412437058063, 989.2984315408055, 998.8378222638866, 1226.932642658321, 851.0762527148714, 1110.1602926151518, 1064.9112930620656, 952.1873719473648, 892.5950905808796, 926.9136826408837, 930.0532735450781, 1149.6949385286052, 1085.9649897919303, 1021.2027022307702, 1117.2493112097864, 822.2560830299354, 973.0121387446461, 982.5425574971068, 1085.8350934845148, 987.7891931319734, 1114.542055560452, 1115.3751616983423, 1118.6992554247736, 1207.1343082061196, 1136.0175746901646, 978.4325558249734, 850.6998964464385, 1279.474379767346, 1257.5031466916987, 791.3190008005845, 1108.2650666001111, 1127.8128451810726, 1120.688964470186, 1177.835074133141, 1060.2584681285173, 1013.9133031921867, 992.0150174451965, 842.0044785531685, 904.0509645186254, 1109.9309339902638, 1254.469481196199, 965.434170246097, 892.1815039980036, 1261.395448677762, 1127.3324492301967, 721.1536229801676, 815.0445157539015, 818.1123074083596, 920.8791558313294, 849.8750428542205, 997.0972860819455, 663.0644534115028, 640.036131227444, 805.9580056474233, 865.0829085719681, 1127.5621933258446, 1158.1463019726395, 609.9853331157867, 699.7330166721355, 816.5263042485527, 872.0434631040664, 849.3953938179696, 735.8355827450515, 812.8030780048076, 846.7414593456336, 671.0309982547747, 908.5375285664051, 670.4414690699393, 678.1893027651082, 819.2806977875242, 776.7627691767219, 716.9883173902656, 697.0616316721432, 825.7303111463993, 813.2787805590211, 703.4858763626752, 1009.9410705830544, 865.661127949855, 766.9216826241444, 619.6232518056476, 713.6321986820759, 813.6290251553222, 821.2588869960355, 716.8253785098294, 804.5176879187705, 560.716677890735, 521.2400862190103, 591.5345196715076, 598.8326375963201, 452.46631511310096, 549.2904892558612, 496.77731654209634, 333.55784827332496, 624.9737015918333, 653.4392279683915, 456.758373965228, 466.61280745329617, 582.6014837396211, 798.120851970204, 429.3708742080132, 439.2650751880065, 780.5436631294966, 893.2174705812542, 544.5368149141702, 474.4860243525398, 501.8194938762128, 550.2362846209817, 684.5697015363723, 651.0629164423549, 833.0831509740783, 773.861261831109, 440.4071455687462, 481.4786873557368, 395.94063724642155, 421.5244972676548, 702.061584575288, 706.0106260310129, 689.9872977648237, 637.5718571857877, 643.1945067560794, 504.8931633838631, 177.87568553104413, 165.2290832733855, 283.6096128880552, 145.8120535807448, 383.1445151481855, 366.96437810492256, 327.2675723421782, 427.2062532666153, 359.46559785500637, 275.79321458675366, 287.2961026454701, 175.9671062595324, 341.58855015213726, 535.7515832223094, 253.00293667093896, 210.46746998155405, 315.29831003265684, 197.11344630171888, 516.2292201245976, 498.3114333194646, 451.8639696494467, 346.8088974358618, 264.2147165087722, 346.16802392848945, 167.74009926108724, 278.6929079343247, 216.68645035385663, 273.50394703991026, 391.15049638679375, 331.9598233968519, 283.06927308099023, 288.8486637919891, 238.80559453190293, 259.91334005935926, 350.79694055849313, 297.39107185589694, 532.8075934790187, 448.1907701398644, 166.23883665335455, 172.4382239581392, 233.26008682824295, 227.43052922101845, 366.57439761036454, 269.42904913594174]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8371424540019052, "mean_inference_ms": 2.216706069361064, "mean_action_processing_ms": 0.3717029444394393, "mean_env_wait_ms": 0.3160605682703343, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009393095970153809, "StateBufferConnector_ms": 0.005012154579162598, "ViewRequirementAgentConnector_ms": 0.14337778091430664}, "num_episodes": 22, "episode_return_max": 2044.8974307827798, "episode_return_min": 581.4318622591875, "episode_return_mean": 1543.7837742412812, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 166.09078642900616, "num_env_steps_trained_throughput_per_sec": 166.09078642900616, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 14730.63, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14730.569, "sample_time_ms": 1695.963, "learn_time_ms": 13009.289, "learn_throughput": 307.473, "synch_weights_time_ms": 23.129}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "479e5_00000", "date": "2024-08-16_11-33-16", "timestamp": 1723788196, "time_this_iter_s": 24.21645498275757, "time_total_s": 389.91596961021423, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78501f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 389.91596961021423, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 64.29705882352941, "ram_util_percent": 82.03823529411764}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0484490995211577, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.115352581670045, "policy_loss": -0.00739098588329932, "vf_loss": 9.121383474238966, "vf_explained_var": -0.05709650106530972, "kl": 0.00906737140447413, "entropy": 1.4016281023858086, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4265486682533588, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.787257290391064, "policy_loss": -0.00402490861181702, "vf_loss": 9.789411044246936, "vf_explained_var": -0.0011357086045401437, "kl": 0.008316269981483477, "entropy": 1.4253086646397908, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 2044.8974307827798, "episode_reward_min": 1006.7317333985507, "episode_reward_mean": 1648.5790125034698, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -749.5567510992598, "predator_policy": 48.46037674743573}, "policy_reward_max": {"prey_policy": 800.5654798918405, "predator_policy": 1279.474379767346}, "policy_reward_mean": {"prey_policy": 262.7678495294058, "predator_policy": 561.5216567223289}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1006.7317333985507, 1713.5046185368374, 1599.1758142357016, 1772.6556602574194, 1701.4631932553345, 1357.624873072953, 1720.6172654825612, 1729.4773770199474, 1357.47472467017, 1405.4556629677172, 1644.562787672127, 1481.9338202012166, 1699.3503073078173, 1752.7711890764967, 1651.241872687901, 1451.8300650610963, 1446.5351494551553, 1478.5689828251377, 1315.574033718809, 1749.0778321209764, 1263.3262006792713, 1799.3725910069263, 1849.5672719590627, 1812.9824738524298, 1737.2637103482666, 1846.3247069312526, 1639.8958374180447, 1669.6088738033811, 1704.3684078774684, 1649.046298629302, 1843.989993211949, 1795.1244814946047, 1620.2525513717362, 1812.5894226852026, 1585.0885214894988, 1859.8232248544866, 1757.6470126605388, 1515.7039565017499, 1954.942374108556, 1662.2362690134705, 1863.7609486099211, 1894.0630532537969, 1762.8339258937121, 1590.7297391298314, 1852.4602585787543, 1895.2099785386317, 1571.0411638315866, 1614.7517251833056, 1918.3039891228048, 1979.9254451864172, 1876.842076881833, 1674.2703865670487, 1883.5608489061308, 2044.8974307827798, 1875.6619117770854, 1422.395276606957, 1428.4402232718405, 1693.0670262624378, 1878.6177358483096, 1813.1107855802636, 1680.1038161095846, 1738.2739671628592, 1466.9236629195427, 1313.6393202692668, 1771.784630673316, 1885.119048987752, 1484.9745183035752, 1536.7114648126578, 1605.0644041040557, 1796.7486188359512, 1697.2455033897163, 1730.3402185676914, 1525.326423369294, 1744.9592071469178, 1204.1167450690316, 1229.8202792857896, 1886.679252967992, 1458.5584341115507, 1643.599584782308, 1654.2225244433444, 1570.3359595269278, 1413.0208023389698, 1838.8267584681662, 1729.1637297730176, 1527.0289742724171, 1604.2792171833642, 1717.294674488269, 1686.5142419251983, 1792.6831374599476, 1551.8777298331952, 1516.2404018098798, 1609.7826178152725, 1382.0504445371946, 1551.10646307514, 1551.7922562447454, 1505.3884904124952, 1807.69757511604, 1219.137843179801, 1746.9818839873344, 1533.7613508528125], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-479.3714438227249, -749.5567510992598, -37.63160830077036, -387.31578660294906, -34.921670348531194, -161.1707371903486, -293.14257951453413, -2.5794112096675734, -132.02132137519706, -268.84673406189313, -395.4703059886681, -480.9792380614956, -271.9771676259975, -350.55744978772566, 156.15946058672017, -255.8145358381839, -581.9931754739324, -597.5096263149418, -157.0848379308552, -337.0435665021231, 111.82692259200978, -715.7659445711419, -212.5985839495654, -543.5611381108762, -509.6675763995955, 203.08956307002933, -240.59422754831076, 247.30997355301338, -576.1966754626931, -136.96186703586812, -168.2238072020546, -237.56180198095075, -487.071904268365, -455.1208441844387, -66.05751599963237, 8.428360090701167, -64.8997752091098, -358.5176543117699, -113.76656562731993, 15.872068812129545, -60.656486822699065, 20.882102863023647, -110.23247055958164, 238.56414734711663, -342.2610079355672, -93.88021540385587, 115.95285377272242, 387.3112702917861, -67.20184846612406, 115.89579146177176, 24.736288211216362, 236.3574421570142, 133.19299169169284, -152.84169162408833, 39.6592342586098, 50.38111272359244, 151.71086806512884, 204.0267679772916, 215.41762986269936, -162.41479819764373, 96.57155585494446, 333.36848829459626, 174.3955908162161, -18.280201027031154, -37.498787019450674, -55.6756085545442, 301.1449838701533, -121.13837175895044, 67.28189375143144, 184.55117725034407, 244.79859050623156, -19.863277803102715, 44.617847679836295, 191.68609855210147, 249.98927746134095, 183.75791493066242, 383.9575777216572, 380.61763911906917, 285.31613081632514, 375.16333382818334, 647.4792996586658, 385.9464841358338, 380.2744084556035, 235.37571523796757, 449.885293780215, 389.5774506949712, 50.612234509856364, 159.39516891014995, 493.02007537417757, 490.8042338085567, 278.8635764753025, -57.41473164742288, 405.096117313308, 146.92220725156727, 122.23069767236427, 440.465249013746, 96.52222553149429, 486.1491456125832, 2.576297148509628, 370.4047352327207, 402.8259160405499, 552.1303279168005, 304.7525880333646, 552.0526640196075, 287.13639336387996, 188.3522449359496, 468.2703479193208, 249.06792791284727, 331.23287685168054, 396.34136478546077, 684.0556072084003, 395.23490059412825, 422.3946569647586, 576.6238998382828, 426.80746131658844, 516.1506716927399, 642.1851300604558, 481.95878017905886, 562.1550393201761, 615.6969338183272, 674.8315372874297, 542.0090699171521, 405.8915974998344, 455.0422362885791, 575.002654539008, 428.45060172804233, 391.4053859546451, 409.82217798024584, 311.88768198837636, 445.3562952408783, 536.3967236875678, 550.0494582148721, 520.869668036816, 353.7221098294987, 543.5644005203214, 546.7140570969256, 566.0951228362626, 548.7788838740278, 767.2590711226935, 306.3792279296096, 541.0381991830244, 584.2893673337144, 517.1555667999944, 714.4657171764343, 432.49988969867087, 444.6385212562328, 454.91540071161586, 309.04544281641864, 436.41490713842734, 429.02477731910955, 397.1140821165791, 372.01558111995047, 663.3840217146883, 587.2917845069967, 482.2677290131064, 484.70485256017827, 578.5195008166254, 499.19663956315225, 666.2231273437304, 420.2666662977046, 539.8641915369471, 580.310471328431, 451.1536773103715, 626.9157716658573, 621.7168336773287, 481.3942722325856, 563.3277605937523, 614.2419745271624, 562.6816600766879, 721.929326439667, 597.8215433515774, 581.5148113937479, 585.1991626268704, 643.8514151842124, 660.9267701500546, 717.1860963413512, 624.023714013494, 587.0721843421092, 795.8526871421749, 590.7291924525882, 672.3676291615197, 521.5837975244547, 605.0799288727832, 353.9957949036715, 560.8109895627832, 446.89963114277384, 534.544583131676, 515.7054169819035, 523.7734616582761, 542.125801541165, 700.381640979052, 622.8515496594233, 721.8940076379384, 800.5654798918405, 468.24520359685675, 308.73136877347577, 620.2800378264068, 767.4986086781079, 536.7473455594272, 587.6684036517346], "policy_predator_policy_reward": [1149.6949385286052, 1085.9649897919303, 1021.2027022307702, 1117.2493112097864, 822.2560830299354, 973.0121387446461, 982.5425574971068, 1085.8350934845148, 987.7891931319734, 1114.542055560452, 1115.3751616983423, 1118.6992554247736, 1207.1343082061196, 1136.0175746901646, 978.4325558249734, 850.6998964464385, 1279.474379767346, 1257.5031466916987, 791.3190008005845, 1108.2650666001111, 1127.8128451810726, 1120.688964470186, 1177.835074133141, 1060.2584681285173, 1013.9133031921867, 992.0150174451965, 842.0044785531685, 904.0509645186254, 1109.9309339902638, 1254.469481196199, 965.434170246097, 892.1815039980036, 1261.395448677762, 1127.3324492301967, 721.1536229801676, 815.0445157539015, 818.1123074083596, 920.8791558313294, 849.8750428542205, 997.0972860819455, 663.0644534115028, 640.036131227444, 805.9580056474233, 865.0829085719681, 1127.5621933258446, 1158.1463019726395, 609.9853331157867, 699.7330166721355, 816.5263042485527, 872.0434631040664, 849.3953938179696, 735.8355827450515, 812.8030780048076, 846.7414593456336, 671.0309982547747, 908.5375285664051, 670.4414690699393, 678.1893027651082, 819.2806977875242, 776.7627691767219, 716.9883173902656, 697.0616316721432, 825.7303111463993, 813.2787805590211, 703.4858763626752, 1009.9410705830544, 865.661127949855, 766.9216826241444, 619.6232518056476, 713.6321986820759, 813.6290251553222, 821.2588869960355, 716.8253785098294, 804.5176879187705, 560.716677890735, 521.2400862190103, 591.5345196715076, 598.8326375963201, 452.46631511310096, 549.2904892558612, 496.77731654209634, 333.55784827332496, 624.9737015918333, 653.4392279683915, 456.758373965228, 466.61280745329617, 582.6014837396211, 798.120851970204, 429.3708742080132, 439.2650751880065, 780.5436631294966, 893.2174705812542, 544.5368149141702, 474.4860243525398, 501.8194938762128, 550.2362846209817, 684.5697015363723, 651.0629164423549, 833.0831509740783, 773.861261831109, 440.4071455687462, 481.4786873557368, 395.94063724642155, 421.5244972676548, 702.061584575288, 706.0106260310129, 689.9872977648237, 637.5718571857877, 643.1945067560794, 504.8931633838631, 177.87568553104413, 165.2290832733855, 283.6096128880552, 145.8120535807448, 383.1445151481855, 366.96437810492256, 327.2675723421782, 427.2062532666153, 359.46559785500637, 275.79321458675366, 287.2961026454701, 175.9671062595324, 341.58855015213726, 535.7515832223094, 253.00293667093896, 210.46746998155405, 315.29831003265684, 197.11344630171888, 516.2292201245976, 498.3114333194646, 451.8639696494467, 346.8088974358618, 264.2147165087722, 346.16802392848945, 167.74009926108724, 278.6929079343247, 216.68645035385663, 273.50394703991026, 391.15049638679375, 331.9598233968519, 283.06927308099023, 288.8486637919891, 238.80559453190293, 259.91334005935926, 350.79694055849313, 297.39107185589694, 532.8075934790187, 448.1907701398644, 166.23883665335455, 172.4382239581392, 233.26008682824295, 227.43052922101845, 366.57439761036454, 269.42904913594174, 344.9310872682081, 146.65476527005922, 220.39577956664868, 345.48766483588275, 241.69210700553225, 326.04062379637827, 287.52296410730514, 162.63833255424413, 93.24061501035617, 241.7107383523834, 407.2008808396405, 328.51477171861075, 325.7455113872652, 225.8484832648389, 129.00191657195168, 113.41607118411167, 191.21932279615837, 233.7235396418811, 245.81776751186774, 242.42632916531883, 101.15508253145669, 207.24629290233645, 350.0879620983604, 231.49927700598414, 48.46037674743573, 116.83547349099577, 219.21933887910419, 103.06963624480197, 217.7718225619712, 432.9350714768468, 184.69807129669672, 189.64175253494213, 337.35154304130066, 163.50491992026056, 292.7930470014772, 193.09994604382814, 110.29339464276521, 71.86190513125507, 117.78760846028588, 167.45047912597434, 256.2100469863906, 185.95122382307804, 251.91258632769774, 107.29065115512243, 256.3538071748167, 152.99179446683564]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8761462960049036, "mean_inference_ms": 2.324423002444263, "mean_action_processing_ms": 0.39820768049810346, "mean_env_wait_ms": 0.331510103640625, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04350996017456055, "StateBufferConnector_ms": 0.027751684188842773, "ViewRequirementAgentConnector_ms": 0.45727860927581787}, "num_episodes": 23, "episode_return_max": 2044.8974307827798, "episode_return_min": 1006.7317333985507, "episode_return_mean": 1648.5790125034698, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 77.06842628533926, "num_env_steps_trained_throughput_per_sec": 77.06842628533926, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 18531.44, "restore_workers_time_ms": 0.019, "training_step_time_ms": 18531.369, "sample_time_ms": 2761.234, "learn_time_ms": 15742.387, "learn_throughput": 254.091, "synch_weights_time_ms": 25.282}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "479e5_00000", "date": "2024-08-16_11-34-08", "timestamp": 1723788248, "time_this_iter_s": 51.963504791259766, "time_total_s": 441.879474401474, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7daa940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 441.879474401474, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 57.24594594594594, "ram_util_percent": 81.96891891891892}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.794579387058026, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.321765011580533, "policy_loss": -0.016434749632226252, "vf_loss": 9.335703772085685, "vf_explained_var": -0.06131391127904256, "kl": 0.016639991390284554, "entropy": 1.4022559845889055, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3207638120367413, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.878602867530137, "policy_loss": -0.0035187395362222874, "vf_loss": 9.880585057899435, "vf_explained_var": -0.0004607889071974174, "kl": 0.006829143916597593, "entropy": 1.3929435962722414, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 2044.8974307827798, "episode_reward_min": 1204.1167450690316, "episode_reward_mean": 1675.935638394259, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -358.5176543117699, "predator_policy": 34.60683464833149}, "policy_reward_max": {"prey_policy": 800.5654798918405, "predator_policy": 1158.1463019726395}, "policy_reward_mean": {"prey_policy": 419.0353275922695, "predator_policy": 418.9324916048603}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1315.574033718809, 1749.0778321209764, 1263.3262006792713, 1799.3725910069263, 1849.5672719590627, 1812.9824738524298, 1737.2637103482666, 1846.3247069312526, 1639.8958374180447, 1669.6088738033811, 1704.3684078774684, 1649.046298629302, 1843.989993211949, 1795.1244814946047, 1620.2525513717362, 1812.5894226852026, 1585.0885214894988, 1859.8232248544866, 1757.6470126605388, 1515.7039565017499, 1954.942374108556, 1662.2362690134705, 1863.7609486099211, 1894.0630532537969, 1762.8339258937121, 1590.7297391298314, 1852.4602585787543, 1895.2099785386317, 1571.0411638315866, 1614.7517251833056, 1918.3039891228048, 1979.9254451864172, 1876.842076881833, 1674.2703865670487, 1883.5608489061308, 2044.8974307827798, 1875.6619117770854, 1422.395276606957, 1428.4402232718405, 1693.0670262624378, 1878.6177358483096, 1813.1107855802636, 1680.1038161095846, 1738.2739671628592, 1466.9236629195427, 1313.6393202692668, 1771.784630673316, 1885.119048987752, 1484.9745183035752, 1536.7114648126578, 1605.0644041040557, 1796.7486188359512, 1697.2455033897163, 1730.3402185676914, 1525.326423369294, 1744.9592071469178, 1204.1167450690316, 1229.8202792857896, 1886.679252967992, 1458.5584341115507, 1643.599584782308, 1654.2225244433444, 1570.3359595269278, 1413.0208023389698, 1838.8267584681662, 1729.1637297730176, 1527.0289742724171, 1604.2792171833642, 1717.294674488269, 1686.5142419251983, 1792.6831374599476, 1551.8777298331952, 1516.2404018098798, 1609.7826178152725, 1382.0504445371946, 1551.10646307514, 1551.7922562447454, 1505.3884904124952, 1807.69757511604, 1219.137843179801, 1746.9818839873344, 1533.7613508528125, 1652.2911556916938, 1823.8240499342517, 1751.0599145426513, 1655.5291917044797, 1637.8644546840494, 1516.8135732667913, 1711.630590271576, 1790.1892985930258, 1665.2865916363708, 1845.3844342673053, 1386.3652858971464, 1757.1844878582147, 1775.652090400187, 1524.9826153754361, 1754.9592688847526, 1804.2560260104187, 1688.1850956162418, 1965.1795616285067], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-64.8997752091098, -358.5176543117699, -113.76656562731993, 15.872068812129545, -60.656486822699065, 20.882102863023647, -110.23247055958164, 238.56414734711663, -342.2610079355672, -93.88021540385587, 115.95285377272242, 387.3112702917861, -67.20184846612406, 115.89579146177176, 24.736288211216362, 236.3574421570142, 133.19299169169284, -152.84169162408833, 39.6592342586098, 50.38111272359244, 151.71086806512884, 204.0267679772916, 215.41762986269936, -162.41479819764373, 96.57155585494446, 333.36848829459626, 174.3955908162161, -18.280201027031154, -37.498787019450674, -55.6756085545442, 301.1449838701533, -121.13837175895044, 67.28189375143144, 184.55117725034407, 244.79859050623156, -19.863277803102715, 44.617847679836295, 191.68609855210147, 249.98927746134095, 183.75791493066242, 383.9575777216572, 380.61763911906917, 285.31613081632514, 375.16333382818334, 647.4792996586658, 385.9464841358338, 380.2744084556035, 235.37571523796757, 449.885293780215, 389.5774506949712, 50.612234509856364, 159.39516891014995, 493.02007537417757, 490.8042338085567, 278.8635764753025, -57.41473164742288, 405.096117313308, 146.92220725156727, 122.23069767236427, 440.465249013746, 96.52222553149429, 486.1491456125832, 2.576297148509628, 370.4047352327207, 402.8259160405499, 552.1303279168005, 304.7525880333646, 552.0526640196075, 287.13639336387996, 188.3522449359496, 468.2703479193208, 249.06792791284727, 331.23287685168054, 396.34136478546077, 684.0556072084003, 395.23490059412825, 422.3946569647586, 576.6238998382828, 426.80746131658844, 516.1506716927399, 642.1851300604558, 481.95878017905886, 562.1550393201761, 615.6969338183272, 674.8315372874297, 542.0090699171521, 405.8915974998344, 455.0422362885791, 575.002654539008, 428.45060172804233, 391.4053859546451, 409.82217798024584, 311.88768198837636, 445.3562952408783, 536.3967236875678, 550.0494582148721, 520.869668036816, 353.7221098294987, 543.5644005203214, 546.7140570969256, 566.0951228362626, 548.7788838740278, 767.2590711226935, 306.3792279296096, 541.0381991830244, 584.2893673337144, 517.1555667999944, 714.4657171764343, 432.49988969867087, 444.6385212562328, 454.91540071161586, 309.04544281641864, 436.41490713842734, 429.02477731910955, 397.1140821165791, 372.01558111995047, 663.3840217146883, 587.2917845069967, 482.2677290131064, 484.70485256017827, 578.5195008166254, 499.19663956315225, 666.2231273437304, 420.2666662977046, 539.8641915369471, 580.310471328431, 451.1536773103715, 626.9157716658573, 621.7168336773287, 481.3942722325856, 563.3277605937523, 614.2419745271624, 562.6816600766879, 721.929326439667, 597.8215433515774, 581.5148113937479, 585.1991626268704, 643.8514151842124, 660.9267701500546, 717.1860963413512, 624.023714013494, 587.0721843421092, 795.8526871421749, 590.7291924525882, 672.3676291615197, 521.5837975244547, 605.0799288727832, 353.9957949036715, 560.8109895627832, 446.89963114277384, 534.544583131676, 515.7054169819035, 523.7734616582761, 542.125801541165, 700.381640979052, 622.8515496594233, 721.8940076379384, 800.5654798918405, 468.24520359685675, 308.73136877347577, 620.2800378264068, 767.4986086781079, 536.7473455594272, 587.6684036517346, 671.4337203403651, 734.8583493877561, 483.2275804063344, 663.7498984430059, 609.5258594161513, 710.4573698157875, 689.402261834171, 560.6004774029651, 550.8321315146894, 582.1166505653886, 628.728085949366, 488.26344028882545, 660.1491607611846, 404.4127608712931, 752.8092756705482, 632.9739855938129, 657.5131076265757, 754.336435974112, 611.8110209039021, 570.5668152933033, 524.1712764611685, 557.7659860564576, 619.2139486905282, 618.8224304771762, 488.41274121270635, 668.3347831663947, 557.3807733255006, 551.5641623044197, 531.0274127387914, 578.3134446897376, 687.6605164327067, 522.5188720171043, 422.2017431227729, 576.0577997576047, 628.7517369045884, 705.9740432847046], "policy_predator_policy_reward": [818.1123074083596, 920.8791558313294, 849.8750428542205, 997.0972860819455, 663.0644534115028, 640.036131227444, 805.9580056474233, 865.0829085719681, 1127.5621933258446, 1158.1463019726395, 609.9853331157867, 699.7330166721355, 816.5263042485527, 872.0434631040664, 849.3953938179696, 735.8355827450515, 812.8030780048076, 846.7414593456336, 671.0309982547747, 908.5375285664051, 670.4414690699393, 678.1893027651082, 819.2806977875242, 776.7627691767219, 716.9883173902656, 697.0616316721432, 825.7303111463993, 813.2787805590211, 703.4858763626752, 1009.9410705830544, 865.661127949855, 766.9216826241444, 619.6232518056476, 713.6321986820759, 813.6290251553222, 821.2588869960355, 716.8253785098294, 804.5176879187705, 560.716677890735, 521.2400862190103, 591.5345196715076, 598.8326375963201, 452.46631511310096, 549.2904892558612, 496.77731654209634, 333.55784827332496, 624.9737015918333, 653.4392279683915, 456.758373965228, 466.61280745329617, 582.6014837396211, 798.120851970204, 429.3708742080132, 439.2650751880065, 780.5436631294966, 893.2174705812542, 544.5368149141702, 474.4860243525398, 501.8194938762128, 550.2362846209817, 684.5697015363723, 651.0629164423549, 833.0831509740783, 773.861261831109, 440.4071455687462, 481.4786873557368, 395.94063724642155, 421.5244972676548, 702.061584575288, 706.0106260310129, 689.9872977648237, 637.5718571857877, 643.1945067560794, 504.8931633838631, 177.87568553104413, 165.2290832733855, 283.6096128880552, 145.8120535807448, 383.1445151481855, 366.96437810492256, 327.2675723421782, 427.2062532666153, 359.46559785500637, 275.79321458675366, 287.2961026454701, 175.9671062595324, 341.58855015213726, 535.7515832223094, 253.00293667093896, 210.46746998155405, 315.29831003265684, 197.11344630171888, 516.2292201245976, 498.3114333194646, 451.8639696494467, 346.8088974358618, 264.2147165087722, 346.16802392848945, 167.74009926108724, 278.6929079343247, 216.68645035385663, 273.50394703991026, 391.15049638679375, 331.9598233968519, 283.06927308099023, 288.8486637919891, 238.80559453190293, 259.91334005935926, 350.79694055849313, 297.39107185589694, 532.8075934790187, 448.1907701398644, 166.23883665335455, 172.4382239581392, 233.26008682824295, 227.43052922101845, 366.57439761036454, 269.42904913594174, 344.9310872682081, 146.65476527005922, 220.39577956664868, 345.48766483588275, 241.69210700553225, 326.04062379637827, 287.52296410730514, 162.63833255424413, 93.24061501035617, 241.7107383523834, 407.2008808396405, 328.51477171861075, 325.7455113872652, 225.8484832648389, 129.00191657195168, 113.41607118411167, 191.21932279615837, 233.7235396418811, 245.81776751186774, 242.42632916531883, 101.15508253145669, 207.24629290233645, 350.0879620983604, 231.49927700598414, 48.46037674743573, 116.83547349099577, 219.21933887910419, 103.06963624480197, 217.7718225619712, 432.9350714768468, 184.69807129669672, 189.64175253494213, 337.35154304130066, 163.50491992026056, 292.7930470014772, 193.09994604382814, 110.29339464276521, 71.86190513125507, 117.78760846028588, 167.45047912597434, 256.2100469863906, 185.95122382307804, 251.91258632769774, 107.29065115512243, 256.3538071748167, 152.99179446683564, 211.39225131524375, 34.60683464833149, 312.97595438407774, 363.8706167008349, 172.9144153156971, 258.1622699950131, 206.56658802326348, 198.959864444078, 247.41913001824395, 257.4965425857275, 174.8870114092241, 224.93503561937584, 335.7902693538918, 311.27839928520683, 216.70360041614833, 187.70243691251312, 124.36038171507587, 129.07666632060915, 246.41112340579406, 416.5954746643082, 64.26240452264187, 240.16561885687895, 248.6360718304359, 270.51203686007557, 365.33102254013835, 253.57354348094913, 232.1303177493523, 183.90736199616526, 340.9332255038169, 304.6851859524065, 253.56920304818638, 340.50743451241965, 481.17420126690075, 208.7513514689641, 376.57660807255553, 253.87717336665935]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9207683914463644, "mean_inference_ms": 2.4482630357119564, "mean_action_processing_ms": 0.42578982461567966, "mean_env_wait_ms": 0.3483487497083966, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04411745071411133, "StateBufferConnector_ms": 0.02855706214904785, "ViewRequirementAgentConnector_ms": 0.5301874876022339}, "num_episodes": 18, "episode_return_max": 2044.8974307827798, "episode_return_min": 1204.1167450690316, "episode_return_mean": 1675.935638394259, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 89.51989508832371, "num_env_steps_trained_throughput_per_sec": 89.51989508832371, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 21662.67, "restore_workers_time_ms": 0.02, "training_step_time_ms": 21662.597, "sample_time_ms": 3339.553, "learn_time_ms": 18291.217, "learn_throughput": 218.684, "synch_weights_time_ms": 29.847}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "479e5_00000", "date": "2024-08-16_11-34-53", "timestamp": 1723788293, "time_this_iter_s": 44.77086877822876, "time_total_s": 486.65034317970276, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78a0e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 486.65034317970276, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 54.05555555555555, "ram_util_percent": 81.1888888888889}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5349119016260067, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.649049599460824, "policy_loss": -0.01504153422124329, "vf_loss": 9.661467017824688, "vf_explained_var": -0.07801777856059806, "kl": 0.017494082111107458, "entropy": 1.3685380651206567, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3768681831933833, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.838649357185162, "policy_loss": -0.004979881415606806, "vf_loss": 9.841609934145811, "vf_explained_var": -0.032054051709553555, "kl": 0.008974654442905645, "entropy": 1.4149024152881884, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 2044.8974307827798, "episode_reward_min": 1204.1167450690316, "episode_reward_mean": 1693.6466571645267, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -57.41473164742288, "predator_policy": 34.60683464833149}, "policy_reward_max": {"prey_policy": 800.5654798918405, "predator_policy": 893.2174705812542}, "policy_reward_mean": {"prey_policy": 504.47399925540833, "predator_policy": 342.349329326855}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1757.6470126605388, 1515.7039565017499, 1954.942374108556, 1662.2362690134705, 1863.7609486099211, 1894.0630532537969, 1762.8339258937121, 1590.7297391298314, 1852.4602585787543, 1895.2099785386317, 1571.0411638315866, 1614.7517251833056, 1918.3039891228048, 1979.9254451864172, 1876.842076881833, 1674.2703865670487, 1883.5608489061308, 2044.8974307827798, 1875.6619117770854, 1422.395276606957, 1428.4402232718405, 1693.0670262624378, 1878.6177358483096, 1813.1107855802636, 1680.1038161095846, 1738.2739671628592, 1466.9236629195427, 1313.6393202692668, 1771.784630673316, 1885.119048987752, 1484.9745183035752, 1536.7114648126578, 1605.0644041040557, 1796.7486188359512, 1697.2455033897163, 1730.3402185676914, 1525.326423369294, 1744.9592071469178, 1204.1167450690316, 1229.8202792857896, 1886.679252967992, 1458.5584341115507, 1643.599584782308, 1654.2225244433444, 1570.3359595269278, 1413.0208023389698, 1838.8267584681662, 1729.1637297730176, 1527.0289742724171, 1604.2792171833642, 1717.294674488269, 1686.5142419251983, 1792.6831374599476, 1551.8777298331952, 1516.2404018098798, 1609.7826178152725, 1382.0504445371946, 1551.10646307514, 1551.7922562447454, 1505.3884904124952, 1807.69757511604, 1219.137843179801, 1746.9818839873344, 1533.7613508528125, 1652.2911556916938, 1823.8240499342517, 1751.0599145426513, 1655.5291917044797, 1637.8644546840494, 1516.8135732667913, 1711.630590271576, 1790.1892985930258, 1665.2865916363708, 1845.3844342673053, 1386.3652858971464, 1757.1844878582147, 1775.652090400187, 1524.9826153754361, 1754.9592688847526, 1804.2560260104187, 1688.1850956162418, 1965.1795616285067, 1661.9135546650068, 1902.9046040181327, 1932.303643410645, 1775.4043516283766, 1706.5060785149483, 1903.4794411514908, 1988.41768884466, 1816.1069545609614, 1739.1895107721052, 1898.159306042149, 1650.5156009762704, 1828.6728268080572, 1747.7026048180355, 1768.2951984478532, 1854.590496373908, 1633.3975844411711, 1722.093355558651, 1794.725509446995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [44.617847679836295, 191.68609855210147, 249.98927746134095, 183.75791493066242, 383.9575777216572, 380.61763911906917, 285.31613081632514, 375.16333382818334, 647.4792996586658, 385.9464841358338, 380.2744084556035, 235.37571523796757, 449.885293780215, 389.5774506949712, 50.612234509856364, 159.39516891014995, 493.02007537417757, 490.8042338085567, 278.8635764753025, -57.41473164742288, 405.096117313308, 146.92220725156727, 122.23069767236427, 440.465249013746, 96.52222553149429, 486.1491456125832, 2.576297148509628, 370.4047352327207, 402.8259160405499, 552.1303279168005, 304.7525880333646, 552.0526640196075, 287.13639336387996, 188.3522449359496, 468.2703479193208, 249.06792791284727, 331.23287685168054, 396.34136478546077, 684.0556072084003, 395.23490059412825, 422.3946569647586, 576.6238998382828, 426.80746131658844, 516.1506716927399, 642.1851300604558, 481.95878017905886, 562.1550393201761, 615.6969338183272, 674.8315372874297, 542.0090699171521, 405.8915974998344, 455.0422362885791, 575.002654539008, 428.45060172804233, 391.4053859546451, 409.82217798024584, 311.88768198837636, 445.3562952408783, 536.3967236875678, 550.0494582148721, 520.869668036816, 353.7221098294987, 543.5644005203214, 546.7140570969256, 566.0951228362626, 548.7788838740278, 767.2590711226935, 306.3792279296096, 541.0381991830244, 584.2893673337144, 517.1555667999944, 714.4657171764343, 432.49988969867087, 444.6385212562328, 454.91540071161586, 309.04544281641864, 436.41490713842734, 429.02477731910955, 397.1140821165791, 372.01558111995047, 663.3840217146883, 587.2917845069967, 482.2677290131064, 484.70485256017827, 578.5195008166254, 499.19663956315225, 666.2231273437304, 420.2666662977046, 539.8641915369471, 580.310471328431, 451.1536773103715, 626.9157716658573, 621.7168336773287, 481.3942722325856, 563.3277605937523, 614.2419745271624, 562.6816600766879, 721.929326439667, 597.8215433515774, 581.5148113937479, 585.1991626268704, 643.8514151842124, 660.9267701500546, 717.1860963413512, 624.023714013494, 587.0721843421092, 795.8526871421749, 590.7291924525882, 672.3676291615197, 521.5837975244547, 605.0799288727832, 353.9957949036715, 560.8109895627832, 446.89963114277384, 534.544583131676, 515.7054169819035, 523.7734616582761, 542.125801541165, 700.381640979052, 622.8515496594233, 721.8940076379384, 800.5654798918405, 468.24520359685675, 308.73136877347577, 620.2800378264068, 767.4986086781079, 536.7473455594272, 587.6684036517346, 671.4337203403651, 734.8583493877561, 483.2275804063344, 663.7498984430059, 609.5258594161513, 710.4573698157875, 689.402261834171, 560.6004774029651, 550.8321315146894, 582.1166505653886, 628.728085949366, 488.26344028882545, 660.1491607611846, 404.4127608712931, 752.8092756705482, 632.9739855938129, 657.5131076265757, 754.336435974112, 611.8110209039021, 570.5668152933033, 524.1712764611685, 557.7659860564576, 619.2139486905282, 618.8224304771762, 488.41274121270635, 668.3347831663947, 557.3807733255006, 551.5641623044197, 531.0274127387914, 578.3134446897376, 687.6605164327067, 522.5188720171043, 422.2017431227729, 576.0577997576047, 628.7517369045884, 705.9740432847046, 583.738715978807, 689.788127165368, 402.8060613197716, 642.917194324473, 610.4801397646054, 612.0132485043189, 617.4977418303466, 465.7533607469722, 429.9491678567262, 405.0325064669513, 460.9123418936421, 551.2459432124732, 544.4255212305078, 571.2235737397378, 486.330761377919, 419.17228779750417, 512.6683161113142, 601.4222411500818, 404.9082212243101, 527.9961982328455, 626.5080196736116, 468.3880662362939, 297.88133875176834, 546.1835639934743, 602.1259921903674, 712.5491739132973, 509.5974745013736, 604.5445941419306, 471.6297421940751, 534.0415882850408, 540.17833412727, 607.2263423059104, 407.32831651957684, 330.06170250974293, 391.6055388988846, 470.546963975369], "policy_predator_policy_reward": [716.8253785098294, 804.5176879187705, 560.716677890735, 521.2400862190103, 591.5345196715076, 598.8326375963201, 452.46631511310096, 549.2904892558612, 496.77731654209634, 333.55784827332496, 624.9737015918333, 653.4392279683915, 456.758373965228, 466.61280745329617, 582.6014837396211, 798.120851970204, 429.3708742080132, 439.2650751880065, 780.5436631294966, 893.2174705812542, 544.5368149141702, 474.4860243525398, 501.8194938762128, 550.2362846209817, 684.5697015363723, 651.0629164423549, 833.0831509740783, 773.861261831109, 440.4071455687462, 481.4786873557368, 395.94063724642155, 421.5244972676548, 702.061584575288, 706.0106260310129, 689.9872977648237, 637.5718571857877, 643.1945067560794, 504.8931633838631, 177.87568553104413, 165.2290832733855, 283.6096128880552, 145.8120535807448, 383.1445151481855, 366.96437810492256, 327.2675723421782, 427.2062532666153, 359.46559785500637, 275.79321458675366, 287.2961026454701, 175.9671062595324, 341.58855015213726, 535.7515832223094, 253.00293667093896, 210.46746998155405, 315.29831003265684, 197.11344630171888, 516.2292201245976, 498.3114333194646, 451.8639696494467, 346.8088974358618, 264.2147165087722, 346.16802392848945, 167.74009926108724, 278.6929079343247, 216.68645035385663, 273.50394703991026, 391.15049638679375, 331.9598233968519, 283.06927308099023, 288.8486637919891, 238.80559453190293, 259.91334005935926, 350.79694055849313, 297.39107185589694, 532.8075934790187, 448.1907701398644, 166.23883665335455, 172.4382239581392, 233.26008682824295, 227.43052922101845, 366.57439761036454, 269.42904913594174, 344.9310872682081, 146.65476527005922, 220.39577956664868, 345.48766483588275, 241.69210700553225, 326.04062379637827, 287.52296410730514, 162.63833255424413, 93.24061501035617, 241.7107383523834, 407.2008808396405, 328.51477171861075, 325.7455113872652, 225.8484832648389, 129.00191657195168, 113.41607118411167, 191.21932279615837, 233.7235396418811, 245.81776751186774, 242.42632916531883, 101.15508253145669, 207.24629290233645, 350.0879620983604, 231.49927700598414, 48.46037674743573, 116.83547349099577, 219.21933887910419, 103.06963624480197, 217.7718225619712, 432.9350714768468, 184.69807129669672, 189.64175253494213, 337.35154304130066, 163.50491992026056, 292.7930470014772, 193.09994604382814, 110.29339464276521, 71.86190513125507, 117.78760846028588, 167.45047912597434, 256.2100469863906, 185.95122382307804, 251.91258632769774, 107.29065115512243, 256.3538071748167, 152.99179446683564, 211.39225131524375, 34.60683464833149, 312.97595438407774, 363.8706167008349, 172.9144153156971, 258.1622699950131, 206.56658802326348, 198.959864444078, 247.41913001824395, 257.4965425857275, 174.8870114092241, 224.93503561937584, 335.7902693538918, 311.27839928520683, 216.70360041614833, 187.70243691251312, 124.36038171507587, 129.07666632060915, 246.41112340579406, 416.5954746643082, 64.26240452264187, 240.16561885687895, 248.6360718304359, 270.51203686007557, 365.33102254013835, 253.57354348094913, 232.1303177493523, 183.90736199616526, 340.9332255038169, 304.6851859524065, 253.56920304818638, 340.50743451241965, 481.17420126690075, 208.7513514689641, 376.57660807255553, 253.87717336665935, 196.95984185448444, 191.42686966634662, 391.09680523875807, 466.0845431351278, 351.92519945485293, 357.8850556868685, 265.1676013129684, 426.98564773809, 377.9677684816576, 493.55663570961497, 471.6659230491805, 419.6552329961948, 407.138090192558, 465.6305036818579, 528.7801628834161, 381.82374250212024, 396.4144279926545, 228.68452551805507, 444.44237147417556, 520.8125151108198, 305.18322745455424, 250.4362876118088, 474.71558647007294, 509.892337592741, 112.41153579475636, 320.61590291961465, 260.9024131845649, 393.2507166199832, 355.8831497088598, 493.0360161859332, 213.6655558549968, 272.3273521529935, 417.30206150260915, 567.4012750267219, 514.4738446398086, 418.09916193293265]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9783806032779591, "mean_inference_ms": 2.6091686842885466, "mean_action_processing_ms": 0.4511187970695572, "mean_env_wait_ms": 0.3707507279955384, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.045104384422302246, "StateBufferConnector_ms": 0.0679858922958374, "ViewRequirementAgentConnector_ms": 0.5800111293792725}, "num_episodes": 18, "episode_return_max": 2044.8974307827798, "episode_return_min": 1204.1167450690316, "episode_return_mean": 1693.6466571645267, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 91.81318644755216, "num_env_steps_trained_throughput_per_sec": 91.81318644755216, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 24718.397, "restore_workers_time_ms": 0.024, "training_step_time_ms": 24718.314, "sample_time_ms": 3865.577, "learn_time_ms": 20818.29, "learn_throughput": 192.139, "synch_weights_time_ms": 32.432}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "479e5_00000", "date": "2024-08-16_11-35-36", "timestamp": 1723788336, "time_this_iter_s": 43.64760231971741, "time_total_s": 530.2979454994202, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7900dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 530.2979454994202, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 53.51290322580645, "ram_util_percent": 81.12258064516128}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3560644625986695, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.748105995743362, "policy_loss": -0.008694745718733106, "vf_loss": 9.75514979892307, "vf_explained_var": -0.049715492649683876, "kl": 0.011006359809639602, "entropy": 1.3536564494566943, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5599257533354733, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.721300985447314, "policy_loss": -0.0025070346804414553, "vf_loss": 9.72188589358456, "vf_explained_var": -0.031538893116845025, "kl": 0.008542786196121789, "entropy": 1.4204566765083837, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 1988.41768884466, "episode_reward_min": 1204.1167450690316, "episode_reward_mean": 1695.1733350241182, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 200.57679729292164, "predator_policy": 34.60683464833149}, "policy_reward_max": {"prey_policy": 800.5654798918405, "predator_policy": 650.4122718445877}, "policy_reward_mean": {"prey_policy": 530.2837403482521, "predator_policy": 317.30292716380717}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1875.6619117770854, 1422.395276606957, 1428.4402232718405, 1693.0670262624378, 1878.6177358483096, 1813.1107855802636, 1680.1038161095846, 1738.2739671628592, 1466.9236629195427, 1313.6393202692668, 1771.784630673316, 1885.119048987752, 1484.9745183035752, 1536.7114648126578, 1605.0644041040557, 1796.7486188359512, 1697.2455033897163, 1730.3402185676914, 1525.326423369294, 1744.9592071469178, 1204.1167450690316, 1229.8202792857896, 1886.679252967992, 1458.5584341115507, 1643.599584782308, 1654.2225244433444, 1570.3359595269278, 1413.0208023389698, 1838.8267584681662, 1729.1637297730176, 1527.0289742724171, 1604.2792171833642, 1717.294674488269, 1686.5142419251983, 1792.6831374599476, 1551.8777298331952, 1516.2404018098798, 1609.7826178152725, 1382.0504445371946, 1551.10646307514, 1551.7922562447454, 1505.3884904124952, 1807.69757511604, 1219.137843179801, 1746.9818839873344, 1533.7613508528125, 1652.2911556916938, 1823.8240499342517, 1751.0599145426513, 1655.5291917044797, 1637.8644546840494, 1516.8135732667913, 1711.630590271576, 1790.1892985930258, 1665.2865916363708, 1845.3844342673053, 1386.3652858971464, 1757.1844878582147, 1775.652090400187, 1524.9826153754361, 1754.9592688847526, 1804.2560260104187, 1688.1850956162418, 1965.1795616285067, 1661.9135546650068, 1902.9046040181327, 1932.303643410645, 1775.4043516283766, 1706.5060785149483, 1903.4794411514908, 1988.41768884466, 1816.1069545609614, 1739.1895107721052, 1898.159306042149, 1650.5156009762704, 1828.6728268080572, 1747.7026048180355, 1768.2951984478532, 1854.590496373908, 1633.3975844411711, 1722.093355558651, 1794.725509446995, 1863.3851119188275, 1644.391175627006, 1888.086901687725, 1765.2516809447573, 1884.2427141448334, 1884.5440191855164, 1757.7675366374979, 1720.0793225553282, 1694.4102974901418, 1700.3616776849528, 1695.9443700103309, 1807.0780365677724, 1802.482473131813, 1904.6879827991604, 1905.3970456681618, 1801.8398099998994, 1953.7653297222123, 1792.1328829341141], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [331.23287685168054, 396.34136478546077, 684.0556072084003, 395.23490059412825, 422.3946569647586, 576.6238998382828, 426.80746131658844, 516.1506716927399, 642.1851300604558, 481.95878017905886, 562.1550393201761, 615.6969338183272, 674.8315372874297, 542.0090699171521, 405.8915974998344, 455.0422362885791, 575.002654539008, 428.45060172804233, 391.4053859546451, 409.82217798024584, 311.88768198837636, 445.3562952408783, 536.3967236875678, 550.0494582148721, 520.869668036816, 353.7221098294987, 543.5644005203214, 546.7140570969256, 566.0951228362626, 548.7788838740278, 767.2590711226935, 306.3792279296096, 541.0381991830244, 584.2893673337144, 517.1555667999944, 714.4657171764343, 432.49988969867087, 444.6385212562328, 454.91540071161586, 309.04544281641864, 436.41490713842734, 429.02477731910955, 397.1140821165791, 372.01558111995047, 663.3840217146883, 587.2917845069967, 482.2677290131064, 484.70485256017827, 578.5195008166254, 499.19663956315225, 666.2231273437304, 420.2666662977046, 539.8641915369471, 580.310471328431, 451.1536773103715, 626.9157716658573, 621.7168336773287, 481.3942722325856, 563.3277605937523, 614.2419745271624, 562.6816600766879, 721.929326439667, 597.8215433515774, 581.5148113937479, 585.1991626268704, 643.8514151842124, 660.9267701500546, 717.1860963413512, 624.023714013494, 587.0721843421092, 795.8526871421749, 590.7291924525882, 672.3676291615197, 521.5837975244547, 605.0799288727832, 353.9957949036715, 560.8109895627832, 446.89963114277384, 534.544583131676, 515.7054169819035, 523.7734616582761, 542.125801541165, 700.381640979052, 622.8515496594233, 721.8940076379384, 800.5654798918405, 468.24520359685675, 308.73136877347577, 620.2800378264068, 767.4986086781079, 536.7473455594272, 587.6684036517346, 671.4337203403651, 734.8583493877561, 483.2275804063344, 663.7498984430059, 609.5258594161513, 710.4573698157875, 689.402261834171, 560.6004774029651, 550.8321315146894, 582.1166505653886, 628.728085949366, 488.26344028882545, 660.1491607611846, 404.4127608712931, 752.8092756705482, 632.9739855938129, 657.5131076265757, 754.336435974112, 611.8110209039021, 570.5668152933033, 524.1712764611685, 557.7659860564576, 619.2139486905282, 618.8224304771762, 488.41274121270635, 668.3347831663947, 557.3807733255006, 551.5641623044197, 531.0274127387914, 578.3134446897376, 687.6605164327067, 522.5188720171043, 422.2017431227729, 576.0577997576047, 628.7517369045884, 705.9740432847046, 583.738715978807, 689.788127165368, 402.8060613197716, 642.917194324473, 610.4801397646054, 612.0132485043189, 617.4977418303466, 465.7533607469722, 429.9491678567262, 405.0325064669513, 460.9123418936421, 551.2459432124732, 544.4255212305078, 571.2235737397378, 486.330761377919, 419.17228779750417, 512.6683161113142, 601.4222411500818, 404.9082212243101, 527.9961982328455, 626.5080196736116, 468.3880662362939, 297.88133875176834, 546.1835639934743, 602.1259921903674, 712.5491739132973, 509.5974745013736, 604.5445941419306, 471.6297421940751, 534.0415882850408, 540.17833412727, 607.2263423059104, 407.32831651957684, 330.06170250974293, 391.6055388988846, 470.546963975369, 390.7732519303824, 578.2275208039395, 346.8250901064687, 283.9937047073745, 609.1870009840457, 493.25519899885825, 515.3687588413059, 464.6163282095275, 568.5377720881806, 569.3524224953053, 392.965681532912, 608.559958360289, 599.6381862175843, 594.3194113361884, 364.4414753843975, 267.7730509124984, 405.52623420247374, 408.28912272240706, 464.91514576786733, 483.9482241364035, 332.9083011790671, 428.69221494876587, 339.1450246926334, 200.57679729292164, 518.5323646409738, 714.4662110804462, 481.00830987479577, 479.4226165897207, 474.7381096950475, 516.8009173051489, 376.36692722380985, 312.2239621904323, 440.09477570508085, 558.099676972262, 372.1992604685779, 280.0393233923256], "policy_predator_policy_reward": [643.1945067560794, 504.8931633838631, 177.87568553104413, 165.2290832733855, 283.6096128880552, 145.8120535807448, 383.1445151481855, 366.96437810492256, 327.2675723421782, 427.2062532666153, 359.46559785500637, 275.79321458675366, 287.2961026454701, 175.9671062595324, 341.58855015213726, 535.7515832223094, 253.00293667093896, 210.46746998155405, 315.29831003265684, 197.11344630171888, 516.2292201245976, 498.3114333194646, 451.8639696494467, 346.8088974358618, 264.2147165087722, 346.16802392848945, 167.74009926108724, 278.6929079343247, 216.68645035385663, 273.50394703991026, 391.15049638679375, 331.9598233968519, 283.06927308099023, 288.8486637919891, 238.80559453190293, 259.91334005935926, 350.79694055849313, 297.39107185589694, 532.8075934790187, 448.1907701398644, 166.23883665335455, 172.4382239581392, 233.26008682824295, 227.43052922101845, 366.57439761036454, 269.42904913594174, 344.9310872682081, 146.65476527005922, 220.39577956664868, 345.48766483588275, 241.69210700553225, 326.04062379637827, 287.52296410730514, 162.63833255424413, 93.24061501035617, 241.7107383523834, 407.2008808396405, 328.51477171861075, 325.7455113872652, 225.8484832648389, 129.00191657195168, 113.41607118411167, 191.21932279615837, 233.7235396418811, 245.81776751186774, 242.42632916531883, 101.15508253145669, 207.24629290233645, 350.0879620983604, 231.49927700598414, 48.46037674743573, 116.83547349099577, 219.21933887910419, 103.06963624480197, 217.7718225619712, 432.9350714768468, 184.69807129669672, 189.64175253494213, 337.35154304130066, 163.50491992026056, 292.7930470014772, 193.09994604382814, 110.29339464276521, 71.86190513125507, 117.78760846028588, 167.45047912597434, 256.2100469863906, 185.95122382307804, 251.91258632769774, 107.29065115512243, 256.3538071748167, 152.99179446683564, 211.39225131524375, 34.60683464833149, 312.97595438407774, 363.8706167008349, 172.9144153156971, 258.1622699950131, 206.56658802326348, 198.959864444078, 247.41913001824395, 257.4965425857275, 174.8870114092241, 224.93503561937584, 335.7902693538918, 311.27839928520683, 216.70360041614833, 187.70243691251312, 124.36038171507587, 129.07666632060915, 246.41112340579406, 416.5954746643082, 64.26240452264187, 240.16561885687895, 248.6360718304359, 270.51203686007557, 365.33102254013835, 253.57354348094913, 232.1303177493523, 183.90736199616526, 340.9332255038169, 304.6851859524065, 253.56920304818638, 340.50743451241965, 481.17420126690075, 208.7513514689641, 376.57660807255553, 253.87717336665935, 196.95984185448444, 191.42686966634662, 391.09680523875807, 466.0845431351278, 351.92519945485293, 357.8850556868685, 265.1676013129684, 426.98564773809, 377.9677684816576, 493.55663570961497, 471.6659230491805, 419.6552329961948, 407.138090192558, 465.6305036818579, 528.7801628834161, 381.82374250212024, 396.4144279926545, 228.68452551805507, 444.44237147417556, 520.8125151108198, 305.18322745455424, 250.4362876118088, 474.71558647007294, 509.892337592741, 112.41153579475636, 320.61590291961465, 260.9024131845649, 393.2507166199832, 355.8831497088598, 493.0360161859332, 213.6655558549968, 272.3273521529935, 417.30206150260915, 567.4012750267219, 514.4738446398086, 418.09916193293265, 487.0266131024859, 407.35772608202035, 487.4717982902354, 526.1005825229275, 355.6113225966977, 430.03337910812377, 418.96121948580804, 366.30537440811634, 376.05393710962926, 370.2985824517177, 330.28980840881826, 552.7285708834925, 326.56999493094685, 237.23994415277946, 602.0116124103583, 485.8531838480747, 330.29642042302817, 550.2985201422327, 425.4754059718464, 326.022901808835, 587.9776760896065, 346.36617779289077, 650.4122718445877, 616.9439427376304, 329.36404220018704, 240.11985521020534, 495.585167258086, 448.67188907655657, 533.2854215705819, 380.57259709738486, 472.11730777720953, 641.1316128084471, 407.7513761730237, 547.8195008718454, 551.7217515077359, 588.1725475654752]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0499050101294676, "mean_inference_ms": 2.8035002931655386, "mean_action_processing_ms": 0.48123737112134113, "mean_env_wait_ms": 0.3980984646800411, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04458129405975342, "StateBufferConnector_ms": 0.06908965110778809, "ViewRequirementAgentConnector_ms": 0.6662789583206177}, "num_episodes": 18, "episode_return_max": 1988.41768884466, "episode_return_min": 1204.1167450690316, "episode_return_mean": 1695.1733350241182, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 95.84720165794499, "num_env_steps_trained_throughput_per_sec": 95.84720165794499, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 27522.818, "restore_workers_time_ms": 0.024, "training_step_time_ms": 27522.732, "sample_time_ms": 4373.191, "learn_time_ms": 23111.854, "learn_throughput": 173.071, "synch_weights_time_ms": 35.078}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "479e5_00000", "date": "2024-08-16_11-36-18", "timestamp": 1723788378, "time_this_iter_s": 41.777047872543335, "time_total_s": 572.0749933719635, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78ef280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 572.0749933719635, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 52.827118644067795, "ram_util_percent": 80.98305084745763}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4315805719958412, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.72293927379386, "policy_loss": -0.006848971273937317, "vf_loss": 9.728488199042264, "vf_explained_var": -0.013288016830171858, "kl": 0.008666831083556837, "entropy": 1.304301749335395, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.857136437880299, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.472917567863666, "policy_loss": -0.0073958147771745215, "vf_loss": 9.477649440967216, "vf_explained_var": -0.031104649879314283, "kl": 0.011839838011384673, "entropy": 1.4101869733876022, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 1988.41768884466, "episode_reward_min": 1219.137843179801, "episode_reward_mean": 1743.3247136560365, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 95.67895223254625, "predator_policy": 34.60683464833149}, "policy_reward_max": {"prey_policy": 800.5654798918405, "predator_policy": 792.9394421820259}, "policy_reward_mean": {"prey_policy": 485.9980151953565, "predator_policy": 385.66434163266183}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1413.0208023389698, 1838.8267584681662, 1729.1637297730176, 1527.0289742724171, 1604.2792171833642, 1717.294674488269, 1686.5142419251983, 1792.6831374599476, 1551.8777298331952, 1516.2404018098798, 1609.7826178152725, 1382.0504445371946, 1551.10646307514, 1551.7922562447454, 1505.3884904124952, 1807.69757511604, 1219.137843179801, 1746.9818839873344, 1533.7613508528125, 1652.2911556916938, 1823.8240499342517, 1751.0599145426513, 1655.5291917044797, 1637.8644546840494, 1516.8135732667913, 1711.630590271576, 1790.1892985930258, 1665.2865916363708, 1845.3844342673053, 1386.3652858971464, 1757.1844878582147, 1775.652090400187, 1524.9826153754361, 1754.9592688847526, 1804.2560260104187, 1688.1850956162418, 1965.1795616285067, 1661.9135546650068, 1902.9046040181327, 1932.303643410645, 1775.4043516283766, 1706.5060785149483, 1903.4794411514908, 1988.41768884466, 1816.1069545609614, 1739.1895107721052, 1898.159306042149, 1650.5156009762704, 1828.6728268080572, 1747.7026048180355, 1768.2951984478532, 1854.590496373908, 1633.3975844411711, 1722.093355558651, 1794.725509446995, 1863.3851119188275, 1644.391175627006, 1888.086901687725, 1765.2516809447573, 1884.2427141448334, 1884.5440191855164, 1757.7675366374979, 1720.0793225553282, 1694.4102974901418, 1700.3616776849528, 1695.9443700103309, 1807.0780365677724, 1802.482473131813, 1904.6879827991604, 1905.3970456681618, 1801.8398099998994, 1953.7653297222123, 1792.1328829341141, 1662.7404716113601, 1808.8345101360837, 1879.021518553754, 1827.5264022019555, 1925.377141615797, 1912.9433364621152, 1711.8948227022242, 1864.2433938205388, 1781.5999846969898, 1730.2481071609272, 1730.4665013810918, 1728.248485912533, 1765.6549584337981, 1759.1882017428368, 1915.120935178315, 1837.5370102588372, 1721.794765094856, 1860.5571041919002, 1797.8404629608438, 1904.310488039799, 1779.659682122285, 1884.6069523177293, 1781.748055244065, 1715.2711510961988, 1703.2181499512164, 1691.7803161383274, 1869.5454983514308], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [451.1536773103715, 626.9157716658573, 621.7168336773287, 481.3942722325856, 563.3277605937523, 614.2419745271624, 562.6816600766879, 721.929326439667, 597.8215433515774, 581.5148113937479, 585.1991626268704, 643.8514151842124, 660.9267701500546, 717.1860963413512, 624.023714013494, 587.0721843421092, 795.8526871421749, 590.7291924525882, 672.3676291615197, 521.5837975244547, 605.0799288727832, 353.9957949036715, 560.8109895627832, 446.89963114277384, 534.544583131676, 515.7054169819035, 523.7734616582761, 542.125801541165, 700.381640979052, 622.8515496594233, 721.8940076379384, 800.5654798918405, 468.24520359685675, 308.73136877347577, 620.2800378264068, 767.4986086781079, 536.7473455594272, 587.6684036517346, 671.4337203403651, 734.8583493877561, 483.2275804063344, 663.7498984430059, 609.5258594161513, 710.4573698157875, 689.402261834171, 560.6004774029651, 550.8321315146894, 582.1166505653886, 628.728085949366, 488.26344028882545, 660.1491607611846, 404.4127608712931, 752.8092756705482, 632.9739855938129, 657.5131076265757, 754.336435974112, 611.8110209039021, 570.5668152933033, 524.1712764611685, 557.7659860564576, 619.2139486905282, 618.8224304771762, 488.41274121270635, 668.3347831663947, 557.3807733255006, 551.5641623044197, 531.0274127387914, 578.3134446897376, 687.6605164327067, 522.5188720171043, 422.2017431227729, 576.0577997576047, 628.7517369045884, 705.9740432847046, 583.738715978807, 689.788127165368, 402.8060613197716, 642.917194324473, 610.4801397646054, 612.0132485043189, 617.4977418303466, 465.7533607469722, 429.9491678567262, 405.0325064669513, 460.9123418936421, 551.2459432124732, 544.4255212305078, 571.2235737397378, 486.330761377919, 419.17228779750417, 512.6683161113142, 601.4222411500818, 404.9082212243101, 527.9961982328455, 626.5080196736116, 468.3880662362939, 297.88133875176834, 546.1835639934743, 602.1259921903674, 712.5491739132973, 509.5974745013736, 604.5445941419306, 471.6297421940751, 534.0415882850408, 540.17833412727, 607.2263423059104, 407.32831651957684, 330.06170250974293, 391.6055388988846, 470.546963975369, 390.7732519303824, 578.2275208039395, 346.8250901064687, 283.9937047073745, 609.1870009840457, 493.25519899885825, 515.3687588413059, 464.6163282095275, 568.5377720881806, 569.3524224953053, 392.965681532912, 608.559958360289, 599.6381862175843, 594.3194113361884, 364.4414753843975, 267.7730509124984, 405.52623420247374, 408.28912272240706, 464.91514576786733, 483.9482241364035, 332.9083011790671, 428.69221494876587, 339.1450246926334, 200.57679729292164, 518.5323646409738, 714.4662110804462, 481.00830987479577, 479.4226165897207, 474.7381096950475, 516.8009173051489, 376.36692722380985, 312.2239621904323, 440.09477570508085, 558.099676972262, 372.1992604685779, 280.0393233923256, 298.85431552067007, 427.53098558149986, 281.11160102602355, 467.67252575537253, 346.5665282123067, 368.7218865832283, 444.404141155683, 436.422932199249, 95.67895223254625, 321.41387043058853, 416.88136182256244, 281.3566180982028, 319.70989634830977, 248.00150925674203, 326.28777104153403, 194.3387666143732, 223.49577713072782, 237.53943786831715, 372.17427785791165, 474.5688801969867, 214.2228379029348, 143.97957393066744, 353.50667352817544, 164.1306049121999, 577.186486903859, 286.5571501317208, 433.5057536856099, 279.3716921532827, 313.82904341915037, 325.384271926893, 432.5818753274479, 366.0685754750347, 328.268061108079, 271.84304294636286, 280.4545012951103, 350.91113904754855, 554.4090603477706, 382.35871073182886, 300.96758250842515, 396.76672227978884, 257.3653690487036, 428.1753266736484, 474.43288114951923, 463.01599132457176, 224.16112391227378, 421.84735400829027, 291.17814562266375, 401.2040108446585, 237.91930826526337, 249.74205680171124, 307.0423012506763, 350.1220054503702, 411.65702964478515, 350.96839248359464], "policy_predator_policy_reward": [93.24061501035617, 241.7107383523834, 407.2008808396405, 328.51477171861075, 325.7455113872652, 225.8484832648389, 129.00191657195168, 113.41607118411167, 191.21932279615837, 233.7235396418811, 245.81776751186774, 242.42632916531883, 101.15508253145669, 207.24629290233645, 350.0879620983604, 231.49927700598414, 48.46037674743573, 116.83547349099577, 219.21933887910419, 103.06963624480197, 217.7718225619712, 432.9350714768468, 184.69807129669672, 189.64175253494213, 337.35154304130066, 163.50491992026056, 292.7930470014772, 193.09994604382814, 110.29339464276521, 71.86190513125507, 117.78760846028588, 167.45047912597434, 256.2100469863906, 185.95122382307804, 251.91258632769774, 107.29065115512243, 256.3538071748167, 152.99179446683564, 211.39225131524375, 34.60683464833149, 312.97595438407774, 363.8706167008349, 172.9144153156971, 258.1622699950131, 206.56658802326348, 198.959864444078, 247.41913001824395, 257.4965425857275, 174.8870114092241, 224.93503561937584, 335.7902693538918, 311.27839928520683, 216.70360041614833, 187.70243691251312, 124.36038171507587, 129.07666632060915, 246.41112340579406, 416.5954746643082, 64.26240452264187, 240.16561885687895, 248.6360718304359, 270.51203686007557, 365.33102254013835, 253.57354348094913, 232.1303177493523, 183.90736199616526, 340.9332255038169, 304.6851859524065, 253.56920304818638, 340.50743451241965, 481.17420126690075, 208.7513514689641, 376.57660807255553, 253.87717336665935, 196.95984185448444, 191.42686966634662, 391.09680523875807, 466.0845431351278, 351.92519945485293, 357.8850556868685, 265.1676013129684, 426.98564773809, 377.9677684816576, 493.55663570961497, 471.6659230491805, 419.6552329961948, 407.138090192558, 465.6305036818579, 528.7801628834161, 381.82374250212024, 396.4144279926545, 228.68452551805507, 444.44237147417556, 520.8125151108198, 305.18322745455424, 250.4362876118088, 474.71558647007294, 509.892337592741, 112.41153579475636, 320.61590291961465, 260.9024131845649, 393.2507166199832, 355.8831497088598, 493.0360161859332, 213.6655558549968, 272.3273521529935, 417.30206150260915, 567.4012750267219, 514.4738446398086, 418.09916193293265, 487.0266131024859, 407.35772608202035, 487.4717982902354, 526.1005825229275, 355.6113225966977, 430.03337910812377, 418.96121948580804, 366.30537440811634, 376.05393710962926, 370.2985824517177, 330.28980840881826, 552.7285708834925, 326.56999493094685, 237.23994415277946, 602.0116124103583, 485.8531838480747, 330.29642042302817, 550.2985201422327, 425.4754059718464, 326.022901808835, 587.9776760896065, 346.36617779289077, 650.4122718445877, 616.9439427376304, 329.36404220018704, 240.11985521020534, 495.585167258086, 448.67188907655657, 533.2854215705819, 380.57259709738486, 472.11730777720953, 641.1316128084471, 407.7513761730237, 547.8195008718454, 551.7217515077359, 588.1725475654752, 380.2263169081387, 556.1288536010505, 425.64026335345824, 634.4101200012303, 524.9489575144431, 638.7841462437744, 434.4970581809962, 512.2022706660267, 715.3448767706362, 792.9394421820259, 607.9319024363879, 606.7734541049659, 612.6307545214454, 531.5526625757303, 647.6682577414564, 695.9485984231743, 684.3530964194803, 636.2116732784649, 527.0543719370555, 356.4505771689751, 780.8964637854014, 591.3676257620882, 596.1008463758772, 614.510361096281, 545.8093429966829, 356.1019784015354, 566.0485925889077, 480.26216331503747, 599.1020567581052, 676.8055630741654, 538.1899340625448, 500.69662539381113, 555.8507981766612, 565.8328628637532, 616.4906135290456, 612.7008503201967, 414.5550761691543, 446.5176157120907, 615.0909100114891, 591.4852732400967, 490.2506647047011, 603.8683216952337, 460.46265687890826, 486.695422964731, 596.9136223593758, 538.8259549641264, 471.72269446712005, 551.1663001617557, 617.9116724953395, 597.6451123889002, 537.5128898319987, 497.1031196052822, 641.0975347238808, 465.8225414991711]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.169042208376857, "mean_inference_ms": 3.1282021369864608, "mean_action_processing_ms": 0.5290705322255919, "mean_env_wait_ms": 0.4438276507475311, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04392695426940918, "StateBufferConnector_ms": 0.06696915626525879, "ViewRequirementAgentConnector_ms": 0.8514761924743652}, "num_episodes": 27, "episode_return_max": 1988.41768884466, "episode_return_min": 1219.137843179801, "episode_return_mean": 1743.3247136560365, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 89.69937063150923, "num_env_steps_trained_throughput_per_sec": 89.69937063150923, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 30633.546, "restore_workers_time_ms": 0.025, "training_step_time_ms": 30633.456, "sample_time_ms": 4867.48, "learn_time_ms": 25726.392, "learn_throughput": 155.482, "synch_weights_time_ms": 36.848}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "479e5_00000", "date": "2024-08-16_11-37-03", "timestamp": 1723788423, "time_this_iter_s": 44.642189264297485, "time_total_s": 616.717182636261, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7900ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 616.717182636261, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 54.060317460317464, "ram_util_percent": 81.25714285714287}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4091897090749135, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.789161426301986, "policy_loss": -0.0057852918649259856, "vf_loss": 9.79345378320684, "vf_explained_var": 0.014142976109943693, "kl": 0.009953035278836567, "entropy": 1.244697395518974, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9101733391247098, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.419396576553426, "policy_loss": -0.0023455856768315824, "vf_loss": 9.418898648559733, "vf_explained_var": -0.019756051787623654, "kl": 0.012637827459270955, "entropy": 1.4500240494965246, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 1988.41768884466, "episode_reward_min": 1386.3652858971464, "episode_reward_mean": 1777.6036471150633, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 95.67895223254625, "predator_policy": 34.60683464833149}, "policy_reward_max": {"prey_policy": 754.336435974112, "predator_policy": 792.9394421820259}, "policy_reward_mean": {"prey_policy": 435.37510666786807, "predator_policy": 453.4267168896637}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1533.7613508528125, 1652.2911556916938, 1823.8240499342517, 1751.0599145426513, 1655.5291917044797, 1637.8644546840494, 1516.8135732667913, 1711.630590271576, 1790.1892985930258, 1665.2865916363708, 1845.3844342673053, 1386.3652858971464, 1757.1844878582147, 1775.652090400187, 1524.9826153754361, 1754.9592688847526, 1804.2560260104187, 1688.1850956162418, 1965.1795616285067, 1661.9135546650068, 1902.9046040181327, 1932.303643410645, 1775.4043516283766, 1706.5060785149483, 1903.4794411514908, 1988.41768884466, 1816.1069545609614, 1739.1895107721052, 1898.159306042149, 1650.5156009762704, 1828.6728268080572, 1747.7026048180355, 1768.2951984478532, 1854.590496373908, 1633.3975844411711, 1722.093355558651, 1794.725509446995, 1863.3851119188275, 1644.391175627006, 1888.086901687725, 1765.2516809447573, 1884.2427141448334, 1884.5440191855164, 1757.7675366374979, 1720.0793225553282, 1694.4102974901418, 1700.3616776849528, 1695.9443700103309, 1807.0780365677724, 1802.482473131813, 1904.6879827991604, 1905.3970456681618, 1801.8398099998994, 1953.7653297222123, 1792.1328829341141, 1662.7404716113601, 1808.8345101360837, 1879.021518553754, 1827.5264022019555, 1925.377141615797, 1912.9433364621152, 1711.8948227022242, 1864.2433938205388, 1781.5999846969898, 1730.2481071609272, 1730.4665013810918, 1728.248485912533, 1765.6549584337981, 1759.1882017428368, 1915.120935178315, 1837.5370102588372, 1721.794765094856, 1860.5571041919002, 1797.8404629608438, 1904.310488039799, 1779.659682122285, 1884.6069523177293, 1781.748055244065, 1715.2711510961988, 1703.2181499512164, 1691.7803161383274, 1869.5454983514308, 1932.0193484527063, 1810.2978933247591, 1780.5239562622278, 1546.5295376914614, 1699.790400908386, 1959.9116844497582, 1850.3372477891762, 1688.172154106185, 1781.2271224564279, 1540.2864744726458, 1959.09901593306, 1656.472336469121, 1960.4927108762001, 1790.2573349427648, 1686.8658010342272, 1871.485047555164, 1832.843946960545, 1832.148574138317], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [536.7473455594272, 587.6684036517346, 671.4337203403651, 734.8583493877561, 483.2275804063344, 663.7498984430059, 609.5258594161513, 710.4573698157875, 689.402261834171, 560.6004774029651, 550.8321315146894, 582.1166505653886, 628.728085949366, 488.26344028882545, 660.1491607611846, 404.4127608712931, 752.8092756705482, 632.9739855938129, 657.5131076265757, 754.336435974112, 611.8110209039021, 570.5668152933033, 524.1712764611685, 557.7659860564576, 619.2139486905282, 618.8224304771762, 488.41274121270635, 668.3347831663947, 557.3807733255006, 551.5641623044197, 531.0274127387914, 578.3134446897376, 687.6605164327067, 522.5188720171043, 422.2017431227729, 576.0577997576047, 628.7517369045884, 705.9740432847046, 583.738715978807, 689.788127165368, 402.8060613197716, 642.917194324473, 610.4801397646054, 612.0132485043189, 617.4977418303466, 465.7533607469722, 429.9491678567262, 405.0325064669513, 460.9123418936421, 551.2459432124732, 544.4255212305078, 571.2235737397378, 486.330761377919, 419.17228779750417, 512.6683161113142, 601.4222411500818, 404.9082212243101, 527.9961982328455, 626.5080196736116, 468.3880662362939, 297.88133875176834, 546.1835639934743, 602.1259921903674, 712.5491739132973, 509.5974745013736, 604.5445941419306, 471.6297421940751, 534.0415882850408, 540.17833412727, 607.2263423059104, 407.32831651957684, 330.06170250974293, 391.6055388988846, 470.546963975369, 390.7732519303824, 578.2275208039395, 346.8250901064687, 283.9937047073745, 609.1870009840457, 493.25519899885825, 515.3687588413059, 464.6163282095275, 568.5377720881806, 569.3524224953053, 392.965681532912, 608.559958360289, 599.6381862175843, 594.3194113361884, 364.4414753843975, 267.7730509124984, 405.52623420247374, 408.28912272240706, 464.91514576786733, 483.9482241364035, 332.9083011790671, 428.69221494876587, 339.1450246926334, 200.57679729292164, 518.5323646409738, 714.4662110804462, 481.00830987479577, 479.4226165897207, 474.7381096950475, 516.8009173051489, 376.36692722380985, 312.2239621904323, 440.09477570508085, 558.099676972262, 372.1992604685779, 280.0393233923256, 298.85431552067007, 427.53098558149986, 281.11160102602355, 467.67252575537253, 346.5665282123067, 368.7218865832283, 444.404141155683, 436.422932199249, 95.67895223254625, 321.41387043058853, 416.88136182256244, 281.3566180982028, 319.70989634830977, 248.00150925674203, 326.28777104153403, 194.3387666143732, 223.49577713072782, 237.53943786831715, 372.17427785791165, 474.5688801969867, 214.2228379029348, 143.97957393066744, 353.50667352817544, 164.1306049121999, 577.186486903859, 286.5571501317208, 433.5057536856099, 279.3716921532827, 313.82904341915037, 325.384271926893, 432.5818753274479, 366.0685754750347, 328.268061108079, 271.84304294636286, 280.4545012951103, 350.91113904754855, 554.4090603477706, 382.35871073182886, 300.96758250842515, 396.76672227978884, 257.3653690487036, 428.1753266736484, 474.43288114951923, 463.01599132457176, 224.16112391227378, 421.84735400829027, 291.17814562266375, 401.2040108446585, 237.91930826526337, 249.74205680171124, 307.0423012506763, 350.1220054503702, 411.65702964478515, 350.96839248359464, 452.7609849623876, 327.5488497459616, 369.67512959594234, 447.7870065119445, 183.35884691498148, 257.6848423467563, 248.19050983184462, 219.1240221161797, 478.2735497090408, 295.27626690426104, 386.6716660219511, 416.13207737016046, 296.7084974123082, 251.38219992529284, 225.31762596379866, 218.96552988862695, 268.20097803270187, 280.85634823019114, 396.5085744866869, 321.9773616282325, 414.4001901642057, 291.2244989921707, 169.88933407616267, 265.4588327762094, 332.4790093633004, 406.55961736970823, 182.14051947198016, 381.62846779375235, 279.4980325473527, 298.6063540711226, 315.48875273558446, 404.3729037698831, 307.31563649850625, 263.82497975101614, 300.8740735507811, 234.1300090170305], "policy_predator_policy_reward": [256.3538071748167, 152.99179446683564, 211.39225131524375, 34.60683464833149, 312.97595438407774, 363.8706167008349, 172.9144153156971, 258.1622699950131, 206.56658802326348, 198.959864444078, 247.41913001824395, 257.4965425857275, 174.8870114092241, 224.93503561937584, 335.7902693538918, 311.27839928520683, 216.70360041614833, 187.70243691251312, 124.36038171507587, 129.07666632060915, 246.41112340579406, 416.5954746643082, 64.26240452264187, 240.16561885687895, 248.6360718304359, 270.51203686007557, 365.33102254013835, 253.57354348094913, 232.1303177493523, 183.90736199616526, 340.9332255038169, 304.6851859524065, 253.56920304818638, 340.50743451241965, 481.17420126690075, 208.7513514689641, 376.57660807255553, 253.87717336665935, 196.95984185448444, 191.42686966634662, 391.09680523875807, 466.0845431351278, 351.92519945485293, 357.8850556868685, 265.1676013129684, 426.98564773809, 377.9677684816576, 493.55663570961497, 471.6659230491805, 419.6552329961948, 407.138090192558, 465.6305036818579, 528.7801628834161, 381.82374250212024, 396.4144279926545, 228.68452551805507, 444.44237147417556, 520.8125151108198, 305.18322745455424, 250.4362876118088, 474.71558647007294, 509.892337592741, 112.41153579475636, 320.61590291961465, 260.9024131845649, 393.2507166199832, 355.8831497088598, 493.0360161859332, 213.6655558549968, 272.3273521529935, 417.30206150260915, 567.4012750267219, 514.4738446398086, 418.09916193293265, 487.0266131024859, 407.35772608202035, 487.4717982902354, 526.1005825229275, 355.6113225966977, 430.03337910812377, 418.96121948580804, 366.30537440811634, 376.05393710962926, 370.2985824517177, 330.28980840881826, 552.7285708834925, 326.56999493094685, 237.23994415277946, 602.0116124103583, 485.8531838480747, 330.29642042302817, 550.2985201422327, 425.4754059718464, 326.022901808835, 587.9776760896065, 346.36617779289077, 650.4122718445877, 616.9439427376304, 329.36404220018704, 240.11985521020534, 495.585167258086, 448.67188907655657, 533.2854215705819, 380.57259709738486, 472.11730777720953, 641.1316128084471, 407.7513761730237, 547.8195008718454, 551.7217515077359, 588.1725475654752, 380.2263169081387, 556.1288536010505, 425.64026335345824, 634.4101200012303, 524.9489575144431, 638.7841462437744, 434.4970581809962, 512.2022706660267, 715.3448767706362, 792.9394421820259, 607.9319024363879, 606.7734541049659, 612.6307545214454, 531.5526625757303, 647.6682577414564, 695.9485984231743, 684.3530964194803, 636.2116732784649, 527.0543719370555, 356.4505771689751, 780.8964637854014, 591.3676257620882, 596.1008463758772, 614.510361096281, 545.8093429966829, 356.1019784015354, 566.0485925889077, 480.26216331503747, 599.1020567581052, 676.8055630741654, 538.1899340625448, 500.69662539381113, 555.8507981766612, 565.8328628637532, 616.4906135290456, 612.7008503201967, 414.5550761691543, 446.5176157120907, 615.0909100114891, 591.4852732400967, 490.2506647047011, 603.8683216952337, 460.46265687890826, 486.695422964731, 596.9136223593758, 538.8259549641264, 471.72269446712005, 551.1663001617557, 617.9116724953395, 597.6451123889002, 537.5128898319987, 497.1031196052822, 641.0975347238808, 465.8225414991711, 609.9212285494339, 541.7882851949245, 465.64201573170857, 527.1937414851658, 708.2787283750288, 631.2015386254635, 522.7730498174989, 556.4419559259381, 447.9498858870927, 478.2906984079915, 548.5270252437934, 608.5809158138541, 595.5649880822158, 706.6815623693589, 624.3410837671826, 619.5479144865773, 651.4768972957431, 580.6928988977927, 440.9893296771017, 380.811208680624, 618.8998946141303, 634.5744321625559, 667.8936544767606, 553.2305151399892, 615.0166264608341, 606.4374576823564, 676.2877985988995, 550.2005490781331, 662.96469030018, 445.7967241155709, 625.8297657134317, 525.7936253362665, 671.6168282277946, 590.0865024832309, 661.2834803885446, 635.8610111819614]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2349713010510488, "mean_inference_ms": 3.3102458805255837, "mean_action_processing_ms": 0.5558087248038158, "mean_env_wait_ms": 0.47011997034282216, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010636687278747559, "StateBufferConnector_ms": 0.053829193115234375, "ViewRequirementAgentConnector_ms": 0.6291474103927612}, "num_episodes": 18, "episode_return_max": 1988.41768884466, "episode_return_min": 1386.3652858971464, "episode_return_mean": 1777.6036471150633, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 86.7650838732223, "num_env_steps_trained_throughput_per_sec": 86.7650838732223, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 33855.871, "restore_workers_time_ms": 0.026, "training_step_time_ms": 33855.777, "sample_time_ms": 5519.291, "learn_time_ms": 28290.408, "learn_throughput": 141.391, "synch_weights_time_ms": 43.042}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "479e5_00000", "date": "2024-08-16_11-37-49", "timestamp": 1723788469, "time_this_iter_s": 46.254966020584106, "time_total_s": 662.9721486568451, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7884b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 662.9721486568451, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 55.70151515151515, "ram_util_percent": 81.41818181818181}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2705687912131745, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.873287695930118, "policy_loss": -0.00409819873347977, "vf_loss": 9.876281048002697, "vf_explained_var": -0.034831629827539755, "kl": 0.007365779289259261, "entropy": 1.1668154644587683, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.796389574600906, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.509741510159124, "policy_loss": -0.007702297646005357, "vf_loss": 9.513886138371058, "vf_explained_var": -0.01984303530561861, "kl": 0.015811946602282842, "entropy": 1.4076511989825617, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 1988.41768884466, "episode_reward_min": 1540.2864744726458, "episode_reward_mean": 1796.95288838914, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 83.19027371665135, "predator_policy": 112.41153579475636}, "policy_reward_max": {"prey_policy": 714.4662110804462, "predator_policy": 792.9394421820259}, "policy_reward_mean": {"prey_policy": 387.5945355226028, "predator_policy": 510.88190867196727}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1965.1795616285067, 1661.9135546650068, 1902.9046040181327, 1932.303643410645, 1775.4043516283766, 1706.5060785149483, 1903.4794411514908, 1988.41768884466, 1816.1069545609614, 1739.1895107721052, 1898.159306042149, 1650.5156009762704, 1828.6728268080572, 1747.7026048180355, 1768.2951984478532, 1854.590496373908, 1633.3975844411711, 1722.093355558651, 1794.725509446995, 1863.3851119188275, 1644.391175627006, 1888.086901687725, 1765.2516809447573, 1884.2427141448334, 1884.5440191855164, 1757.7675366374979, 1720.0793225553282, 1694.4102974901418, 1700.3616776849528, 1695.9443700103309, 1807.0780365677724, 1802.482473131813, 1904.6879827991604, 1905.3970456681618, 1801.8398099998994, 1953.7653297222123, 1792.1328829341141, 1662.7404716113601, 1808.8345101360837, 1879.021518553754, 1827.5264022019555, 1925.377141615797, 1912.9433364621152, 1711.8948227022242, 1864.2433938205388, 1781.5999846969898, 1730.2481071609272, 1730.4665013810918, 1728.248485912533, 1765.6549584337981, 1759.1882017428368, 1915.120935178315, 1837.5370102588372, 1721.794765094856, 1860.5571041919002, 1797.8404629608438, 1904.310488039799, 1779.659682122285, 1884.6069523177293, 1781.748055244065, 1715.2711510961988, 1703.2181499512164, 1691.7803161383274, 1869.5454983514308, 1932.0193484527063, 1810.2978933247591, 1780.5239562622278, 1546.5295376914614, 1699.790400908386, 1959.9116844497582, 1850.3372477891762, 1688.172154106185, 1781.2271224564279, 1540.2864744726458, 1959.09901593306, 1656.472336469121, 1960.4927108762001, 1790.2573349427648, 1686.8658010342272, 1871.485047555164, 1832.843946960545, 1832.148574138317, 1755.656289368393, 1893.0559735852044, 1832.5173961562898, 1712.327577543672, 1697.4650718291973, 1775.8157372787027, 1709.2250899395765, 1848.034377733587, 1826.0576373701351, 1956.8112305133056, 1768.7118783409908, 1680.7201830655831, 1807.8299539003658, 1903.6206649801256, 1753.1235944902344, 1772.716691928203, 1710.1641508287307, 1806.2901040427862], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [628.7517369045884, 705.9740432847046, 583.738715978807, 689.788127165368, 402.8060613197716, 642.917194324473, 610.4801397646054, 612.0132485043189, 617.4977418303466, 465.7533607469722, 429.9491678567262, 405.0325064669513, 460.9123418936421, 551.2459432124732, 544.4255212305078, 571.2235737397378, 486.330761377919, 419.17228779750417, 512.6683161113142, 601.4222411500818, 404.9082212243101, 527.9961982328455, 626.5080196736116, 468.3880662362939, 297.88133875176834, 546.1835639934743, 602.1259921903674, 712.5491739132973, 509.5974745013736, 604.5445941419306, 471.6297421940751, 534.0415882850408, 540.17833412727, 607.2263423059104, 407.32831651957684, 330.06170250974293, 391.6055388988846, 470.546963975369, 390.7732519303824, 578.2275208039395, 346.8250901064687, 283.9937047073745, 609.1870009840457, 493.25519899885825, 515.3687588413059, 464.6163282095275, 568.5377720881806, 569.3524224953053, 392.965681532912, 608.559958360289, 599.6381862175843, 594.3194113361884, 364.4414753843975, 267.7730509124984, 405.52623420247374, 408.28912272240706, 464.91514576786733, 483.9482241364035, 332.9083011790671, 428.69221494876587, 339.1450246926334, 200.57679729292164, 518.5323646409738, 714.4662110804462, 481.00830987479577, 479.4226165897207, 474.7381096950475, 516.8009173051489, 376.36692722380985, 312.2239621904323, 440.09477570508085, 558.099676972262, 372.1992604685779, 280.0393233923256, 298.85431552067007, 427.53098558149986, 281.11160102602355, 467.67252575537253, 346.5665282123067, 368.7218865832283, 444.404141155683, 436.422932199249, 95.67895223254625, 321.41387043058853, 416.88136182256244, 281.3566180982028, 319.70989634830977, 248.00150925674203, 326.28777104153403, 194.3387666143732, 223.49577713072782, 237.53943786831715, 372.17427785791165, 474.5688801969867, 214.2228379029348, 143.97957393066744, 353.50667352817544, 164.1306049121999, 577.186486903859, 286.5571501317208, 433.5057536856099, 279.3716921532827, 313.82904341915037, 325.384271926893, 432.5818753274479, 366.0685754750347, 328.268061108079, 271.84304294636286, 280.4545012951103, 350.91113904754855, 554.4090603477706, 382.35871073182886, 300.96758250842515, 396.76672227978884, 257.3653690487036, 428.1753266736484, 474.43288114951923, 463.01599132457176, 224.16112391227378, 421.84735400829027, 291.17814562266375, 401.2040108446585, 237.91930826526337, 249.74205680171124, 307.0423012506763, 350.1220054503702, 411.65702964478515, 350.96839248359464, 452.7609849623876, 327.5488497459616, 369.67512959594234, 447.7870065119445, 183.35884691498148, 257.6848423467563, 248.19050983184462, 219.1240221161797, 478.2735497090408, 295.27626690426104, 386.6716660219511, 416.13207737016046, 296.7084974123082, 251.38219992529284, 225.31762596379866, 218.96552988862695, 268.20097803270187, 280.85634823019114, 396.5085744866869, 321.9773616282325, 414.4001901642057, 291.2244989921707, 169.88933407616267, 265.4588327762094, 332.4790093633004, 406.55961736970823, 182.14051947198016, 381.62846779375235, 279.4980325473527, 298.6063540711226, 315.48875273558446, 404.3729037698831, 307.31563649850625, 263.82497975101614, 300.8740735507811, 234.1300090170305, 83.19027371665135, 516.2661712656727, 305.89162296047107, 453.3331221491544, 206.8996191680405, 360.41656245465623, 467.4994202672512, 347.3708928202723, 371.13037803851745, 147.07960907885726, 393.6738897770905, 118.64236381545912, 411.0909054933079, 236.2170618079601, 218.81119443115028, 383.89690331177496, 452.66138963905047, 470.46928482416376, 540.3221255971608, 387.5515145610086, 292.6006573401541, 330.31928670511024, 106.2651514257107, 261.3315217877609, 331.9651730001926, 318.5781280787649, 267.91393357227554, 346.60216961756254, 452.5206494249316, 284.32983850129654, 297.94189727504283, 297.04513558216325, 316.1595278335509, 393.89248452644125, 244.68277030330285, 474.95316851879363], "policy_predator_policy_reward": [376.57660807255553, 253.87717336665935, 196.95984185448444, 191.42686966634662, 391.09680523875807, 466.0845431351278, 351.92519945485293, 357.8850556868685, 265.1676013129684, 426.98564773809, 377.9677684816576, 493.55663570961497, 471.6659230491805, 419.6552329961948, 407.138090192558, 465.6305036818579, 528.7801628834161, 381.82374250212024, 396.4144279926545, 228.68452551805507, 444.44237147417556, 520.8125151108198, 305.18322745455424, 250.4362876118088, 474.71558647007294, 509.892337592741, 112.41153579475636, 320.61590291961465, 260.9024131845649, 393.2507166199832, 355.8831497088598, 493.0360161859332, 213.6655558549968, 272.3273521529935, 417.30206150260915, 567.4012750267219, 514.4738446398086, 418.09916193293265, 487.0266131024859, 407.35772608202035, 487.4717982902354, 526.1005825229275, 355.6113225966977, 430.03337910812377, 418.96121948580804, 366.30537440811634, 376.05393710962926, 370.2985824517177, 330.28980840881826, 552.7285708834925, 326.56999493094685, 237.23994415277946, 602.0116124103583, 485.8531838480747, 330.29642042302817, 550.2985201422327, 425.4754059718464, 326.022901808835, 587.9776760896065, 346.36617779289077, 650.4122718445877, 616.9439427376304, 329.36404220018704, 240.11985521020534, 495.585167258086, 448.67188907655657, 533.2854215705819, 380.57259709738486, 472.11730777720953, 641.1316128084471, 407.7513761730237, 547.8195008718454, 551.7217515077359, 588.1725475654752, 380.2263169081387, 556.1288536010505, 425.64026335345824, 634.4101200012303, 524.9489575144431, 638.7841462437744, 434.4970581809962, 512.2022706660267, 715.3448767706362, 792.9394421820259, 607.9319024363879, 606.7734541049659, 612.6307545214454, 531.5526625757303, 647.6682577414564, 695.9485984231743, 684.3530964194803, 636.2116732784649, 527.0543719370555, 356.4505771689751, 780.8964637854014, 591.3676257620882, 596.1008463758772, 614.510361096281, 545.8093429966829, 356.1019784015354, 566.0485925889077, 480.26216331503747, 599.1020567581052, 676.8055630741654, 538.1899340625448, 500.69662539381113, 555.8507981766612, 565.8328628637532, 616.4906135290456, 612.7008503201967, 414.5550761691543, 446.5176157120907, 615.0909100114891, 591.4852732400967, 490.2506647047011, 603.8683216952337, 460.46265687890826, 486.695422964731, 596.9136223593758, 538.8259549641264, 471.72269446712005, 551.1663001617557, 617.9116724953395, 597.6451123889002, 537.5128898319987, 497.1031196052822, 641.0975347238808, 465.8225414991711, 609.9212285494339, 541.7882851949245, 465.64201573170857, 527.1937414851658, 708.2787283750288, 631.2015386254635, 522.7730498174989, 556.4419559259381, 447.9498858870927, 478.2906984079915, 548.5270252437934, 608.5809158138541, 595.5649880822158, 706.6815623693589, 624.3410837671826, 619.5479144865773, 651.4768972957431, 580.6928988977927, 440.9893296771017, 380.811208680624, 618.8998946141303, 634.5744321625559, 667.8936544767606, 553.2305151399892, 615.0166264608341, 606.4374576823564, 676.2877985988995, 550.2005490781331, 662.96469030018, 445.7967241155709, 625.8297657134317, 525.7936253362665, 671.6168282277946, 590.0865024832309, 661.2834803885446, 635.8610111819614, 470.2399572435469, 685.9598871425223, 614.4692074661957, 519.36202100938, 681.5341084866674, 583.6671060469274, 569.4246934929346, 328.0325709632162, 682.3045269604505, 496.9505577513739, 582.3007254078614, 681.1987582782898, 550.3792761285227, 511.5378465097848, 678.2029771537383, 567.1233028369232, 412.60596562297263, 490.3209972839505, 504.27270064777605, 524.6648897073595, 672.1072732271106, 473.68466106861666, 682.6262106123544, 630.4972992397572, 651.0627793948873, 506.2238734265193, 633.5203423042792, 655.5842194860055, 505.01826826542003, 511.2548382985881, 587.4689433883673, 590.2607156826286, 521.4908777348655, 478.6212607338738, 538.6691427521044, 547.9850224685832]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3169366804689833, "mean_inference_ms": 3.518145064116161, "mean_action_processing_ms": 0.5867432609953223, "mean_env_wait_ms": 0.500748814262842, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04689192771911621, "StateBufferConnector_ms": 0.05400562286376953, "ViewRequirementAgentConnector_ms": 0.7317862510681152}, "num_episodes": 18, "episode_return_max": 1988.41768884466, "episode_return_min": 1540.2864744726458, "episode_return_mean": 1796.95288838914, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 88.0612482687359, "num_env_steps_trained_throughput_per_sec": 88.0612482687359, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 37001.211, "restore_workers_time_ms": 0.026, "training_step_time_ms": 37001.117, "sample_time_ms": 6603.07, "learn_time_ms": 30323.492, "learn_throughput": 131.911, "synch_weights_time_ms": 71.395}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "479e5_00000", "date": "2024-08-16_11-38-35", "timestamp": 1723788515, "time_this_iter_s": 45.462456941604614, "time_total_s": 708.4346055984497, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7877dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 708.4346055984497, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 53.84920634920635, "ram_util_percent": 82.10158730158733}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.279332998316124, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.85335729891661, "policy_loss": -0.003735362072278149, "vf_loss": 9.855935302613274, "vf_explained_var": -0.05567266755003147, "kl": 0.007715806430734671, "entropy": 1.1871115212087278, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7791270545550755, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.581101291898698, "policy_loss": -0.007263569827758209, "vf_loss": 9.585352186172727, "vf_explained_var": -0.017394721161120782, "kl": 0.013389608933377232, "entropy": 1.3888321622338875, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 2003.6417270215413, "episode_reward_min": 1540.2864744726458, "episode_reward_mean": 1803.832915638465, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 83.19027371665135, "predator_policy": 237.23994415277946}, "policy_reward_max": {"prey_policy": 714.4662110804462, "predator_policy": 792.9394421820259}, "policy_reward_mean": {"prey_policy": 355.20888693112005, "predator_policy": 546.7075708881123}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1794.725509446995, 1863.3851119188275, 1644.391175627006, 1888.086901687725, 1765.2516809447573, 1884.2427141448334, 1884.5440191855164, 1757.7675366374979, 1720.0793225553282, 1694.4102974901418, 1700.3616776849528, 1695.9443700103309, 1807.0780365677724, 1802.482473131813, 1904.6879827991604, 1905.3970456681618, 1801.8398099998994, 1953.7653297222123, 1792.1328829341141, 1662.7404716113601, 1808.8345101360837, 1879.021518553754, 1827.5264022019555, 1925.377141615797, 1912.9433364621152, 1711.8948227022242, 1864.2433938205388, 1781.5999846969898, 1730.2481071609272, 1730.4665013810918, 1728.248485912533, 1765.6549584337981, 1759.1882017428368, 1915.120935178315, 1837.5370102588372, 1721.794765094856, 1860.5571041919002, 1797.8404629608438, 1904.310488039799, 1779.659682122285, 1884.6069523177293, 1781.748055244065, 1715.2711510961988, 1703.2181499512164, 1691.7803161383274, 1869.5454983514308, 1932.0193484527063, 1810.2978933247591, 1780.5239562622278, 1546.5295376914614, 1699.790400908386, 1959.9116844497582, 1850.3372477891762, 1688.172154106185, 1781.2271224564279, 1540.2864744726458, 1959.09901593306, 1656.472336469121, 1960.4927108762001, 1790.2573349427648, 1686.8658010342272, 1871.485047555164, 1832.843946960545, 1832.148574138317, 1755.656289368393, 1893.0559735852044, 1832.5173961562898, 1712.327577543672, 1697.4650718291973, 1775.8157372787027, 1709.2250899395765, 1848.034377733587, 1826.0576373701351, 1956.8112305133056, 1768.7118783409908, 1680.7201830655831, 1807.8299539003658, 1903.6206649801256, 1753.1235944902344, 1772.716691928203, 1710.1641508287307, 1806.2901040427862, 1747.1533740065108, 1875.9513663935413, 1821.5995657459246, 1859.0639932343302, 1916.5585397991322, 1909.3751114803206, 1970.8370316184141, 2003.6417270215413, 1813.085630399882, 1697.456885904052, 1807.095727046961, 1729.0220432639996, 1855.5348438548856, 1633.721994530837, 1805.2935516697091, 1953.6269645253635, 1968.7013205386263, 1815.115416559353], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [391.6055388988846, 470.546963975369, 390.7732519303824, 578.2275208039395, 346.8250901064687, 283.9937047073745, 609.1870009840457, 493.25519899885825, 515.3687588413059, 464.6163282095275, 568.5377720881806, 569.3524224953053, 392.965681532912, 608.559958360289, 599.6381862175843, 594.3194113361884, 364.4414753843975, 267.7730509124984, 405.52623420247374, 408.28912272240706, 464.91514576786733, 483.9482241364035, 332.9083011790671, 428.69221494876587, 339.1450246926334, 200.57679729292164, 518.5323646409738, 714.4662110804462, 481.00830987479577, 479.4226165897207, 474.7381096950475, 516.8009173051489, 376.36692722380985, 312.2239621904323, 440.09477570508085, 558.099676972262, 372.1992604685779, 280.0393233923256, 298.85431552067007, 427.53098558149986, 281.11160102602355, 467.67252575537253, 346.5665282123067, 368.7218865832283, 444.404141155683, 436.422932199249, 95.67895223254625, 321.41387043058853, 416.88136182256244, 281.3566180982028, 319.70989634830977, 248.00150925674203, 326.28777104153403, 194.3387666143732, 223.49577713072782, 237.53943786831715, 372.17427785791165, 474.5688801969867, 214.2228379029348, 143.97957393066744, 353.50667352817544, 164.1306049121999, 577.186486903859, 286.5571501317208, 433.5057536856099, 279.3716921532827, 313.82904341915037, 325.384271926893, 432.5818753274479, 366.0685754750347, 328.268061108079, 271.84304294636286, 280.4545012951103, 350.91113904754855, 554.4090603477706, 382.35871073182886, 300.96758250842515, 396.76672227978884, 257.3653690487036, 428.1753266736484, 474.43288114951923, 463.01599132457176, 224.16112391227378, 421.84735400829027, 291.17814562266375, 401.2040108446585, 237.91930826526337, 249.74205680171124, 307.0423012506763, 350.1220054503702, 411.65702964478515, 350.96839248359464, 452.7609849623876, 327.5488497459616, 369.67512959594234, 447.7870065119445, 183.35884691498148, 257.6848423467563, 248.19050983184462, 219.1240221161797, 478.2735497090408, 295.27626690426104, 386.6716660219511, 416.13207737016046, 296.7084974123082, 251.38219992529284, 225.31762596379866, 218.96552988862695, 268.20097803270187, 280.85634823019114, 396.5085744866869, 321.9773616282325, 414.4001901642057, 291.2244989921707, 169.88933407616267, 265.4588327762094, 332.4790093633004, 406.55961736970823, 182.14051947198016, 381.62846779375235, 279.4980325473527, 298.6063540711226, 315.48875273558446, 404.3729037698831, 307.31563649850625, 263.82497975101614, 300.8740735507811, 234.1300090170305, 83.19027371665135, 516.2661712656727, 305.89162296047107, 453.3331221491544, 206.8996191680405, 360.41656245465623, 467.4994202672512, 347.3708928202723, 371.13037803851745, 147.07960907885726, 393.6738897770905, 118.64236381545912, 411.0909054933079, 236.2170618079601, 218.81119443115028, 383.89690331177496, 452.66138963905047, 470.46928482416376, 540.3221255971608, 387.5515145610086, 292.6006573401541, 330.31928670511024, 106.2651514257107, 261.3315217877609, 331.9651730001926, 318.5781280787649, 267.91393357227554, 346.60216961756254, 452.5206494249316, 284.32983850129654, 297.94189727504283, 297.04513558216325, 316.1595278335509, 393.89248452644125, 244.68277030330285, 474.95316851879363, 307.64723492931955, 241.76952312890245, 406.3065773901712, 300.4451066763335, 284.81320777648375, 398.4095452360599, 340.41479123062004, 339.97829012759985, 290.58148690560756, 319.9739418643938, 442.29175751898765, 521.1269359779668, 473.9115795058747, 261.66447795150447, 521.4366365208933, 453.5505533757814, 297.78992442587105, 271.46544222643297, 263.3607143044894, 222.94815066737053, 434.52257966402703, 463.860900991209, 322.39919965764, 380.7980403126725, 352.5568022234813, 202.6547647667208, 192.93094567678236, 434.2934554657991, 394.6261936936989, 267.1578519629354, 330.8023109425242, 368.9900606107275, 314.1243278145348, 441.0947234106608, 456.25690054493384, 339.16704568613864], "policy_predator_policy_reward": [514.4738446398086, 418.09916193293265, 487.0266131024859, 407.35772608202035, 487.4717982902354, 526.1005825229275, 355.6113225966977, 430.03337910812377, 418.96121948580804, 366.30537440811634, 376.05393710962926, 370.2985824517177, 330.28980840881826, 552.7285708834925, 326.56999493094685, 237.23994415277946, 602.0116124103583, 485.8531838480747, 330.29642042302817, 550.2985201422327, 425.4754059718464, 326.022901808835, 587.9776760896065, 346.36617779289077, 650.4122718445877, 616.9439427376304, 329.36404220018704, 240.11985521020534, 495.585167258086, 448.67188907655657, 533.2854215705819, 380.57259709738486, 472.11730777720953, 641.1316128084471, 407.7513761730237, 547.8195008718454, 551.7217515077359, 588.1725475654752, 380.2263169081387, 556.1288536010505, 425.64026335345824, 634.4101200012303, 524.9489575144431, 638.7841462437744, 434.4970581809962, 512.2022706660267, 715.3448767706362, 792.9394421820259, 607.9319024363879, 606.7734541049659, 612.6307545214454, 531.5526625757303, 647.6682577414564, 695.9485984231743, 684.3530964194803, 636.2116732784649, 527.0543719370555, 356.4505771689751, 780.8964637854014, 591.3676257620882, 596.1008463758772, 614.510361096281, 545.8093429966829, 356.1019784015354, 566.0485925889077, 480.26216331503747, 599.1020567581052, 676.8055630741654, 538.1899340625448, 500.69662539381113, 555.8507981766612, 565.8328628637532, 616.4906135290456, 612.7008503201967, 414.5550761691543, 446.5176157120907, 615.0909100114891, 591.4852732400967, 490.2506647047011, 603.8683216952337, 460.46265687890826, 486.695422964731, 596.9136223593758, 538.8259549641264, 471.72269446712005, 551.1663001617557, 617.9116724953395, 597.6451123889002, 537.5128898319987, 497.1031196052822, 641.0975347238808, 465.8225414991711, 609.9212285494339, 541.7882851949245, 465.64201573170857, 527.1937414851658, 708.2787283750288, 631.2015386254635, 522.7730498174989, 556.4419559259381, 447.9498858870927, 478.2906984079915, 548.5270252437934, 608.5809158138541, 595.5649880822158, 706.6815623693589, 624.3410837671826, 619.5479144865773, 651.4768972957431, 580.6928988977927, 440.9893296771017, 380.811208680624, 618.8998946141303, 634.5744321625559, 667.8936544767606, 553.2305151399892, 615.0166264608341, 606.4374576823564, 676.2877985988995, 550.2005490781331, 662.96469030018, 445.7967241155709, 625.8297657134317, 525.7936253362665, 671.6168282277946, 590.0865024832309, 661.2834803885446, 635.8610111819614, 470.2399572435469, 685.9598871425223, 614.4692074661957, 519.36202100938, 681.5341084866674, 583.6671060469274, 569.4246934929346, 328.0325709632162, 682.3045269604505, 496.9505577513739, 582.3007254078614, 681.1987582782898, 550.3792761285227, 511.5378465097848, 678.2029771537383, 567.1233028369232, 412.60596562297263, 490.3209972839505, 504.27270064777605, 524.6648897073595, 672.1072732271106, 473.68466106861666, 682.6262106123544, 630.4972992397572, 651.0627793948873, 506.2238734265193, 633.5203423042792, 655.5842194860055, 505.01826826542003, 511.2548382985881, 587.4689433883673, 590.2607156826286, 521.4908777348655, 478.6212607338738, 538.6691427521044, 547.9850224685832, 689.0566677231095, 508.67994822517807, 592.4114221673319, 576.7882601597021, 621.8426351436418, 516.534177589741, 656.966308953355, 521.704602922754, 658.4064314544835, 647.5966795746491, 495.6480411686475, 450.30837681472013, 624.4480692570398, 610.8129049039949, 524.9969766183215, 503.65756050654744, 655.2209756346477, 588.6092881129291, 519.2170599762758, 691.9309609559168, 389.7342398098552, 518.978006581871, 471.9335216355391, 553.8912816581477, 717.8375952883464, 582.4856815763386, 455.9976021956286, 550.4999911926265, 570.7442301079216, 572.7652759051537, 575.0584578606231, 678.7761351114893, 596.8209052947228, 616.6613640187073, 500.82932064248416, 518.8621496857982]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4092760196602354, "mean_inference_ms": 3.754556098494975, "mean_action_processing_ms": 0.6222073512460347, "mean_env_wait_ms": 0.5356683376462291, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04620802402496338, "StateBufferConnector_ms": 0.01736581325531006, "ViewRequirementAgentConnector_ms": 0.9111009836196899}, "num_episodes": 18, "episode_return_max": 2003.6417270215413, "episode_return_min": 1540.2864744726458, "episode_return_mean": 1803.832915638465, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 87.03572399288988, "num_env_steps_trained_throughput_per_sec": 87.03572399288988, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 40151.005, "restore_workers_time_ms": 0.027, "training_step_time_ms": 40150.907, "sample_time_ms": 7660.342, "learn_time_ms": 32397.74, "learn_throughput": 123.465, "synch_weights_time_ms": 89.664}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "479e5_00000", "date": "2024-08-16_11-39-21", "timestamp": 1723788561, "time_this_iter_s": 46.03033208847046, "time_total_s": 754.4649376869202, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78501f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 754.4649376869202, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 56.072307692307696, "ram_util_percent": 82.26}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.59320200986017, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.669955277316785, "policy_loss": -0.0049199153841645625, "vf_loss": 9.67343627132436, "vf_explained_var": -0.02481527568171264, "kl": 0.00959287878312925, "entropy": 1.1098244709943337, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6254881427243904, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.65115051723662, "policy_loss": -0.0018696367738167286, "vf_loss": 9.651673796820262, "vf_explained_var": -0.017403964516977784, "kl": 0.005983785595913947, "entropy": 1.3949230424310795, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 2003.6417270215413, "episode_reward_min": 1147.257876741764, "episode_reward_mean": 1802.3542710559934, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 83.19027371665135, "predator_policy": 173.5843585198197}, "policy_reward_max": {"prey_policy": 577.186486903859, "predator_policy": 792.9394421820259}, "policy_reward_mean": {"prey_policy": 346.6304422565035, "predator_policy": 554.5466932714933}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1827.5264022019555, 1925.377141615797, 1912.9433364621152, 1711.8948227022242, 1864.2433938205388, 1781.5999846969898, 1730.2481071609272, 1730.4665013810918, 1728.248485912533, 1765.6549584337981, 1759.1882017428368, 1915.120935178315, 1837.5370102588372, 1721.794765094856, 1860.5571041919002, 1797.8404629608438, 1904.310488039799, 1779.659682122285, 1884.6069523177293, 1781.748055244065, 1715.2711510961988, 1703.2181499512164, 1691.7803161383274, 1869.5454983514308, 1932.0193484527063, 1810.2978933247591, 1780.5239562622278, 1546.5295376914614, 1699.790400908386, 1959.9116844497582, 1850.3372477891762, 1688.172154106185, 1781.2271224564279, 1540.2864744726458, 1959.09901593306, 1656.472336469121, 1960.4927108762001, 1790.2573349427648, 1686.8658010342272, 1871.485047555164, 1832.843946960545, 1832.148574138317, 1755.656289368393, 1893.0559735852044, 1832.5173961562898, 1712.327577543672, 1697.4650718291973, 1775.8157372787027, 1709.2250899395765, 1848.034377733587, 1826.0576373701351, 1956.8112305133056, 1768.7118783409908, 1680.7201830655831, 1807.8299539003658, 1903.6206649801256, 1753.1235944902344, 1772.716691928203, 1710.1641508287307, 1806.2901040427862, 1747.1533740065108, 1875.9513663935413, 1821.5995657459246, 1859.0639932343302, 1916.5585397991322, 1909.3751114803206, 1970.8370316184141, 2003.6417270215413, 1813.085630399882, 1697.456885904052, 1807.095727046961, 1729.0220432639996, 1855.5348438548856, 1633.721994530837, 1805.2935516697091, 1953.6269645253635, 1968.7013205386263, 1815.115416559353, 1894.9252182013793, 1946.2983328573498, 1661.4533054247327, 1948.734187923327, 1818.9802736456224, 1799.4357476205407, 1892.653890949763, 1558.9444678818127, 1816.565973614985, 1816.944001581008, 1840.465346395358, 1693.1586844437547, 1825.9926219893339, 1957.9571456830797, 1872.5528052853865, 1147.257876741764, 1783.5211858855207, 1788.4856274542817, 1888.4442458378207, 1911.9880296277927, 1856.984875946725, 1741.5620752197854], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [444.404141155683, 436.422932199249, 95.67895223254625, 321.41387043058853, 416.88136182256244, 281.3566180982028, 319.70989634830977, 248.00150925674203, 326.28777104153403, 194.3387666143732, 223.49577713072782, 237.53943786831715, 372.17427785791165, 474.5688801969867, 214.2228379029348, 143.97957393066744, 353.50667352817544, 164.1306049121999, 577.186486903859, 286.5571501317208, 433.5057536856099, 279.3716921532827, 313.82904341915037, 325.384271926893, 432.5818753274479, 366.0685754750347, 328.268061108079, 271.84304294636286, 280.4545012951103, 350.91113904754855, 554.4090603477706, 382.35871073182886, 300.96758250842515, 396.76672227978884, 257.3653690487036, 428.1753266736484, 474.43288114951923, 463.01599132457176, 224.16112391227378, 421.84735400829027, 291.17814562266375, 401.2040108446585, 237.91930826526337, 249.74205680171124, 307.0423012506763, 350.1220054503702, 411.65702964478515, 350.96839248359464, 452.7609849623876, 327.5488497459616, 369.67512959594234, 447.7870065119445, 183.35884691498148, 257.6848423467563, 248.19050983184462, 219.1240221161797, 478.2735497090408, 295.27626690426104, 386.6716660219511, 416.13207737016046, 296.7084974123082, 251.38219992529284, 225.31762596379866, 218.96552988862695, 268.20097803270187, 280.85634823019114, 396.5085744866869, 321.9773616282325, 414.4001901642057, 291.2244989921707, 169.88933407616267, 265.4588327762094, 332.4790093633004, 406.55961736970823, 182.14051947198016, 381.62846779375235, 279.4980325473527, 298.6063540711226, 315.48875273558446, 404.3729037698831, 307.31563649850625, 263.82497975101614, 300.8740735507811, 234.1300090170305, 83.19027371665135, 516.2661712656727, 305.89162296047107, 453.3331221491544, 206.8996191680405, 360.41656245465623, 467.4994202672512, 347.3708928202723, 371.13037803851745, 147.07960907885726, 393.6738897770905, 118.64236381545912, 411.0909054933079, 236.2170618079601, 218.81119443115028, 383.89690331177496, 452.66138963905047, 470.46928482416376, 540.3221255971608, 387.5515145610086, 292.6006573401541, 330.31928670511024, 106.2651514257107, 261.3315217877609, 331.9651730001926, 318.5781280787649, 267.91393357227554, 346.60216961756254, 452.5206494249316, 284.32983850129654, 297.94189727504283, 297.04513558216325, 316.1595278335509, 393.89248452644125, 244.68277030330285, 474.95316851879363, 307.64723492931955, 241.76952312890245, 406.3065773901712, 300.4451066763335, 284.81320777648375, 398.4095452360599, 340.41479123062004, 339.97829012759985, 290.58148690560756, 319.9739418643938, 442.29175751898765, 521.1269359779668, 473.9115795058747, 261.66447795150447, 521.4366365208933, 453.5505533757814, 297.78992442587105, 271.46544222643297, 263.3607143044894, 222.94815066737053, 434.52257966402703, 463.860900991209, 322.39919965764, 380.7980403126725, 352.5568022234813, 202.6547647667208, 192.93094567678236, 434.2934554657991, 394.6261936936989, 267.1578519629354, 330.8023109425242, 368.9900606107275, 314.1243278145348, 441.0947234106608, 456.25690054493384, 339.16704568613864, 402.9151821741851, 514.133306563466, 517.3925437608781, 475.68856555917046, 396.04884354545044, 422.8611336105331, 317.5005713351162, 486.81164583210483, 485.9769316939972, 382.1978183965416, 454.9137651284978, 293.0131702358145, 369.59336920703475, 329.1132448583784, 391.83771385153557, 413.6312283093228, 476.89323494873344, 265.63105677973016, 211.45380563727147, 488.6103816380309, 415.0342788283012, 503.28151860199193, 263.76558316672316, 230.93265191658094, 381.3645680302027, 242.93519713769388, 543.5908480526246, 394.8859910398673, 480.0967272598094, 331.0693108275909, 208.58654435923268, 361.69735455374206, 372.39692060203583, 479.53692194115393, 383.1797924310274, 386.20606278855723, 490.53565531072934, 486.64904338891023, 489.5847447943429, 489.85890867740653, 272.1500022903372, 389.6038662336906, 492.2932964396894, 387.29644188242474], "policy_predator_policy_reward": [434.4970581809962, 512.2022706660267, 715.3448767706362, 792.9394421820259, 607.9319024363879, 606.7734541049659, 612.6307545214454, 531.5526625757303, 647.6682577414564, 695.9485984231743, 684.3530964194803, 636.2116732784649, 527.0543719370555, 356.4505771689751, 780.8964637854014, 591.3676257620882, 596.1008463758772, 614.510361096281, 545.8093429966829, 356.1019784015354, 566.0485925889077, 480.26216331503747, 599.1020567581052, 676.8055630741654, 538.1899340625448, 500.69662539381113, 555.8507981766612, 565.8328628637532, 616.4906135290456, 612.7008503201967, 414.5550761691543, 446.5176157120907, 615.0909100114891, 591.4852732400967, 490.2506647047011, 603.8683216952337, 460.46265687890826, 486.695422964731, 596.9136223593758, 538.8259549641264, 471.72269446712005, 551.1663001617557, 617.9116724953395, 597.6451123889002, 537.5128898319987, 497.1031196052822, 641.0975347238808, 465.8225414991711, 609.9212285494339, 541.7882851949245, 465.64201573170857, 527.1937414851658, 708.2787283750288, 631.2015386254635, 522.7730498174989, 556.4419559259381, 447.9498858870927, 478.2906984079915, 548.5270252437934, 608.5809158138541, 595.5649880822158, 706.6815623693589, 624.3410837671826, 619.5479144865773, 651.4768972957431, 580.6928988977927, 440.9893296771017, 380.811208680624, 618.8998946141303, 634.5744321625559, 667.8936544767606, 553.2305151399892, 615.0166264608341, 606.4374576823564, 676.2877985988995, 550.2005490781331, 662.96469030018, 445.7967241155709, 625.8297657134317, 525.7936253362665, 671.6168282277946, 590.0865024832309, 661.2834803885446, 635.8610111819614, 470.2399572435469, 685.9598871425223, 614.4692074661957, 519.36202100938, 681.5341084866674, 583.6671060469274, 569.4246934929346, 328.0325709632162, 682.3045269604505, 496.9505577513739, 582.3007254078614, 681.1987582782898, 550.3792761285227, 511.5378465097848, 678.2029771537383, 567.1233028369232, 412.60596562297263, 490.3209972839505, 504.27270064777605, 524.6648897073595, 672.1072732271106, 473.68466106861666, 682.6262106123544, 630.4972992397572, 651.0627793948873, 506.2238734265193, 633.5203423042792, 655.5842194860055, 505.01826826542003, 511.2548382985881, 587.4689433883673, 590.2607156826286, 521.4908777348655, 478.6212607338738, 538.6691427521044, 547.9850224685832, 689.0566677231095, 508.67994822517807, 592.4114221673319, 576.7882601597021, 621.8426351436418, 516.534177589741, 656.966308953355, 521.704602922754, 658.4064314544835, 647.5966795746491, 495.6480411686475, 450.30837681472013, 624.4480692570398, 610.8129049039949, 524.9969766183215, 503.65756050654744, 655.2209756346477, 588.6092881129291, 519.2170599762758, 691.9309609559168, 389.7342398098552, 518.978006581871, 471.9335216355391, 553.8912816581477, 717.8375952883464, 582.4856815763386, 455.9976021956286, 550.4999911926265, 570.7442301079216, 572.7652759051537, 575.0584578606231, 678.7761351114893, 596.8209052947228, 616.6613640187073, 500.82932064248416, 518.8621496857982, 406.1477375977885, 571.7289918659363, 506.7899902296107, 446.42723330769144, 455.84138931893216, 386.70193894981594, 571.86883544002, 572.553135316081, 456.4544750777449, 494.35104847733857, 499.80756452714064, 551.7012477290889, 525.2057370102228, 668.7415398741252, 579.8911672011341, 173.5843585198197, 512.4476439672302, 561.5940379192936, 550.1816635951039, 566.6981507106024, 439.5368525486303, 482.61269641643423, 501.29770434843357, 697.1627450120163, 505.7134910135351, 695.9793658079011, 560.2485972713395, 459.23170931924795, 575.5790996965779, 485.80766750140754, 356.0350562538481, 220.938921574942, 461.7357633045727, 469.85158003775865, 444.68327009227335, 574.4165021424249, 423.2954313558922, 487.9641157822917, 499.1633282964996, 433.3810478595419, 588.4413593292512, 606.7896480934452, 422.78201786362524, 439.19031903404635]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.53104035308001, "mean_inference_ms": 4.079020198971971, "mean_action_processing_ms": 0.6713000609019505, "mean_env_wait_ms": 0.5856767804599382, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04660332202911377, "StateBufferConnector_ms": 0.017082571983337402, "ViewRequirementAgentConnector_ms": 0.913314700126648}, "num_episodes": 22, "episode_return_max": 2003.6417270215413, "episode_return_min": 1147.257876741764, "episode_return_mean": 1802.3542710559934, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 89.44544776274769, "num_env_steps_trained_throughput_per_sec": 89.44544776274769, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 43276.399, "restore_workers_time_ms": 0.03, "training_step_time_ms": 43276.295, "sample_time_ms": 8833.436, "learn_time_ms": 34342.53, "learn_throughput": 116.474, "synch_weights_time_ms": 97.118}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "479e5_00000", "date": "2024-08-16_11-40-06", "timestamp": 1723788606, "time_this_iter_s": 44.83684420585632, "time_total_s": 799.3017818927765, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7900ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 799.3017818927765, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 54.1015873015873, "ram_util_percent": 82.05555555555554}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5164996593717546, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.699845402329057, "policy_loss": -0.0021204035386699375, "vf_loss": 9.700933156190095, "vf_explained_var": 0.00564190805273712, "kl": 0.006884422890520761, "entropy": 1.0624996387138568, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7436676806243008, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.590410149286663, "policy_loss": -0.003887907209283815, "vf_loss": 9.59196199084085, "vf_explained_var": -0.010351071692017651, "kl": 0.010382461535241347, "entropy": 1.3812946364362404, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 2003.6417270215413, "episode_reward_min": 1147.257876741764, "episode_reward_mean": 1774.8633164675148, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 82.21779067394957, "predator_policy": 173.5843585198197}, "policy_reward_max": {"prey_policy": 577.5904184438643, "predator_policy": 717.8375952883464}, "policy_reward_mean": {"prey_policy": 357.8033370454111, "predator_policy": 529.6283211883465}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1869.5454983514308, 1932.0193484527063, 1810.2978933247591, 1780.5239562622278, 1546.5295376914614, 1699.790400908386, 1959.9116844497582, 1850.3372477891762, 1688.172154106185, 1781.2271224564279, 1540.2864744726458, 1959.09901593306, 1656.472336469121, 1960.4927108762001, 1790.2573349427648, 1686.8658010342272, 1871.485047555164, 1832.843946960545, 1832.148574138317, 1755.656289368393, 1893.0559735852044, 1832.5173961562898, 1712.327577543672, 1697.4650718291973, 1775.8157372787027, 1709.2250899395765, 1848.034377733587, 1826.0576373701351, 1956.8112305133056, 1768.7118783409908, 1680.7201830655831, 1807.8299539003658, 1903.6206649801256, 1753.1235944902344, 1772.716691928203, 1710.1641508287307, 1806.2901040427862, 1747.1533740065108, 1875.9513663935413, 1821.5995657459246, 1859.0639932343302, 1916.5585397991322, 1909.3751114803206, 1970.8370316184141, 2003.6417270215413, 1813.085630399882, 1697.456885904052, 1807.095727046961, 1729.0220432639996, 1855.5348438548856, 1633.721994530837, 1805.2935516697091, 1953.6269645253635, 1968.7013205386263, 1815.115416559353, 1894.9252182013793, 1946.2983328573498, 1661.4533054247327, 1948.734187923327, 1818.9802736456224, 1799.4357476205407, 1892.653890949763, 1558.9444678818127, 1816.565973614985, 1816.944001581008, 1840.465346395358, 1693.1586844437547, 1825.9926219893339, 1957.9571456830797, 1872.5528052853865, 1147.257876741764, 1783.5211858855207, 1788.4856274542817, 1888.4442458378207, 1911.9880296277927, 1856.984875946725, 1741.5620752197854, 1694.6647559301562, 1633.3764760438285, 1879.0899771863378, 1520.788567330869, 1468.23624642292, 1720.3365057192934, 1907.5029740681384, 1878.0075407966135, 1380.6164324252961, 1524.9892138619214, 1760.8089389063796, 1624.5486580449422, 1768.4924563275372, 1873.4077106212906, 1837.6606567901931, 1880.242460694354, 1374.5846360831415, 1527.4218346174614, 1713.7078347871627, 1838.1017023926104, 1739.2342738224222, 1430.7280496756402, 1605.1930473288305], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [411.65702964478515, 350.96839248359464, 452.7609849623876, 327.5488497459616, 369.67512959594234, 447.7870065119445, 183.35884691498148, 257.6848423467563, 248.19050983184462, 219.1240221161797, 478.2735497090408, 295.27626690426104, 386.6716660219511, 416.13207737016046, 296.7084974123082, 251.38219992529284, 225.31762596379866, 218.96552988862695, 268.20097803270187, 280.85634823019114, 396.5085744866869, 321.9773616282325, 414.4001901642057, 291.2244989921707, 169.88933407616267, 265.4588327762094, 332.4790093633004, 406.55961736970823, 182.14051947198016, 381.62846779375235, 279.4980325473527, 298.6063540711226, 315.48875273558446, 404.3729037698831, 307.31563649850625, 263.82497975101614, 300.8740735507811, 234.1300090170305, 83.19027371665135, 516.2661712656727, 305.89162296047107, 453.3331221491544, 206.8996191680405, 360.41656245465623, 467.4994202672512, 347.3708928202723, 371.13037803851745, 147.07960907885726, 393.6738897770905, 118.64236381545912, 411.0909054933079, 236.2170618079601, 218.81119443115028, 383.89690331177496, 452.66138963905047, 470.46928482416376, 540.3221255971608, 387.5515145610086, 292.6006573401541, 330.31928670511024, 106.2651514257107, 261.3315217877609, 331.9651730001926, 318.5781280787649, 267.91393357227554, 346.60216961756254, 452.5206494249316, 284.32983850129654, 297.94189727504283, 297.04513558216325, 316.1595278335509, 393.89248452644125, 244.68277030330285, 474.95316851879363, 307.64723492931955, 241.76952312890245, 406.3065773901712, 300.4451066763335, 284.81320777648375, 398.4095452360599, 340.41479123062004, 339.97829012759985, 290.58148690560756, 319.9739418643938, 442.29175751898765, 521.1269359779668, 473.9115795058747, 261.66447795150447, 521.4366365208933, 453.5505533757814, 297.78992442587105, 271.46544222643297, 263.3607143044894, 222.94815066737053, 434.52257966402703, 463.860900991209, 322.39919965764, 380.7980403126725, 352.5568022234813, 202.6547647667208, 192.93094567678236, 434.2934554657991, 394.6261936936989, 267.1578519629354, 330.8023109425242, 368.9900606107275, 314.1243278145348, 441.0947234106608, 456.25690054493384, 339.16704568613864, 402.9151821741851, 514.133306563466, 517.3925437608781, 475.68856555917046, 396.04884354545044, 422.8611336105331, 317.5005713351162, 486.81164583210483, 485.9769316939972, 382.1978183965416, 454.9137651284978, 293.0131702358145, 369.59336920703475, 329.1132448583784, 391.83771385153557, 413.6312283093228, 476.89323494873344, 265.63105677973016, 211.45380563727147, 488.6103816380309, 415.0342788283012, 503.28151860199193, 263.76558316672316, 230.93265191658094, 381.3645680302027, 242.93519713769388, 543.5908480526246, 394.8859910398673, 480.0967272598094, 331.0693108275909, 208.58654435923268, 361.69735455374206, 372.39692060203583, 479.53692194115393, 383.1797924310274, 386.20606278855723, 490.53565531072934, 486.64904338891023, 489.5847447943429, 489.85890867740653, 272.1500022903372, 389.6038662336906, 492.2932964396894, 387.29644188242474, 361.58003110187656, 357.6653183799079, 334.81664471546793, 372.3512719545135, 450.2647507952758, 424.5447346790539, 311.9896351860421, 316.58717235235605, 396.3658533853686, 359.79400268453196, 390.8732340606926, 493.2528057381585, 377.44470176085844, 501.5166147265729, 353.5618373311597, 436.92696207203414, 340.5947419696965, 418.4511248308334, 421.08295684153137, 466.6105484322389, 543.4341432620167, 527.8421511500297, 460.3475511593481, 577.5904184438643, 444.420159570537, 436.5714119801082, 402.23504534225344, 382.620183652847, 401.7929948657736, 505.04675573308543, 311.22369979366607, 482.37108854885037, 332.24007916678437, 164.0214433927012, 213.11899867560197, 207.28305882258692, 417.8819181412276, 509.4951271718984, 232.60616691521926, 443.8983233840634, 405.61779057680826, 365.45334131463267, 82.21779067394957, 244.87090140626395, 307.48204517007986, 201.4048526371208], "policy_predator_policy_reward": [641.0975347238808, 465.8225414991711, 609.9212285494339, 541.7882851949245, 465.64201573170857, 527.1937414851658, 708.2787283750288, 631.2015386254635, 522.7730498174989, 556.4419559259381, 447.9498858870927, 478.2906984079915, 548.5270252437934, 608.5809158138541, 595.5649880822158, 706.6815623693589, 624.3410837671826, 619.5479144865773, 651.4768972957431, 580.6928988977927, 440.9893296771017, 380.811208680624, 618.8998946141303, 634.5744321625559, 667.8936544767606, 553.2305151399892, 615.0166264608341, 606.4374576823564, 676.2877985988995, 550.2005490781331, 662.96469030018, 445.7967241155709, 625.8297657134317, 525.7936253362665, 671.6168282277946, 590.0865024832309, 661.2834803885446, 635.8610111819614, 470.2399572435469, 685.9598871425223, 614.4692074661957, 519.36202100938, 681.5341084866674, 583.6671060469274, 569.4246934929346, 328.0325709632162, 682.3045269604505, 496.9505577513739, 582.3007254078614, 681.1987582782898, 550.3792761285227, 511.5378465097848, 678.2029771537383, 567.1233028369232, 412.60596562297263, 490.3209972839505, 504.27270064777605, 524.6648897073595, 672.1072732271106, 473.68466106861666, 682.6262106123544, 630.4972992397572, 651.0627793948873, 506.2238734265193, 633.5203423042792, 655.5842194860055, 505.01826826542003, 511.2548382985881, 587.4689433883673, 590.2607156826286, 521.4908777348655, 478.6212607338738, 538.6691427521044, 547.9850224685832, 689.0566677231095, 508.67994822517807, 592.4114221673319, 576.7882601597021, 621.8426351436418, 516.534177589741, 656.966308953355, 521.704602922754, 658.4064314544835, 647.5966795746491, 495.6480411686475, 450.30837681472013, 624.4480692570398, 610.8129049039949, 524.9969766183215, 503.65756050654744, 655.2209756346477, 588.6092881129291, 519.2170599762758, 691.9309609559168, 389.7342398098552, 518.978006581871, 471.9335216355391, 553.8912816581477, 717.8375952883464, 582.4856815763386, 455.9976021956286, 550.4999911926265, 570.7442301079216, 572.7652759051537, 575.0584578606231, 678.7761351114893, 596.8209052947228, 616.6613640187073, 500.82932064248416, 518.8621496857982, 406.1477375977885, 571.7289918659363, 506.7899902296107, 446.42723330769144, 455.84138931893216, 386.70193894981594, 571.86883544002, 572.553135316081, 456.4544750777449, 494.35104847733857, 499.80756452714064, 551.7012477290889, 525.2057370102228, 668.7415398741252, 579.8911672011341, 173.5843585198197, 512.4476439672302, 561.5940379192936, 550.1816635951039, 566.6981507106024, 439.5368525486303, 482.61269641643423, 501.29770434843357, 697.1627450120163, 505.7134910135351, 695.9793658079011, 560.2485972713395, 459.23170931924795, 575.5790996965779, 485.80766750140754, 356.0350562538481, 220.938921574942, 461.7357633045727, 469.85158003775865, 444.68327009227335, 574.4165021424249, 423.2954313558922, 487.9641157822917, 499.1633282964996, 433.3810478595419, 588.4413593292512, 606.7896480934452, 422.78201786362524, 439.19031903404635, 425.1404378944044, 550.2789685539677, 488.12903523254573, 438.0795241412999, 486.66145397239865, 517.6190377396109, 349.5392485618797, 542.672511230595, 336.50280171771993, 375.5735886352983, 433.693006504268, 402.51745941617594, 466.5621773936998, 561.9794801870089, 518.0861347570878, 569.4326066363309, 303.39522656535576, 318.17533905941184, 273.20752127431643, 364.08818731383496, 256.04025240455786, 433.49239208977457, 323.5743436626971, 263.03634477903336, 477.0744943524173, 410.4263904244758, 550.5232203296594, 538.0292612965302, 444.3053118021471, 486.51559438918457, 491.0318568884809, 595.615815463358, 390.0906984604627, 488.2324150631953, 589.3228184542019, 517.6969586650713, 374.4393861594346, 411.8914033146003, 514.337568826519, 647.2596432668088, 539.5237912515539, 428.63935067942816, 550.5803243746036, 553.0590332208244, 556.3683919133407, 539.9377576082895]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.6639635374033852, "mean_inference_ms": 4.441824376186595, "mean_action_processing_ms": 0.7272080091354767, "mean_env_wait_ms": 0.6374114349035174, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0462946891784668, "StateBufferConnector_ms": 0.03814733028411865, "ViewRequirementAgentConnector_ms": 0.9188953638076782}, "num_episodes": 23, "episode_return_max": 2003.6417270215413, "episode_return_min": 1147.257876741764, "episode_return_mean": 1774.8633164675148, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 90.35034398685544, "num_env_steps_trained_throughput_per_sec": 90.35034398685544, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 45295.289, "restore_workers_time_ms": 0.031, "training_step_time_ms": 45295.182, "sample_time_ms": 9741.432, "learn_time_ms": 35454.982, "learn_throughput": 112.819, "synch_weights_time_ms": 95.504}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "479e5_00000", "date": "2024-08-16_11-40-50", "timestamp": 1723788650, "time_this_iter_s": 44.36445903778076, "time_total_s": 843.6662409305573, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78f8280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 843.6662409305573, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 53.935483870967744, "ram_util_percent": 81.841935483871}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5528011678703248, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.707236619475026, "policy_loss": -0.0032287837585148514, "vf_loss": 9.709292949696698, "vf_explained_var": 5.474216723568225e-05, "kl": 0.007816504440303244, "entropy": 1.0708109765456466, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6933470451642596, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.548205412001836, "policy_loss": -0.0017347304623514888, "vf_loss": 9.548465578392069, "vf_explained_var": -0.029435343748677976, "kl": 0.006553613609429329, "entropy": 1.407522137770577, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 2003.6417270215413, "episode_reward_min": 1147.257876741764, "episode_reward_mean": 1738.5382426139417, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 79.41415520043411, "predator_policy": 173.5843585198197}, "policy_reward_max": {"prey_policy": 611.8501742536305, "predator_policy": 724.4895676069473}, "policy_reward_mean": {"prey_policy": 361.4064056892012, "predator_policy": 507.8627156177696}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1832.148574138317, 1755.656289368393, 1893.0559735852044, 1832.5173961562898, 1712.327577543672, 1697.4650718291973, 1775.8157372787027, 1709.2250899395765, 1848.034377733587, 1826.0576373701351, 1956.8112305133056, 1768.7118783409908, 1680.7201830655831, 1807.8299539003658, 1903.6206649801256, 1753.1235944902344, 1772.716691928203, 1710.1641508287307, 1806.2901040427862, 1747.1533740065108, 1875.9513663935413, 1821.5995657459246, 1859.0639932343302, 1916.5585397991322, 1909.3751114803206, 1970.8370316184141, 2003.6417270215413, 1813.085630399882, 1697.456885904052, 1807.095727046961, 1729.0220432639996, 1855.5348438548856, 1633.721994530837, 1805.2935516697091, 1953.6269645253635, 1968.7013205386263, 1815.115416559353, 1894.9252182013793, 1946.2983328573498, 1661.4533054247327, 1948.734187923327, 1818.9802736456224, 1799.4357476205407, 1892.653890949763, 1558.9444678818127, 1816.565973614985, 1816.944001581008, 1840.465346395358, 1693.1586844437547, 1825.9926219893339, 1957.9571456830797, 1872.5528052853865, 1147.257876741764, 1783.5211858855207, 1788.4856274542817, 1888.4442458378207, 1911.9880296277927, 1856.984875946725, 1741.5620752197854, 1694.6647559301562, 1633.3764760438285, 1879.0899771863378, 1520.788567330869, 1468.23624642292, 1720.3365057192934, 1907.5029740681384, 1878.0075407966135, 1380.6164324252961, 1524.9892138619214, 1760.8089389063796, 1624.5486580449422, 1768.4924563275372, 1873.4077106212906, 1837.6606567901931, 1880.242460694354, 1374.5846360831415, 1527.4218346174614, 1713.7078347871627, 1838.1017023926104, 1739.2342738224222, 1430.7280496756402, 1605.1930473288305, 1357.7974589122227, 1541.5613664623402, 1302.6954024616234, 1804.6103438547975, 1663.002085957266, 1537.3433003990967, 1707.815977629405, 1360.6660747534736, 1781.1375051106477, 1719.6606283206154, 1802.6271244255158, 1479.6266635806267, 1626.7858816753765, 1753.6016861313017, 1789.1604714896491, 1396.7021315818974, 1733.4392934266252, 1225.4167305064288], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [300.8740735507811, 234.1300090170305, 83.19027371665135, 516.2661712656727, 305.89162296047107, 453.3331221491544, 206.8996191680405, 360.41656245465623, 467.4994202672512, 347.3708928202723, 371.13037803851745, 147.07960907885726, 393.6738897770905, 118.64236381545912, 411.0909054933079, 236.2170618079601, 218.81119443115028, 383.89690331177496, 452.66138963905047, 470.46928482416376, 540.3221255971608, 387.5515145610086, 292.6006573401541, 330.31928670511024, 106.2651514257107, 261.3315217877609, 331.9651730001926, 318.5781280787649, 267.91393357227554, 346.60216961756254, 452.5206494249316, 284.32983850129654, 297.94189727504283, 297.04513558216325, 316.1595278335509, 393.89248452644125, 244.68277030330285, 474.95316851879363, 307.64723492931955, 241.76952312890245, 406.3065773901712, 300.4451066763335, 284.81320777648375, 398.4095452360599, 340.41479123062004, 339.97829012759985, 290.58148690560756, 319.9739418643938, 442.29175751898765, 521.1269359779668, 473.9115795058747, 261.66447795150447, 521.4366365208933, 453.5505533757814, 297.78992442587105, 271.46544222643297, 263.3607143044894, 222.94815066737053, 434.52257966402703, 463.860900991209, 322.39919965764, 380.7980403126725, 352.5568022234813, 202.6547647667208, 192.93094567678236, 434.2934554657991, 394.6261936936989, 267.1578519629354, 330.8023109425242, 368.9900606107275, 314.1243278145348, 441.0947234106608, 456.25690054493384, 339.16704568613864, 402.9151821741851, 514.133306563466, 517.3925437608781, 475.68856555917046, 396.04884354545044, 422.8611336105331, 317.5005713351162, 486.81164583210483, 485.9769316939972, 382.1978183965416, 454.9137651284978, 293.0131702358145, 369.59336920703475, 329.1132448583784, 391.83771385153557, 413.6312283093228, 476.89323494873344, 265.63105677973016, 211.45380563727147, 488.6103816380309, 415.0342788283012, 503.28151860199193, 263.76558316672316, 230.93265191658094, 381.3645680302027, 242.93519713769388, 543.5908480526246, 394.8859910398673, 480.0967272598094, 331.0693108275909, 208.58654435923268, 361.69735455374206, 372.39692060203583, 479.53692194115393, 383.1797924310274, 386.20606278855723, 490.53565531072934, 486.64904338891023, 489.5847447943429, 489.85890867740653, 272.1500022903372, 389.6038662336906, 492.2932964396894, 387.29644188242474, 361.58003110187656, 357.6653183799079, 334.81664471546793, 372.3512719545135, 450.2647507952758, 424.5447346790539, 311.9896351860421, 316.58717235235605, 396.3658533853686, 359.79400268453196, 390.8732340606926, 493.2528057381585, 377.44470176085844, 501.5166147265729, 353.5618373311597, 436.92696207203414, 340.5947419696965, 418.4511248308334, 421.08295684153137, 466.6105484322389, 543.4341432620167, 527.8421511500297, 460.3475511593481, 577.5904184438643, 444.420159570537, 436.5714119801082, 402.23504534225344, 382.620183652847, 401.7929948657736, 505.04675573308543, 311.22369979366607, 482.37108854885037, 332.24007916678437, 164.0214433927012, 213.11899867560197, 207.28305882258692, 417.8819181412276, 509.4951271718984, 232.60616691521926, 443.8983233840634, 405.61779057680826, 365.45334131463267, 82.21779067394957, 244.87090140626395, 307.48204517007986, 201.4048526371208, 235.9387534977686, 133.3622189792908, 611.8501742536305, 122.95400443487561, 286.397513105295, 356.71793000941125, 304.63834655429855, 322.86222997994776, 186.04045248737054, 315.84192692067626, 246.33098314717216, 274.7768698373167, 197.38866527006334, 587.9237375968725, 221.53469455622724, 507.7245986005795, 408.1717214800862, 449.08562274834986, 366.1143968337139, 415.2775559162093, 375.9092523604221, 79.41415520043411, 239.14315934189216, 215.8453402857535, 432.13134977660496, 413.6829741805211, 307.1300982805004, 463.417507157603, 544.5020474645494, 414.8705614751986, 348.5411566047292, 342.03628426916003, 245.25907524231124, 324.5466172607397, 321.53393288022244, 519.6312398768142], "policy_predator_policy_reward": [661.2834803885446, 635.8610111819614, 470.2399572435469, 685.9598871425223, 614.4692074661957, 519.36202100938, 681.5341084866674, 583.6671060469274, 569.4246934929346, 328.0325709632162, 682.3045269604505, 496.9505577513739, 582.3007254078614, 681.1987582782898, 550.3792761285227, 511.5378465097848, 678.2029771537383, 567.1233028369232, 412.60596562297263, 490.3209972839505, 504.27270064777605, 524.6648897073595, 672.1072732271106, 473.68466106861666, 682.6262106123544, 630.4972992397572, 651.0627793948873, 506.2238734265193, 633.5203423042792, 655.5842194860055, 505.01826826542003, 511.2548382985881, 587.4689433883673, 590.2607156826286, 521.4908777348655, 478.6212607338738, 538.6691427521044, 547.9850224685832, 689.0566677231095, 508.67994822517807, 592.4114221673319, 576.7882601597021, 621.8426351436418, 516.534177589741, 656.966308953355, 521.704602922754, 658.4064314544835, 647.5966795746491, 495.6480411686475, 450.30837681472013, 624.4480692570398, 610.8129049039949, 524.9969766183215, 503.65756050654744, 655.2209756346477, 588.6092881129291, 519.2170599762758, 691.9309609559168, 389.7342398098552, 518.978006581871, 471.9335216355391, 553.8912816581477, 717.8375952883464, 582.4856815763386, 455.9976021956286, 550.4999911926265, 570.7442301079216, 572.7652759051537, 575.0584578606231, 678.7761351114893, 596.8209052947228, 616.6613640187073, 500.82932064248416, 518.8621496857982, 406.1477375977885, 571.7289918659363, 506.7899902296107, 446.42723330769144, 455.84138931893216, 386.70193894981594, 571.86883544002, 572.553135316081, 456.4544750777449, 494.35104847733857, 499.80756452714064, 551.7012477290889, 525.2057370102228, 668.7415398741252, 579.8911672011341, 173.5843585198197, 512.4476439672302, 561.5940379192936, 550.1816635951039, 566.6981507106024, 439.5368525486303, 482.61269641643423, 501.29770434843357, 697.1627450120163, 505.7134910135351, 695.9793658079011, 560.2485972713395, 459.23170931924795, 575.5790996965779, 485.80766750140754, 356.0350562538481, 220.938921574942, 461.7357633045727, 469.85158003775865, 444.68327009227335, 574.4165021424249, 423.2954313558922, 487.9641157822917, 499.1633282964996, 433.3810478595419, 588.4413593292512, 606.7896480934452, 422.78201786362524, 439.19031903404635, 425.1404378944044, 550.2789685539677, 488.12903523254573, 438.0795241412999, 486.66145397239865, 517.6190377396109, 349.5392485618797, 542.672511230595, 336.50280171771993, 375.5735886352983, 433.693006504268, 402.51745941617594, 466.5621773936998, 561.9794801870089, 518.0861347570878, 569.4326066363309, 303.39522656535576, 318.17533905941184, 273.20752127431643, 364.08818731383496, 256.04025240455786, 433.49239208977457, 323.5743436626971, 263.03634477903336, 477.0744943524173, 410.4263904244758, 550.5232203296594, 538.0292612965302, 444.3053118021471, 486.51559438918457, 491.0318568884809, 595.615815463358, 390.0906984604627, 488.2324150631953, 589.3228184542019, 517.6969586650713, 374.4393861594346, 411.8914033146003, 514.337568826519, 647.2596432668088, 539.5237912515539, 428.63935067942816, 550.5803243746036, 553.0590332208244, 556.3683919133407, 539.9377576082895, 547.1907674702601, 441.3057189649028, 273.03743547827787, 533.7197522955555, 437.3122293432511, 222.26773000366606, 539.5351728173321, 637.5745945032187, 580.9427425868232, 580.176963962395, 407.2097728706749, 609.0256745439341, 428.3517593066573, 494.1518154558141, 411.46578195467214, 219.94099964199538, 370.0957455030294, 553.7844153791823, 369.91648051939933, 568.3521950512926, 724.4895676069473, 622.8141492577126, 497.7435287994093, 526.894635153573, 472.0638644860468, 308.9076932322034, 406.30676769667105, 576.7473129965266, 392.1337328788569, 437.65412967104373, 250.59018806356204, 455.53450264444643, 561.3420101454025, 602.2915907781704, 183.61664111356376, 200.63491663582846]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.7677070358901572, "mean_inference_ms": 4.720722362639347, "mean_action_processing_ms": 0.7704804372483476, "mean_env_wait_ms": 0.6778511661556184, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.059946298599243164, "StateBufferConnector_ms": 0.04199254512786865, "ViewRequirementAgentConnector_ms": 1.0125885009765625}, "num_episodes": 18, "episode_return_max": 2003.6417270215413, "episode_return_min": 1147.257876741764, "episode_return_mean": 1738.5382426139417, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 89.35322973761187, "num_env_steps_trained_throughput_per_sec": 89.35322973761187, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 44581.71, "restore_workers_time_ms": 0.031, "training_step_time_ms": 44581.605, "sample_time_ms": 9490.688, "learn_time_ms": 34973.112, "learn_throughput": 114.374, "synch_weights_time_ms": 114.705}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "479e5_00000", "date": "2024-08-16_11-41-35", "timestamp": 1723788695, "time_this_iter_s": 44.80023813247681, "time_total_s": 888.4664790630341, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78e5e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 888.4664790630341, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 54.20317460317461, "ram_util_percent": 81.97619047619047}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.403645948537443, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.77930977685111, "policy_loss": -0.0035445357313152975, "vf_loss": 9.781946144406758, "vf_explained_var": 0.004807683242061151, "kl": 0.0060544464513318606, "entropy": 1.0217190122793591, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7661468035802639, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.472154890292536, "policy_loss": -0.004041547674153532, "vf_loss": 9.474643044749264, "vf_explained_var": -0.031822392202558974, "kl": 0.0069038715564164865, "entropy": 1.4293834743676361, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 2003.6417270215413, "episode_reward_min": 984.7592091675908, "episode_reward_mean": 1701.5808234281985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 37.77529408991452, "predator_policy": 173.5843585198197}, "policy_reward_max": {"prey_policy": 611.8501742536305, "predator_policy": 724.4895676069473}, "policy_reward_mean": {"prey_policy": 357.40172110304746, "predator_policy": 493.388690611052}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1806.2901040427862, 1747.1533740065108, 1875.9513663935413, 1821.5995657459246, 1859.0639932343302, 1916.5585397991322, 1909.3751114803206, 1970.8370316184141, 2003.6417270215413, 1813.085630399882, 1697.456885904052, 1807.095727046961, 1729.0220432639996, 1855.5348438548856, 1633.721994530837, 1805.2935516697091, 1953.6269645253635, 1968.7013205386263, 1815.115416559353, 1894.9252182013793, 1946.2983328573498, 1661.4533054247327, 1948.734187923327, 1818.9802736456224, 1799.4357476205407, 1892.653890949763, 1558.9444678818127, 1816.565973614985, 1816.944001581008, 1840.465346395358, 1693.1586844437547, 1825.9926219893339, 1957.9571456830797, 1872.5528052853865, 1147.257876741764, 1783.5211858855207, 1788.4856274542817, 1888.4442458378207, 1911.9880296277927, 1856.984875946725, 1741.5620752197854, 1694.6647559301562, 1633.3764760438285, 1879.0899771863378, 1520.788567330869, 1468.23624642292, 1720.3365057192934, 1907.5029740681384, 1878.0075407966135, 1380.6164324252961, 1524.9892138619214, 1760.8089389063796, 1624.5486580449422, 1768.4924563275372, 1873.4077106212906, 1837.6606567901931, 1880.242460694354, 1374.5846360831415, 1527.4218346174614, 1713.7078347871627, 1838.1017023926104, 1739.2342738224222, 1430.7280496756402, 1605.1930473288305, 1357.7974589122227, 1541.5613664623402, 1302.6954024616234, 1804.6103438547975, 1663.002085957266, 1537.3433003990967, 1707.815977629405, 1360.6660747534736, 1781.1375051106477, 1719.6606283206154, 1802.6271244255158, 1479.6266635806267, 1626.7858816753765, 1753.6016861313017, 1789.1604714896491, 1396.7021315818974, 1733.4392934266252, 1225.4167305064288, 1634.7443678834609, 1048.9225551122977, 1705.2456386759923, 1693.374017309755, 1771.2680366882516, 984.7592091675908, 1983.635916499855, 1615.8972664968771, 1629.8129048651947, 1859.2358418496706, 1623.476962428761, 1672.72244343833, 1658.1412461271857, 1787.983803131379, 1754.9070561516296, 1493.7862112980918, 1353.640532731578, 1268.7061445604381], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [244.68277030330285, 474.95316851879363, 307.64723492931955, 241.76952312890245, 406.3065773901712, 300.4451066763335, 284.81320777648375, 398.4095452360599, 340.41479123062004, 339.97829012759985, 290.58148690560756, 319.9739418643938, 442.29175751898765, 521.1269359779668, 473.9115795058747, 261.66447795150447, 521.4366365208933, 453.5505533757814, 297.78992442587105, 271.46544222643297, 263.3607143044894, 222.94815066737053, 434.52257966402703, 463.860900991209, 322.39919965764, 380.7980403126725, 352.5568022234813, 202.6547647667208, 192.93094567678236, 434.2934554657991, 394.6261936936989, 267.1578519629354, 330.8023109425242, 368.9900606107275, 314.1243278145348, 441.0947234106608, 456.25690054493384, 339.16704568613864, 402.9151821741851, 514.133306563466, 517.3925437608781, 475.68856555917046, 396.04884354545044, 422.8611336105331, 317.5005713351162, 486.81164583210483, 485.9769316939972, 382.1978183965416, 454.9137651284978, 293.0131702358145, 369.59336920703475, 329.1132448583784, 391.83771385153557, 413.6312283093228, 476.89323494873344, 265.63105677973016, 211.45380563727147, 488.6103816380309, 415.0342788283012, 503.28151860199193, 263.76558316672316, 230.93265191658094, 381.3645680302027, 242.93519713769388, 543.5908480526246, 394.8859910398673, 480.0967272598094, 331.0693108275909, 208.58654435923268, 361.69735455374206, 372.39692060203583, 479.53692194115393, 383.1797924310274, 386.20606278855723, 490.53565531072934, 486.64904338891023, 489.5847447943429, 489.85890867740653, 272.1500022903372, 389.6038662336906, 492.2932964396894, 387.29644188242474, 361.58003110187656, 357.6653183799079, 334.81664471546793, 372.3512719545135, 450.2647507952758, 424.5447346790539, 311.9896351860421, 316.58717235235605, 396.3658533853686, 359.79400268453196, 390.8732340606926, 493.2528057381585, 377.44470176085844, 501.5166147265729, 353.5618373311597, 436.92696207203414, 340.5947419696965, 418.4511248308334, 421.08295684153137, 466.6105484322389, 543.4341432620167, 527.8421511500297, 460.3475511593481, 577.5904184438643, 444.420159570537, 436.5714119801082, 402.23504534225344, 382.620183652847, 401.7929948657736, 505.04675573308543, 311.22369979366607, 482.37108854885037, 332.24007916678437, 164.0214433927012, 213.11899867560197, 207.28305882258692, 417.8819181412276, 509.4951271718984, 232.60616691521926, 443.8983233840634, 405.61779057680826, 365.45334131463267, 82.21779067394957, 244.87090140626395, 307.48204517007986, 201.4048526371208, 235.9387534977686, 133.3622189792908, 611.8501742536305, 122.95400443487561, 286.397513105295, 356.71793000941125, 304.63834655429855, 322.86222997994776, 186.04045248737054, 315.84192692067626, 246.33098314717216, 274.7768698373167, 197.38866527006334, 587.9237375968725, 221.53469455622724, 507.7245986005795, 408.1717214800862, 449.08562274834986, 366.1143968337139, 415.2775559162093, 375.9092523604221, 79.41415520043411, 239.14315934189216, 215.8453402857535, 432.13134977660496, 413.6829741805211, 307.1300982805004, 463.417507157603, 544.5020474645494, 414.8705614751986, 348.5411566047292, 342.03628426916003, 245.25907524231124, 324.5466172607397, 321.53393288022244, 519.6312398768142, 498.92819958863817, 520.6335570713953, 257.61341264657227, 242.02785977048103, 139.38021495088753, 375.2098651593378, 401.68789818474863, 162.82519464037543, 248.08992510349316, 258.44145271433564, 37.77529408991452, 246.58911472016533, 469.28644168226225, 177.7040828897826, 358.49255261333536, 271.77538108979945, 268.07905616252026, 338.66855535271316, 63.99830874743509, 431.28738581685406, 348.32895430461184, 196.83338602629487, 359.51205381464325, 338.4382014556796, 403.3485702917089, 384.9455858861775, 326.12623517349937, 351.96774267737095, 292.4219136803109, 289.32921370065935, 412.45009236849137, 238.12949285122022, 391.5403721053024, 364.45921130782807, 249.17139790111491, 188.45084864571874], "policy_predator_policy_reward": [538.6691427521044, 547.9850224685832, 689.0566677231095, 508.67994822517807, 592.4114221673319, 576.7882601597021, 621.8426351436418, 516.534177589741, 656.966308953355, 521.704602922754, 658.4064314544835, 647.5966795746491, 495.6480411686475, 450.30837681472013, 624.4480692570398, 610.8129049039949, 524.9969766183215, 503.65756050654744, 655.2209756346477, 588.6092881129291, 519.2170599762758, 691.9309609559168, 389.7342398098552, 518.978006581871, 471.9335216355391, 553.8912816581477, 717.8375952883464, 582.4856815763386, 455.9976021956286, 550.4999911926265, 570.7442301079216, 572.7652759051537, 575.0584578606231, 678.7761351114893, 596.8209052947228, 616.6613640187073, 500.82932064248416, 518.8621496857982, 406.1477375977885, 571.7289918659363, 506.7899902296107, 446.42723330769144, 455.84138931893216, 386.70193894981594, 571.86883544002, 572.553135316081, 456.4544750777449, 494.35104847733857, 499.80756452714064, 551.7012477290889, 525.2057370102228, 668.7415398741252, 579.8911672011341, 173.5843585198197, 512.4476439672302, 561.5940379192936, 550.1816635951039, 566.6981507106024, 439.5368525486303, 482.61269641643423, 501.29770434843357, 697.1627450120163, 505.7134910135351, 695.9793658079011, 560.2485972713395, 459.23170931924795, 575.5790996965779, 485.80766750140754, 356.0350562538481, 220.938921574942, 461.7357633045727, 469.85158003775865, 444.68327009227335, 574.4165021424249, 423.2954313558922, 487.9641157822917, 499.1633282964996, 433.3810478595419, 588.4413593292512, 606.7896480934452, 422.78201786362524, 439.19031903404635, 425.1404378944044, 550.2789685539677, 488.12903523254573, 438.0795241412999, 486.66145397239865, 517.6190377396109, 349.5392485618797, 542.672511230595, 336.50280171771993, 375.5735886352983, 433.693006504268, 402.51745941617594, 466.5621773936998, 561.9794801870089, 518.0861347570878, 569.4326066363309, 303.39522656535576, 318.17533905941184, 273.20752127431643, 364.08818731383496, 256.04025240455786, 433.49239208977457, 323.5743436626971, 263.03634477903336, 477.0744943524173, 410.4263904244758, 550.5232203296594, 538.0292612965302, 444.3053118021471, 486.51559438918457, 491.0318568884809, 595.615815463358, 390.0906984604627, 488.2324150631953, 589.3228184542019, 517.6969586650713, 374.4393861594346, 411.8914033146003, 514.337568826519, 647.2596432668088, 539.5237912515539, 428.63935067942816, 550.5803243746036, 553.0590332208244, 556.3683919133407, 539.9377576082895, 547.1907674702601, 441.3057189649028, 273.03743547827787, 533.7197522955555, 437.3122293432511, 222.26773000366606, 539.5351728173321, 637.5745945032187, 580.9427425868232, 580.176963962395, 407.2097728706749, 609.0256745439341, 428.3517593066573, 494.1518154558141, 411.46578195467214, 219.94099964199538, 370.0957455030294, 553.7844153791823, 369.91648051939933, 568.3521950512926, 724.4895676069473, 622.8141492577126, 497.7435287994093, 526.894635153573, 472.0638644860468, 308.9076932322034, 406.30676769667105, 576.7473129965266, 392.1337328788569, 437.65412967104373, 250.59018806356204, 455.53450264444643, 561.3420101454025, 602.2915907781704, 183.61664111356376, 200.63491663582846, 177.09352169783432, 438.08908952559284, 238.15168188937142, 311.1296008058732, 610.5073740436815, 580.1481845220859, 598.305276011395, 530.555648473234, 579.7086077593589, 685.0280511110623, 220.55163683455896, 479.8431635229535, 672.2365381103579, 664.4088538174517, 569.2357977841081, 416.39353500963307, 450.65431422462507, 572.4109791253364, 674.7493506735494, 689.2007966118347, 496.6770485531874, 581.6375735446677, 417.0049849648232, 557.7672032031852, 577.2490555281136, 292.59803442118636, 630.1647395570559, 479.72508572345333, 472.01647697793675, 701.1394517927218, 385.46856636153404, 457.7380597168461, 297.1212793646144, 300.51966995383367, 413.37956097461057, 417.70433703899494]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.8534250805943615, "mean_inference_ms": 4.965259239743309, "mean_action_processing_ms": 0.8084779164030728, "mean_env_wait_ms": 0.7132762789442616, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02730870246887207, "StateBufferConnector_ms": 0.0418698787689209, "ViewRequirementAgentConnector_ms": 0.9013568162918091}, "num_episodes": 18, "episode_return_max": 2003.6417270215413, "episode_return_min": 984.7592091675908, "episode_return_mean": 1701.5808234281985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 94.71099450705886, "num_env_steps_trained_throughput_per_sec": 94.71099450705886, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 44336.804, "restore_workers_time_ms": 0.032, "training_step_time_ms": 44336.697, "sample_time_ms": 9665.906, "learn_time_ms": 34542.665, "learn_throughput": 115.799, "synch_weights_time_ms": 124.923}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "479e5_00000", "date": "2024-08-16_11-42-18", "timestamp": 1723788738, "time_this_iter_s": 42.318947076797485, "time_total_s": 930.7854261398315, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7877790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 930.7854261398315, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 54.110169491525426, "ram_util_percent": 81.80677966101696}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1623846266320144, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.861176011928174, "policy_loss": -0.003650759023530458, "vf_loss": 9.863880668115364, "vf_explained_var": -0.04456119070608149, "kl": 0.006307155298351958, "entropy": 0.9800763352207406, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7555519208390877, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.526808888571603, "policy_loss": -0.004887719448069455, "vf_loss": 9.529188611267736, "vf_explained_var": -0.02948274852106811, "kl": 0.011146766906735087, "entropy": 1.4598571832848604, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 1983.635916499855, "episode_reward_min": 984.7592091675908, "episode_reward_mean": 1674.3343101859925, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 4.1191773650736465, "predator_policy": 173.5843585198197}, "policy_reward_max": {"prey_policy": 611.8501742536305, "predator_policy": 827.9893478312468}, "policy_reward_mean": {"prey_policy": 346.6944127052772, "predator_policy": 490.4727423877191}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1948.734187923327, 1818.9802736456224, 1799.4357476205407, 1892.653890949763, 1558.9444678818127, 1816.565973614985, 1816.944001581008, 1840.465346395358, 1693.1586844437547, 1825.9926219893339, 1957.9571456830797, 1872.5528052853865, 1147.257876741764, 1783.5211858855207, 1788.4856274542817, 1888.4442458378207, 1911.9880296277927, 1856.984875946725, 1741.5620752197854, 1694.6647559301562, 1633.3764760438285, 1879.0899771863378, 1520.788567330869, 1468.23624642292, 1720.3365057192934, 1907.5029740681384, 1878.0075407966135, 1380.6164324252961, 1524.9892138619214, 1760.8089389063796, 1624.5486580449422, 1768.4924563275372, 1873.4077106212906, 1837.6606567901931, 1880.242460694354, 1374.5846360831415, 1527.4218346174614, 1713.7078347871627, 1838.1017023926104, 1739.2342738224222, 1430.7280496756402, 1605.1930473288305, 1357.7974589122227, 1541.5613664623402, 1302.6954024616234, 1804.6103438547975, 1663.002085957266, 1537.3433003990967, 1707.815977629405, 1360.6660747534736, 1781.1375051106477, 1719.6606283206154, 1802.6271244255158, 1479.6266635806267, 1626.7858816753765, 1753.6016861313017, 1789.1604714896491, 1396.7021315818974, 1733.4392934266252, 1225.4167305064288, 1634.7443678834609, 1048.9225551122977, 1705.2456386759923, 1693.374017309755, 1771.2680366882516, 984.7592091675908, 1983.635916499855, 1615.8972664968771, 1629.8129048651947, 1859.2358418496706, 1623.476962428761, 1672.72244343833, 1658.1412461271857, 1787.983803131379, 1754.9070561516296, 1493.7862112980918, 1353.640532731578, 1268.7061445604381, 1819.9041177462677, 1741.3366084212028, 1398.5506044019223, 1420.2524469459827, 1822.5078195694907, 1702.4276789833903, 1704.0132458759726, 1737.2659808248718, 1620.5016527164341, 1694.6802854744617, 1696.6689302518612, 1668.4112779100074, 1795.9943837286519, 1768.5625296384846, 1732.7830178049962, 1817.602573871821, 1770.4604634668224, 1728.7400360049874, 1575.5694106747114, 1789.157383846148, 1858.4679437645118, 1903.2923319760123], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [317.5005713351162, 486.81164583210483, 485.9769316939972, 382.1978183965416, 454.9137651284978, 293.0131702358145, 369.59336920703475, 329.1132448583784, 391.83771385153557, 413.6312283093228, 476.89323494873344, 265.63105677973016, 211.45380563727147, 488.6103816380309, 415.0342788283012, 503.28151860199193, 263.76558316672316, 230.93265191658094, 381.3645680302027, 242.93519713769388, 543.5908480526246, 394.8859910398673, 480.0967272598094, 331.0693108275909, 208.58654435923268, 361.69735455374206, 372.39692060203583, 479.53692194115393, 383.1797924310274, 386.20606278855723, 490.53565531072934, 486.64904338891023, 489.5847447943429, 489.85890867740653, 272.1500022903372, 389.6038662336906, 492.2932964396894, 387.29644188242474, 361.58003110187656, 357.6653183799079, 334.81664471546793, 372.3512719545135, 450.2647507952758, 424.5447346790539, 311.9896351860421, 316.58717235235605, 396.3658533853686, 359.79400268453196, 390.8732340606926, 493.2528057381585, 377.44470176085844, 501.5166147265729, 353.5618373311597, 436.92696207203414, 340.5947419696965, 418.4511248308334, 421.08295684153137, 466.6105484322389, 543.4341432620167, 527.8421511500297, 460.3475511593481, 577.5904184438643, 444.420159570537, 436.5714119801082, 402.23504534225344, 382.620183652847, 401.7929948657736, 505.04675573308543, 311.22369979366607, 482.37108854885037, 332.24007916678437, 164.0214433927012, 213.11899867560197, 207.28305882258692, 417.8819181412276, 509.4951271718984, 232.60616691521926, 443.8983233840634, 405.61779057680826, 365.45334131463267, 82.21779067394957, 244.87090140626395, 307.48204517007986, 201.4048526371208, 235.9387534977686, 133.3622189792908, 611.8501742536305, 122.95400443487561, 286.397513105295, 356.71793000941125, 304.63834655429855, 322.86222997994776, 186.04045248737054, 315.84192692067626, 246.33098314717216, 274.7768698373167, 197.38866527006334, 587.9237375968725, 221.53469455622724, 507.7245986005795, 408.1717214800862, 449.08562274834986, 366.1143968337139, 415.2775559162093, 375.9092523604221, 79.41415520043411, 239.14315934189216, 215.8453402857535, 432.13134977660496, 413.6829741805211, 307.1300982805004, 463.417507157603, 544.5020474645494, 414.8705614751986, 348.5411566047292, 342.03628426916003, 245.25907524231124, 324.5466172607397, 321.53393288022244, 519.6312398768142, 498.92819958863817, 520.6335570713953, 257.61341264657227, 242.02785977048103, 139.38021495088753, 375.2098651593378, 401.68789818474863, 162.82519464037543, 248.08992510349316, 258.44145271433564, 37.77529408991452, 246.58911472016533, 469.28644168226225, 177.7040828897826, 358.49255261333536, 271.77538108979945, 268.07905616252026, 338.66855535271316, 63.99830874743509, 431.28738581685406, 348.32895430461184, 196.83338602629487, 359.51205381464325, 338.4382014556796, 403.3485702917089, 384.9455858861775, 326.12623517349937, 351.96774267737095, 292.4219136803109, 289.32921370065935, 412.45009236849137, 238.12949285122022, 391.5403721053024, 364.45921130782807, 249.17139790111491, 188.45084864571874, 434.11868146229085, 84.18701834346668, 364.58875999735903, 423.69184507470226, 271.26776929435647, 288.6663890306692, 423.0276683085826, 323.97041733134296, 4.1191773650736465, 423.57257639091546, 135.27143258153347, 383.59604276434237, 362.29654355394024, 289.4046287156198, 247.34245566942832, 334.59075632134864, 508.80935129895147, 384.9623691467362, 300.976616562614, 291.97897545387264, 33.90558399496847, 362.4467001702426, 342.8610158164747, 424.0763157221837, 378.2203702339985, 314.51375641765924, 355.4524019704929, 228.55602173799298, 358.04626620562135, 400.1317324141882, 311.146782983476, 498.7864447418137, 303.8934077312316, 436.24080399988134, 347.81690403470884, 306.2624750958245, 246.9441738746473, 296.8452956694522, 534.4481706373027, 356.5418291986771, 153.1832738156254, 325.8756977759622, 94.77493299173388, 271.9259837455943], "policy_predator_policy_reward": [571.86883544002, 572.553135316081, 456.4544750777449, 494.35104847733857, 499.80756452714064, 551.7012477290889, 525.2057370102228, 668.7415398741252, 579.8911672011341, 173.5843585198197, 512.4476439672302, 561.5940379192936, 550.1816635951039, 566.6981507106024, 439.5368525486303, 482.61269641643423, 501.29770434843357, 697.1627450120163, 505.7134910135351, 695.9793658079011, 560.2485972713395, 459.23170931924795, 575.5790996965779, 485.80766750140754, 356.0350562538481, 220.938921574942, 461.7357633045727, 469.85158003775865, 444.68327009227335, 574.4165021424249, 423.2954313558922, 487.9641157822917, 499.1633282964996, 433.3810478595419, 588.4413593292512, 606.7896480934452, 422.78201786362524, 439.19031903404635, 425.1404378944044, 550.2789685539677, 488.12903523254573, 438.0795241412999, 486.66145397239865, 517.6190377396109, 349.5392485618797, 542.672511230595, 336.50280171771993, 375.5735886352983, 433.693006504268, 402.51745941617594, 466.5621773936998, 561.9794801870089, 518.0861347570878, 569.4326066363309, 303.39522656535576, 318.17533905941184, 273.20752127431643, 364.08818731383496, 256.04025240455786, 433.49239208977457, 323.5743436626971, 263.03634477903336, 477.0744943524173, 410.4263904244758, 550.5232203296594, 538.0292612965302, 444.3053118021471, 486.51559438918457, 491.0318568884809, 595.615815463358, 390.0906984604627, 488.2324150631953, 589.3228184542019, 517.6969586650713, 374.4393861594346, 411.8914033146003, 514.337568826519, 647.2596432668088, 539.5237912515539, 428.63935067942816, 550.5803243746036, 553.0590332208244, 556.3683919133407, 539.9377576082895, 547.1907674702601, 441.3057189649028, 273.03743547827787, 533.7197522955555, 437.3122293432511, 222.26773000366606, 539.5351728173321, 637.5745945032187, 580.9427425868232, 580.176963962395, 407.2097728706749, 609.0256745439341, 428.3517593066573, 494.1518154558141, 411.46578195467214, 219.94099964199538, 370.0957455030294, 553.7844153791823, 369.91648051939933, 568.3521950512926, 724.4895676069473, 622.8141492577126, 497.7435287994093, 526.894635153573, 472.0638644860468, 308.9076932322034, 406.30676769667105, 576.7473129965266, 392.1337328788569, 437.65412967104373, 250.59018806356204, 455.53450264444643, 561.3420101454025, 602.2915907781704, 183.61664111356376, 200.63491663582846, 177.09352169783432, 438.08908952559284, 238.15168188937142, 311.1296008058732, 610.5073740436815, 580.1481845220859, 598.305276011395, 530.555648473234, 579.7086077593589, 685.0280511110623, 220.55163683455896, 479.8431635229535, 672.2365381103579, 664.4088538174517, 569.2357977841081, 416.39353500963307, 450.65431422462507, 572.4109791253364, 674.7493506735494, 689.2007966118347, 496.6770485531874, 581.6375735446677, 417.0049849648232, 557.7672032031852, 577.2490555281136, 292.59803442118636, 630.1647395570559, 479.72508572345333, 472.01647697793675, 701.1394517927218, 385.46856636153404, 457.7380597168461, 297.1212793646144, 300.51966995383367, 413.37956097461057, 417.70433703899494, 615.9478146166372, 685.6506033238741, 499.6698308482126, 453.38617250092835, 516.531869822888, 322.0845762540094, 271.33033729731034, 401.92402400874636, 566.8267179822542, 827.9893478312468, 632.4225469612899, 551.1376566762232, 362.9740031388023, 689.3380704676125, 626.7677112029256, 528.5650576311707, 436.5252592063995, 290.20467306434466, 597.7451002713483, 503.9795931866249, 581.1218104118952, 719.1948356747545, 450.3830561226568, 451.0908902486916, 481.1404427209934, 622.1198143560014, 661.8203938231196, 522.7337121068792, 547.8166540582826, 426.7883651269046, 553.4448928604787, 454.2244532860523, 432.4076833019276, 597.9185684337805, 555.219052501049, 519.4416043734054, 560.6925448164062, 471.08739631420605, 378.99751352083035, 519.1698704893369, 735.2447140035679, 644.1642581693585, 751.0312774059499, 785.560137832739]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.9383459881280072, "mean_inference_ms": 5.19672424130139, "mean_action_processing_ms": 0.8435235008445987, "mean_env_wait_ms": 0.7473153567240118, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.027037382125854492, "StateBufferConnector_ms": 0.03971719741821289, "ViewRequirementAgentConnector_ms": 0.7456474304199219}, "num_episodes": 22, "episode_return_max": 1983.635916499855, "episode_return_min": 984.7592091675908, "episode_return_mean": 1674.3343101859925, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 87.98461219971678, "num_env_steps_trained_throughput_per_sec": 87.98461219971678, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 44526.379, "restore_workers_time_ms": 0.03, "training_step_time_ms": 44526.277, "sample_time_ms": 9781.738, "learn_time_ms": 34615.356, "learn_throughput": 115.556, "synch_weights_time_ms": 125.678}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "479e5_00000", "date": "2024-08-16_11-43-03", "timestamp": 1723788783, "time_this_iter_s": 45.55979895591736, "time_total_s": 976.3452250957489, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7f2c940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 976.3452250957489, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 55.3875, "ram_util_percent": 82.3953125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.264021368080346, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.796262868750032, "policy_loss": -0.0018580673660383259, "vf_loss": 9.797428980327787, "vf_explained_var": -0.028148653204478916, "kl": 0.004612882706994133, "entropy": 0.928194361136704, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.760276356575981, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.460886863930515, "policy_loss": -0.006938741652161948, "vf_loss": 9.464692529042562, "vf_explained_var": -0.029890251601183856, "kl": 0.013924860414529132, "entropy": 1.438955457879122, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 1983.635916499855, "episode_reward_min": 984.7592091675908, "episode_reward_mean": 1676.092952275532, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -18.74377918804547, "predator_policy": 177.09352169783432}, "policy_reward_max": {"prey_policy": 611.8501742536305, "predator_policy": 849.312244038764}, "policy_reward_mean": {"prey_policy": 329.38171996410586, "predator_policy": 508.6647561736603}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1468.23624642292, 1720.3365057192934, 1907.5029740681384, 1878.0075407966135, 1380.6164324252961, 1524.9892138619214, 1760.8089389063796, 1624.5486580449422, 1768.4924563275372, 1873.4077106212906, 1837.6606567901931, 1880.242460694354, 1374.5846360831415, 1527.4218346174614, 1713.7078347871627, 1838.1017023926104, 1739.2342738224222, 1430.7280496756402, 1605.1930473288305, 1357.7974589122227, 1541.5613664623402, 1302.6954024616234, 1804.6103438547975, 1663.002085957266, 1537.3433003990967, 1707.815977629405, 1360.6660747534736, 1781.1375051106477, 1719.6606283206154, 1802.6271244255158, 1479.6266635806267, 1626.7858816753765, 1753.6016861313017, 1789.1604714896491, 1396.7021315818974, 1733.4392934266252, 1225.4167305064288, 1634.7443678834609, 1048.9225551122977, 1705.2456386759923, 1693.374017309755, 1771.2680366882516, 984.7592091675908, 1983.635916499855, 1615.8972664968771, 1629.8129048651947, 1859.2358418496706, 1623.476962428761, 1672.72244343833, 1658.1412461271857, 1787.983803131379, 1754.9070561516296, 1493.7862112980918, 1353.640532731578, 1268.7061445604381, 1819.9041177462677, 1741.3366084212028, 1398.5506044019223, 1420.2524469459827, 1822.5078195694907, 1702.4276789833903, 1704.0132458759726, 1737.2659808248718, 1620.5016527164341, 1694.6802854744617, 1696.6689302518612, 1668.4112779100074, 1795.9943837286519, 1768.5625296384846, 1732.7830178049962, 1817.602573871821, 1770.4604634668224, 1728.7400360049874, 1575.5694106747114, 1789.157383846148, 1858.4679437645118, 1903.2923319760123, 1796.0930978486058, 1512.2430015581601, 1798.1707253797745, 1907.015639503253, 1814.3337087824914, 1704.0017756575282, 1769.9201547272194, 1885.4096201838809, 1728.2711444317172, 1592.420654761672, 1857.6405351781652, 1776.9814523145992, 1885.7138635446925, 1866.370055802029, 1718.2967992925742, 1461.7991130237094, 1900.8677026479281, 1920.9245501714583, 1753.3624405140977, 1826.7549354130174, 1666.1689589459452, 1792.6524592300796, 1929.000660260217], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [396.3658533853686, 359.79400268453196, 390.8732340606926, 493.2528057381585, 377.44470176085844, 501.5166147265729, 353.5618373311597, 436.92696207203414, 340.5947419696965, 418.4511248308334, 421.08295684153137, 466.6105484322389, 543.4341432620167, 527.8421511500297, 460.3475511593481, 577.5904184438643, 444.420159570537, 436.5714119801082, 402.23504534225344, 382.620183652847, 401.7929948657736, 505.04675573308543, 311.22369979366607, 482.37108854885037, 332.24007916678437, 164.0214433927012, 213.11899867560197, 207.28305882258692, 417.8819181412276, 509.4951271718984, 232.60616691521926, 443.8983233840634, 405.61779057680826, 365.45334131463267, 82.21779067394957, 244.87090140626395, 307.48204517007986, 201.4048526371208, 235.9387534977686, 133.3622189792908, 611.8501742536305, 122.95400443487561, 286.397513105295, 356.71793000941125, 304.63834655429855, 322.86222997994776, 186.04045248737054, 315.84192692067626, 246.33098314717216, 274.7768698373167, 197.38866527006334, 587.9237375968725, 221.53469455622724, 507.7245986005795, 408.1717214800862, 449.08562274834986, 366.1143968337139, 415.2775559162093, 375.9092523604221, 79.41415520043411, 239.14315934189216, 215.8453402857535, 432.13134977660496, 413.6829741805211, 307.1300982805004, 463.417507157603, 544.5020474645494, 414.8705614751986, 348.5411566047292, 342.03628426916003, 245.25907524231124, 324.5466172607397, 321.53393288022244, 519.6312398768142, 498.92819958863817, 520.6335570713953, 257.61341264657227, 242.02785977048103, 139.38021495088753, 375.2098651593378, 401.68789818474863, 162.82519464037543, 248.08992510349316, 258.44145271433564, 37.77529408991452, 246.58911472016533, 469.28644168226225, 177.7040828897826, 358.49255261333536, 271.77538108979945, 268.07905616252026, 338.66855535271316, 63.99830874743509, 431.28738581685406, 348.32895430461184, 196.83338602629487, 359.51205381464325, 338.4382014556796, 403.3485702917089, 384.9455858861775, 326.12623517349937, 351.96774267737095, 292.4219136803109, 289.32921370065935, 412.45009236849137, 238.12949285122022, 391.5403721053024, 364.45921130782807, 249.17139790111491, 188.45084864571874, 434.11868146229085, 84.18701834346668, 364.58875999735903, 423.69184507470226, 271.26776929435647, 288.6663890306692, 423.0276683085826, 323.97041733134296, 4.1191773650736465, 423.57257639091546, 135.27143258153347, 383.59604276434237, 362.29654355394024, 289.4046287156198, 247.34245566942832, 334.59075632134864, 508.80935129895147, 384.9623691467362, 300.976616562614, 291.97897545387264, 33.90558399496847, 362.4467001702426, 342.8610158164747, 424.0763157221837, 378.2203702339985, 314.51375641765924, 355.4524019704929, 228.55602173799298, 358.04626620562135, 400.1317324141882, 311.146782983476, 498.7864447418137, 303.8934077312316, 436.24080399988134, 347.81690403470884, 306.2624750958245, 246.9441738746473, 296.8452956694522, 534.4481706373027, 356.5418291986771, 153.1832738156254, 325.8756977759622, 94.77493299173388, 271.9259837455943, 243.10733099340405, 402.62937830736644, 276.94769224928285, 298.44509944173456, 366.1513718513186, 280.279919746368, 398.4832784011949, 409.1445173657373, 354.03118638343, 203.8920156648081, 333.4369721455286, 387.7865647413639, 354.5721037106251, 273.0592101910851, 475.7102298043677, 483.0287070225578, -18.74377918804547, 361.5998188989523, 268.83213915858835, 449.8029240297239, 267.63525693949, 404.4828289330085, 335.92469883775425, 306.68781483525396, 347.8528682380061, 219.1303436437108, 390.9410726947799, 288.41725011627244, 276.39227759097736, 116.85834767683562, 452.89234615903194, 353.1392050383486, 333.4681107812891, 362.1241208816782, 361.34864593351995, 176.94415234773143, 356.93490765456454, 164.98595577863284, 153.38790174620368, 319.68027853746713, 121.30291016407408, 186.7185948631016, 274.7120249731766, 293.50397295706927, 364.6171071002889, 478.6915039953353], "policy_predator_policy_reward": [336.50280171771993, 375.5735886352983, 433.693006504268, 402.51745941617594, 466.5621773936998, 561.9794801870089, 518.0861347570878, 569.4326066363309, 303.39522656535576, 318.17533905941184, 273.20752127431643, 364.08818731383496, 256.04025240455786, 433.49239208977457, 323.5743436626971, 263.03634477903336, 477.0744943524173, 410.4263904244758, 550.5232203296594, 538.0292612965302, 444.3053118021471, 486.51559438918457, 491.0318568884809, 595.615815463358, 390.0906984604627, 488.2324150631953, 589.3228184542019, 517.6969586650713, 374.4393861594346, 411.8914033146003, 514.337568826519, 647.2596432668088, 539.5237912515539, 428.63935067942816, 550.5803243746036, 553.0590332208244, 556.3683919133407, 539.9377576082895, 547.1907674702601, 441.3057189649028, 273.03743547827787, 533.7197522955555, 437.3122293432511, 222.26773000366606, 539.5351728173321, 637.5745945032187, 580.9427425868232, 580.176963962395, 407.2097728706749, 609.0256745439341, 428.3517593066573, 494.1518154558141, 411.46578195467214, 219.94099964199538, 370.0957455030294, 553.7844153791823, 369.91648051939933, 568.3521950512926, 724.4895676069473, 622.8141492577126, 497.7435287994093, 526.894635153573, 472.0638644860468, 308.9076932322034, 406.30676769667105, 576.7473129965266, 392.1337328788569, 437.65412967104373, 250.59018806356204, 455.53450264444643, 561.3420101454025, 602.2915907781704, 183.61664111356376, 200.63491663582846, 177.09352169783432, 438.08908952559284, 238.15168188937142, 311.1296008058732, 610.5073740436815, 580.1481845220859, 598.305276011395, 530.555648473234, 579.7086077593589, 685.0280511110623, 220.55163683455896, 479.8431635229535, 672.2365381103579, 664.4088538174517, 569.2357977841081, 416.39353500963307, 450.65431422462507, 572.4109791253364, 674.7493506735494, 689.2007966118347, 496.6770485531874, 581.6375735446677, 417.0049849648232, 557.7672032031852, 577.2490555281136, 292.59803442118636, 630.1647395570559, 479.72508572345333, 472.01647697793675, 701.1394517927218, 385.46856636153404, 457.7380597168461, 297.1212793646144, 300.51966995383367, 413.37956097461057, 417.70433703899494, 615.9478146166372, 685.6506033238741, 499.6698308482126, 453.38617250092835, 516.531869822888, 322.0845762540094, 271.33033729731034, 401.92402400874636, 566.8267179822542, 827.9893478312468, 632.4225469612899, 551.1376566762232, 362.9740031388023, 689.3380704676125, 626.7677112029256, 528.5650576311707, 436.5252592063995, 290.20467306434466, 597.7451002713483, 503.9795931866249, 581.1218104118952, 719.1948356747545, 450.3830561226568, 451.0908902486916, 481.1404427209934, 622.1198143560014, 661.8203938231196, 522.7337121068792, 547.8166540582826, 426.7883651269046, 553.4448928604787, 454.2244532860523, 432.4076833019276, 597.9185684337805, 555.219052501049, 519.4416043734054, 560.6925448164062, 471.08739631420605, 378.99751352083035, 519.1698704893369, 735.2447140035679, 644.1642581693585, 751.0312774059499, 785.560137832739, 665.8542400810381, 484.50214846679756, 541.3453456003543, 395.50486426679026, 589.1098803698039, 562.6295534122842, 542.8430188561263, 556.5448248801946, 679.4974950146682, 576.9130117195851, 587.7036301873584, 395.0746085832767, 651.2934794595285, 490.99536136598044, 481.67528615668016, 444.9953972002738, 738.103870783819, 647.3112339369903, 380.44616560630084, 493.33942596706004, 655.0585001422938, 530.4639491633741, 448.4173356464491, 685.9516029951378, 711.9449434796595, 606.785708183317, 654.3971547307535, 532.6145782602241, 475.7339299859972, 849.312244038764, 348.3791048083757, 307.3884570179525, 665.8790653156104, 539.3964056693511, 666.3529382004018, 716.2788136898097, 636.4629986179691, 594.9785784629322, 643.9590677972433, 709.7276873321026, 659.0672174311228, 699.0802364876472, 595.4012611365606, 629.0352001632729, 565.4659350039988, 520.2261141605937]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.0154060078021754, "mean_inference_ms": 5.395363302132407, "mean_action_processing_ms": 0.8736885567883047, "mean_env_wait_ms": 0.7728939226814326, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03328812122344971, "StateBufferConnector_ms": 0.039780616760253906, "ViewRequirementAgentConnector_ms": 0.7499691247940063}, "num_episodes": 23, "episode_return_max": 1983.635916499855, "episode_return_min": 984.7592091675908, "episode_return_mean": 1676.092952275532, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 26.147709449932027, "num_env_steps_trained_throughput_per_sec": 26.147709449932027, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 55650.777, "restore_workers_time_ms": 0.03, "training_step_time_ms": 55650.674, "sample_time_ms": 10117.366, "learn_time_ms": 45405.026, "learn_throughput": 88.096, "synch_weights_time_ms": 125.145}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "479e5_00000", "date": "2024-08-16_11-45-37", "timestamp": 1723788937, "time_this_iter_s": 153.1471128463745, "time_total_s": 1129.4923379421234, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78e55e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1129.4923379421234, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 59.02528735632185, "ram_util_percent": 81.4448275862069}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4568412499768393, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.684207310752264, "policy_loss": -0.002909722314314749, "vf_loss": 9.686457976083906, "vf_explained_var": 0.01876725983367395, "kl": 0.008787544931612655, "entropy": 0.9216186000871911, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7262249712433133, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.588671603530804, "policy_loss": -0.008923407070456989, "vf_loss": 9.594868643321687, "vf_explained_var": -0.012332974224494248, "kl": 0.012117291358357476, "entropy": 1.390253705574722, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 1983.635916499855, "episode_reward_min": 984.7592091675908, "episode_reward_mean": 1684.748186812611, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -18.74377918804547, "predator_policy": 177.09352169783432}, "policy_reward_max": {"prey_policy": 611.8501742536305, "predator_policy": 849.312244038764}, "policy_reward_mean": {"prey_policy": 329.4720714526679, "predator_policy": 512.9020219536377}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1605.1930473288305, 1357.7974589122227, 1541.5613664623402, 1302.6954024616234, 1804.6103438547975, 1663.002085957266, 1537.3433003990967, 1707.815977629405, 1360.6660747534736, 1781.1375051106477, 1719.6606283206154, 1802.6271244255158, 1479.6266635806267, 1626.7858816753765, 1753.6016861313017, 1789.1604714896491, 1396.7021315818974, 1733.4392934266252, 1225.4167305064288, 1634.7443678834609, 1048.9225551122977, 1705.2456386759923, 1693.374017309755, 1771.2680366882516, 984.7592091675908, 1983.635916499855, 1615.8972664968771, 1629.8129048651947, 1859.2358418496706, 1623.476962428761, 1672.72244343833, 1658.1412461271857, 1787.983803131379, 1754.9070561516296, 1493.7862112980918, 1353.640532731578, 1268.7061445604381, 1819.9041177462677, 1741.3366084212028, 1398.5506044019223, 1420.2524469459827, 1822.5078195694907, 1702.4276789833903, 1704.0132458759726, 1737.2659808248718, 1620.5016527164341, 1694.6802854744617, 1696.6689302518612, 1668.4112779100074, 1795.9943837286519, 1768.5625296384846, 1732.7830178049962, 1817.602573871821, 1770.4604634668224, 1728.7400360049874, 1575.5694106747114, 1789.157383846148, 1858.4679437645118, 1903.2923319760123, 1796.0930978486058, 1512.2430015581601, 1798.1707253797745, 1907.015639503253, 1814.3337087824914, 1704.0017756575282, 1769.9201547272194, 1885.4096201838809, 1728.2711444317172, 1592.420654761672, 1857.6405351781652, 1776.9814523145992, 1885.7138635446925, 1866.370055802029, 1718.2967992925742, 1461.7991130237094, 1900.8677026479281, 1920.9245501714583, 1753.3624405140977, 1826.7549354130174, 1666.1689589459452, 1792.6524592300796, 1929.000660260217, 1908.6401135110723, 1799.459916874347, 1846.9364777350124, 1965.9896272427386, 1607.1917047386012, 1567.97135599013, 1576.8960717606676, 1817.2815352390828, 1838.7053679517057, 1699.7550048349528, 1615.8796800837817, 1573.9384826614646, 1888.5104915045627, 1675.2712925284266, 1687.8764231985483, 1876.3658809228032, 1661.4723192311915, 1506.009833756114], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [307.48204517007986, 201.4048526371208, 235.9387534977686, 133.3622189792908, 611.8501742536305, 122.95400443487561, 286.397513105295, 356.71793000941125, 304.63834655429855, 322.86222997994776, 186.04045248737054, 315.84192692067626, 246.33098314717216, 274.7768698373167, 197.38866527006334, 587.9237375968725, 221.53469455622724, 507.7245986005795, 408.1717214800862, 449.08562274834986, 366.1143968337139, 415.2775559162093, 375.9092523604221, 79.41415520043411, 239.14315934189216, 215.8453402857535, 432.13134977660496, 413.6829741805211, 307.1300982805004, 463.417507157603, 544.5020474645494, 414.8705614751986, 348.5411566047292, 342.03628426916003, 245.25907524231124, 324.5466172607397, 321.53393288022244, 519.6312398768142, 498.92819958863817, 520.6335570713953, 257.61341264657227, 242.02785977048103, 139.38021495088753, 375.2098651593378, 401.68789818474863, 162.82519464037543, 248.08992510349316, 258.44145271433564, 37.77529408991452, 246.58911472016533, 469.28644168226225, 177.7040828897826, 358.49255261333536, 271.77538108979945, 268.07905616252026, 338.66855535271316, 63.99830874743509, 431.28738581685406, 348.32895430461184, 196.83338602629487, 359.51205381464325, 338.4382014556796, 403.3485702917089, 384.9455858861775, 326.12623517349937, 351.96774267737095, 292.4219136803109, 289.32921370065935, 412.45009236849137, 238.12949285122022, 391.5403721053024, 364.45921130782807, 249.17139790111491, 188.45084864571874, 434.11868146229085, 84.18701834346668, 364.58875999735903, 423.69184507470226, 271.26776929435647, 288.6663890306692, 423.0276683085826, 323.97041733134296, 4.1191773650736465, 423.57257639091546, 135.27143258153347, 383.59604276434237, 362.29654355394024, 289.4046287156198, 247.34245566942832, 334.59075632134864, 508.80935129895147, 384.9623691467362, 300.976616562614, 291.97897545387264, 33.90558399496847, 362.4467001702426, 342.8610158164747, 424.0763157221837, 378.2203702339985, 314.51375641765924, 355.4524019704929, 228.55602173799298, 358.04626620562135, 400.1317324141882, 311.146782983476, 498.7864447418137, 303.8934077312316, 436.24080399988134, 347.81690403470884, 306.2624750958245, 246.9441738746473, 296.8452956694522, 534.4481706373027, 356.5418291986771, 153.1832738156254, 325.8756977759622, 94.77493299173388, 271.9259837455943, 243.10733099340405, 402.62937830736644, 276.94769224928285, 298.44509944173456, 366.1513718513186, 280.279919746368, 398.4832784011949, 409.1445173657373, 354.03118638343, 203.8920156648081, 333.4369721455286, 387.7865647413639, 354.5721037106251, 273.0592101910851, 475.7102298043677, 483.0287070225578, -18.74377918804547, 361.5998188989523, 268.83213915858835, 449.8029240297239, 267.63525693949, 404.4828289330085, 335.92469883775425, 306.68781483525396, 347.8528682380061, 219.1303436437108, 390.9410726947799, 288.41725011627244, 276.39227759097736, 116.85834767683562, 452.89234615903194, 353.1392050383486, 333.4681107812891, 362.1241208816782, 361.34864593351995, 176.94415234773143, 356.93490765456454, 164.98595577863284, 153.38790174620368, 319.68027853746713, 121.30291016407408, 186.7185948631016, 274.7120249731766, 293.50397295706927, 364.6171071002889, 478.6915039953353, 360.63195531443967, 148.25770905970867, 463.26310287275754, 424.87386178135665, 494.8253936822007, 257.4049299293084, 276.8551496544462, 393.6517587663233, 452.73223049024506, 383.5052831011756, 339.96973829568526, 510.00689058770627, 576.0129518153899, 318.46030506371955, 245.14839259695927, 500.4557706694799, 578.1778100830971, 278.82954634663986, 354.4409371545348, 487.5265736040986, 365.8215049046947, 388.03566834583654, 423.957081579555, 426.888322620569, 575.241605970848, 452.1854914657424, 332.1072001388312, 270.32717687750414, 449.98873339454514, 294.239267837749, 440.76192406139387, 495.460381251464, 257.88636496431803, 372.2378226996478, 562.3008260230558, 116.27656168516637], "policy_predator_policy_reward": [556.3683919133407, 539.9377576082895, 547.1907674702601, 441.3057189649028, 273.03743547827787, 533.7197522955555, 437.3122293432511, 222.26773000366606, 539.5351728173321, 637.5745945032187, 580.9427425868232, 580.176963962395, 407.2097728706749, 609.0256745439341, 428.3517593066573, 494.1518154558141, 411.46578195467214, 219.94099964199538, 370.0957455030294, 553.7844153791823, 369.91648051939933, 568.3521950512926, 724.4895676069473, 622.8141492577126, 497.7435287994093, 526.894635153573, 472.0638644860468, 308.9076932322034, 406.30676769667105, 576.7473129965266, 392.1337328788569, 437.65412967104373, 250.59018806356204, 455.53450264444643, 561.3420101454025, 602.2915907781704, 183.61664111356376, 200.63491663582846, 177.09352169783432, 438.08908952559284, 238.15168188937142, 311.1296008058732, 610.5073740436815, 580.1481845220859, 598.305276011395, 530.555648473234, 579.7086077593589, 685.0280511110623, 220.55163683455896, 479.8431635229535, 672.2365381103579, 664.4088538174517, 569.2357977841081, 416.39353500963307, 450.65431422462507, 572.4109791253364, 674.7493506735494, 689.2007966118347, 496.6770485531874, 581.6375735446677, 417.0049849648232, 557.7672032031852, 577.2490555281136, 292.59803442118636, 630.1647395570559, 479.72508572345333, 472.01647697793675, 701.1394517927218, 385.46856636153404, 457.7380597168461, 297.1212793646144, 300.51966995383367, 413.37956097461057, 417.70433703899494, 615.9478146166372, 685.6506033238741, 499.6698308482126, 453.38617250092835, 516.531869822888, 322.0845762540094, 271.33033729731034, 401.92402400874636, 566.8267179822542, 827.9893478312468, 632.4225469612899, 551.1376566762232, 362.9740031388023, 689.3380704676125, 626.7677112029256, 528.5650576311707, 436.5252592063995, 290.20467306434466, 597.7451002713483, 503.9795931866249, 581.1218104118952, 719.1948356747545, 450.3830561226568, 451.0908902486916, 481.1404427209934, 622.1198143560014, 661.8203938231196, 522.7337121068792, 547.8166540582826, 426.7883651269046, 553.4448928604787, 454.2244532860523, 432.4076833019276, 597.9185684337805, 555.219052501049, 519.4416043734054, 560.6925448164062, 471.08739631420605, 378.99751352083035, 519.1698704893369, 735.2447140035679, 644.1642581693585, 751.0312774059499, 785.560137832739, 665.8542400810381, 484.50214846679756, 541.3453456003543, 395.50486426679026, 589.1098803698039, 562.6295534122842, 542.8430188561263, 556.5448248801946, 679.4974950146682, 576.9130117195851, 587.7036301873584, 395.0746085832767, 651.2934794595285, 490.99536136598044, 481.67528615668016, 444.9953972002738, 738.103870783819, 647.3112339369903, 380.44616560630084, 493.33942596706004, 655.0585001422938, 530.4639491633741, 448.4173356464491, 685.9516029951378, 711.9449434796595, 606.785708183317, 654.3971547307535, 532.6145782602241, 475.7339299859972, 849.312244038764, 348.3791048083757, 307.3884570179525, 665.8790653156104, 539.3964056693511, 666.3529382004018, 716.2788136898097, 636.4629986179691, 594.9785784629322, 643.9590677972433, 709.7276873321026, 659.0672174311228, 699.0802364876472, 595.4012611365606, 629.0352001632729, 565.4659350039988, 520.2261141605937, 658.768534004552, 740.9819151323744, 496.8155301579415, 414.50742206229285, 614.3793832445313, 480.32677087897184, 612.2659874651864, 683.2167313567791, 479.8927289861899, 291.0614621609893, 290.014130263826, 427.98059684291303, 326.1629523729092, 356.2598625086508, 626.7830680661402, 444.89430390650165, 519.0383392436148, 462.6596722783553, 531.5230316509289, 326.2644624253903, 475.655159577577, 386.3673472556729, 339.35583094263797, 383.73724751870276, 409.17901520943957, 451.9043788585319, 565.5364125346426, 507.30050297744845, 372.3147487330063, 571.3336732332477, 461.6729145604685, 478.47066104947703, 625.0594077921705, 406.2887237750537, 286.39465659315766, 541.037789454734]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.072109047976425, "mean_inference_ms": 5.535529728639472, "mean_action_processing_ms": 0.8958995230555223, "mean_env_wait_ms": 0.7928895769836308, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03388321399688721, "StateBufferConnector_ms": 0.01197659969329834, "ViewRequirementAgentConnector_ms": 0.7225164175033569}, "num_episodes": 18, "episode_return_max": 1983.635916499855, "episode_return_min": 984.7592091675908, "episode_return_mean": 1684.748186812611, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 6.618138086840602, "num_env_steps_trained_throughput_per_sec": 6.618138086840602, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 111631.402, "restore_workers_time_ms": 0.031, "training_step_time_ms": 111631.291, "sample_time_ms": 10369.881, "learn_time_ms": 101132.309, "learn_throughput": 39.552, "synch_weights_time_ms": 126.058}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "479e5_00000", "date": "2024-08-16_11-55-41", "timestamp": 1723789541, "time_this_iter_s": 604.468593120575, "time_total_s": 1733.9609310626984, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7f2ca60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1733.9609310626984, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 61.47142857142857, "ram_util_percent": 80.22380952380952}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5515758906880384, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.627265418521942, "policy_loss": -0.004978661059534976, "vf_loss": 9.631403564271473, "vf_explained_var": -0.052378733637471676, "kl": 0.011207152310991236, "entropy": 0.9269848342295046, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6312674201512463, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.682959237678972, "policy_loss": -0.0017090096251753271, "vf_loss": 9.68217326875717, "vf_explained_var": -0.014657722516034645, "kl": 0.011088773563299797, "entropy": 1.388886235315333, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 1985.4311303934949, "episode_reward_min": 984.7592091675908, "episode_reward_mean": 1716.026955177042, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -18.74377918804547, "predator_policy": 177.09352169783432}, "policy_reward_max": {"prey_policy": 707.1236759598886, "predator_policy": 849.312244038764}, "policy_reward_mean": {"prey_policy": 354.247284450539, "predator_policy": 503.7661931379823}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1225.4167305064288, 1634.7443678834609, 1048.9225551122977, 1705.2456386759923, 1693.374017309755, 1771.2680366882516, 984.7592091675908, 1983.635916499855, 1615.8972664968771, 1629.8129048651947, 1859.2358418496706, 1623.476962428761, 1672.72244343833, 1658.1412461271857, 1787.983803131379, 1754.9070561516296, 1493.7862112980918, 1353.640532731578, 1268.7061445604381, 1819.9041177462677, 1741.3366084212028, 1398.5506044019223, 1420.2524469459827, 1822.5078195694907, 1702.4276789833903, 1704.0132458759726, 1737.2659808248718, 1620.5016527164341, 1694.6802854744617, 1696.6689302518612, 1668.4112779100074, 1795.9943837286519, 1768.5625296384846, 1732.7830178049962, 1817.602573871821, 1770.4604634668224, 1728.7400360049874, 1575.5694106747114, 1789.157383846148, 1858.4679437645118, 1903.2923319760123, 1796.0930978486058, 1512.2430015581601, 1798.1707253797745, 1907.015639503253, 1814.3337087824914, 1704.0017756575282, 1769.9201547272194, 1885.4096201838809, 1728.2711444317172, 1592.420654761672, 1857.6405351781652, 1776.9814523145992, 1885.7138635446925, 1866.370055802029, 1718.2967992925742, 1461.7991130237094, 1900.8677026479281, 1920.9245501714583, 1753.3624405140977, 1826.7549354130174, 1666.1689589459452, 1792.6524592300796, 1929.000660260217, 1908.6401135110723, 1799.459916874347, 1846.9364777350124, 1965.9896272427386, 1607.1917047386012, 1567.97135599013, 1576.8960717606676, 1817.2815352390828, 1838.7053679517057, 1699.7550048349528, 1615.8796800837817, 1573.9384826614646, 1888.5104915045627, 1675.2712925284266, 1687.8764231985483, 1876.3658809228032, 1661.4723192311915, 1506.009833756114, 1768.909693156215, 1895.7479972657877, 1922.0080361830808, 1859.2527271967278, 1934.2613914079598, 1867.920371180885, 1701.4976248062826, 1524.7205262180623, 1985.4311303934949, 1913.3605581495751, 1676.9124260232206, 1877.8154927256921, 1568.4007403560436, 1903.1971785429073, 1550.0350932486438, 1836.8118539235563, 1536.9688927253158, 1768.0515464409907], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [321.53393288022244, 519.6312398768142, 498.92819958863817, 520.6335570713953, 257.61341264657227, 242.02785977048103, 139.38021495088753, 375.2098651593378, 401.68789818474863, 162.82519464037543, 248.08992510349316, 258.44145271433564, 37.77529408991452, 246.58911472016533, 469.28644168226225, 177.7040828897826, 358.49255261333536, 271.77538108979945, 268.07905616252026, 338.66855535271316, 63.99830874743509, 431.28738581685406, 348.32895430461184, 196.83338602629487, 359.51205381464325, 338.4382014556796, 403.3485702917089, 384.9455858861775, 326.12623517349937, 351.96774267737095, 292.4219136803109, 289.32921370065935, 412.45009236849137, 238.12949285122022, 391.5403721053024, 364.45921130782807, 249.17139790111491, 188.45084864571874, 434.11868146229085, 84.18701834346668, 364.58875999735903, 423.69184507470226, 271.26776929435647, 288.6663890306692, 423.0276683085826, 323.97041733134296, 4.1191773650736465, 423.57257639091546, 135.27143258153347, 383.59604276434237, 362.29654355394024, 289.4046287156198, 247.34245566942832, 334.59075632134864, 508.80935129895147, 384.9623691467362, 300.976616562614, 291.97897545387264, 33.90558399496847, 362.4467001702426, 342.8610158164747, 424.0763157221837, 378.2203702339985, 314.51375641765924, 355.4524019704929, 228.55602173799298, 358.04626620562135, 400.1317324141882, 311.146782983476, 498.7864447418137, 303.8934077312316, 436.24080399988134, 347.81690403470884, 306.2624750958245, 246.9441738746473, 296.8452956694522, 534.4481706373027, 356.5418291986771, 153.1832738156254, 325.8756977759622, 94.77493299173388, 271.9259837455943, 243.10733099340405, 402.62937830736644, 276.94769224928285, 298.44509944173456, 366.1513718513186, 280.279919746368, 398.4832784011949, 409.1445173657373, 354.03118638343, 203.8920156648081, 333.4369721455286, 387.7865647413639, 354.5721037106251, 273.0592101910851, 475.7102298043677, 483.0287070225578, -18.74377918804547, 361.5998188989523, 268.83213915858835, 449.8029240297239, 267.63525693949, 404.4828289330085, 335.92469883775425, 306.68781483525396, 347.8528682380061, 219.1303436437108, 390.9410726947799, 288.41725011627244, 276.39227759097736, 116.85834767683562, 452.89234615903194, 353.1392050383486, 333.4681107812891, 362.1241208816782, 361.34864593351995, 176.94415234773143, 356.93490765456454, 164.98595577863284, 153.38790174620368, 319.68027853746713, 121.30291016407408, 186.7185948631016, 274.7120249731766, 293.50397295706927, 364.6171071002889, 478.6915039953353, 360.63195531443967, 148.25770905970867, 463.26310287275754, 424.87386178135665, 494.8253936822007, 257.4049299293084, 276.8551496544462, 393.6517587663233, 452.73223049024506, 383.5052831011756, 339.96973829568526, 510.00689058770627, 576.0129518153899, 318.46030506371955, 245.14839259695927, 500.4557706694799, 578.1778100830971, 278.82954634663986, 354.4409371545348, 487.5265736040986, 365.8215049046947, 388.03566834583654, 423.957081579555, 426.888322620569, 575.241605970848, 452.1854914657424, 332.1072001388312, 270.32717687750414, 449.98873339454514, 294.239267837749, 440.76192406139387, 495.460381251464, 257.88636496431803, 372.2378226996478, 562.3008260230558, 116.27656168516637, 602.1217931441794, 530.7519637664444, 487.2936330649755, 401.414876636633, 423.3243131267936, 322.0330547367, 592.5307860347118, 613.5102481996231, 467.290553999579, 490.9025396787835, 618.8710783592164, 544.8751631579848, 344.05931509755317, 403.4337586794336, 416.0949820421673, 477.55866605062437, 453.8890375922885, 604.5245269455302, 360.5718301622745, 707.1236759598886, 307.74467090908905, 444.4036207692579, 445.38171176830747, 387.8502410683299, 211.79761187590213, 534.0321852085539, 590.803343355351, 322.3202373908883, 302.9210008421005, 502.01431813190766, 459.0602328516563, 466.6818343767805, 483.15693355428755, 405.70785463685553, 485.851311289395, 549.388568026954], "policy_predator_policy_reward": [183.61664111356376, 200.63491663582846, 177.09352169783432, 438.08908952559284, 238.15168188937142, 311.1296008058732, 610.5073740436815, 580.1481845220859, 598.305276011395, 530.555648473234, 579.7086077593589, 685.0280511110623, 220.55163683455896, 479.8431635229535, 672.2365381103579, 664.4088538174517, 569.2357977841081, 416.39353500963307, 450.65431422462507, 572.4109791253364, 674.7493506735494, 689.2007966118347, 496.6770485531874, 581.6375735446677, 417.0049849648232, 557.7672032031852, 577.2490555281136, 292.59803442118636, 630.1647395570559, 479.72508572345333, 472.01647697793675, 701.1394517927218, 385.46856636153404, 457.7380597168461, 297.1212793646144, 300.51966995383367, 413.37956097461057, 417.70433703899494, 615.9478146166372, 685.6506033238741, 499.6698308482126, 453.38617250092835, 516.531869822888, 322.0845762540094, 271.33033729731034, 401.92402400874636, 566.8267179822542, 827.9893478312468, 632.4225469612899, 551.1376566762232, 362.9740031388023, 689.3380704676125, 626.7677112029256, 528.5650576311707, 436.5252592063995, 290.20467306434466, 597.7451002713483, 503.9795931866249, 581.1218104118952, 719.1948356747545, 450.3830561226568, 451.0908902486916, 481.1404427209934, 622.1198143560014, 661.8203938231196, 522.7337121068792, 547.8166540582826, 426.7883651269046, 553.4448928604787, 454.2244532860523, 432.4076833019276, 597.9185684337805, 555.219052501049, 519.4416043734054, 560.6925448164062, 471.08739631420605, 378.99751352083035, 519.1698704893369, 735.2447140035679, 644.1642581693585, 751.0312774059499, 785.560137832739, 665.8542400810381, 484.50214846679756, 541.3453456003543, 395.50486426679026, 589.1098803698039, 562.6295534122842, 542.8430188561263, 556.5448248801946, 679.4974950146682, 576.9130117195851, 587.7036301873584, 395.0746085832767, 651.2934794595285, 490.99536136598044, 481.67528615668016, 444.9953972002738, 738.103870783819, 647.3112339369903, 380.44616560630084, 493.33942596706004, 655.0585001422938, 530.4639491633741, 448.4173356464491, 685.9516029951378, 711.9449434796595, 606.785708183317, 654.3971547307535, 532.6145782602241, 475.7339299859972, 849.312244038764, 348.3791048083757, 307.3884570179525, 665.8790653156104, 539.3964056693511, 666.3529382004018, 716.2788136898097, 636.4629986179691, 594.9785784629322, 643.9590677972433, 709.7276873321026, 659.0672174311228, 699.0802364876472, 595.4012611365606, 629.0352001632729, 565.4659350039988, 520.2261141605937, 658.768534004552, 740.9819151323744, 496.8155301579415, 414.50742206229285, 614.3793832445313, 480.32677087897184, 612.2659874651864, 683.2167313567791, 479.8927289861899, 291.0614621609893, 290.014130263826, 427.98059684291303, 326.1629523729092, 356.2598625086508, 626.7830680661402, 444.89430390650165, 519.0383392436148, 462.6596722783553, 531.5230316509289, 326.2644624253903, 475.655159577577, 386.3673472556729, 339.35583094263797, 383.73724751870276, 409.17901520943957, 451.9043788585319, 565.5364125346426, 507.30050297744845, 372.3147487330063, 571.3336732332477, 461.6729145604685, 478.47066104947703, 625.0594077921705, 406.2887237750537, 286.39465659315766, 541.037789454734, 344.04211172663116, 291.99382451896196, 507.1272611526482, 499.91222641153223, 619.3601770791785, 557.2904912404099, 329.68758667731623, 323.5241062850795, 479.2348390591418, 496.8334586704538, 453.7419085678265, 250.43222109585787, 493.9011722079429, 460.10337882135224, 311.6456773831196, 319.4212007421528, 473.4703131298777, 453.5472527257994, 507.0709646998011, 338.59408732761267, 486.10695359147456, 438.65718075340027, 475.8500835205595, 568.7334563684932, 360.22914440199105, 462.34179886959635, 574.8162620155343, 415.2573357811363, 390.45871114065267, 354.64106313398486, 502.14389361720583, 408.9258930779143, 238.3302994452336, 409.7738050889388, 354.8685120900594, 377.943155034583]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1216943387700997, "mean_inference_ms": 5.662679890121192, "mean_action_processing_ms": 0.9174427459332076, "mean_env_wait_ms": 0.8109393326549562, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04414403438568115, "StateBufferConnector_ms": 0.012070178985595703, "ViewRequirementAgentConnector_ms": 0.6374596357345581}, "num_episodes": 18, "episode_return_max": 1985.4311303934949, "episode_return_min": 984.7592091675908, "episode_return_mean": 1716.026955177042, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 83.6177627239943, "num_env_steps_trained_throughput_per_sec": 83.6177627239943, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 111804.925, "restore_workers_time_ms": 0.032, "training_step_time_ms": 111804.814, "sample_time_ms": 10267.351, "learn_time_ms": 101414.287, "learn_throughput": 39.442, "synch_weights_time_ms": 120.034}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "479e5_00000", "date": "2024-08-16_11-56-29", "timestamp": 1723789589, "time_this_iter_s": 47.9661021232605, "time_total_s": 1781.9270331859589, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7f2c790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1781.9270331859589, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 56.702941176470574, "ram_util_percent": 78.74852941176471}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5936771357185626, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.652858807296349, "policy_loss": -0.00559579628746385, "vf_loss": 9.657484168098087, "vf_explained_var": -0.04231429667699905, "kl": 0.012939007400356025, "entropy": 0.9662417318770494, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6837276661995226, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.638058234522582, "policy_loss": -0.006406878504567046, "vf_loss": 9.642198298721716, "vf_explained_var": -0.016416863978855195, "kl": 0.010074737083204952, "entropy": 1.344827354017389, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 1985.4311303934949, "episode_reward_min": 1268.7061445604381, "episode_reward_mean": 1762.598937943255, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -18.74377918804547, "predator_policy": 231.11431937333657}, "policy_reward_max": {"prey_policy": 707.1236759598886, "predator_policy": 849.312244038764}, "policy_reward_mean": {"prey_policy": 380.599577867758, "predator_policy": 500.6998911038696}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1268.7061445604381, 1819.9041177462677, 1741.3366084212028, 1398.5506044019223, 1420.2524469459827, 1822.5078195694907, 1702.4276789833903, 1704.0132458759726, 1737.2659808248718, 1620.5016527164341, 1694.6802854744617, 1696.6689302518612, 1668.4112779100074, 1795.9943837286519, 1768.5625296384846, 1732.7830178049962, 1817.602573871821, 1770.4604634668224, 1728.7400360049874, 1575.5694106747114, 1789.157383846148, 1858.4679437645118, 1903.2923319760123, 1796.0930978486058, 1512.2430015581601, 1798.1707253797745, 1907.015639503253, 1814.3337087824914, 1704.0017756575282, 1769.9201547272194, 1885.4096201838809, 1728.2711444317172, 1592.420654761672, 1857.6405351781652, 1776.9814523145992, 1885.7138635446925, 1866.370055802029, 1718.2967992925742, 1461.7991130237094, 1900.8677026479281, 1920.9245501714583, 1753.3624405140977, 1826.7549354130174, 1666.1689589459452, 1792.6524592300796, 1929.000660260217, 1908.6401135110723, 1799.459916874347, 1846.9364777350124, 1965.9896272427386, 1607.1917047386012, 1567.97135599013, 1576.8960717606676, 1817.2815352390828, 1838.7053679517057, 1699.7550048349528, 1615.8796800837817, 1573.9384826614646, 1888.5104915045627, 1675.2712925284266, 1687.8764231985483, 1876.3658809228032, 1661.4723192311915, 1506.009833756114, 1768.909693156215, 1895.7479972657877, 1922.0080361830808, 1859.2527271967278, 1934.2613914079598, 1867.920371180885, 1701.4976248062826, 1524.7205262180623, 1985.4311303934949, 1913.3605581495751, 1676.9124260232206, 1877.8154927256921, 1568.4007403560436, 1903.1971785429073, 1550.0350932486438, 1836.8118539235563, 1536.9688927253158, 1768.0515464409907, 1807.1568438874133, 1815.7693350800685, 1730.6038495396624, 1953.6682506554419, 1827.0683313599538, 1898.5979641364786, 1917.1739713650493, 1888.8984271676884, 1605.856670135378, 1793.7798431203773, 1802.7293585845327, 1947.7146133883, 1940.439036801598, 1761.2059807471974, 1876.1475466890452, 1809.9666339612245, 1874.690231006228, 1902.70212935795], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [249.17139790111491, 188.45084864571874, 434.11868146229085, 84.18701834346668, 364.58875999735903, 423.69184507470226, 271.26776929435647, 288.6663890306692, 423.0276683085826, 323.97041733134296, 4.1191773650736465, 423.57257639091546, 135.27143258153347, 383.59604276434237, 362.29654355394024, 289.4046287156198, 247.34245566942832, 334.59075632134864, 508.80935129895147, 384.9623691467362, 300.976616562614, 291.97897545387264, 33.90558399496847, 362.4467001702426, 342.8610158164747, 424.0763157221837, 378.2203702339985, 314.51375641765924, 355.4524019704929, 228.55602173799298, 358.04626620562135, 400.1317324141882, 311.146782983476, 498.7864447418137, 303.8934077312316, 436.24080399988134, 347.81690403470884, 306.2624750958245, 246.9441738746473, 296.8452956694522, 534.4481706373027, 356.5418291986771, 153.1832738156254, 325.8756977759622, 94.77493299173388, 271.9259837455943, 243.10733099340405, 402.62937830736644, 276.94769224928285, 298.44509944173456, 366.1513718513186, 280.279919746368, 398.4832784011949, 409.1445173657373, 354.03118638343, 203.8920156648081, 333.4369721455286, 387.7865647413639, 354.5721037106251, 273.0592101910851, 475.7102298043677, 483.0287070225578, -18.74377918804547, 361.5998188989523, 268.83213915858835, 449.8029240297239, 267.63525693949, 404.4828289330085, 335.92469883775425, 306.68781483525396, 347.8528682380061, 219.1303436437108, 390.9410726947799, 288.41725011627244, 276.39227759097736, 116.85834767683562, 452.89234615903194, 353.1392050383486, 333.4681107812891, 362.1241208816782, 361.34864593351995, 176.94415234773143, 356.93490765456454, 164.98595577863284, 153.38790174620368, 319.68027853746713, 121.30291016407408, 186.7185948631016, 274.7120249731766, 293.50397295706927, 364.6171071002889, 478.6915039953353, 360.63195531443967, 148.25770905970867, 463.26310287275754, 424.87386178135665, 494.8253936822007, 257.4049299293084, 276.8551496544462, 393.6517587663233, 452.73223049024506, 383.5052831011756, 339.96973829568526, 510.00689058770627, 576.0129518153899, 318.46030506371955, 245.14839259695927, 500.4557706694799, 578.1778100830971, 278.82954634663986, 354.4409371545348, 487.5265736040986, 365.8215049046947, 388.03566834583654, 423.957081579555, 426.888322620569, 575.241605970848, 452.1854914657424, 332.1072001388312, 270.32717687750414, 449.98873339454514, 294.239267837749, 440.76192406139387, 495.460381251464, 257.88636496431803, 372.2378226996478, 562.3008260230558, 116.27656168516637, 602.1217931441794, 530.7519637664444, 487.2936330649755, 401.414876636633, 423.3243131267936, 322.0330547367, 592.5307860347118, 613.5102481996231, 467.290553999579, 490.9025396787835, 618.8710783592164, 544.8751631579848, 344.05931509755317, 403.4337586794336, 416.0949820421673, 477.55866605062437, 453.8890375922885, 604.5245269455302, 360.5718301622745, 707.1236759598886, 307.74467090908905, 444.4036207692579, 445.38171176830747, 387.8502410683299, 211.79761187590213, 534.0321852085539, 590.803343355351, 322.3202373908883, 302.9210008421005, 502.01431813190766, 459.0602328516563, 466.6818343767805, 483.15693355428755, 405.70785463685553, 485.851311289395, 549.388568026954, 412.64948062568607, 438.4038429191896, 553.3792973721847, 376.9066586299317, 505.04539661649716, 479.9446337594027, 438.52070978690006, 334.4602186908664, 588.170424127428, 457.2765143713207, 320.8389992526683, 403.9404932756774, 572.5565633344083, 603.1734683736033, 190.22875802935832, 436.174552153213, 299.43629227487605, 343.3939796766935, 569.8682782016684, 480.2299894769156, 476.52598562036985, 482.1567892107753, 472.7225395674947, 495.6658389873405, 625.300219540131, 383.314280498499, 534.8895521004249, 427.983488954757, 577.3353784573103, 555.8992206395199, 313.480196793848, 556.7785108011423, 503.44409641378314, 457.3725340298076, 479.85716655984925, 430.62428571612867], "policy_predator_policy_reward": [413.37956097461057, 417.70433703899494, 615.9478146166372, 685.6506033238741, 499.6698308482126, 453.38617250092835, 516.531869822888, 322.0845762540094, 271.33033729731034, 401.92402400874636, 566.8267179822542, 827.9893478312468, 632.4225469612899, 551.1376566762232, 362.9740031388023, 689.3380704676125, 626.7677112029256, 528.5650576311707, 436.5252592063995, 290.20467306434466, 597.7451002713483, 503.9795931866249, 581.1218104118952, 719.1948356747545, 450.3830561226568, 451.0908902486916, 481.1404427209934, 622.1198143560014, 661.8203938231196, 522.7337121068792, 547.8166540582826, 426.7883651269046, 553.4448928604787, 454.2244532860523, 432.4076833019276, 597.9185684337805, 555.219052501049, 519.4416043734054, 560.6925448164062, 471.08739631420605, 378.99751352083035, 519.1698704893369, 735.2447140035679, 644.1642581693585, 751.0312774059499, 785.560137832739, 665.8542400810381, 484.50214846679756, 541.3453456003543, 395.50486426679026, 589.1098803698039, 562.6295534122842, 542.8430188561263, 556.5448248801946, 679.4974950146682, 576.9130117195851, 587.7036301873584, 395.0746085832767, 651.2934794595285, 490.99536136598044, 481.67528615668016, 444.9953972002738, 738.103870783819, 647.3112339369903, 380.44616560630084, 493.33942596706004, 655.0585001422938, 530.4639491633741, 448.4173356464491, 685.9516029951378, 711.9449434796595, 606.785708183317, 654.3971547307535, 532.6145782602241, 475.7339299859972, 849.312244038764, 348.3791048083757, 307.3884570179525, 665.8790653156104, 539.3964056693511, 666.3529382004018, 716.2788136898097, 636.4629986179691, 594.9785784629322, 643.9590677972433, 709.7276873321026, 659.0672174311228, 699.0802364876472, 595.4012611365606, 629.0352001632729, 565.4659350039988, 520.2261141605937, 658.768534004552, 740.9819151323744, 496.8155301579415, 414.50742206229285, 614.3793832445313, 480.32677087897184, 612.2659874651864, 683.2167313567791, 479.8927289861899, 291.0614621609893, 290.014130263826, 427.98059684291303, 326.1629523729092, 356.2598625086508, 626.7830680661402, 444.89430390650165, 519.0383392436148, 462.6596722783553, 531.5230316509289, 326.2644624253903, 475.655159577577, 386.3673472556729, 339.35583094263797, 383.73724751870276, 409.17901520943957, 451.9043788585319, 565.5364125346426, 507.30050297744845, 372.3147487330063, 571.3336732332477, 461.6729145604685, 478.47066104947703, 625.0594077921705, 406.2887237750537, 286.39465659315766, 541.037789454734, 344.04211172663116, 291.99382451896196, 507.1272611526482, 499.91222641153223, 619.3601770791785, 557.2904912404099, 329.68758667731623, 323.5241062850795, 479.2348390591418, 496.8334586704538, 453.7419085678265, 250.43222109585787, 493.9011722079429, 460.10337882135224, 311.6456773831196, 319.4212007421528, 473.4703131298777, 453.5472527257994, 507.0709646998011, 338.59408732761267, 486.10695359147456, 438.65718075340027, 475.8500835205595, 568.7334563684932, 360.22914440199105, 462.34179886959635, 574.8162620155343, 415.2573357811363, 390.45871114065267, 354.64106313398486, 502.14389361720583, 408.9258930779143, 238.3302994452336, 409.7738050889388, 354.8685120900594, 377.943155034583, 503.71268345324665, 452.39083688929134, 543.536300689819, 341.94707838813366, 231.11431937333657, 514.4994997904256, 613.4986189227265, 567.188703254948, 510.2328846651302, 271.38850819607734, 628.1007616090877, 545.7177099990436, 267.1876502787255, 474.25628937831095, 606.4888508862656, 656.0062660988506, 501.88442993130195, 461.1419682525053, 361.7367233105443, 381.9448521312502, 422.19213660240223, 421.85444715098777, 470.21275054161384, 509.1134842918548, 440.49160913188757, 491.33292763108216, 388.64738681797894, 409.6855528740357, 449.27077475705164, 293.6421728351645, 468.0098426504029, 471.69808371582957, 364.64933989061143, 549.224260672028, 529.8685770737129, 462.3521000082564]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1653303893607037, "mean_inference_ms": 5.772860883405226, "mean_action_processing_ms": 0.9354485212828382, "mean_env_wait_ms": 0.826474749806251, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.040547847747802734, "StateBufferConnector_ms": 0.012232661247253418, "ViewRequirementAgentConnector_ms": 0.6284823417663574}, "num_episodes": 18, "episode_return_max": 1985.4311303934949, "episode_return_min": 1268.7061445604381, "episode_return_mean": 1762.598937943255, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 91.45199798920484, "num_env_steps_trained_throughput_per_sec": 91.45199798920484, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 111636.51, "restore_workers_time_ms": 0.031, "training_step_time_ms": 111636.401, "sample_time_ms": 9666.377, "learn_time_ms": 101872.598, "learn_throughput": 39.265, "synch_weights_time_ms": 94.301}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "479e5_00000", "date": "2024-08-16_11-57-13", "timestamp": 1723789633, "time_this_iter_s": 43.755064249038696, "time_total_s": 1825.6820974349976, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78e51f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1825.6820974349976, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 54.6, "ram_util_percent": 77.43548387096776}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7482298745837792, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.659460389172589, "policy_loss": -0.0040016012212074304, "vf_loss": 9.663075145337947, "vf_explained_var": -0.03135840403970587, "kl": 0.005157703869432832, "entropy": 0.982732022502435, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7313401650184046, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.587293629419236, "policy_loss": -0.006044518517172605, "vf_loss": 9.590453304815545, "vf_explained_var": -0.0162391724094512, "kl": 0.012821386880463848, "entropy": 1.2839576871937546, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 2009.739815538454, "episode_reward_min": 1446.2145516971595, "episode_reward_mean": 1788.4175721669026, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -18.74377918804547, "predator_policy": 231.11431937333657}, "policy_reward_max": {"prey_policy": 707.1236759598886, "predator_policy": 849.312244038764}, "policy_reward_mean": {"prey_policy": 409.28146328283003, "predator_policy": 484.9273228006215}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1903.2923319760123, 1796.0930978486058, 1512.2430015581601, 1798.1707253797745, 1907.015639503253, 1814.3337087824914, 1704.0017756575282, 1769.9201547272194, 1885.4096201838809, 1728.2711444317172, 1592.420654761672, 1857.6405351781652, 1776.9814523145992, 1885.7138635446925, 1866.370055802029, 1718.2967992925742, 1461.7991130237094, 1900.8677026479281, 1920.9245501714583, 1753.3624405140977, 1826.7549354130174, 1666.1689589459452, 1792.6524592300796, 1929.000660260217, 1908.6401135110723, 1799.459916874347, 1846.9364777350124, 1965.9896272427386, 1607.1917047386012, 1567.97135599013, 1576.8960717606676, 1817.2815352390828, 1838.7053679517057, 1699.7550048349528, 1615.8796800837817, 1573.9384826614646, 1888.5104915045627, 1675.2712925284266, 1687.8764231985483, 1876.3658809228032, 1661.4723192311915, 1506.009833756114, 1768.909693156215, 1895.7479972657877, 1922.0080361830808, 1859.2527271967278, 1934.2613914079598, 1867.920371180885, 1701.4976248062826, 1524.7205262180623, 1985.4311303934949, 1913.3605581495751, 1676.9124260232206, 1877.8154927256921, 1568.4007403560436, 1903.1971785429073, 1550.0350932486438, 1836.8118539235563, 1536.9688927253158, 1768.0515464409907, 1807.1568438874133, 1815.7693350800685, 1730.6038495396624, 1953.6682506554419, 1827.0683313599538, 1898.5979641364786, 1917.1739713650493, 1888.8984271676884, 1605.856670135378, 1793.7798431203773, 1802.7293585845327, 1947.7146133883, 1940.439036801598, 1761.2059807471974, 1876.1475466890452, 1809.9666339612245, 1874.690231006228, 1902.70212935795, 1756.8425813836036, 1827.0007336727124, 1898.7986592687423, 2004.1341806436155, 1781.4444552368523, 1707.2419396506086, 1770.1672453227345, 1968.5613843033589, 1873.7959484792236, 1491.9494764713284, 1876.1449700941737, 2009.739815538454, 1895.7453184153828, 1898.4109341184383, 1633.1394414844624, 1446.2145516971595, 1884.7113659826136, 1794.9450710999174, 1619.8524385682388, 1993.2481329506222, 1626.1351439125594, 1956.2041705534014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [94.77493299173388, 271.9259837455943, 243.10733099340405, 402.62937830736644, 276.94769224928285, 298.44509944173456, 366.1513718513186, 280.279919746368, 398.4832784011949, 409.1445173657373, 354.03118638343, 203.8920156648081, 333.4369721455286, 387.7865647413639, 354.5721037106251, 273.0592101910851, 475.7102298043677, 483.0287070225578, -18.74377918804547, 361.5998188989523, 268.83213915858835, 449.8029240297239, 267.63525693949, 404.4828289330085, 335.92469883775425, 306.68781483525396, 347.8528682380061, 219.1303436437108, 390.9410726947799, 288.41725011627244, 276.39227759097736, 116.85834767683562, 452.89234615903194, 353.1392050383486, 333.4681107812891, 362.1241208816782, 361.34864593351995, 176.94415234773143, 356.93490765456454, 164.98595577863284, 153.38790174620368, 319.68027853746713, 121.30291016407408, 186.7185948631016, 274.7120249731766, 293.50397295706927, 364.6171071002889, 478.6915039953353, 360.63195531443967, 148.25770905970867, 463.26310287275754, 424.87386178135665, 494.8253936822007, 257.4049299293084, 276.8551496544462, 393.6517587663233, 452.73223049024506, 383.5052831011756, 339.96973829568526, 510.00689058770627, 576.0129518153899, 318.46030506371955, 245.14839259695927, 500.4557706694799, 578.1778100830971, 278.82954634663986, 354.4409371545348, 487.5265736040986, 365.8215049046947, 388.03566834583654, 423.957081579555, 426.888322620569, 575.241605970848, 452.1854914657424, 332.1072001388312, 270.32717687750414, 449.98873339454514, 294.239267837749, 440.76192406139387, 495.460381251464, 257.88636496431803, 372.2378226996478, 562.3008260230558, 116.27656168516637, 602.1217931441794, 530.7519637664444, 487.2936330649755, 401.414876636633, 423.3243131267936, 322.0330547367, 592.5307860347118, 613.5102481996231, 467.290553999579, 490.9025396787835, 618.8710783592164, 544.8751631579848, 344.05931509755317, 403.4337586794336, 416.0949820421673, 477.55866605062437, 453.8890375922885, 604.5245269455302, 360.5718301622745, 707.1236759598886, 307.74467090908905, 444.4036207692579, 445.38171176830747, 387.8502410683299, 211.79761187590213, 534.0321852085539, 590.803343355351, 322.3202373908883, 302.9210008421005, 502.01431813190766, 459.0602328516563, 466.6818343767805, 483.15693355428755, 405.70785463685553, 485.851311289395, 549.388568026954, 412.64948062568607, 438.4038429191896, 553.3792973721847, 376.9066586299317, 505.04539661649716, 479.9446337594027, 438.52070978690006, 334.4602186908664, 588.170424127428, 457.2765143713207, 320.8389992526683, 403.9404932756774, 572.5565633344083, 603.1734683736033, 190.22875802935832, 436.174552153213, 299.43629227487605, 343.3939796766935, 569.8682782016684, 480.2299894769156, 476.52598562036985, 482.1567892107753, 472.7225395674947, 495.6658389873405, 625.300219540131, 383.314280498499, 534.8895521004249, 427.983488954757, 577.3353784573103, 555.8992206395199, 313.480196793848, 556.7785108011423, 503.44409641378314, 457.3725340298076, 479.85716655984925, 430.62428571612867, 481.55117070115995, 545.996635052376, 437.71638325082176, 444.3931893687781, 611.7451116807027, 429.9667225627093, 665.0347396314286, 417.9735210509903, 275.9473840149787, 406.7540031644031, 541.0070377081715, 362.4197767674264, 447.4516265304924, 627.8373929778704, 553.0783120945918, 437.13675930354924, 544.7425143563811, 592.7713026422417, 232.9664561428416, 403.338808291197, 494.40682700165195, 409.6111791457329, 480.1218580181221, 408.0234634050658, 519.8732313587444, 589.367435251579, 399.3631206898792, 426.5990663221594, 384.6313168320651, 598.1980810671363, 315.927021640175, 153.86839751361723, 220.71285800680457, 519.7245589510414, 552.4638259639215, 546.664484136989, 422.0209353436193, 371.8212512376654, 432.942240425901, 445.57125303282027, 369.46238410596607, 281.27036905388496, 457.98679235118834, 510.1734303219644], "policy_predator_policy_reward": [751.0312774059499, 785.560137832739, 665.8542400810381, 484.50214846679756, 541.3453456003543, 395.50486426679026, 589.1098803698039, 562.6295534122842, 542.8430188561263, 556.5448248801946, 679.4974950146682, 576.9130117195851, 587.7036301873584, 395.0746085832767, 651.2934794595285, 490.99536136598044, 481.67528615668016, 444.9953972002738, 738.103870783819, 647.3112339369903, 380.44616560630084, 493.33942596706004, 655.0585001422938, 530.4639491633741, 448.4173356464491, 685.9516029951378, 711.9449434796595, 606.785708183317, 654.3971547307535, 532.6145782602241, 475.7339299859972, 849.312244038764, 348.3791048083757, 307.3884570179525, 665.8790653156104, 539.3964056693511, 666.3529382004018, 716.2788136898097, 636.4629986179691, 594.9785784629322, 643.9590677972433, 709.7276873321026, 659.0672174311228, 699.0802364876472, 595.4012611365606, 629.0352001632729, 565.4659350039988, 520.2261141605937, 658.768534004552, 740.9819151323744, 496.8155301579415, 414.50742206229285, 614.3793832445313, 480.32677087897184, 612.2659874651864, 683.2167313567791, 479.8927289861899, 291.0614621609893, 290.014130263826, 427.98059684291303, 326.1629523729092, 356.2598625086508, 626.7830680661402, 444.89430390650165, 519.0383392436148, 462.6596722783553, 531.5230316509289, 326.2644624253903, 475.655159577577, 386.3673472556729, 339.35583094263797, 383.73724751870276, 409.17901520943957, 451.9043788585319, 565.5364125346426, 507.30050297744845, 372.3147487330063, 571.3336732332477, 461.6729145604685, 478.47066104947703, 625.0594077921705, 406.2887237750537, 286.39465659315766, 541.037789454734, 344.04211172663116, 291.99382451896196, 507.1272611526482, 499.91222641153223, 619.3601770791785, 557.2904912404099, 329.68758667731623, 323.5241062850795, 479.2348390591418, 496.8334586704538, 453.7419085678265, 250.43222109585787, 493.9011722079429, 460.10337882135224, 311.6456773831196, 319.4212007421528, 473.4703131298777, 453.5472527257994, 507.0709646998011, 338.59408732761267, 486.10695359147456, 438.65718075340027, 475.8500835205595, 568.7334563684932, 360.22914440199105, 462.34179886959635, 574.8162620155343, 415.2573357811363, 390.45871114065267, 354.64106313398486, 502.14389361720583, 408.9258930779143, 238.3302994452336, 409.7738050889388, 354.8685120900594, 377.943155034583, 503.71268345324665, 452.39083688929134, 543.536300689819, 341.94707838813366, 231.11431937333657, 514.4994997904256, 613.4986189227265, 567.188703254948, 510.2328846651302, 271.38850819607734, 628.1007616090877, 545.7177099990436, 267.1876502787255, 474.25628937831095, 606.4888508862656, 656.0062660988506, 501.88442993130195, 461.1419682525053, 361.7367233105443, 381.9448521312502, 422.19213660240223, 421.85444715098777, 470.21275054161384, 509.1134842918548, 440.49160913188757, 491.33292763108216, 388.64738681797894, 409.6855528740357, 449.27077475705164, 293.6421728351645, 468.0098426504029, 471.69808371582957, 364.64933989061143, 549.224260672028, 529.8685770737129, 462.3521000082564, 378.54100987245823, 350.7537657576126, 430.8949640792645, 513.9961969738492, 488.7682569985139, 368.31856802681517, 531.5824405951984, 389.54347936599737, 529.6093039401655, 569.1337641173036, 411.0230890201114, 392.7920361549003, 357.1907990885727, 337.6874267257994, 458.32514509727355, 520.0211678079434, 311.78602952635373, 424.496101954246, 522.5986550454759, 333.0455569918157, 485.020397262147, 487.1065666846385, 556.2484827196364, 565.3460113956301, 371.7104170839811, 414.7942347210793, 575.1903989544825, 497.2583481519155, 379.4094336313291, 270.9006099539312, 492.2738268209381, 484.14530572242916, 628.3653030400892, 515.9086459846786, 331.9705970756077, 363.8461639234009, 407.5214666092768, 418.4887853776779, 522.6519304585402, 592.0827090333578, 470.2445355771129, 505.1578551755949, 463.1908914731616, 524.8530564070866]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.2116238746133936, "mean_inference_ms": 5.896307780217819, "mean_action_processing_ms": 0.9557755079795033, "mean_env_wait_ms": 0.8445083171320309, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.048398494720458984, "StateBufferConnector_ms": 0.01215982437133789, "ViewRequirementAgentConnector_ms": 0.5778785943984985}, "num_episodes": 22, "episode_return_max": 2009.739815538454, "episode_return_min": 1446.2145516971595, "episode_return_mean": 1788.4175721669026, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 90.35494419449006, "num_env_steps_trained_throughput_per_sec": 90.35494419449006, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 111467.681, "restore_workers_time_ms": 0.031, "training_step_time_ms": 111467.573, "sample_time_ms": 9072.793, "learn_time_ms": 102314.544, "learn_throughput": 39.095, "synch_weights_time_ms": 77.093}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "479e5_00000", "date": "2024-08-16_11-57-57", "timestamp": 1723789677, "time_this_iter_s": 44.29445815086365, "time_total_s": 1869.9765555858612, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78775e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1869.9765555858612, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 56.85322580645162, "ram_util_percent": 77.33709677419355}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2578711575931973, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.31875396859709, "policy_loss": -0.0018061605469377898, "vf_loss": 9.31993036976567, "vf_explained_var": -0.013517890405402612, "kl": 0.008396739713539528, "entropy": 1.036755809929005, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5400034849763546, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.78067529718712, "policy_loss": -0.004074976402433422, "vf_loss": 9.782543266134917, "vf_explained_var": -0.010063994466943085, "kl": 0.009808900786774783, "entropy": 1.2243582231027108, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 2009.739815538454, "episode_reward_min": 1446.2145516971595, "episode_reward_mean": 1785.8542054764412, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 116.27656168516637, "predator_policy": 144.56521312559357}, "policy_reward_max": {"prey_policy": 765.7568382729803, "predator_policy": 740.9819151323744}, "policy_reward_mean": {"prey_policy": 462.5908176585202, "predator_policy": 430.3362850797003}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1929.000660260217, 1908.6401135110723, 1799.459916874347, 1846.9364777350124, 1965.9896272427386, 1607.1917047386012, 1567.97135599013, 1576.8960717606676, 1817.2815352390828, 1838.7053679517057, 1699.7550048349528, 1615.8796800837817, 1573.9384826614646, 1888.5104915045627, 1675.2712925284266, 1687.8764231985483, 1876.3658809228032, 1661.4723192311915, 1506.009833756114, 1768.909693156215, 1895.7479972657877, 1922.0080361830808, 1859.2527271967278, 1934.2613914079598, 1867.920371180885, 1701.4976248062826, 1524.7205262180623, 1985.4311303934949, 1913.3605581495751, 1676.9124260232206, 1877.8154927256921, 1568.4007403560436, 1903.1971785429073, 1550.0350932486438, 1836.8118539235563, 1536.9688927253158, 1768.0515464409907, 1807.1568438874133, 1815.7693350800685, 1730.6038495396624, 1953.6682506554419, 1827.0683313599538, 1898.5979641364786, 1917.1739713650493, 1888.8984271676884, 1605.856670135378, 1793.7798431203773, 1802.7293585845327, 1947.7146133883, 1940.439036801598, 1761.2059807471974, 1876.1475466890452, 1809.9666339612245, 1874.690231006228, 1902.70212935795, 1756.8425813836036, 1827.0007336727124, 1898.7986592687423, 2004.1341806436155, 1781.4444552368523, 1707.2419396506086, 1770.1672453227345, 1968.5613843033589, 1873.7959484792236, 1491.9494764713284, 1876.1449700941737, 2009.739815538454, 1895.7453184153828, 1898.4109341184383, 1633.1394414844624, 1446.2145516971595, 1884.7113659826136, 1794.9450710999174, 1619.8524385682388, 1993.2481329506222, 1626.1351439125594, 1956.2041705534014, 1777.3894589410463, 1761.8064536190066, 1653.7686241227655, 1634.818891980241, 1770.3049617050171, 1974.71503560606, 1602.5323971078735, 1736.9322089286318, 1791.8329758791197, 1936.7385410074075, 1982.4629796055403, 1944.1936243128005, 1767.0658975891492, 1726.4809572417594, 1989.1345709918053, 1752.496487875379, 1828.3367835476163, 1658.8819981614313, 1595.1321566357492, 1451.0829525408199, 1644.766582024043, 1838.7844834124742, 1762.7090290066985], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [364.6171071002889, 478.6915039953353, 360.63195531443967, 148.25770905970867, 463.26310287275754, 424.87386178135665, 494.8253936822007, 257.4049299293084, 276.8551496544462, 393.6517587663233, 452.73223049024506, 383.5052831011756, 339.96973829568526, 510.00689058770627, 576.0129518153899, 318.46030506371955, 245.14839259695927, 500.4557706694799, 578.1778100830971, 278.82954634663986, 354.4409371545348, 487.5265736040986, 365.8215049046947, 388.03566834583654, 423.957081579555, 426.888322620569, 575.241605970848, 452.1854914657424, 332.1072001388312, 270.32717687750414, 449.98873339454514, 294.239267837749, 440.76192406139387, 495.460381251464, 257.88636496431803, 372.2378226996478, 562.3008260230558, 116.27656168516637, 602.1217931441794, 530.7519637664444, 487.2936330649755, 401.414876636633, 423.3243131267936, 322.0330547367, 592.5307860347118, 613.5102481996231, 467.290553999579, 490.9025396787835, 618.8710783592164, 544.8751631579848, 344.05931509755317, 403.4337586794336, 416.0949820421673, 477.55866605062437, 453.8890375922885, 604.5245269455302, 360.5718301622745, 707.1236759598886, 307.74467090908905, 444.4036207692579, 445.38171176830747, 387.8502410683299, 211.79761187590213, 534.0321852085539, 590.803343355351, 322.3202373908883, 302.9210008421005, 502.01431813190766, 459.0602328516563, 466.6818343767805, 483.15693355428755, 405.70785463685553, 485.851311289395, 549.388568026954, 412.64948062568607, 438.4038429191896, 553.3792973721847, 376.9066586299317, 505.04539661649716, 479.9446337594027, 438.52070978690006, 334.4602186908664, 588.170424127428, 457.2765143713207, 320.8389992526683, 403.9404932756774, 572.5565633344083, 603.1734683736033, 190.22875802935832, 436.174552153213, 299.43629227487605, 343.3939796766935, 569.8682782016684, 480.2299894769156, 476.52598562036985, 482.1567892107753, 472.7225395674947, 495.6658389873405, 625.300219540131, 383.314280498499, 534.8895521004249, 427.983488954757, 577.3353784573103, 555.8992206395199, 313.480196793848, 556.7785108011423, 503.44409641378314, 457.3725340298076, 479.85716655984925, 430.62428571612867, 481.55117070115995, 545.996635052376, 437.71638325082176, 444.3931893687781, 611.7451116807027, 429.9667225627093, 665.0347396314286, 417.9735210509903, 275.9473840149787, 406.7540031644031, 541.0070377081715, 362.4197767674264, 447.4516265304924, 627.8373929778704, 553.0783120945918, 437.13675930354924, 544.7425143563811, 592.7713026422417, 232.9664561428416, 403.338808291197, 494.40682700165195, 409.6111791457329, 480.1218580181221, 408.0234634050658, 519.8732313587444, 589.367435251579, 399.3631206898792, 426.5990663221594, 384.6313168320651, 598.1980810671363, 315.927021640175, 153.86839751361723, 220.71285800680457, 519.7245589510414, 552.4638259639215, 546.664484136989, 422.0209353436193, 371.8212512376654, 432.942240425901, 445.57125303282027, 369.46238410596607, 281.27036905388496, 457.98679235118834, 510.1734303219644, 721.8571311677724, 603.6120611738219, 614.6716813885321, 630.5158398913374, 617.6826451297919, 504.5594073399731, 561.7453062431609, 765.7568382729803, 577.5264408027898, 456.9809805705822, 738.8119924247012, 683.1696720203583, 509.81688711109564, 223.23973029719434, 484.7132680027195, 542.389733884288, 384.57605189044773, 627.711288928608, 545.3182502114131, 572.3208166982017, 452.1994099616452, 692.1815707083389, 621.9462658666093, 363.4750167399176, 475.07508631079384, 604.7467075243383, 504.7054626871933, 413.54677290070083, 580.8841783672557, 563.1150773623914, 444.63782579425805, 510.9660581223184, 653.4618466455255, 578.4060261657185, 385.39710462560976, 597.6311757366437, 442.4020871442642, 643.2814275093855, 491.25376092159775, 366.1119059227926, 344.9603761451476, 401.295119438897, 551.5454602099773, 479.53040359384227, 390.6938189469686, 575.8083913148515], "policy_predator_policy_reward": [565.4659350039988, 520.2261141605937, 658.768534004552, 740.9819151323744, 496.8155301579415, 414.50742206229285, 614.3793832445313, 480.32677087897184, 612.2659874651864, 683.2167313567791, 479.8927289861899, 291.0614621609893, 290.014130263826, 427.98059684291303, 326.1629523729092, 356.2598625086508, 626.7830680661402, 444.89430390650165, 519.0383392436148, 462.6596722783553, 531.5230316509289, 326.2644624253903, 475.655159577577, 386.3673472556729, 339.35583094263797, 383.73724751870276, 409.17901520943957, 451.9043788585319, 565.5364125346426, 507.30050297744845, 372.3147487330063, 571.3336732332477, 461.6729145604685, 478.47066104947703, 625.0594077921705, 406.2887237750537, 286.39465659315766, 541.037789454734, 344.04211172663116, 291.99382451896196, 507.1272611526482, 499.91222641153223, 619.3601770791785, 557.2904912404099, 329.68758667731623, 323.5241062850795, 479.2348390591418, 496.8334586704538, 453.7419085678265, 250.43222109585787, 493.9011722079429, 460.10337882135224, 311.6456773831196, 319.4212007421528, 473.4703131298777, 453.5472527257994, 507.0709646998011, 338.59408732761267, 486.10695359147456, 438.65718075340027, 475.8500835205595, 568.7334563684932, 360.22914440199105, 462.34179886959635, 574.8162620155343, 415.2573357811363, 390.45871114065267, 354.64106313398486, 502.14389361720583, 408.9258930779143, 238.3302994452336, 409.7738050889388, 354.8685120900594, 377.943155034583, 503.71268345324665, 452.39083688929134, 543.536300689819, 341.94707838813366, 231.11431937333657, 514.4994997904256, 613.4986189227265, 567.188703254948, 510.2328846651302, 271.38850819607734, 628.1007616090877, 545.7177099990436, 267.1876502787255, 474.25628937831095, 606.4888508862656, 656.0062660988506, 501.88442993130195, 461.1419682525053, 361.7367233105443, 381.9448521312502, 422.19213660240223, 421.85444715098777, 470.21275054161384, 509.1134842918548, 440.49160913188757, 491.33292763108216, 388.64738681797894, 409.6855528740357, 449.27077475705164, 293.6421728351645, 468.0098426504029, 471.69808371582957, 364.64933989061143, 549.224260672028, 529.8685770737129, 462.3521000082564, 378.54100987245823, 350.7537657576126, 430.8949640792645, 513.9961969738492, 488.7682569985139, 368.31856802681517, 531.5824405951984, 389.54347936599737, 529.6093039401655, 569.1337641173036, 411.0230890201114, 392.7920361549003, 357.1907990885727, 337.6874267257994, 458.32514509727355, 520.0211678079434, 311.78602952635373, 424.496101954246, 522.5986550454759, 333.0455569918157, 485.020397262147, 487.1065666846385, 556.2484827196364, 565.3460113956301, 371.7104170839811, 414.7942347210793, 575.1903989544825, 497.2583481519155, 379.4094336313291, 270.9006099539312, 492.2738268209381, 484.14530572242916, 628.3653030400892, 515.9086459846786, 331.9705970756077, 363.8461639234009, 407.5214666092768, 418.4887853776779, 522.6519304585402, 592.0827090333578, 470.2445355771129, 505.1578551755949, 463.1908914731616, 524.8530564070866, 289.3579650253096, 162.562301574145, 253.62788939102617, 262.99104294811383, 289.7131371033155, 241.81343454968433, 162.7515343385067, 144.56521312559357, 381.03034592348166, 354.7671944081641, 289.3473375685875, 263.38603359241415, 471.2024047123562, 398.27337498722704, 354.7997408592605, 355.02946618236473, 384.69458986087875, 394.8510451991841, 420.01222271928714, 399.08725137850604, 415.7792435947017, 422.302755340853, 500.1879103169984, 458.5844313892746, 299.8929481852873, 387.35115556872864, 458.81837359804905, 349.4103480558149, 475.975299183075, 369.16001607908055, 365.32661531433365, 431.56598864447005, 345.78168050329265, 250.68723023307962, 324.5306437106504, 351.32307408852773, 268.1609980318686, 241.28764395023055, 283.53863020584134, 310.17865549059076, 502.8423797215899, 395.66870671840894, 348.36886551051686, 459.33975409813667, 365.30293875470056, 430.9038799901782]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.2661807567371297, "mean_inference_ms": 6.0377434060770785, "mean_action_processing_ms": 0.9778174397850168, "mean_env_wait_ms": 0.8643144381625799, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04331016540527344, "StateBufferConnector_ms": 0.015150666236877441, "ViewRequirementAgentConnector_ms": 0.8391939401626587}, "num_episodes": 23, "episode_return_max": 2009.739815538454, "episode_return_min": 1446.2145516971595, "episode_return_mean": 1785.8542054764412, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 82.84024591894465, "num_env_steps_trained_throughput_per_sec": 82.84024591894465, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 111824.251, "restore_workers_time_ms": 0.03, "training_step_time_ms": 111824.147, "sample_time_ms": 9019.005, "learn_time_ms": 102726.325, "learn_throughput": 38.938, "synch_weights_time_ms": 75.725}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "479e5_00000", "date": "2024-08-16_11-58-46", "timestamp": 1723789726, "time_this_iter_s": 48.37667107582092, "time_total_s": 1918.3532266616821, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78774c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1918.3532266616821, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 55.36956521739131, "ram_util_percent": 77.60724637681159}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.413937302871987, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.243350130918795, "policy_loss": -0.0037341872607136056, "vf_loss": 9.246402595156715, "vf_explained_var": -0.038366472689563, "kl": 0.009089773186659742, "entropy": 1.0831574621970061, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3621068665590237, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.807559983692473, "policy_loss": -0.0040644568923328605, "vf_loss": 9.809374104858076, "vf_explained_var": -0.004186135372787557, "kl": 0.010001501604818271, "entropy": 1.168240220521493, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 2077.1832040936406, "episode_reward_min": 1446.2145516971595, "episode_reward_mean": 1792.6203805804764, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 116.27656168516637, "predator_policy": 93.3462650302157}, "policy_reward_max": {"prey_policy": 876.3449924033807, "predator_policy": 656.0062660988506}, "policy_reward_mean": {"prey_policy": 504.5195717265804, "predator_policy": 391.79061856365774}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1506.009833756114, 1768.909693156215, 1895.7479972657877, 1922.0080361830808, 1859.2527271967278, 1934.2613914079598, 1867.920371180885, 1701.4976248062826, 1524.7205262180623, 1985.4311303934949, 1913.3605581495751, 1676.9124260232206, 1877.8154927256921, 1568.4007403560436, 1903.1971785429073, 1550.0350932486438, 1836.8118539235563, 1536.9688927253158, 1768.0515464409907, 1807.1568438874133, 1815.7693350800685, 1730.6038495396624, 1953.6682506554419, 1827.0683313599538, 1898.5979641364786, 1917.1739713650493, 1888.8984271676884, 1605.856670135378, 1793.7798431203773, 1802.7293585845327, 1947.7146133883, 1940.439036801598, 1761.2059807471974, 1876.1475466890452, 1809.9666339612245, 1874.690231006228, 1902.70212935795, 1756.8425813836036, 1827.0007336727124, 1898.7986592687423, 2004.1341806436155, 1781.4444552368523, 1707.2419396506086, 1770.1672453227345, 1968.5613843033589, 1873.7959484792236, 1491.9494764713284, 1876.1449700941737, 2009.739815538454, 1895.7453184153828, 1898.4109341184383, 1633.1394414844624, 1446.2145516971595, 1884.7113659826136, 1794.9450710999174, 1619.8524385682388, 1993.2481329506222, 1626.1351439125594, 1956.2041705534014, 1777.3894589410463, 1761.8064536190066, 1653.7686241227655, 1634.818891980241, 1770.3049617050171, 1974.71503560606, 1602.5323971078735, 1736.9322089286318, 1791.8329758791197, 1936.7385410074075, 1982.4629796055403, 1944.1936243128005, 1767.0658975891492, 1726.4809572417594, 1989.1345709918053, 1752.496487875379, 1828.3367835476163, 1658.8819981614313, 1595.1321566357492, 1451.0829525408199, 1644.766582024043, 1838.7844834124742, 1762.7090290066985, 1616.663991940051, 1868.206268564595, 1867.9743417565694, 1733.775188087702, 1797.0190361638547, 2025.3072316409327, 2077.1832040936406, 1896.9537116924255, 2004.6524913085254, 1675.6693607741138, 1559.9522252934762, 1640.5571241945765, 1729.674497916276, 1782.4192425180174, 1835.5062820732753, 1518.9851819323835, 1908.1041682096993, 1675.1563685127235], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [562.3008260230558, 116.27656168516637, 602.1217931441794, 530.7519637664444, 487.2936330649755, 401.414876636633, 423.3243131267936, 322.0330547367, 592.5307860347118, 613.5102481996231, 467.290553999579, 490.9025396787835, 618.8710783592164, 544.8751631579848, 344.05931509755317, 403.4337586794336, 416.0949820421673, 477.55866605062437, 453.8890375922885, 604.5245269455302, 360.5718301622745, 707.1236759598886, 307.74467090908905, 444.4036207692579, 445.38171176830747, 387.8502410683299, 211.79761187590213, 534.0321852085539, 590.803343355351, 322.3202373908883, 302.9210008421005, 502.01431813190766, 459.0602328516563, 466.6818343767805, 483.15693355428755, 405.70785463685553, 485.851311289395, 549.388568026954, 412.64948062568607, 438.4038429191896, 553.3792973721847, 376.9066586299317, 505.04539661649716, 479.9446337594027, 438.52070978690006, 334.4602186908664, 588.170424127428, 457.2765143713207, 320.8389992526683, 403.9404932756774, 572.5565633344083, 603.1734683736033, 190.22875802935832, 436.174552153213, 299.43629227487605, 343.3939796766935, 569.8682782016684, 480.2299894769156, 476.52598562036985, 482.1567892107753, 472.7225395674947, 495.6658389873405, 625.300219540131, 383.314280498499, 534.8895521004249, 427.983488954757, 577.3353784573103, 555.8992206395199, 313.480196793848, 556.7785108011423, 503.44409641378314, 457.3725340298076, 479.85716655984925, 430.62428571612867, 481.55117070115995, 545.996635052376, 437.71638325082176, 444.3931893687781, 611.7451116807027, 429.9667225627093, 665.0347396314286, 417.9735210509903, 275.9473840149787, 406.7540031644031, 541.0070377081715, 362.4197767674264, 447.4516265304924, 627.8373929778704, 553.0783120945918, 437.13675930354924, 544.7425143563811, 592.7713026422417, 232.9664561428416, 403.338808291197, 494.40682700165195, 409.6111791457329, 480.1218580181221, 408.0234634050658, 519.8732313587444, 589.367435251579, 399.3631206898792, 426.5990663221594, 384.6313168320651, 598.1980810671363, 315.927021640175, 153.86839751361723, 220.71285800680457, 519.7245589510414, 552.4638259639215, 546.664484136989, 422.0209353436193, 371.8212512376654, 432.942240425901, 445.57125303282027, 369.46238410596607, 281.27036905388496, 457.98679235118834, 510.1734303219644, 721.8571311677724, 603.6120611738219, 614.6716813885321, 630.5158398913374, 617.6826451297919, 504.5594073399731, 561.7453062431609, 765.7568382729803, 577.5264408027898, 456.9809805705822, 738.8119924247012, 683.1696720203583, 509.81688711109564, 223.23973029719434, 484.7132680027195, 542.389733884288, 384.57605189044773, 627.711288928608, 545.3182502114131, 572.3208166982017, 452.1994099616452, 692.1815707083389, 621.9462658666093, 363.4750167399176, 475.07508631079384, 604.7467075243383, 504.7054626871933, 413.54677290070083, 580.8841783672557, 563.1150773623914, 444.63782579425805, 510.9660581223184, 653.4618466455255, 578.4060261657185, 385.39710462560976, 597.6311757366437, 442.4020871442642, 643.2814275093855, 491.25376092159775, 366.1119059227926, 344.9603761451476, 401.295119438897, 551.5454602099773, 479.53040359384227, 390.6938189469686, 575.8083913148515, 419.2857018668547, 477.7071837705151, 611.1038529158295, 662.5792080203746, 678.6912443766565, 654.23649194471, 525.460331717686, 876.3449924033807, 670.9332836448787, 710.0121621061292, 693.1963922454706, 599.0774677080806, 850.1173594827678, 475.35165585186337, 427.8341115140131, 682.4508972373347, 645.4080726906137, 712.8137943710751, 514.2891927691653, 664.9416735953031, 482.2122553569844, 543.1682881707476, 607.7629561525032, 697.59722231349, 676.0293450405337, 509.3743017954094, 804.8745497503867, 665.2104951031656, 835.0539988557113, 745.110608616784, 525.878447204822, 611.5021718707698, 529.3735995890249, 584.5243827323015, 557.2371171163416, 692.4834517879523], "policy_predator_policy_reward": [286.39465659315766, 541.037789454734, 344.04211172663116, 291.99382451896196, 507.1272611526482, 499.91222641153223, 619.3601770791785, 557.2904912404099, 329.68758667731623, 323.5241062850795, 479.2348390591418, 496.8334586704538, 453.7419085678265, 250.43222109585787, 493.9011722079429, 460.10337882135224, 311.6456773831196, 319.4212007421528, 473.4703131298777, 453.5472527257994, 507.0709646998011, 338.59408732761267, 486.10695359147456, 438.65718075340027, 475.8500835205595, 568.7334563684932, 360.22914440199105, 462.34179886959635, 574.8162620155343, 415.2573357811363, 390.45871114065267, 354.64106313398486, 502.14389361720583, 408.9258930779143, 238.3302994452336, 409.7738050889388, 354.8685120900594, 377.943155034583, 503.71268345324665, 452.39083688929134, 543.536300689819, 341.94707838813366, 231.11431937333657, 514.4994997904256, 613.4986189227265, 567.188703254948, 510.2328846651302, 271.38850819607734, 628.1007616090877, 545.7177099990436, 267.1876502787255, 474.25628937831095, 606.4888508862656, 656.0062660988506, 501.88442993130195, 461.1419682525053, 361.7367233105443, 381.9448521312502, 422.19213660240223, 421.85444715098777, 470.21275054161384, 509.1134842918548, 440.49160913188757, 491.33292763108216, 388.64738681797894, 409.6855528740357, 449.27077475705164, 293.6421728351645, 468.0098426504029, 471.69808371582957, 364.64933989061143, 549.224260672028, 529.8685770737129, 462.3521000082564, 378.54100987245823, 350.7537657576126, 430.8949640792645, 513.9961969738492, 488.7682569985139, 368.31856802681517, 531.5824405951984, 389.54347936599737, 529.6093039401655, 569.1337641173036, 411.0230890201114, 392.7920361549003, 357.1907990885727, 337.6874267257994, 458.32514509727355, 520.0211678079434, 311.78602952635373, 424.496101954246, 522.5986550454759, 333.0455569918157, 485.020397262147, 487.1065666846385, 556.2484827196364, 565.3460113956301, 371.7104170839811, 414.7942347210793, 575.1903989544825, 497.2583481519155, 379.4094336313291, 270.9006099539312, 492.2738268209381, 484.14530572242916, 628.3653030400892, 515.9086459846786, 331.9705970756077, 363.8461639234009, 407.5214666092768, 418.4887853776779, 522.6519304585402, 592.0827090333578, 470.2445355771129, 505.1578551755949, 463.1908914731616, 524.8530564070866, 289.3579650253096, 162.562301574145, 253.62788939102617, 262.99104294811383, 289.7131371033155, 241.81343454968433, 162.7515343385067, 144.56521312559357, 381.03034592348166, 354.7671944081641, 289.3473375685875, 263.38603359241415, 471.2024047123562, 398.27337498722704, 354.7997408592605, 355.02946618236473, 384.69458986087875, 394.8510451991841, 420.01222271928714, 399.08725137850604, 415.7792435947017, 422.302755340853, 500.1879103169984, 458.5844313892746, 299.8929481852873, 387.35115556872864, 458.81837359804905, 349.4103480558149, 475.975299183075, 369.16001607908055, 365.32661531433365, 431.56598864447005, 345.78168050329265, 250.68723023307962, 324.5306437106504, 351.32307408852773, 268.1609980318686, 241.28764395023055, 283.53863020584134, 310.17865549059076, 502.8423797215899, 395.66870671840894, 348.36886551051686, 459.33975409813667, 365.30293875470056, 430.9038799901782, 317.6657905687325, 402.0053157339493, 351.2823331903925, 243.2408744379952, 251.10714506164604, 283.93946037355744, 201.84565446438947, 130.1242095022477, 247.15707837022825, 168.91651204261728, 394.98255375093566, 338.05081793644734, 372.8628997715272, 378.8512889874775, 329.56092673635067, 457.10777620472686, 374.9982321354159, 271.43239211142327, 247.31437999637757, 249.124114413268, 343.35948935563084, 191.212192410113, 136.9689647775596, 198.22798095102377, 263.44966721335743, 280.82118386697414, 103.86293740830783, 208.47126025615623, 161.99540957056203, 93.3462650302157, 136.5061651633546, 245.0983976934368, 358.5209189850982, 435.6852669032755, 194.8754283010117, 230.5603713074168]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.313659180461491, "mean_inference_ms": 6.157095307050586, "mean_action_processing_ms": 0.9974792727237103, "mean_env_wait_ms": 0.8807515592197822, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.08609509468078613, "StateBufferConnector_ms": 0.015099287033081055, "ViewRequirementAgentConnector_ms": 0.9772523641586304}, "num_episodes": 18, "episode_return_max": 2077.1832040936406, "episode_return_min": 1446.2145516971595, "episode_return_mean": 1792.6203805804764, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 91.63387735930438, "num_env_steps_trained_throughput_per_sec": 91.63387735930438, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 111762.238, "restore_workers_time_ms": 0.031, "training_step_time_ms": 111762.132, "sample_time_ms": 9181.616, "learn_time_ms": 102504.414, "learn_throughput": 39.023, "synch_weights_time_ms": 73.152}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "479e5_00000", "date": "2024-08-16_11-59-30", "timestamp": 1723789770, "time_this_iter_s": 43.66818714141846, "time_total_s": 1962.0214138031006, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78e55e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1962.0214138031006, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 54.670967741935485, "ram_util_percent": 77.2258064516129}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.408923053930676, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.161292056936436, "policy_loss": -0.00813347443029107, "vf_loss": 9.168103847301825, "vf_explained_var": -0.07316515641237693, "kl": 0.017622546319504013, "entropy": 1.1591667027700514, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4738740004086621, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.799385092498133, "policy_loss": -0.003599895417158093, "vf_loss": 9.80124186763057, "vf_explained_var": -0.02757905403142253, "kl": 0.007747189896719689, "entropy": 1.1040646031420067, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 2077.1832040936406, "episode_reward_min": 876.603769134487, "episode_reward_mean": 1784.7111127789715, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 153.86839751361723, "predator_policy": 27.3746493727311}, "policy_reward_max": {"prey_policy": 876.3449924033807, "predator_policy": 656.0062660988506}, "policy_reward_mean": {"prey_policy": 532.8658294315801, "predator_policy": 359.48972695790576}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1768.0515464409907, 1807.1568438874133, 1815.7693350800685, 1730.6038495396624, 1953.6682506554419, 1827.0683313599538, 1898.5979641364786, 1917.1739713650493, 1888.8984271676884, 1605.856670135378, 1793.7798431203773, 1802.7293585845327, 1947.7146133883, 1940.439036801598, 1761.2059807471974, 1876.1475466890452, 1809.9666339612245, 1874.690231006228, 1902.70212935795, 1756.8425813836036, 1827.0007336727124, 1898.7986592687423, 2004.1341806436155, 1781.4444552368523, 1707.2419396506086, 1770.1672453227345, 1968.5613843033589, 1873.7959484792236, 1491.9494764713284, 1876.1449700941737, 2009.739815538454, 1895.7453184153828, 1898.4109341184383, 1633.1394414844624, 1446.2145516971595, 1884.7113659826136, 1794.9450710999174, 1619.8524385682388, 1993.2481329506222, 1626.1351439125594, 1956.2041705534014, 1777.3894589410463, 1761.8064536190066, 1653.7686241227655, 1634.818891980241, 1770.3049617050171, 1974.71503560606, 1602.5323971078735, 1736.9322089286318, 1791.8329758791197, 1936.7385410074075, 1982.4629796055403, 1944.1936243128005, 1767.0658975891492, 1726.4809572417594, 1989.1345709918053, 1752.496487875379, 1828.3367835476163, 1658.8819981614313, 1595.1321566357492, 1451.0829525408199, 1644.766582024043, 1838.7844834124742, 1762.7090290066985, 1616.663991940051, 1868.206268564595, 1867.9743417565694, 1733.775188087702, 1797.0190361638547, 2025.3072316409327, 2077.1832040936406, 1896.9537116924255, 2004.6524913085254, 1675.6693607741138, 1559.9522252934762, 1640.5571241945765, 1729.674497916276, 1782.4192425180174, 1835.5062820732753, 1518.9851819323835, 1908.1041682096993, 1675.1563685127235, 1848.2475025902652, 1909.732471987923, 1866.01550404192, 1727.350291271417, 1792.2781335272334, 1779.8261740857347, 1827.3687758042531, 1600.8302165413104, 1712.3531213712397, 876.603769134487, 1755.320349208999, 1802.8644016709907, 1564.9059327930347, 1819.8560468271694, 1532.575988905127, 1915.683707279501, 1931.8524720489334, 1774.6699280195587], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [485.851311289395, 549.388568026954, 412.64948062568607, 438.4038429191896, 553.3792973721847, 376.9066586299317, 505.04539661649716, 479.9446337594027, 438.52070978690006, 334.4602186908664, 588.170424127428, 457.2765143713207, 320.8389992526683, 403.9404932756774, 572.5565633344083, 603.1734683736033, 190.22875802935832, 436.174552153213, 299.43629227487605, 343.3939796766935, 569.8682782016684, 480.2299894769156, 476.52598562036985, 482.1567892107753, 472.7225395674947, 495.6658389873405, 625.300219540131, 383.314280498499, 534.8895521004249, 427.983488954757, 577.3353784573103, 555.8992206395199, 313.480196793848, 556.7785108011423, 503.44409641378314, 457.3725340298076, 479.85716655984925, 430.62428571612867, 481.55117070115995, 545.996635052376, 437.71638325082176, 444.3931893687781, 611.7451116807027, 429.9667225627093, 665.0347396314286, 417.9735210509903, 275.9473840149787, 406.7540031644031, 541.0070377081715, 362.4197767674264, 447.4516265304924, 627.8373929778704, 553.0783120945918, 437.13675930354924, 544.7425143563811, 592.7713026422417, 232.9664561428416, 403.338808291197, 494.40682700165195, 409.6111791457329, 480.1218580181221, 408.0234634050658, 519.8732313587444, 589.367435251579, 399.3631206898792, 426.5990663221594, 384.6313168320651, 598.1980810671363, 315.927021640175, 153.86839751361723, 220.71285800680457, 519.7245589510414, 552.4638259639215, 546.664484136989, 422.0209353436193, 371.8212512376654, 432.942240425901, 445.57125303282027, 369.46238410596607, 281.27036905388496, 457.98679235118834, 510.1734303219644, 721.8571311677724, 603.6120611738219, 614.6716813885321, 630.5158398913374, 617.6826451297919, 504.5594073399731, 561.7453062431609, 765.7568382729803, 577.5264408027898, 456.9809805705822, 738.8119924247012, 683.1696720203583, 509.81688711109564, 223.23973029719434, 484.7132680027195, 542.389733884288, 384.57605189044773, 627.711288928608, 545.3182502114131, 572.3208166982017, 452.1994099616452, 692.1815707083389, 621.9462658666093, 363.4750167399176, 475.07508631079384, 604.7467075243383, 504.7054626871933, 413.54677290070083, 580.8841783672557, 563.1150773623914, 444.63782579425805, 510.9660581223184, 653.4618466455255, 578.4060261657185, 385.39710462560976, 597.6311757366437, 442.4020871442642, 643.2814275093855, 491.25376092159775, 366.1119059227926, 344.9603761451476, 401.295119438897, 551.5454602099773, 479.53040359384227, 390.6938189469686, 575.8083913148515, 419.2857018668547, 477.7071837705151, 611.1038529158295, 662.5792080203746, 678.6912443766565, 654.23649194471, 525.460331717686, 876.3449924033807, 670.9332836448787, 710.0121621061292, 693.1963922454706, 599.0774677080806, 850.1173594827678, 475.35165585186337, 427.8341115140131, 682.4508972373347, 645.4080726906137, 712.8137943710751, 514.2891927691653, 664.9416735953031, 482.2122553569844, 543.1682881707476, 607.7629561525032, 697.59722231349, 676.0293450405337, 509.3743017954094, 804.8745497503867, 665.2104951031656, 835.0539988557113, 745.110608616784, 525.878447204822, 611.5021718707698, 529.3735995890249, 584.5243827323015, 557.2371171163416, 692.4834517879523, 510.7571549677628, 565.9712323064779, 669.0468907167907, 652.049588570909, 671.912068630321, 567.4142798397634, 576.351937003808, 731.6408060987185, 599.5913304112262, 632.8468599295182, 686.6912504656466, 667.9141231752694, 565.1016951515712, 619.3080997562245, 655.9483651519175, 653.8631658221375, 568.6325060609466, 666.1458426804678, 375.74961507677466, 388.5190731467237, 556.263810119403, 668.9692611105979, 567.1980394680999, 759.0276138797743, 592.1933038064142, 679.2146239881592, 605.1257889387173, 696.8278015519799, 561.2068000340535, 637.8905354886937, 627.9262982977451, 656.4088496550188, 619.9643903095233, 510.3765317678228, 731.2074322135368, 578.6235562902782], "policy_predator_policy_reward": [354.8685120900594, 377.943155034583, 503.71268345324665, 452.39083688929134, 543.536300689819, 341.94707838813366, 231.11431937333657, 514.4994997904256, 613.4986189227265, 567.188703254948, 510.2328846651302, 271.38850819607734, 628.1007616090877, 545.7177099990436, 267.1876502787255, 474.25628937831095, 606.4888508862656, 656.0062660988506, 501.88442993130195, 461.1419682525053, 361.7367233105443, 381.9448521312502, 422.19213660240223, 421.85444715098777, 470.21275054161384, 509.1134842918548, 440.49160913188757, 491.33292763108216, 388.64738681797894, 409.6855528740357, 449.27077475705164, 293.6421728351645, 468.0098426504029, 471.69808371582957, 364.64933989061143, 549.224260672028, 529.8685770737129, 462.3521000082564, 378.54100987245823, 350.7537657576126, 430.8949640792645, 513.9961969738492, 488.7682569985139, 368.31856802681517, 531.5824405951984, 389.54347936599737, 529.6093039401655, 569.1337641173036, 411.0230890201114, 392.7920361549003, 357.1907990885727, 337.6874267257994, 458.32514509727355, 520.0211678079434, 311.78602952635373, 424.496101954246, 522.5986550454759, 333.0455569918157, 485.020397262147, 487.1065666846385, 556.2484827196364, 565.3460113956301, 371.7104170839811, 414.7942347210793, 575.1903989544825, 497.2583481519155, 379.4094336313291, 270.9006099539312, 492.2738268209381, 484.14530572242916, 628.3653030400892, 515.9086459846786, 331.9705970756077, 363.8461639234009, 407.5214666092768, 418.4887853776779, 522.6519304585402, 592.0827090333578, 470.2445355771129, 505.1578551755949, 463.1908914731616, 524.8530564070866, 289.3579650253096, 162.562301574145, 253.62788939102617, 262.99104294811383, 289.7131371033155, 241.81343454968433, 162.7515343385067, 144.56521312559357, 381.03034592348166, 354.7671944081641, 289.3473375685875, 263.38603359241415, 471.2024047123562, 398.27337498722704, 354.7997408592605, 355.02946618236473, 384.69458986087875, 394.8510451991841, 420.01222271928714, 399.08725137850604, 415.7792435947017, 422.302755340853, 500.1879103169984, 458.5844313892746, 299.8929481852873, 387.35115556872864, 458.81837359804905, 349.4103480558149, 475.975299183075, 369.16001607908055, 365.32661531433365, 431.56598864447005, 345.78168050329265, 250.68723023307962, 324.5306437106504, 351.32307408852773, 268.1609980318686, 241.28764395023055, 283.53863020584134, 310.17865549059076, 502.8423797215899, 395.66870671840894, 348.36886551051686, 459.33975409813667, 365.30293875470056, 430.9038799901782, 317.6657905687325, 402.0053157339493, 351.2823331903925, 243.2408744379952, 251.10714506164604, 283.93946037355744, 201.84565446438947, 130.1242095022477, 247.15707837022825, 168.91651204261728, 394.98255375093566, 338.05081793644734, 372.8628997715272, 378.8512889874775, 329.56092673635067, 457.10777620472686, 374.9982321354159, 271.43239211142327, 247.31437999637757, 249.124114413268, 343.35948935563084, 191.212192410113, 136.9689647775596, 198.22798095102377, 263.44966721335743, 280.82118386697414, 103.86293740830783, 208.47126025615623, 161.99540957056203, 93.3462650302157, 136.5061651633546, 245.0983976934368, 358.5209189850982, 435.6852669032755, 194.8754283010117, 230.5603713074168, 387.7986141457379, 383.7205011702869, 274.98838103725825, 313.647611662965, 262.89390734517576, 363.7952482266613, 256.6353011025132, 162.72224706637766, 287.8167762033767, 272.02316698311205, 206.98170169944981, 218.23909874537011, 356.9724593160457, 285.9865215804121, 210.48222734808925, 80.53645821916777, 200.98561094255146, 276.58916168727285, 27.3746493727311, 84.96043153825705, 281.5465698535615, 248.54070812543804, 238.15149998279335, 238.4872483403239, 110.72922801868077, 182.76877697978034, 296.23693346408515, 221.6655228723883, 181.44070095624284, 152.03795242613694, 297.4934541610038, 333.85510516573225, 422.7159614037349, 378.79558856785286, 249.80843741117127, 215.03050210457081]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3616741558071728, "mean_inference_ms": 6.276766396204415, "mean_action_processing_ms": 1.0165815018904514, "mean_env_wait_ms": 0.8969240709988228, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.06567537784576416, "StateBufferConnector_ms": 0.011139154434204102, "ViewRequirementAgentConnector_ms": 0.9516298770904541}, "num_episodes": 18, "episode_return_max": 2077.1832040936406, "episode_return_min": 876.603769134487, "episode_return_mean": 1784.7111127789715, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 124.77030979332065, "num_env_steps_trained_throughput_per_sec": 124.77030979332065, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 110491.512, "restore_workers_time_ms": 0.029, "training_step_time_ms": 110491.412, "sample_time_ms": 9135.71, "learn_time_ms": 101299.415, "learn_throughput": 39.487, "synch_weights_time_ms": 53.41}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "479e5_00000", "date": "2024-08-16_12-00-02", "timestamp": 1723789802, "time_this_iter_s": 32.06807804107666, "time_total_s": 1994.0894918441772, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7f2caf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1994.0894918441772, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 45.90666666666667, "ram_util_percent": 72.9}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2242703059993723, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.240620006076874, "policy_loss": -0.013827607412970374, "vf_loss": 9.252934382706092, "vf_explained_var": -0.024248835397145105, "kl": 0.020176418053918656, "entropy": 1.2013203849868168, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3843960469756176, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.81734391621181, "policy_loss": -0.0036255645918014346, "vf_loss": 9.8189478803564, "vf_explained_var": -0.05024998355164099, "kl": 0.008984796248641045, "entropy": 1.1038016767728895, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 2077.1832040936406, "episode_reward_min": 876.603769134487, "episode_reward_mean": 1772.4377944470284, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 153.86839751361723, "predator_policy": 27.3746493727311}, "policy_reward_max": {"prey_policy": 876.3449924033807, "predator_policy": 628.3653030400892}, "policy_reward_mean": {"prey_policy": 561.5895597273355, "predator_policy": 324.6293374961787}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2004.1341806436155, 1781.4444552368523, 1707.2419396506086, 1770.1672453227345, 1968.5613843033589, 1873.7959484792236, 1491.9494764713284, 1876.1449700941737, 2009.739815538454, 1895.7453184153828, 1898.4109341184383, 1633.1394414844624, 1446.2145516971595, 1884.7113659826136, 1794.9450710999174, 1619.8524385682388, 1993.2481329506222, 1626.1351439125594, 1956.2041705534014, 1777.3894589410463, 1761.8064536190066, 1653.7686241227655, 1634.818891980241, 1770.3049617050171, 1974.71503560606, 1602.5323971078735, 1736.9322089286318, 1791.8329758791197, 1936.7385410074075, 1982.4629796055403, 1944.1936243128005, 1767.0658975891492, 1726.4809572417594, 1989.1345709918053, 1752.496487875379, 1828.3367835476163, 1658.8819981614313, 1595.1321566357492, 1451.0829525408199, 1644.766582024043, 1838.7844834124742, 1762.7090290066985, 1616.663991940051, 1868.206268564595, 1867.9743417565694, 1733.775188087702, 1797.0190361638547, 2025.3072316409327, 2077.1832040936406, 1896.9537116924255, 2004.6524913085254, 1675.6693607741138, 1559.9522252934762, 1640.5571241945765, 1729.674497916276, 1782.4192425180174, 1835.5062820732753, 1518.9851819323835, 1908.1041682096993, 1675.1563685127235, 1848.2475025902652, 1909.732471987923, 1866.01550404192, 1727.350291271417, 1792.2781335272334, 1779.8261740857347, 1827.3687758042531, 1600.8302165413104, 1712.3531213712397, 876.603769134487, 1755.320349208999, 1802.8644016709907, 1564.9059327930347, 1819.8560468271694, 1532.575988905127, 1915.683707279501, 1931.8524720489334, 1774.6699280195587, 1775.9141871700508, 1691.019429031559, 2004.6677695324026, 1478.2740744853425, 1868.3962848317983, 1762.1255956784344, 1758.7881964842095, 1764.1671998139911, 1776.1959375963493, 1665.6494285284216, 1716.4665816006964, 1703.1768088819622, 1846.9418443019504, 1849.073676957736, 1833.6228134284322, 1897.8993825121015, 1675.6412653012198, 1808.4500404765208, 1853.312569926621, 1804.9212105986778, 1756.1186847734145, 1886.7077226434424], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [665.0347396314286, 417.9735210509903, 275.9473840149787, 406.7540031644031, 541.0070377081715, 362.4197767674264, 447.4516265304924, 627.8373929778704, 553.0783120945918, 437.13675930354924, 544.7425143563811, 592.7713026422417, 232.9664561428416, 403.338808291197, 494.40682700165195, 409.6111791457329, 480.1218580181221, 408.0234634050658, 519.8732313587444, 589.367435251579, 399.3631206898792, 426.5990663221594, 384.6313168320651, 598.1980810671363, 315.927021640175, 153.86839751361723, 220.71285800680457, 519.7245589510414, 552.4638259639215, 546.664484136989, 422.0209353436193, 371.8212512376654, 432.942240425901, 445.57125303282027, 369.46238410596607, 281.27036905388496, 457.98679235118834, 510.1734303219644, 721.8571311677724, 603.6120611738219, 614.6716813885321, 630.5158398913374, 617.6826451297919, 504.5594073399731, 561.7453062431609, 765.7568382729803, 577.5264408027898, 456.9809805705822, 738.8119924247012, 683.1696720203583, 509.81688711109564, 223.23973029719434, 484.7132680027195, 542.389733884288, 384.57605189044773, 627.711288928608, 545.3182502114131, 572.3208166982017, 452.1994099616452, 692.1815707083389, 621.9462658666093, 363.4750167399176, 475.07508631079384, 604.7467075243383, 504.7054626871933, 413.54677290070083, 580.8841783672557, 563.1150773623914, 444.63782579425805, 510.9660581223184, 653.4618466455255, 578.4060261657185, 385.39710462560976, 597.6311757366437, 442.4020871442642, 643.2814275093855, 491.25376092159775, 366.1119059227926, 344.9603761451476, 401.295119438897, 551.5454602099773, 479.53040359384227, 390.6938189469686, 575.8083913148515, 419.2857018668547, 477.7071837705151, 611.1038529158295, 662.5792080203746, 678.6912443766565, 654.23649194471, 525.460331717686, 876.3449924033807, 670.9332836448787, 710.0121621061292, 693.1963922454706, 599.0774677080806, 850.1173594827678, 475.35165585186337, 427.8341115140131, 682.4508972373347, 645.4080726906137, 712.8137943710751, 514.2891927691653, 664.9416735953031, 482.2122553569844, 543.1682881707476, 607.7629561525032, 697.59722231349, 676.0293450405337, 509.3743017954094, 804.8745497503867, 665.2104951031656, 835.0539988557113, 745.110608616784, 525.878447204822, 611.5021718707698, 529.3735995890249, 584.5243827323015, 557.2371171163416, 692.4834517879523, 510.7571549677628, 565.9712323064779, 669.0468907167907, 652.049588570909, 671.912068630321, 567.4142798397634, 576.351937003808, 731.6408060987185, 599.5913304112262, 632.8468599295182, 686.6912504656466, 667.9141231752694, 565.1016951515712, 619.3080997562245, 655.9483651519175, 653.8631658221375, 568.6325060609466, 666.1458426804678, 375.74961507677466, 388.5190731467237, 556.263810119403, 668.9692611105979, 567.1980394680999, 759.0276138797743, 592.1933038064142, 679.2146239881592, 605.1257889387173, 696.8278015519799, 561.2068000340535, 637.8905354886937, 627.9262982977451, 656.4088496550188, 619.9643903095233, 510.3765317678228, 731.2074322135368, 578.6235562902782, 525.061004932368, 643.0153187985711, 710.4874692770466, 602.6731015897103, 547.5378709307514, 636.8102923036255, 608.904764053984, 573.7244424463281, 669.4363863018417, 573.3306931806226, 540.8280294861978, 693.361497667106, 610.4306427581087, 627.6276672278234, 599.2128249918657, 525.9907864039565, 593.620608651625, 616.2377108593416, 705.12382881455, 685.0708830101828, 494.51326039419314, 636.8214899365668, 419.6041619497203, 663.1464457983301, 610.8977215324063, 449.2435671517974, 709.9387362304593, 607.4611823984696, 689.2001473922558, 606.4649269099998, 418.3665152106753, 582.5221222008157, 560.2229755544487, 596.1345735861315, 561.6640331738114, 605.9925127377007, 501.91804040124026, 623.011173096734, 604.4570760581423, 525.4878893165203, 625.5472728158827, 621.2407902457577, 577.1911084299671, 729.7702397160335], "policy_predator_policy_reward": [531.5824405951984, 389.54347936599737, 529.6093039401655, 569.1337641173036, 411.0230890201114, 392.7920361549003, 357.1907990885727, 337.6874267257994, 458.32514509727355, 520.0211678079434, 311.78602952635373, 424.496101954246, 522.5986550454759, 333.0455569918157, 485.020397262147, 487.1065666846385, 556.2484827196364, 565.3460113956301, 371.7104170839811, 414.7942347210793, 575.1903989544825, 497.2583481519155, 379.4094336313291, 270.9006099539312, 492.2738268209381, 484.14530572242916, 628.3653030400892, 515.9086459846786, 331.9705970756077, 363.8461639234009, 407.5214666092768, 418.4887853776779, 522.6519304585402, 592.0827090333578, 470.2445355771129, 505.1578551755949, 463.1908914731616, 524.8530564070866, 289.3579650253096, 162.562301574145, 253.62788939102617, 262.99104294811383, 289.7131371033155, 241.81343454968433, 162.7515343385067, 144.56521312559357, 381.03034592348166, 354.7671944081641, 289.3473375685875, 263.38603359241415, 471.2024047123562, 398.27337498722704, 354.7997408592605, 355.02946618236473, 384.69458986087875, 394.8510451991841, 420.01222271928714, 399.08725137850604, 415.7792435947017, 422.302755340853, 500.1879103169984, 458.5844313892746, 299.8929481852873, 387.35115556872864, 458.81837359804905, 349.4103480558149, 475.975299183075, 369.16001607908055, 365.32661531433365, 431.56598864447005, 345.78168050329265, 250.68723023307962, 324.5306437106504, 351.32307408852773, 268.1609980318686, 241.28764395023055, 283.53863020584134, 310.17865549059076, 502.8423797215899, 395.66870671840894, 348.36886551051686, 459.33975409813667, 365.30293875470056, 430.9038799901782, 317.6657905687325, 402.0053157339493, 351.2823331903925, 243.2408744379952, 251.10714506164604, 283.93946037355744, 201.84565446438947, 130.1242095022477, 247.15707837022825, 168.91651204261728, 394.98255375093566, 338.05081793644734, 372.8628997715272, 378.8512889874775, 329.56092673635067, 457.10777620472686, 374.9982321354159, 271.43239211142327, 247.31437999637757, 249.124114413268, 343.35948935563084, 191.212192410113, 136.9689647775596, 198.22798095102377, 263.44966721335743, 280.82118386697414, 103.86293740830783, 208.47126025615623, 161.99540957056203, 93.3462650302157, 136.5061651633546, 245.0983976934368, 358.5209189850982, 435.6852669032755, 194.8754283010117, 230.5603713074168, 387.7986141457379, 383.7205011702869, 274.98838103725825, 313.647611662965, 262.89390734517576, 363.7952482266613, 256.6353011025132, 162.72224706637766, 287.8167762033767, 272.02316698311205, 206.98170169944981, 218.23909874537011, 356.9724593160457, 285.9865215804121, 210.48222734808925, 80.53645821916777, 200.98561094255146, 276.58916168727285, 27.3746493727311, 84.96043153825705, 281.5465698535615, 248.54070812543804, 238.15149998279335, 238.4872483403239, 110.72922801868077, 182.76877697978034, 296.23693346408515, 221.6655228723883, 181.44070095624284, 152.03795242613694, 297.4934541610038, 333.85510516573225, 422.7159614037349, 378.79558856785286, 249.80843741117127, 215.03050210457081, 234.88493733002323, 372.95292610908837, 178.19637331612267, 199.66248484867643, 390.98110807403594, 429.3384982239881, 138.49614470882028, 157.14872327621134, 407.1039570073136, 218.5252483420209, 269.4489415520483, 258.48712697308315, 215.74587277978344, 304.98401371849377, 274.67039107669467, 364.2931973414753, 308.3532727533498, 257.9843453320356, 182.60325452627217, 92.85146217741696, 253.8847090876312, 331.2471221823048, 267.40614441527487, 353.020056718635, 330.2692063041074, 456.5313493136365, 309.2678489270043, 222.40590940180329, 274.8054388753378, 263.1523002508378, 438.94507771049456, 458.06566739011777, 237.08417311580442, 282.19954304483934, 298.34444024983316, 342.44905431517697, 363.87759770888215, 364.5057587197661, 267.5573333336945, 407.4189118903203, 188.27953845595653, 321.05108325581637, 345.72564542684233, 234.02072907059915]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.427297227236585, "mean_inference_ms": 6.42834188528153, "mean_action_processing_ms": 1.0402723685586852, "mean_env_wait_ms": 0.9174258758495049, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0880807638168335, "StateBufferConnector_ms": 0.0158766508102417, "ViewRequirementAgentConnector_ms": 1.080979824066162}, "num_episodes": 22, "episode_return_max": 2077.1832040936406, "episode_return_min": 876.603769134487, "episode_return_mean": 1772.4377944470284, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 126.51249272724658, "num_env_steps_trained_throughput_per_sec": 126.51249272724658, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 109429.879, "restore_workers_time_ms": 0.027, "training_step_time_ms": 109429.784, "sample_time_ms": 9174.602, "learn_time_ms": 100213.237, "learn_throughput": 39.915, "synch_weights_time_ms": 39.234}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "479e5_00000", "date": "2024-08-16_12-00-33", "timestamp": 1723789833, "time_this_iter_s": 31.62524437904358, "time_total_s": 2025.7147362232208, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78b93a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2025.7147362232208, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 46.16888888888889, "ram_util_percent": 75.13333333333331}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0158315326486314, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.54173200445831, "policy_loss": -0.003422280307612801, "vf_loss": 9.543116125480207, "vf_explained_var": -0.01623354131582553, "kl": 0.01811685838638209, "entropy": 1.2384336887844025, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5438272761289404, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.685686418240664, "policy_loss": 0.0002656131000972535, "vf_loss": 9.682359218597412, "vf_explained_var": -0.03148735704876128, "kl": 0.013607055584551572, "entropy": 1.0687944905152396, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 2077.1832040936406, "episode_reward_min": 876.603769134487, "episode_reward_mean": 1782.1852461279072, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 223.23973029719434, "predator_policy": 27.3746493727311}, "policy_reward_max": {"prey_policy": 876.3449924033807, "predator_policy": 643.7166699546436}, "policy_reward_mean": {"prey_policy": 573.6604571330978, "predator_policy": 317.43216593085594}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1770.3049617050171, 1974.71503560606, 1602.5323971078735, 1736.9322089286318, 1791.8329758791197, 1936.7385410074075, 1982.4629796055403, 1944.1936243128005, 1767.0658975891492, 1726.4809572417594, 1989.1345709918053, 1752.496487875379, 1828.3367835476163, 1658.8819981614313, 1595.1321566357492, 1451.0829525408199, 1644.766582024043, 1838.7844834124742, 1762.7090290066985, 1616.663991940051, 1868.206268564595, 1867.9743417565694, 1733.775188087702, 1797.0190361638547, 2025.3072316409327, 2077.1832040936406, 1896.9537116924255, 2004.6524913085254, 1675.6693607741138, 1559.9522252934762, 1640.5571241945765, 1729.674497916276, 1782.4192425180174, 1835.5062820732753, 1518.9851819323835, 1908.1041682096993, 1675.1563685127235, 1848.2475025902652, 1909.732471987923, 1866.01550404192, 1727.350291271417, 1792.2781335272334, 1779.8261740857347, 1827.3687758042531, 1600.8302165413104, 1712.3531213712397, 876.603769134487, 1755.320349208999, 1802.8644016709907, 1564.9059327930347, 1819.8560468271694, 1532.575988905127, 1915.683707279501, 1931.8524720489334, 1774.6699280195587, 1775.9141871700508, 1691.019429031559, 2004.6677695324026, 1478.2740744853425, 1868.3962848317983, 1762.1255956784344, 1758.7881964842095, 1764.1671998139911, 1776.1959375963493, 1665.6494285284216, 1716.4665816006964, 1703.1768088819622, 1846.9418443019504, 1849.073676957736, 1833.6228134284322, 1897.8993825121015, 1675.6412653012198, 1808.4500404765208, 1853.312569926621, 1804.9212105986778, 1756.1186847734145, 1886.7077226434424, 1806.8175236918003, 1891.5745509368905, 1871.2318909193448, 1847.9129882327456, 1937.788281239231, 1944.180857418237, 1894.2751217158304, 1873.1545683260117, 1625.381106428532, 1848.694968751886, 1813.4231450897441, 1816.6325741772584, 1875.847578141836, 1876.3633306689944, 1852.9094205973825, 1814.8958303206082, 1789.5040776800931, 1763.0939971551948, 1656.9430505061573, 1871.7573874011316, 1750.0028429670806, 1820.4135387831768, 1791.515950124929], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [577.5264408027898, 456.9809805705822, 738.8119924247012, 683.1696720203583, 509.81688711109564, 223.23973029719434, 484.7132680027195, 542.389733884288, 384.57605189044773, 627.711288928608, 545.3182502114131, 572.3208166982017, 452.1994099616452, 692.1815707083389, 621.9462658666093, 363.4750167399176, 475.07508631079384, 604.7467075243383, 504.7054626871933, 413.54677290070083, 580.8841783672557, 563.1150773623914, 444.63782579425805, 510.9660581223184, 653.4618466455255, 578.4060261657185, 385.39710462560976, 597.6311757366437, 442.4020871442642, 643.2814275093855, 491.25376092159775, 366.1119059227926, 344.9603761451476, 401.295119438897, 551.5454602099773, 479.53040359384227, 390.6938189469686, 575.8083913148515, 419.2857018668547, 477.7071837705151, 611.1038529158295, 662.5792080203746, 678.6912443766565, 654.23649194471, 525.460331717686, 876.3449924033807, 670.9332836448787, 710.0121621061292, 693.1963922454706, 599.0774677080806, 850.1173594827678, 475.35165585186337, 427.8341115140131, 682.4508972373347, 645.4080726906137, 712.8137943710751, 514.2891927691653, 664.9416735953031, 482.2122553569844, 543.1682881707476, 607.7629561525032, 697.59722231349, 676.0293450405337, 509.3743017954094, 804.8745497503867, 665.2104951031656, 835.0539988557113, 745.110608616784, 525.878447204822, 611.5021718707698, 529.3735995890249, 584.5243827323015, 557.2371171163416, 692.4834517879523, 510.7571549677628, 565.9712323064779, 669.0468907167907, 652.049588570909, 671.912068630321, 567.4142798397634, 576.351937003808, 731.6408060987185, 599.5913304112262, 632.8468599295182, 686.6912504656466, 667.9141231752694, 565.1016951515712, 619.3080997562245, 655.9483651519175, 653.8631658221375, 568.6325060609466, 666.1458426804678, 375.74961507677466, 388.5190731467237, 556.263810119403, 668.9692611105979, 567.1980394680999, 759.0276138797743, 592.1933038064142, 679.2146239881592, 605.1257889387173, 696.8278015519799, 561.2068000340535, 637.8905354886937, 627.9262982977451, 656.4088496550188, 619.9643903095233, 510.3765317678228, 731.2074322135368, 578.6235562902782, 525.061004932368, 643.0153187985711, 710.4874692770466, 602.6731015897103, 547.5378709307514, 636.8102923036255, 608.904764053984, 573.7244424463281, 669.4363863018417, 573.3306931806226, 540.8280294861978, 693.361497667106, 610.4306427581087, 627.6276672278234, 599.2128249918657, 525.9907864039565, 593.620608651625, 616.2377108593416, 705.12382881455, 685.0708830101828, 494.51326039419314, 636.8214899365668, 419.6041619497203, 663.1464457983301, 610.8977215324063, 449.2435671517974, 709.9387362304593, 607.4611823984696, 689.2001473922558, 606.4649269099998, 418.3665152106753, 582.5221222008157, 560.2229755544487, 596.1345735861315, 561.6640331738114, 605.9925127377007, 501.91804040124026, 623.011173096734, 604.4570760581423, 525.4878893165203, 625.5472728158827, 621.2407902457577, 577.1911084299671, 729.7702397160335, 558.5081002917804, 565.2929791572247, 392.82334768634024, 683.4963807581063, 525.8435197946702, 671.0907809202, 539.0352431700603, 460.1364026337903, 396.22636558869436, 608.5169006368939, 625.3182010074066, 444.92865959366196, 585.9082122256874, 344.01524026107523, 590.6735297070015, 408.31330847035133, 490.91029239593337, 617.3269308266349, 470.3797238978903, 399.17834951197983, 532.4465065147004, 571.9796499915434, 566.9047591674138, 567.5787381332534, 487.2898004921075, 532.7383058584373, 515.5458442798772, 589.4784135315656, 703.8427993289832, 712.3544076333538, 499.0937775974004, 442.0898825817963, 730.7557849603271, 575.756245991181, 534.3508185617923, 645.4701994146109, 476.19280241965646, 552.9916264690947, 521.1135776635259, 425.388390261394, 561.6505605921024, 400.8275330001355, 468.005624944122, 225.48493391024704, 427.71336484439496, 608.8785909356883], "policy_predator_policy_reward": [381.03034592348166, 354.7671944081641, 289.3473375685875, 263.38603359241415, 471.2024047123562, 398.27337498722704, 354.7997408592605, 355.02946618236473, 384.69458986087875, 394.8510451991841, 420.01222271928714, 399.08725137850604, 415.7792435947017, 422.302755340853, 500.1879103169984, 458.5844313892746, 299.8929481852873, 387.35115556872864, 458.81837359804905, 349.4103480558149, 475.975299183075, 369.16001607908055, 365.32661531433365, 431.56598864447005, 345.78168050329265, 250.68723023307962, 324.5306437106504, 351.32307408852773, 268.1609980318686, 241.28764395023055, 283.53863020584134, 310.17865549059076, 502.8423797215899, 395.66870671840894, 348.36886551051686, 459.33975409813667, 365.30293875470056, 430.9038799901782, 317.6657905687325, 402.0053157339493, 351.2823331903925, 243.2408744379952, 251.10714506164604, 283.93946037355744, 201.84565446438947, 130.1242095022477, 247.15707837022825, 168.91651204261728, 394.98255375093566, 338.05081793644734, 372.8628997715272, 378.8512889874775, 329.56092673635067, 457.10777620472686, 374.9982321354159, 271.43239211142327, 247.31437999637757, 249.124114413268, 343.35948935563084, 191.212192410113, 136.9689647775596, 198.22798095102377, 263.44966721335743, 280.82118386697414, 103.86293740830783, 208.47126025615623, 161.99540957056203, 93.3462650302157, 136.5061651633546, 245.0983976934368, 358.5209189850982, 435.6852669032755, 194.8754283010117, 230.5603713074168, 387.7986141457379, 383.7205011702869, 274.98838103725825, 313.647611662965, 262.89390734517576, 363.7952482266613, 256.6353011025132, 162.72224706637766, 287.8167762033767, 272.02316698311205, 206.98170169944981, 218.23909874537011, 356.9724593160457, 285.9865215804121, 210.48222734808925, 80.53645821916777, 200.98561094255146, 276.58916168727285, 27.3746493727311, 84.96043153825705, 281.5465698535615, 248.54070812543804, 238.15149998279335, 238.4872483403239, 110.72922801868077, 182.76877697978034, 296.23693346408515, 221.6655228723883, 181.44070095624284, 152.03795242613694, 297.4934541610038, 333.85510516573225, 422.7159614037349, 378.79558856785286, 249.80843741117127, 215.03050210457081, 234.88493733002323, 372.95292610908837, 178.19637331612267, 199.66248484867643, 390.98110807403594, 429.3384982239881, 138.49614470882028, 157.14872327621134, 407.1039570073136, 218.5252483420209, 269.4489415520483, 258.48712697308315, 215.74587277978344, 304.98401371849377, 274.67039107669467, 364.2931973414753, 308.3532727533498, 257.9843453320356, 182.60325452627217, 92.85146217741696, 253.8847090876312, 331.2471221823048, 267.40614441527487, 353.020056718635, 330.2692063041074, 456.5313493136365, 309.2678489270043, 222.40590940180329, 274.8054388753378, 263.1523002508378, 438.94507771049456, 458.06566739011777, 237.08417311580442, 282.19954304483934, 298.34444024983316, 342.44905431517697, 363.87759770888215, 364.5057587197661, 267.5573333336945, 407.4189118903203, 188.27953845595653, 321.05108325581637, 345.72564542684233, 234.02072907059915, 338.7682779935867, 344.2481662492086, 435.58637570424065, 379.66844678820445, 442.75683911925876, 231.54075108521477, 441.9944960892789, 406.74684633961726, 475.45446864623034, 457.5905463674159, 410.5609769082019, 463.3730199089677, 513.6755854198273, 450.6760838092433, 417.86171636367465, 456.30601378498574, 269.4110631810989, 247.7328200248667, 603.2664700907403, 375.8704252512744, 249.42534376537913, 459.5716448181218, 372.8697237323458, 309.2793531442442, 456.5338411631565, 399.2856306281327, 333.71573981988604, 437.6233330376681, 174.19961265370122, 262.51260098134344, 349.37780856247946, 524.3343615789289, 298.305128966528, 184.6869177620586, 246.15395397110828, 337.1190252076858, 360.0138065336678, 267.7448150837387, 427.99623047072834, 497.2591890054846, 346.08576118486724, 441.4389881899732, 643.7166699546436, 483.20630997416464, 375.9813415227292, 378.94265282211535]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.484611008154741, "mean_inference_ms": 6.568289427237142, "mean_action_processing_ms": 1.0634126558363206, "mean_env_wait_ms": 0.9344122490129877, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.08636033535003662, "StateBufferConnector_ms": 0.013701081275939941, "ViewRequirementAgentConnector_ms": 1.0471259355545044}, "num_episodes": 23, "episode_return_max": 2077.1832040936406, "episode_return_min": 876.603769134487, "episode_return_mean": 1782.1852461279072, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 137.43822445567724, "num_env_steps_trained_throughput_per_sec": 137.43822445567724, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 107794.026, "restore_workers_time_ms": 0.026, "training_step_time_ms": 107793.935, "sample_time_ms": 8929.772, "learn_time_ms": 98822.19, "learn_throughput": 40.477, "synch_weights_time_ms": 39.539}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "479e5_00000", "date": "2024-08-16_12-01-03", "timestamp": 1723789863, "time_this_iter_s": 29.114296674728394, "time_total_s": 2054.829032897949, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78b9f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2054.829032897949, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 43.41463414634146, "ram_util_percent": 75.24146341463414}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6823893552734739, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.67280493741313, "policy_loss": -0.0033598172305910677, "vf_loss": 9.674860267538243, "vf_explained_var": -0.028883546653878753, "kl": 0.011595466046905726, "entropy": 1.2249320174020435, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7059091698398035, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.576078845331908, "policy_loss": 0.0021386255867404756, "vf_loss": 9.570853295401921, "vf_explained_var": -0.04030635776343169, "kl": 0.013719746375659116, "entropy": 1.060293826381996, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 2077.1832040936406, "episode_reward_min": 876.603769134487, "episode_reward_mean": 1795.7838559397046, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 225.48493391024704, "predator_policy": 27.3746493727311}, "policy_reward_max": {"prey_policy": 876.3449924033807, "predator_policy": 739.6081766279366}, "policy_reward_mean": {"prey_policy": 556.3196320293509, "predator_policy": 341.57229594050136}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1762.7090290066985, 1616.663991940051, 1868.206268564595, 1867.9743417565694, 1733.775188087702, 1797.0190361638547, 2025.3072316409327, 2077.1832040936406, 1896.9537116924255, 2004.6524913085254, 1675.6693607741138, 1559.9522252934762, 1640.5571241945765, 1729.674497916276, 1782.4192425180174, 1835.5062820732753, 1518.9851819323835, 1908.1041682096993, 1675.1563685127235, 1848.2475025902652, 1909.732471987923, 1866.01550404192, 1727.350291271417, 1792.2781335272334, 1779.8261740857347, 1827.3687758042531, 1600.8302165413104, 1712.3531213712397, 876.603769134487, 1755.320349208999, 1802.8644016709907, 1564.9059327930347, 1819.8560468271694, 1532.575988905127, 1915.683707279501, 1931.8524720489334, 1774.6699280195587, 1775.9141871700508, 1691.019429031559, 2004.6677695324026, 1478.2740744853425, 1868.3962848317983, 1762.1255956784344, 1758.7881964842095, 1764.1671998139911, 1776.1959375963493, 1665.6494285284216, 1716.4665816006964, 1703.1768088819622, 1846.9418443019504, 1849.073676957736, 1833.6228134284322, 1897.8993825121015, 1675.6412653012198, 1808.4500404765208, 1853.312569926621, 1804.9212105986778, 1756.1186847734145, 1886.7077226434424, 1806.8175236918003, 1891.5745509368905, 1871.2318909193448, 1847.9129882327456, 1937.788281239231, 1944.180857418237, 1894.2751217158304, 1873.1545683260117, 1625.381106428532, 1848.694968751886, 1813.4231450897441, 1816.6325741772584, 1875.847578141836, 1876.3633306689944, 1852.9094205973825, 1814.8958303206082, 1789.5040776800931, 1763.0939971551948, 1656.9430505061573, 1871.7573874011316, 1750.0028429670806, 1820.4135387831768, 1791.515950124929, 1916.618611792215, 1970.8636980978251, 1786.9387548372124, 1768.3189588559492, 1966.3341013298154, 1719.7686461735154, 1835.8074986636057, 1863.72325078339, 1801.3516338801217, 1806.430804748189, 1909.3165131566884, 1917.0460093839592, 1656.2149364944719, 1983.0765000615445, 1866.5349439088136, 1974.2537639493098, 1674.9532585045988, 1934.1846907311697], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [390.6938189469686, 575.8083913148515, 419.2857018668547, 477.7071837705151, 611.1038529158295, 662.5792080203746, 678.6912443766565, 654.23649194471, 525.460331717686, 876.3449924033807, 670.9332836448787, 710.0121621061292, 693.1963922454706, 599.0774677080806, 850.1173594827678, 475.35165585186337, 427.8341115140131, 682.4508972373347, 645.4080726906137, 712.8137943710751, 514.2891927691653, 664.9416735953031, 482.2122553569844, 543.1682881707476, 607.7629561525032, 697.59722231349, 676.0293450405337, 509.3743017954094, 804.8745497503867, 665.2104951031656, 835.0539988557113, 745.110608616784, 525.878447204822, 611.5021718707698, 529.3735995890249, 584.5243827323015, 557.2371171163416, 692.4834517879523, 510.7571549677628, 565.9712323064779, 669.0468907167907, 652.049588570909, 671.912068630321, 567.4142798397634, 576.351937003808, 731.6408060987185, 599.5913304112262, 632.8468599295182, 686.6912504656466, 667.9141231752694, 565.1016951515712, 619.3080997562245, 655.9483651519175, 653.8631658221375, 568.6325060609466, 666.1458426804678, 375.74961507677466, 388.5190731467237, 556.263810119403, 668.9692611105979, 567.1980394680999, 759.0276138797743, 592.1933038064142, 679.2146239881592, 605.1257889387173, 696.8278015519799, 561.2068000340535, 637.8905354886937, 627.9262982977451, 656.4088496550188, 619.9643903095233, 510.3765317678228, 731.2074322135368, 578.6235562902782, 525.061004932368, 643.0153187985711, 710.4874692770466, 602.6731015897103, 547.5378709307514, 636.8102923036255, 608.904764053984, 573.7244424463281, 669.4363863018417, 573.3306931806226, 540.8280294861978, 693.361497667106, 610.4306427581087, 627.6276672278234, 599.2128249918657, 525.9907864039565, 593.620608651625, 616.2377108593416, 705.12382881455, 685.0708830101828, 494.51326039419314, 636.8214899365668, 419.6041619497203, 663.1464457983301, 610.8977215324063, 449.2435671517974, 709.9387362304593, 607.4611823984696, 689.2001473922558, 606.4649269099998, 418.3665152106753, 582.5221222008157, 560.2229755544487, 596.1345735861315, 561.6640331738114, 605.9925127377007, 501.91804040124026, 623.011173096734, 604.4570760581423, 525.4878893165203, 625.5472728158827, 621.2407902457577, 577.1911084299671, 729.7702397160335, 558.5081002917804, 565.2929791572247, 392.82334768634024, 683.4963807581063, 525.8435197946702, 671.0907809202, 539.0352431700603, 460.1364026337903, 396.22636558869436, 608.5169006368939, 625.3182010074066, 444.92865959366196, 585.9082122256874, 344.01524026107523, 590.6735297070015, 408.31330847035133, 490.91029239593337, 617.3269308266349, 470.3797238978903, 399.17834951197983, 532.4465065147004, 571.9796499915434, 566.9047591674138, 567.5787381332534, 487.2898004921075, 532.7383058584373, 515.5458442798772, 589.4784135315656, 703.8427993289832, 712.3544076333538, 499.0937775974004, 442.0898825817963, 730.7557849603271, 575.756245991181, 534.3508185617923, 645.4701994146109, 476.19280241965646, 552.9916264690947, 521.1135776635259, 425.388390261394, 561.6505605921024, 400.8275330001355, 468.005624944122, 225.48493391024704, 427.71336484439496, 608.8785909356883, 401.77842122678203, 647.0869168186365, 429.00353848475606, 479.3443550795315, 320.11937554359645, 254.49037341172945, 351.6705368099942, 371.7513768215564, 497.8789648737774, 465.77937479810805, 434.77460770879077, 316.06599194757854, 463.7852242535871, 333.1929319545736, 534.802121440981, 425.67710681346983, 542.1453615731348, 411.47511942713857, 535.6991741963376, 347.9134186499456, 334.0516132433728, 298.6492414407608, 430.7564721293419, 519.7440372137132, 475.43560617462833, 256.65571289266893, 528.0990960122314, 360.16194673787237, 487.93940987499036, 228.9387290590734, 467.3239116221072, 554.4266559288374, 369.5763930037231, 380.7233112303898, 336.5597677232284, 447.6900223772495], "policy_predator_policy_reward": [365.30293875470056, 430.9038799901782, 317.6657905687325, 402.0053157339493, 351.2823331903925, 243.2408744379952, 251.10714506164604, 283.93946037355744, 201.84565446438947, 130.1242095022477, 247.15707837022825, 168.91651204261728, 394.98255375093566, 338.05081793644734, 372.8628997715272, 378.8512889874775, 329.56092673635067, 457.10777620472686, 374.9982321354159, 271.43239211142327, 247.31437999637757, 249.124114413268, 343.35948935563084, 191.212192410113, 136.9689647775596, 198.22798095102377, 263.44966721335743, 280.82118386697414, 103.86293740830783, 208.47126025615623, 161.99540957056203, 93.3462650302157, 136.5061651633546, 245.0983976934368, 358.5209189850982, 435.6852669032755, 194.8754283010117, 230.5603713074168, 387.7986141457379, 383.7205011702869, 274.98838103725825, 313.647611662965, 262.89390734517576, 363.7952482266613, 256.6353011025132, 162.72224706637766, 287.8167762033767, 272.02316698311205, 206.98170169944981, 218.23909874537011, 356.9724593160457, 285.9865215804121, 210.48222734808925, 80.53645821916777, 200.98561094255146, 276.58916168727285, 27.3746493727311, 84.96043153825705, 281.5465698535615, 248.54070812543804, 238.15149998279335, 238.4872483403239, 110.72922801868077, 182.76877697978034, 296.23693346408515, 221.6655228723883, 181.44070095624284, 152.03795242613694, 297.4934541610038, 333.85510516573225, 422.7159614037349, 378.79558856785286, 249.80843741117127, 215.03050210457081, 234.88493733002323, 372.95292610908837, 178.19637331612267, 199.66248484867643, 390.98110807403594, 429.3384982239881, 138.49614470882028, 157.14872327621134, 407.1039570073136, 218.5252483420209, 269.4489415520483, 258.48712697308315, 215.74587277978344, 304.98401371849377, 274.67039107669467, 364.2931973414753, 308.3532727533498, 257.9843453320356, 182.60325452627217, 92.85146217741696, 253.8847090876312, 331.2471221823048, 267.40614441527487, 353.020056718635, 330.2692063041074, 456.5313493136365, 309.2678489270043, 222.40590940180329, 274.8054388753378, 263.1523002508378, 438.94507771049456, 458.06566739011777, 237.08417311580442, 282.19954304483934, 298.34444024983316, 342.44905431517697, 363.87759770888215, 364.5057587197661, 267.5573333336945, 407.4189118903203, 188.27953845595653, 321.05108325581637, 345.72564542684233, 234.02072907059915, 338.7682779935867, 344.2481662492086, 435.58637570424065, 379.66844678820445, 442.75683911925876, 231.54075108521477, 441.9944960892789, 406.74684633961726, 475.45446864623034, 457.5905463674159, 410.5609769082019, 463.3730199089677, 513.6755854198273, 450.6760838092433, 417.86171636367465, 456.30601378498574, 269.4110631810989, 247.7328200248667, 603.2664700907403, 375.8704252512744, 249.42534376537913, 459.5716448181218, 372.8697237323458, 309.2793531442442, 456.5338411631565, 399.2856306281327, 333.71573981988604, 437.6233330376681, 174.19961265370122, 262.51260098134344, 349.37780856247946, 524.3343615789289, 298.305128966528, 184.6869177620586, 246.15395397110828, 337.1190252076858, 360.0138065336678, 267.7448150837387, 427.99623047072834, 497.2591890054846, 346.08576118486724, 441.4389881899732, 643.7166699546436, 483.20630997416464, 375.9813415227292, 378.94265282211535, 369.7357713180534, 498.0175024287434, 496.63978541097697, 565.8760191225593, 723.8604445523637, 488.4685613295224, 515.2360234631244, 529.6610217612725, 533.1692466507892, 469.5065150071417, 562.2272504589899, 406.7007960581554, 507.43358099462955, 531.3957614608134, 488.97082498179645, 414.27319754714125, 482.0627121011502, 365.6684407786991, 421.28773688951446, 501.5304750123914, 739.6081766279366, 537.0074818446185, 550.7273388421054, 415.81816119879994, 397.1111557319966, 527.0124616951782, 540.1719224100407, 554.6435349013994, 554.9473481294716, 594.7094568452808, 528.9722950030042, 423.530901395361, 505.25639053111814, 419.3971637393676, 602.607911071588, 547.3269895591039]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.514929077248776, "mean_inference_ms": 6.643618202970735, "mean_action_processing_ms": 1.0778453469394313, "mean_env_wait_ms": 0.9453826973811688, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.08513152599334717, "StateBufferConnector_ms": 0.014668107032775879, "ViewRequirementAgentConnector_ms": 0.811776876449585}, "num_episodes": 18, "episode_return_max": 2077.1832040936406, "episode_return_min": 876.603769134487, "episode_return_mean": 1795.7838559397046, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 137.620321078012, "num_env_steps_trained_throughput_per_sec": 137.620321078012, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 95402.866, "restore_workers_time_ms": 0.027, "training_step_time_ms": 95402.774, "sample_time_ms": 8515.315, "learn_time_ms": 86846.62, "learn_throughput": 46.058, "synch_weights_time_ms": 38.774}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "479e5_00000", "date": "2024-08-16_12-01-32", "timestamp": 1723789892, "time_this_iter_s": 29.071959972381592, "time_total_s": 2083.900992870331, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7f2c670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2083.900992870331, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 45.546341463414635, "ram_util_percent": 75.58536585365853}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7895847725489782, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.608708354404994, "policy_loss": -0.005674637158810304, "vf_loss": 9.61281406109926, "vf_explained_var": -0.04840860357360234, "kl": 0.013946117995754827, "entropy": 1.237229283083053, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.546110502878825, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.644145582088086, "policy_loss": -0.0063617716777439, "vf_loss": 9.648565788369961, "vf_explained_var": -0.022558384566080003, "kl": 0.008629134203951455, "entropy": 0.9882997302781968, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 2042.7650260420478, "episode_reward_min": 876.603769134487, "episode_reward_mean": 1808.380687606005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 194.54875448405488, "predator_policy": 27.3746493727311}, "policy_reward_max": {"prey_policy": 759.0276138797743, "predator_policy": 739.6081766279366}, "policy_reward_mean": {"prey_policy": 524.9488846948977, "predator_policy": 379.24145910810483}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1675.1563685127235, 1848.2475025902652, 1909.732471987923, 1866.01550404192, 1727.350291271417, 1792.2781335272334, 1779.8261740857347, 1827.3687758042531, 1600.8302165413104, 1712.3531213712397, 876.603769134487, 1755.320349208999, 1802.8644016709907, 1564.9059327930347, 1819.8560468271694, 1532.575988905127, 1915.683707279501, 1931.8524720489334, 1774.6699280195587, 1775.9141871700508, 1691.019429031559, 2004.6677695324026, 1478.2740744853425, 1868.3962848317983, 1762.1255956784344, 1758.7881964842095, 1764.1671998139911, 1776.1959375963493, 1665.6494285284216, 1716.4665816006964, 1703.1768088819622, 1846.9418443019504, 1849.073676957736, 1833.6228134284322, 1897.8993825121015, 1675.6412653012198, 1808.4500404765208, 1853.312569926621, 1804.9212105986778, 1756.1186847734145, 1886.7077226434424, 1806.8175236918003, 1891.5745509368905, 1871.2318909193448, 1847.9129882327456, 1937.788281239231, 1944.180857418237, 1894.2751217158304, 1873.1545683260117, 1625.381106428532, 1848.694968751886, 1813.4231450897441, 1816.6325741772584, 1875.847578141836, 1876.3633306689944, 1852.9094205973825, 1814.8958303206082, 1789.5040776800931, 1763.0939971551948, 1656.9430505061573, 1871.7573874011316, 1750.0028429670806, 1820.4135387831768, 1791.515950124929, 1916.618611792215, 1970.8636980978251, 1786.9387548372124, 1768.3189588559492, 1966.3341013298154, 1719.7686461735154, 1835.8074986636057, 1863.72325078339, 1801.3516338801217, 1806.430804748189, 1909.3165131566884, 1917.0460093839592, 1656.2149364944719, 1983.0765000615445, 1866.5349439088136, 1974.2537639493098, 1674.9532585045988, 1934.1846907311697, 1804.3386561411592, 1861.6499975375023, 1793.6677352839633, 1851.429437333498, 1908.12976822319, 1980.6831050773806, 1892.0114681096823, 1857.9899284418882, 1816.551277716792, 1768.9895677778904, 1818.0677108085822, 1738.0232653929093, 2042.7650260420478, 1920.3532330213004, 1845.0473139167918, 1894.4934505110748, 1868.8797127730454, 1897.92508968816], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [557.2371171163416, 692.4834517879523, 510.7571549677628, 565.9712323064779, 669.0468907167907, 652.049588570909, 671.912068630321, 567.4142798397634, 576.351937003808, 731.6408060987185, 599.5913304112262, 632.8468599295182, 686.6912504656466, 667.9141231752694, 565.1016951515712, 619.3080997562245, 655.9483651519175, 653.8631658221375, 568.6325060609466, 666.1458426804678, 375.74961507677466, 388.5190731467237, 556.263810119403, 668.9692611105979, 567.1980394680999, 759.0276138797743, 592.1933038064142, 679.2146239881592, 605.1257889387173, 696.8278015519799, 561.2068000340535, 637.8905354886937, 627.9262982977451, 656.4088496550188, 619.9643903095233, 510.3765317678228, 731.2074322135368, 578.6235562902782, 525.061004932368, 643.0153187985711, 710.4874692770466, 602.6731015897103, 547.5378709307514, 636.8102923036255, 608.904764053984, 573.7244424463281, 669.4363863018417, 573.3306931806226, 540.8280294861978, 693.361497667106, 610.4306427581087, 627.6276672278234, 599.2128249918657, 525.9907864039565, 593.620608651625, 616.2377108593416, 705.12382881455, 685.0708830101828, 494.51326039419314, 636.8214899365668, 419.6041619497203, 663.1464457983301, 610.8977215324063, 449.2435671517974, 709.9387362304593, 607.4611823984696, 689.2001473922558, 606.4649269099998, 418.3665152106753, 582.5221222008157, 560.2229755544487, 596.1345735861315, 561.6640331738114, 605.9925127377007, 501.91804040124026, 623.011173096734, 604.4570760581423, 525.4878893165203, 625.5472728158827, 621.2407902457577, 577.1911084299671, 729.7702397160335, 558.5081002917804, 565.2929791572247, 392.82334768634024, 683.4963807581063, 525.8435197946702, 671.0907809202, 539.0352431700603, 460.1364026337903, 396.22636558869436, 608.5169006368939, 625.3182010074066, 444.92865959366196, 585.9082122256874, 344.01524026107523, 590.6735297070015, 408.31330847035133, 490.91029239593337, 617.3269308266349, 470.3797238978903, 399.17834951197983, 532.4465065147004, 571.9796499915434, 566.9047591674138, 567.5787381332534, 487.2898004921075, 532.7383058584373, 515.5458442798772, 589.4784135315656, 703.8427993289832, 712.3544076333538, 499.0937775974004, 442.0898825817963, 730.7557849603271, 575.756245991181, 534.3508185617923, 645.4701994146109, 476.19280241965646, 552.9916264690947, 521.1135776635259, 425.388390261394, 561.6505605921024, 400.8275330001355, 468.005624944122, 225.48493391024704, 427.71336484439496, 608.8785909356883, 401.77842122678203, 647.0869168186365, 429.00353848475606, 479.3443550795315, 320.11937554359645, 254.49037341172945, 351.6705368099942, 371.7513768215564, 497.8789648737774, 465.77937479810805, 434.77460770879077, 316.06599194757854, 463.7852242535871, 333.1929319545736, 534.802121440981, 425.67710681346983, 542.1453615731348, 411.47511942713857, 535.6991741963376, 347.9134186499456, 334.0516132433728, 298.6492414407608, 430.7564721293419, 519.7440372137132, 475.43560617462833, 256.65571289266893, 528.0990960122314, 360.16194673787237, 487.93940987499036, 228.9387290590734, 467.3239116221072, 554.4266559288374, 369.5763930037231, 380.7233112303898, 336.5597677232284, 447.6900223772495, 290.17467564441233, 372.3419995647081, 506.23849204164037, 214.96015366445093, 481.0466832776853, 393.1246680727325, 405.08440897691094, 410.6795080102268, 366.09292622355645, 557.1486928262888, 399.72867246827843, 613.6750140544221, 371.2748779605566, 461.0355873035137, 386.5496061083491, 483.9571612155687, 525.7238095161215, 387.62836160085675, 521.4612796846699, 436.999526285121, 501.52078747933956, 340.84920853005804, 654.8682257501727, 441.31270060457507, 717.8316976790959, 515.1367170222603, 633.0750066282002, 365.01658596452387, 307.49722155959415, 419.7842358182721, 194.54875448405488, 424.1146470519523, 546.033844067848, 349.6405983163411, 528.2852825943684, 537.4188181057913], "policy_predator_policy_reward": [194.8754283010117, 230.5603713074168, 387.7986141457379, 383.7205011702869, 274.98838103725825, 313.647611662965, 262.89390734517576, 363.7952482266613, 256.6353011025132, 162.72224706637766, 287.8167762033767, 272.02316698311205, 206.98170169944981, 218.23909874537011, 356.9724593160457, 285.9865215804121, 210.48222734808925, 80.53645821916777, 200.98561094255146, 276.58916168727285, 27.3746493727311, 84.96043153825705, 281.5465698535615, 248.54070812543804, 238.15149998279335, 238.4872483403239, 110.72922801868077, 182.76877697978034, 296.23693346408515, 221.6655228723883, 181.44070095624284, 152.03795242613694, 297.4934541610038, 333.85510516573225, 422.7159614037349, 378.79558856785286, 249.80843741117127, 215.03050210457081, 234.88493733002323, 372.95292610908837, 178.19637331612267, 199.66248484867643, 390.98110807403594, 429.3384982239881, 138.49614470882028, 157.14872327621134, 407.1039570073136, 218.5252483420209, 269.4489415520483, 258.48712697308315, 215.74587277978344, 304.98401371849377, 274.67039107669467, 364.2931973414753, 308.3532727533498, 257.9843453320356, 182.60325452627217, 92.85146217741696, 253.8847090876312, 331.2471221823048, 267.40614441527487, 353.020056718635, 330.2692063041074, 456.5313493136365, 309.2678489270043, 222.40590940180329, 274.8054388753378, 263.1523002508378, 438.94507771049456, 458.06566739011777, 237.08417311580442, 282.19954304483934, 298.34444024983316, 342.44905431517697, 363.87759770888215, 364.5057587197661, 267.5573333336945, 407.4189118903203, 188.27953845595653, 321.05108325581637, 345.72564542684233, 234.02072907059915, 338.7682779935867, 344.2481662492086, 435.58637570424065, 379.66844678820445, 442.75683911925876, 231.54075108521477, 441.9944960892789, 406.74684633961726, 475.45446864623034, 457.5905463674159, 410.5609769082019, 463.3730199089677, 513.6755854198273, 450.6760838092433, 417.86171636367465, 456.30601378498574, 269.4110631810989, 247.7328200248667, 603.2664700907403, 375.8704252512744, 249.42534376537913, 459.5716448181218, 372.8697237323458, 309.2793531442442, 456.5338411631565, 399.2856306281327, 333.71573981988604, 437.6233330376681, 174.19961265370122, 262.51260098134344, 349.37780856247946, 524.3343615789289, 298.305128966528, 184.6869177620586, 246.15395397110828, 337.1190252076858, 360.0138065336678, 267.7448150837387, 427.99623047072834, 497.2591890054846, 346.08576118486724, 441.4389881899732, 643.7166699546436, 483.20630997416464, 375.9813415227292, 378.94265282211535, 369.7357713180534, 498.0175024287434, 496.63978541097697, 565.8760191225593, 723.8604445523637, 488.4685613295224, 515.2360234631244, 529.6610217612725, 533.1692466507892, 469.5065150071417, 562.2272504589899, 406.7007960581554, 507.43358099462955, 531.3957614608134, 488.97082498179645, 414.27319754714125, 482.0627121011502, 365.6684407786991, 421.28773688951446, 501.5304750123914, 739.6081766279366, 537.0074818446185, 550.7273388421054, 415.81816119879994, 397.1111557319966, 527.0124616951782, 540.1719224100407, 554.6435349013994, 554.9473481294716, 594.7094568452808, 528.9722950030042, 423.530901395361, 505.25639053111814, 419.3971637393676, 602.607911071588, 547.3269895591039, 668.192743316791, 473.62923761524786, 587.9022402096771, 552.5491116217347, 450.72811228025193, 468.76827165329445, 505.0218102814607, 530.6437100648993, 418.5087208267455, 566.3794283465999, 413.9694251787041, 553.3099933759783, 434.0655586511599, 625.6354441944535, 558.5934452191234, 428.88971589884824, 449.26435962249315, 453.9347469773197, 343.6788026991608, 466.8499591089385, 510.6446358222525, 465.05307897693245, 432.8091841909461, 209.03315484721554, 440.4140663238102, 369.3825450168792, 549.9253830000489, 372.336257428526, 498.44406672789955, 619.3217898110272, 714.150275317944, 561.6797736571237, 455.5150629494257, 517.6902074394311, 492.5122375554803, 339.7087514325197]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.534394261882241, "mean_inference_ms": 6.6893460904017035, "mean_action_processing_ms": 1.0861627656412716, "mean_env_wait_ms": 0.9508793483135015, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0417400598526001, "StateBufferConnector_ms": 0.014595866203308105, "ViewRequirementAgentConnector_ms": 0.5941076278686523}, "num_episodes": 18, "episode_return_max": 2042.7650260420478, "episode_return_min": 876.603769134487, "episode_return_mean": 1808.380687606005, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 137.5933508059412, "num_env_steps_trained_throughput_per_sec": 137.5933508059412, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 37870.018, "restore_workers_time_ms": 0.025, "training_step_time_ms": 37869.934, "sample_time_ms": 8132.921, "learn_time_ms": 29694.772, "learn_throughput": 134.704, "synch_weights_time_ms": 40.195}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "479e5_00000", "date": "2024-08-16_12-02-01", "timestamp": 1723789921, "time_this_iter_s": 29.08997392654419, "time_total_s": 2112.990966796875, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78a0820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2112.990966796875, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 43.03658536585366, "ram_util_percent": 75.18536585365854}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7565149735206018, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.554092489474664, "policy_loss": -0.004951934625330583, "vf_loss": 9.557619917834247, "vf_explained_var": -0.055732134504923744, "kl": 0.012662320382463727, "entropy": 1.2534201194369603, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5155217648183228, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.641958885091952, "policy_loss": -0.003176683653269219, "vf_loss": 9.643472858711526, "vf_explained_var": -0.020029123277260513, "kl": 0.0073897968677303855, "entropy": 0.887103245971064, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 2042.7650260420478, "episode_reward_min": 1478.2740744853425, "episode_reward_mean": 1833.1785838557867, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 166.91146162558837, "predator_policy": 92.85146217741696}, "policy_reward_max": {"prey_policy": 731.2074322135368, "predator_policy": 739.6081766279366}, "policy_reward_mean": {"prey_policy": 497.88036762561626, "predator_policy": 418.7089243022767}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1774.6699280195587, 1775.9141871700508, 1691.019429031559, 2004.6677695324026, 1478.2740744853425, 1868.3962848317983, 1762.1255956784344, 1758.7881964842095, 1764.1671998139911, 1776.1959375963493, 1665.6494285284216, 1716.4665816006964, 1703.1768088819622, 1846.9418443019504, 1849.073676957736, 1833.6228134284322, 1897.8993825121015, 1675.6412653012198, 1808.4500404765208, 1853.312569926621, 1804.9212105986778, 1756.1186847734145, 1886.7077226434424, 1806.8175236918003, 1891.5745509368905, 1871.2318909193448, 1847.9129882327456, 1937.788281239231, 1944.180857418237, 1894.2751217158304, 1873.1545683260117, 1625.381106428532, 1848.694968751886, 1813.4231450897441, 1816.6325741772584, 1875.847578141836, 1876.3633306689944, 1852.9094205973825, 1814.8958303206082, 1789.5040776800931, 1763.0939971551948, 1656.9430505061573, 1871.7573874011316, 1750.0028429670806, 1820.4135387831768, 1791.515950124929, 1916.618611792215, 1970.8636980978251, 1786.9387548372124, 1768.3189588559492, 1966.3341013298154, 1719.7686461735154, 1835.8074986636057, 1863.72325078339, 1801.3516338801217, 1806.430804748189, 1909.3165131566884, 1917.0460093839592, 1656.2149364944719, 1983.0765000615445, 1866.5349439088136, 1974.2537639493098, 1674.9532585045988, 1934.1846907311697, 1804.3386561411592, 1861.6499975375023, 1793.6677352839633, 1851.429437333498, 1908.12976822319, 1980.6831050773806, 1892.0114681096823, 1857.9899284418882, 1816.551277716792, 1768.9895677778904, 1818.0677108085822, 1738.0232653929093, 2042.7650260420478, 1920.3532330213004, 1845.0473139167918, 1894.4934505110748, 1868.8797127730454, 1897.92508968816, 1776.6066049774356, 1972.710823055722, 1802.5486049611295, 1869.3094408755833, 1980.6056763791933, 1832.2529686658631, 2029.9400621211414, 1786.4823961039035, 1932.8870470666157, 1824.36433266957, 1940.6914671185716, 1744.8948875466006, 1744.5335617689677, 1880.42882691514, 1806.4151925888407, 1901.9484505162557, 1756.130924533893, 1835.8595847159384], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [731.2074322135368, 578.6235562902782, 525.061004932368, 643.0153187985711, 710.4874692770466, 602.6731015897103, 547.5378709307514, 636.8102923036255, 608.904764053984, 573.7244424463281, 669.4363863018417, 573.3306931806226, 540.8280294861978, 693.361497667106, 610.4306427581087, 627.6276672278234, 599.2128249918657, 525.9907864039565, 593.620608651625, 616.2377108593416, 705.12382881455, 685.0708830101828, 494.51326039419314, 636.8214899365668, 419.6041619497203, 663.1464457983301, 610.8977215324063, 449.2435671517974, 709.9387362304593, 607.4611823984696, 689.2001473922558, 606.4649269099998, 418.3665152106753, 582.5221222008157, 560.2229755544487, 596.1345735861315, 561.6640331738114, 605.9925127377007, 501.91804040124026, 623.011173096734, 604.4570760581423, 525.4878893165203, 625.5472728158827, 621.2407902457577, 577.1911084299671, 729.7702397160335, 558.5081002917804, 565.2929791572247, 392.82334768634024, 683.4963807581063, 525.8435197946702, 671.0907809202, 539.0352431700603, 460.1364026337903, 396.22636558869436, 608.5169006368939, 625.3182010074066, 444.92865959366196, 585.9082122256874, 344.01524026107523, 590.6735297070015, 408.31330847035133, 490.91029239593337, 617.3269308266349, 470.3797238978903, 399.17834951197983, 532.4465065147004, 571.9796499915434, 566.9047591674138, 567.5787381332534, 487.2898004921075, 532.7383058584373, 515.5458442798772, 589.4784135315656, 703.8427993289832, 712.3544076333538, 499.0937775974004, 442.0898825817963, 730.7557849603271, 575.756245991181, 534.3508185617923, 645.4701994146109, 476.19280241965646, 552.9916264690947, 521.1135776635259, 425.388390261394, 561.6505605921024, 400.8275330001355, 468.005624944122, 225.48493391024704, 427.71336484439496, 608.8785909356883, 401.77842122678203, 647.0869168186365, 429.00353848475606, 479.3443550795315, 320.11937554359645, 254.49037341172945, 351.6705368099942, 371.7513768215564, 497.8789648737774, 465.77937479810805, 434.77460770879077, 316.06599194757854, 463.7852242535871, 333.1929319545736, 534.802121440981, 425.67710681346983, 542.1453615731348, 411.47511942713857, 535.6991741963376, 347.9134186499456, 334.0516132433728, 298.6492414407608, 430.7564721293419, 519.7440372137132, 475.43560617462833, 256.65571289266893, 528.0990960122314, 360.16194673787237, 487.93940987499036, 228.9387290590734, 467.3239116221072, 554.4266559288374, 369.5763930037231, 380.7233112303898, 336.5597677232284, 447.6900223772495, 290.17467564441233, 372.3419995647081, 506.23849204164037, 214.96015366445093, 481.0466832776853, 393.1246680727325, 405.08440897691094, 410.6795080102268, 366.09292622355645, 557.1486928262888, 399.72867246827843, 613.6750140544221, 371.2748779605566, 461.0355873035137, 386.5496061083491, 483.9571612155687, 525.7238095161215, 387.62836160085675, 521.4612796846699, 436.999526285121, 501.52078747933956, 340.84920853005804, 654.8682257501727, 441.31270060457507, 717.8316976790959, 515.1367170222603, 633.0750066282002, 365.01658596452387, 307.49722155959415, 419.7842358182721, 194.54875448405488, 424.1146470519523, 546.033844067848, 349.6405983163411, 528.2852825943684, 537.4188181057913, 590.180590779919, 438.0976495837523, 725.0591142868984, 187.12749201652642, 472.0914152074715, 335.8452141102802, 513.0677355288868, 430.7298345893502, 251.7422524058762, 577.2775503385272, 507.54066971874664, 233.97435127918652, 590.6153259144115, 565.8816331211572, 520.6743624639262, 446.0040734930479, 463.78440600357965, 565.6643531311238, 567.3763077353383, 298.10236552940665, 663.9860395508025, 598.7513287664171, 453.16526400282333, 525.2920187735781, 463.94366436759503, 376.62130625065186, 608.7618473863479, 579.9053791788973, 454.74821625682665, 593.5477119660931, 463.33458946831735, 270.4123024512214, 288.2225590901995, 461.98446249511824, 166.91146162558837, 349.641839559086], "policy_predator_policy_reward": [249.80843741117127, 215.03050210457081, 234.88493733002323, 372.95292610908837, 178.19637331612267, 199.66248484867643, 390.98110807403594, 429.3384982239881, 138.49614470882028, 157.14872327621134, 407.1039570073136, 218.5252483420209, 269.4489415520483, 258.48712697308315, 215.74587277978344, 304.98401371849377, 274.67039107669467, 364.2931973414753, 308.3532727533498, 257.9843453320356, 182.60325452627217, 92.85146217741696, 253.8847090876312, 331.2471221823048, 267.40614441527487, 353.020056718635, 330.2692063041074, 456.5313493136365, 309.2678489270043, 222.40590940180329, 274.8054388753378, 263.1523002508378, 438.94507771049456, 458.06566739011777, 237.08417311580442, 282.19954304483934, 298.34444024983316, 342.44905431517697, 363.87759770888215, 364.5057587197661, 267.5573333336945, 407.4189118903203, 188.27953845595653, 321.05108325581637, 345.72564542684233, 234.02072907059915, 338.7682779935867, 344.2481662492086, 435.58637570424065, 379.66844678820445, 442.75683911925876, 231.54075108521477, 441.9944960892789, 406.74684633961726, 475.45446864623034, 457.5905463674159, 410.5609769082019, 463.3730199089677, 513.6755854198273, 450.6760838092433, 417.86171636367465, 456.30601378498574, 269.4110631810989, 247.7328200248667, 603.2664700907403, 375.8704252512744, 249.42534376537913, 459.5716448181218, 372.8697237323458, 309.2793531442442, 456.5338411631565, 399.2856306281327, 333.71573981988604, 437.6233330376681, 174.19961265370122, 262.51260098134344, 349.37780856247946, 524.3343615789289, 298.305128966528, 184.6869177620586, 246.15395397110828, 337.1190252076858, 360.0138065336678, 267.7448150837387, 427.99623047072834, 497.2591890054846, 346.08576118486724, 441.4389881899732, 643.7166699546436, 483.20630997416464, 375.9813415227292, 378.94265282211535, 369.7357713180534, 498.0175024287434, 496.63978541097697, 565.8760191225593, 723.8604445523637, 488.4685613295224, 515.2360234631244, 529.6610217612725, 533.1692466507892, 469.5065150071417, 562.2272504589899, 406.7007960581554, 507.43358099462955, 531.3957614608134, 488.97082498179645, 414.27319754714125, 482.0627121011502, 365.6684407786991, 421.28773688951446, 501.5304750123914, 739.6081766279366, 537.0074818446185, 550.7273388421054, 415.81816119879994, 397.1111557319966, 527.0124616951782, 540.1719224100407, 554.6435349013994, 554.9473481294716, 594.7094568452808, 528.9722950030042, 423.530901395361, 505.25639053111814, 419.3971637393676, 602.607911071588, 547.3269895591039, 668.192743316791, 473.62923761524786, 587.9022402096771, 552.5491116217347, 450.72811228025193, 468.76827165329445, 505.0218102814607, 530.6437100648993, 418.5087208267455, 566.3794283465999, 413.9694251787041, 553.3099933759783, 434.0655586511599, 625.6354441944535, 558.5934452191234, 428.88971589884824, 449.26435962249315, 453.9347469773197, 343.6788026991608, 466.8499591089385, 510.6446358222525, 465.05307897693245, 432.8091841909461, 209.03315484721554, 440.4140663238102, 369.3825450168792, 549.9253830000489, 372.336257428526, 498.44406672789955, 619.3217898110272, 714.150275317944, 561.6797736571237, 455.5150629494257, 517.6902074394311, 492.5122375554803, 339.7087514325197, 334.9052990865528, 413.423065527211, 495.91801785082276, 564.6061989014694, 516.0844480691018, 478.52752757427595, 491.1545032192447, 434.3573675381029, 616.2714118772795, 535.3144617575078, 465.95513754162397, 624.7828101263065, 494.46803302957017, 378.97507005600426, 463.25419878271447, 356.5497613642159, 460.10035460072646, 443.3379333311835, 439.11912163421675, 519.7665377706078, 324.0007320874567, 353.9533667138909, 361.6581899202559, 404.7794148499442, 417.9378805969885, 486.0307105537317, 384.0257614639017, 307.7358388859915, 390.2679294300346, 367.85133493588603, 563.3110784266804, 604.8904801700345, 523.5327149051257, 482.39118804344884, 667.917460855774, 651.38882267549]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.5485370667798866, "mean_inference_ms": 6.720354450366824, "mean_action_processing_ms": 1.0916894077805857, "mean_env_wait_ms": 0.954510443651038, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.05395174026489258, "StateBufferConnector_ms": 0.015070676803588867, "ViewRequirementAgentConnector_ms": 0.6243206262588501}, "num_episodes": 18, "episode_return_max": 2042.7650260420478, "episode_return_min": 1478.2740744853425, "episode_return_mean": 1833.1785838557867, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 134.39741627037415, "num_env_steps_trained_throughput_per_sec": 134.39741627037415, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 36062.592, "restore_workers_time_ms": 0.025, "training_step_time_ms": 36062.511, "sample_time_ms": 7981.375, "learn_time_ms": 28040.645, "learn_throughput": 142.65, "synch_weights_time_ms": 38.84}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "479e5_00000", "date": "2024-08-16_12-02-31", "timestamp": 1723789951, "time_this_iter_s": 29.771260023117065, "time_total_s": 2142.762226819992, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7877e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2142.762226819992, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 43.744186046511636, "ram_util_percent": 75.13953488372094}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8220765357452726, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.51530580268335, "policy_loss": -0.007982179573268959, "vf_loss": 9.521326727589603, "vf_explained_var": -0.061822730365884364, "kl": 0.01743349150306052, "entropy": 1.2409998425100215, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6286817908444733, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.538833028803428, "policy_loss": -0.0034194018763228856, "vf_loss": 9.540840206953584, "vf_explained_var": -0.014412757076283611, "kl": 0.006276402438498928, "entropy": 0.8358886368690975, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 2050.5517344401574, "episode_reward_min": 1125.0047845824317, "episode_reward_mean": 1833.158880016027, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 166.91146162558837, "predator_policy": 170.97937412777503}, "policy_reward_max": {"prey_policy": 730.7557849603271, "predator_policy": 739.6081766279366}, "policy_reward_mean": {"prey_policy": 464.40550688708555, "predator_policy": 452.1739331209281}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1886.7077226434424, 1806.8175236918003, 1891.5745509368905, 1871.2318909193448, 1847.9129882327456, 1937.788281239231, 1944.180857418237, 1894.2751217158304, 1873.1545683260117, 1625.381106428532, 1848.694968751886, 1813.4231450897441, 1816.6325741772584, 1875.847578141836, 1876.3633306689944, 1852.9094205973825, 1814.8958303206082, 1789.5040776800931, 1763.0939971551948, 1656.9430505061573, 1871.7573874011316, 1750.0028429670806, 1820.4135387831768, 1791.515950124929, 1916.618611792215, 1970.8636980978251, 1786.9387548372124, 1768.3189588559492, 1966.3341013298154, 1719.7686461735154, 1835.8074986636057, 1863.72325078339, 1801.3516338801217, 1806.430804748189, 1909.3165131566884, 1917.0460093839592, 1656.2149364944719, 1983.0765000615445, 1866.5349439088136, 1974.2537639493098, 1674.9532585045988, 1934.1846907311697, 1804.3386561411592, 1861.6499975375023, 1793.6677352839633, 1851.429437333498, 1908.12976822319, 1980.6831050773806, 1892.0114681096823, 1857.9899284418882, 1816.551277716792, 1768.9895677778904, 1818.0677108085822, 1738.0232653929093, 2042.7650260420478, 1920.3532330213004, 1845.0473139167918, 1894.4934505110748, 1868.8797127730454, 1897.92508968816, 1776.6066049774356, 1972.710823055722, 1802.5486049611295, 1869.3094408755833, 1980.6056763791933, 1832.2529686658631, 2029.9400621211414, 1786.4823961039035, 1932.8870470666157, 1824.36433266957, 1940.6914671185716, 1744.8948875466006, 1744.5335617689677, 1880.42882691514, 1806.4151925888407, 1901.9484505162557, 1756.130924533893, 1835.8595847159384, 2050.5517344401574, 1732.6156450493313, 1639.9587922743515, 1861.1158642933253, 1585.092284769457, 1721.4913015328884, 1801.2134956489567, 1728.2426304913338, 1125.0047845824317, 1989.990791538992, 1708.8283727223063, 1819.4941215613842, 1783.8873389287266, 1777.4285733521185, 1748.9781826977865, 1829.1327939714997, 1973.3646837057756, 1734.6046649040973, 1998.8633825480665, 1721.4464906356027, 1773.1836396213173, 1959.0329566856553], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [577.1911084299671, 729.7702397160335, 558.5081002917804, 565.2929791572247, 392.82334768634024, 683.4963807581063, 525.8435197946702, 671.0907809202, 539.0352431700603, 460.1364026337903, 396.22636558869436, 608.5169006368939, 625.3182010074066, 444.92865959366196, 585.9082122256874, 344.01524026107523, 590.6735297070015, 408.31330847035133, 490.91029239593337, 617.3269308266349, 470.3797238978903, 399.17834951197983, 532.4465065147004, 571.9796499915434, 566.9047591674138, 567.5787381332534, 487.2898004921075, 532.7383058584373, 515.5458442798772, 589.4784135315656, 703.8427993289832, 712.3544076333538, 499.0937775974004, 442.0898825817963, 730.7557849603271, 575.756245991181, 534.3508185617923, 645.4701994146109, 476.19280241965646, 552.9916264690947, 521.1135776635259, 425.388390261394, 561.6505605921024, 400.8275330001355, 468.005624944122, 225.48493391024704, 427.71336484439496, 608.8785909356883, 401.77842122678203, 647.0869168186365, 429.00353848475606, 479.3443550795315, 320.11937554359645, 254.49037341172945, 351.6705368099942, 371.7513768215564, 497.8789648737774, 465.77937479810805, 434.77460770879077, 316.06599194757854, 463.7852242535871, 333.1929319545736, 534.802121440981, 425.67710681346983, 542.1453615731348, 411.47511942713857, 535.6991741963376, 347.9134186499456, 334.0516132433728, 298.6492414407608, 430.7564721293419, 519.7440372137132, 475.43560617462833, 256.65571289266893, 528.0990960122314, 360.16194673787237, 487.93940987499036, 228.9387290590734, 467.3239116221072, 554.4266559288374, 369.5763930037231, 380.7233112303898, 336.5597677232284, 447.6900223772495, 290.17467564441233, 372.3419995647081, 506.23849204164037, 214.96015366445093, 481.0466832776853, 393.1246680727325, 405.08440897691094, 410.6795080102268, 366.09292622355645, 557.1486928262888, 399.72867246827843, 613.6750140544221, 371.2748779605566, 461.0355873035137, 386.5496061083491, 483.9571612155687, 525.7238095161215, 387.62836160085675, 521.4612796846699, 436.999526285121, 501.52078747933956, 340.84920853005804, 654.8682257501727, 441.31270060457507, 717.8316976790959, 515.1367170222603, 633.0750066282002, 365.01658596452387, 307.49722155959415, 419.7842358182721, 194.54875448405488, 424.1146470519523, 546.033844067848, 349.6405983163411, 528.2852825943684, 537.4188181057913, 590.180590779919, 438.0976495837523, 725.0591142868984, 187.12749201652642, 472.0914152074715, 335.8452141102802, 513.0677355288868, 430.7298345893502, 251.7422524058762, 577.2775503385272, 507.54066971874664, 233.97435127918652, 590.6153259144115, 565.8816331211572, 520.6743624639262, 446.0040734930479, 463.78440600357965, 565.6643531311238, 567.3763077353383, 298.10236552940665, 663.9860395508025, 598.7513287664171, 453.16526400282333, 525.2920187735781, 463.94366436759503, 376.62130625065186, 608.7618473863479, 579.9053791788973, 454.74821625682665, 593.5477119660931, 463.33458946831735, 270.4123024512214, 288.2225590901995, 461.98446249511824, 166.91146162558837, 349.641839559086, 605.8526830181781, 572.8790977681126, 488.7745305856615, 489.4292904248242, 325.49451340838107, 315.52152208093503, 532.8966988257736, 377.6914413574885, 600.6633414383459, 460.0788657404646, 435.0740928528097, 556.8888760146177, 408.45215165624256, 332.950603512872, 415.04199957956945, 373.06919626686584, 251.89654661431166, 492.40914525628, 395.6678943167038, 550.818882713361, 450.47601335169264, 358.35398598072925, 475.3895541415213, 530.512324816685, 463.7982539743561, 474.53897449113697, 261.5006089112159, 363.1185698426559, 368.1960570302946, 257.2626733262592, 440.28970777817415, 563.7478725284096, 528.0156320184497, 554.0554763171109, 608.4274179816123, 534.0254694369311, 582.1332990620506, 254.30664896673713, 483.62176328938455, 443.79199467859536, 466.24998971890415, 356.3304152299173, 344.26130260872, 473.2458996619951], "policy_predator_policy_reward": [345.72564542684233, 234.02072907059915, 338.7682779935867, 344.2481662492086, 435.58637570424065, 379.66844678820445, 442.75683911925876, 231.54075108521477, 441.9944960892789, 406.74684633961726, 475.45446864623034, 457.5905463674159, 410.5609769082019, 463.3730199089677, 513.6755854198273, 450.6760838092433, 417.86171636367465, 456.30601378498574, 269.4110631810989, 247.7328200248667, 603.2664700907403, 375.8704252512744, 249.42534376537913, 459.5716448181218, 372.8697237323458, 309.2793531442442, 456.5338411631565, 399.2856306281327, 333.71573981988604, 437.6233330376681, 174.19961265370122, 262.51260098134344, 349.37780856247946, 524.3343615789289, 298.305128966528, 184.6869177620586, 246.15395397110828, 337.1190252076858, 360.0138065336678, 267.7448150837387, 427.99623047072834, 497.2591890054846, 346.08576118486724, 441.4389881899732, 643.7166699546436, 483.20630997416464, 375.9813415227292, 378.94265282211535, 369.7357713180534, 498.0175024287434, 496.63978541097697, 565.8760191225593, 723.8604445523637, 488.4685613295224, 515.2360234631244, 529.6610217612725, 533.1692466507892, 469.5065150071417, 562.2272504589899, 406.7007960581554, 507.43358099462955, 531.3957614608134, 488.97082498179645, 414.27319754714125, 482.0627121011502, 365.6684407786991, 421.28773688951446, 501.5304750123914, 739.6081766279366, 537.0074818446185, 550.7273388421054, 415.81816119879994, 397.1111557319966, 527.0124616951782, 540.1719224100407, 554.6435349013994, 554.9473481294716, 594.7094568452808, 528.9722950030042, 423.530901395361, 505.25639053111814, 419.3971637393676, 602.607911071588, 547.3269895591039, 668.192743316791, 473.62923761524786, 587.9022402096771, 552.5491116217347, 450.72811228025193, 468.76827165329445, 505.0218102814607, 530.6437100648993, 418.5087208267455, 566.3794283465999, 413.9694251787041, 553.3099933759783, 434.0655586511599, 625.6354441944535, 558.5934452191234, 428.88971589884824, 449.26435962249315, 453.9347469773197, 343.6788026991608, 466.8499591089385, 510.6446358222525, 465.05307897693245, 432.8091841909461, 209.03315484721554, 440.4140663238102, 369.3825450168792, 549.9253830000489, 372.336257428526, 498.44406672789955, 619.3217898110272, 714.150275317944, 561.6797736571237, 455.5150629494257, 517.6902074394311, 492.5122375554803, 339.7087514325197, 334.9052990865528, 413.423065527211, 495.91801785082276, 564.6061989014694, 516.0844480691018, 478.52752757427595, 491.1545032192447, 434.3573675381029, 616.2714118772795, 535.3144617575078, 465.95513754162397, 624.7828101263065, 494.46803302957017, 378.97507005600426, 463.25419878271447, 356.5497613642159, 460.10035460072646, 443.3379333311835, 439.11912163421675, 519.7665377706078, 324.0007320874567, 353.9533667138909, 361.6581899202559, 404.7794148499442, 417.9378805969885, 486.0307105537317, 384.0257614639017, 307.7358388859915, 390.2679294300346, 367.85133493588603, 563.3110784266804, 604.8904801700345, 523.5327149051257, 482.39118804344884, 667.917460855774, 651.38882267549, 449.18197554262406, 422.637978111245, 404.37051114110125, 350.04131289774705, 468.0773880858188, 530.8653686992162, 527.445768084514, 423.0819560255486, 215.63661438968248, 308.7134632009665, 419.8666404437247, 309.66169222173664, 545.6140620406799, 514.1966784391626, 379.468102245574, 560.6633323993265, 170.97937412777503, 209.71971858406548, 527.3141881404963, 516.1898263684349, 460.9634371484354, 439.0349362414493, 438.3592951999254, 375.23294740325383, 455.9388106763344, 389.6112997868979, 685.3279329771373, 467.4814616211082, 645.5501411457709, 477.96931119546156, 501.30059594491746, 323.79461771999956, 489.0329039083036, 402.2606714619142, 311.0548853741983, 281.09689211135304, 546.474707357192, 615.9487271620872, 456.5830435806785, 337.4496890869452, 550.6901770471961, 399.9130576252979, 542.9395869920909, 598.5861674228485]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.555143987010346, "mean_inference_ms": 6.736068937827306, "mean_action_processing_ms": 1.094826382671758, "mean_env_wait_ms": 0.9562998561402556, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.030653834342956543, "StateBufferConnector_ms": 0.010089755058288574, "ViewRequirementAgentConnector_ms": 0.5002797842025757}, "num_episodes": 22, "episode_return_max": 2050.5517344401574, "episode_return_min": 1125.0047845824317, "episode_return_mean": 1833.158880016027, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 135.09603052517392, "num_env_steps_trained_throughput_per_sec": 135.09603052517392, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 34649.569, "restore_workers_time_ms": 0.024, "training_step_time_ms": 34649.491, "sample_time_ms": 7844.338, "learn_time_ms": 26765.434, "learn_throughput": 149.446, "synch_weights_time_ms": 38.31}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "479e5_00000", "date": "2024-08-16_12-03-00", "timestamp": 1723789980, "time_this_iter_s": 29.618199110031128, "time_total_s": 2172.380425930023, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78cc280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2172.380425930023, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 44.46341463414634, "ram_util_percent": 74.5560975609756}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9024036339981847, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.56682141117318, "policy_loss": -0.0016288937751952775, "vf_loss": 9.567536309156468, "vf_explained_var": -0.03394881915793848, "kl": 0.008124184259084758, "entropy": 1.2399085820667328, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1009541290304647, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.453014031667559, "policy_loss": -0.0013770454186236574, "vf_loss": 9.452442582952914, "vf_explained_var": -0.005639035487301135, "kl": 0.00865993928555347, "entropy": 0.8197891735841357, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 2050.5517344401574, "episode_reward_min": 1035.9869291307502, "episode_reward_mean": 1799.7722681836933, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 155.02842573595157, "predator_policy": 120.71618599100069}, "policy_reward_max": {"prey_policy": 736.1770968953147, "predator_policy": 739.6081766279366}, "policy_reward_mean": {"prey_policy": 443.6823305579917, "predator_policy": 456.2038035338552}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1791.515950124929, 1916.618611792215, 1970.8636980978251, 1786.9387548372124, 1768.3189588559492, 1966.3341013298154, 1719.7686461735154, 1835.8074986636057, 1863.72325078339, 1801.3516338801217, 1806.430804748189, 1909.3165131566884, 1917.0460093839592, 1656.2149364944719, 1983.0765000615445, 1866.5349439088136, 1974.2537639493098, 1674.9532585045988, 1934.1846907311697, 1804.3386561411592, 1861.6499975375023, 1793.6677352839633, 1851.429437333498, 1908.12976822319, 1980.6831050773806, 1892.0114681096823, 1857.9899284418882, 1816.551277716792, 1768.9895677778904, 1818.0677108085822, 1738.0232653929093, 2042.7650260420478, 1920.3532330213004, 1845.0473139167918, 1894.4934505110748, 1868.8797127730454, 1897.92508968816, 1776.6066049774356, 1972.710823055722, 1802.5486049611295, 1869.3094408755833, 1980.6056763791933, 1832.2529686658631, 2029.9400621211414, 1786.4823961039035, 1932.8870470666157, 1824.36433266957, 1940.6914671185716, 1744.8948875466006, 1744.5335617689677, 1880.42882691514, 1806.4151925888407, 1901.9484505162557, 1756.130924533893, 1835.8595847159384, 2050.5517344401574, 1732.6156450493313, 1639.9587922743515, 1861.1158642933253, 1585.092284769457, 1721.4913015328884, 1801.2134956489567, 1728.2426304913338, 1125.0047845824317, 1989.990791538992, 1708.8283727223063, 1819.4941215613842, 1783.8873389287266, 1777.4285733521185, 1748.9781826977865, 1829.1327939714997, 1973.3646837057756, 1734.6046649040973, 1998.8633825480665, 1721.4464906356027, 1773.1836396213173, 1959.0329566856553, 1932.000926904674, 1397.0377910666946, 1897.3037503592925, 1923.7293930895175, 1857.636541550933, 1679.686392123253, 1136.6360055914413, 1586.0903629684624, 1864.804529311258, 1858.382201371818, 1882.136602441557, 1918.251048266355, 1878.3462669467815, 1861.765256987439, 1963.3914326821573, 1619.213004047467, 1473.7757946729403, 1576.2562256802646, 1460.3043585355824, 1035.9869291307502, 1885.09984921732, 1778.0634312503078, 1324.9470763629847], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [427.71336484439496, 608.8785909356883, 401.77842122678203, 647.0869168186365, 429.00353848475606, 479.3443550795315, 320.11937554359645, 254.49037341172945, 351.6705368099942, 371.7513768215564, 497.8789648737774, 465.77937479810805, 434.77460770879077, 316.06599194757854, 463.7852242535871, 333.1929319545736, 534.802121440981, 425.67710681346983, 542.1453615731348, 411.47511942713857, 535.6991741963376, 347.9134186499456, 334.0516132433728, 298.6492414407608, 430.7564721293419, 519.7440372137132, 475.43560617462833, 256.65571289266893, 528.0990960122314, 360.16194673787237, 487.93940987499036, 228.9387290590734, 467.3239116221072, 554.4266559288374, 369.5763930037231, 380.7233112303898, 336.5597677232284, 447.6900223772495, 290.17467564441233, 372.3419995647081, 506.23849204164037, 214.96015366445093, 481.0466832776853, 393.1246680727325, 405.08440897691094, 410.6795080102268, 366.09292622355645, 557.1486928262888, 399.72867246827843, 613.6750140544221, 371.2748779605566, 461.0355873035137, 386.5496061083491, 483.9571612155687, 525.7238095161215, 387.62836160085675, 521.4612796846699, 436.999526285121, 501.52078747933956, 340.84920853005804, 654.8682257501727, 441.31270060457507, 717.8316976790959, 515.1367170222603, 633.0750066282002, 365.01658596452387, 307.49722155959415, 419.7842358182721, 194.54875448405488, 424.1146470519523, 546.033844067848, 349.6405983163411, 528.2852825943684, 537.4188181057913, 590.180590779919, 438.0976495837523, 725.0591142868984, 187.12749201652642, 472.0914152074715, 335.8452141102802, 513.0677355288868, 430.7298345893502, 251.7422524058762, 577.2775503385272, 507.54066971874664, 233.97435127918652, 590.6153259144115, 565.8816331211572, 520.6743624639262, 446.0040734930479, 463.78440600357965, 565.6643531311238, 567.3763077353383, 298.10236552940665, 663.9860395508025, 598.7513287664171, 453.16526400282333, 525.2920187735781, 463.94366436759503, 376.62130625065186, 608.7618473863479, 579.9053791788973, 454.74821625682665, 593.5477119660931, 463.33458946831735, 270.4123024512214, 288.2225590901995, 461.98446249511824, 166.91146162558837, 349.641839559086, 605.8526830181781, 572.8790977681126, 488.7745305856615, 489.4292904248242, 325.49451340838107, 315.52152208093503, 532.8966988257736, 377.6914413574885, 600.6633414383459, 460.0788657404646, 435.0740928528097, 556.8888760146177, 408.45215165624256, 332.950603512872, 415.04199957956945, 373.06919626686584, 251.89654661431166, 492.40914525628, 395.6678943167038, 550.818882713361, 450.47601335169264, 358.35398598072925, 475.3895541415213, 530.512324816685, 463.7982539743561, 474.53897449113697, 261.5006089112159, 363.1185698426559, 368.1960570302946, 257.2626733262592, 440.28970777817415, 563.7478725284096, 528.0156320184497, 554.0554763171109, 608.4274179816123, 534.0254694369311, 582.1332990620506, 254.30664896673713, 483.62176328938455, 443.79199467859536, 466.24998971890415, 356.3304152299173, 344.26130260872, 473.2458996619951, 397.4520736888611, 507.4196846108263, 436.39046735639715, 260.50909443832296, 444.8909151428674, 355.48340050095845, 439.1413924845851, 155.02842573595157, 601.935830867164, 469.93629206428494, 467.5534744871405, 611.3374319704045, 415.21002856089046, 455.29465035630847, 197.35683256616656, 476.23688562506834, 534.6025276765735, 443.6675709267234, 360.6183817256613, 411.84734515342615, 633.8919184392673, 506.62322998940664, 545.4551672289896, 736.1770968953147, 500.54192754452146, 373.23531882047774, 660.4930751574857, 340.7661088415221, 576.5576231764168, 224.33089264625002, 424.42579093487495, 553.5512474524022, 354.71726718111137, 384.3220226232693, 598.0474880108848, 403.07396546381653, 441.1616359351713, 467.24168533302344, 350.54504117498277, 323.51392202789975, 320.8264644704909, 561.9989507634639, 557.4892955565699, 392.6331608069827, 386.605367302981, 319.44116444505414], "policy_predator_policy_reward": [375.9813415227292, 378.94265282211535, 369.7357713180534, 498.0175024287434, 496.63978541097697, 565.8760191225593, 723.8604445523637, 488.4685613295224, 515.2360234631244, 529.6610217612725, 533.1692466507892, 469.5065150071417, 562.2272504589899, 406.7007960581554, 507.43358099462955, 531.3957614608134, 488.97082498179645, 414.27319754714125, 482.0627121011502, 365.6684407786991, 421.28773688951446, 501.5304750123914, 739.6081766279366, 537.0074818446185, 550.7273388421054, 415.81816119879994, 397.1111557319966, 527.0124616951782, 540.1719224100407, 554.6435349013994, 554.9473481294716, 594.7094568452808, 528.9722950030042, 423.530901395361, 505.25639053111814, 419.3971637393676, 602.607911071588, 547.3269895591039, 668.192743316791, 473.62923761524786, 587.9022402096771, 552.5491116217347, 450.72811228025193, 468.76827165329445, 505.0218102814607, 530.6437100648993, 418.5087208267455, 566.3794283465999, 413.9694251787041, 553.3099933759783, 434.0655586511599, 625.6354441944535, 558.5934452191234, 428.88971589884824, 449.26435962249315, 453.9347469773197, 343.6788026991608, 466.8499591089385, 510.6446358222525, 465.05307897693245, 432.8091841909461, 209.03315484721554, 440.4140663238102, 369.3825450168792, 549.9253830000489, 372.336257428526, 498.44406672789955, 619.3217898110272, 714.150275317944, 561.6797736571237, 455.5150629494257, 517.6902074394311, 492.5122375554803, 339.7087514325197, 334.9052990865528, 413.423065527211, 495.91801785082276, 564.6061989014694, 516.0844480691018, 478.52752757427595, 491.1545032192447, 434.3573675381029, 616.2714118772795, 535.3144617575078, 465.95513754162397, 624.7828101263065, 494.46803302957017, 378.97507005600426, 463.25419878271447, 356.5497613642159, 460.10035460072646, 443.3379333311835, 439.11912163421675, 519.7665377706078, 324.0007320874567, 353.9533667138909, 361.6581899202559, 404.7794148499442, 417.9378805969885, 486.0307105537317, 384.0257614639017, 307.7358388859915, 390.2679294300346, 367.85133493588603, 563.3110784266804, 604.8904801700345, 523.5327149051257, 482.39118804344884, 667.917460855774, 651.38882267549, 449.18197554262406, 422.637978111245, 404.37051114110125, 350.04131289774705, 468.0773880858188, 530.8653686992162, 527.445768084514, 423.0819560255486, 215.63661438968248, 308.7134632009665, 419.8666404437247, 309.66169222173664, 545.6140620406799, 514.1966784391626, 379.468102245574, 560.6633323993265, 170.97937412777503, 209.71971858406548, 527.3141881404963, 516.1898263684349, 460.9634371484354, 439.0349362414493, 438.3592951999254, 375.23294740325383, 455.9388106763344, 389.6112997868979, 685.3279329771373, 467.4814616211082, 645.5501411457709, 477.96931119546156, 501.30059594491746, 323.79461771999956, 489.0329039083036, 402.2606714619142, 311.0548853741983, 281.09689211135304, 546.474707357192, 615.9487271620872, 456.5830435806785, 337.4496890869452, 550.6901770471961, 399.9130576252979, 542.9395869920909, 598.5861674228485, 552.8940538492213, 474.23511475576714, 286.69757537098144, 413.4406539009932, 519.1261973666464, 577.8032373488219, 671.5882692242031, 657.9713056447804, 471.20216547922405, 314.56225314026074, 294.8359297774518, 305.95955588825746, 120.71618599100069, 145.41514068324142, 442.36610013847815, 470.1305446387487, 377.7902660132536, 508.7441646947072, 492.1622389200312, 593.7542355727, 417.94383265849854, 323.67762135438505, 312.52892492772804, 324.0898592143192, 549.5991431865818, 454.9698773952003, 481.6642300942783, 378.8418428941503, 634.1929264653622, 528.3099903941276, 234.55060319509644, 406.68536246509376, 392.7788168319345, 341.95768803662577, 292.97340966625677, 282.1613625393085, 322.68623974116593, 229.21479752622315, 221.9249012100375, 140.00306471782986, 508.9657745433332, 493.30865944002807, 436.33626958325704, 391.604705303499, 364.05781880286537, 254.84272581208432]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.5662213243521226, "mean_inference_ms": 6.761738848705813, "mean_action_processing_ms": 1.0990469552290356, "mean_env_wait_ms": 0.9589425615397542, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03960466384887695, "StateBufferConnector_ms": 0.010426878929138184, "ViewRequirementAgentConnector_ms": 0.6268740892410278}, "num_episodes": 23, "episode_return_max": 2050.5517344401574, "episode_return_min": 1035.9869291307502, "episode_return_mean": 1799.7722681836933, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 129.4844628247191, "num_env_steps_trained_throughput_per_sec": 129.4844628247191, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 33311.757, "restore_workers_time_ms": 0.024, "training_step_time_ms": 33311.68, "sample_time_ms": 7898.361, "learn_time_ms": 25373.8, "learn_throughput": 157.643, "synch_weights_time_ms": 38.127}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "479e5_00000", "date": "2024-08-16_12-03-31", "timestamp": 1723790011, "time_this_iter_s": 30.90068507194519, "time_total_s": 2203.2811110019684, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78e51f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2203.2811110019684, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 44.22272727272727, "ram_util_percent": 74.20454545454545}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7461444590615216, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.66109647246265, "policy_loss": -0.0022081174732496343, "vf_loss": 9.662123527224102, "vf_explained_var": -0.010807004775950518, "kl": 0.010498363611617184, "entropy": 1.2643261052944041, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3094159668715544, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.485934431086141, "policy_loss": -0.002430934282561774, "vf_loss": 9.487246127355666, "vf_explained_var": -0.03148293570866661, "kl": 0.004974496375249853, "entropy": 0.8248946972624965, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 2050.5517344401574, "episode_reward_min": 1035.9869291307502, "episode_reward_mean": 1792.2355990353794, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 155.02842573595157, "predator_policy": 120.71618599100069}, "policy_reward_max": {"prey_policy": 736.1770968953147, "predator_policy": 714.150275317944}, "policy_reward_mean": {"prey_policy": 447.49082013060143, "predator_policy": 448.62697938708845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1934.1846907311697, 1804.3386561411592, 1861.6499975375023, 1793.6677352839633, 1851.429437333498, 1908.12976822319, 1980.6831050773806, 1892.0114681096823, 1857.9899284418882, 1816.551277716792, 1768.9895677778904, 1818.0677108085822, 1738.0232653929093, 2042.7650260420478, 1920.3532330213004, 1845.0473139167918, 1894.4934505110748, 1868.8797127730454, 1897.92508968816, 1776.6066049774356, 1972.710823055722, 1802.5486049611295, 1869.3094408755833, 1980.6056763791933, 1832.2529686658631, 2029.9400621211414, 1786.4823961039035, 1932.8870470666157, 1824.36433266957, 1940.6914671185716, 1744.8948875466006, 1744.5335617689677, 1880.42882691514, 1806.4151925888407, 1901.9484505162557, 1756.130924533893, 1835.8595847159384, 2050.5517344401574, 1732.6156450493313, 1639.9587922743515, 1861.1158642933253, 1585.092284769457, 1721.4913015328884, 1801.2134956489567, 1728.2426304913338, 1125.0047845824317, 1989.990791538992, 1708.8283727223063, 1819.4941215613842, 1783.8873389287266, 1777.4285733521185, 1748.9781826977865, 1829.1327939714997, 1973.3646837057756, 1734.6046649040973, 1998.8633825480665, 1721.4464906356027, 1773.1836396213173, 1959.0329566856553, 1932.000926904674, 1397.0377910666946, 1897.3037503592925, 1923.7293930895175, 1857.636541550933, 1679.686392123253, 1136.6360055914413, 1586.0903629684624, 1864.804529311258, 1858.382201371818, 1882.136602441557, 1918.251048266355, 1878.3462669467815, 1861.765256987439, 1963.3914326821573, 1619.213004047467, 1473.7757946729403, 1576.2562256802646, 1460.3043585355824, 1035.9869291307502, 1885.09984921732, 1778.0634312503078, 1324.9470763629847, 1595.5625942900713, 1451.1139459387482, 1845.6842041396258, 1909.3538604884295, 1547.1161855138641, 2027.6617583265077, 1862.0845697055872, 1481.9198302517427, 1907.87598325444, 2037.4101595964828, 1910.6164411515254, 1917.0999776705896, 1727.5894124016731, 1962.3479488899313, 2001.5934664666265, 1605.561598810201, 1802.4598526975924, 1862.3491303211197], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [336.5597677232284, 447.6900223772495, 290.17467564441233, 372.3419995647081, 506.23849204164037, 214.96015366445093, 481.0466832776853, 393.1246680727325, 405.08440897691094, 410.6795080102268, 366.09292622355645, 557.1486928262888, 399.72867246827843, 613.6750140544221, 371.2748779605566, 461.0355873035137, 386.5496061083491, 483.9571612155687, 525.7238095161215, 387.62836160085675, 521.4612796846699, 436.999526285121, 501.52078747933956, 340.84920853005804, 654.8682257501727, 441.31270060457507, 717.8316976790959, 515.1367170222603, 633.0750066282002, 365.01658596452387, 307.49722155959415, 419.7842358182721, 194.54875448405488, 424.1146470519523, 546.033844067848, 349.6405983163411, 528.2852825943684, 537.4188181057913, 590.180590779919, 438.0976495837523, 725.0591142868984, 187.12749201652642, 472.0914152074715, 335.8452141102802, 513.0677355288868, 430.7298345893502, 251.7422524058762, 577.2775503385272, 507.54066971874664, 233.97435127918652, 590.6153259144115, 565.8816331211572, 520.6743624639262, 446.0040734930479, 463.78440600357965, 565.6643531311238, 567.3763077353383, 298.10236552940665, 663.9860395508025, 598.7513287664171, 453.16526400282333, 525.2920187735781, 463.94366436759503, 376.62130625065186, 608.7618473863479, 579.9053791788973, 454.74821625682665, 593.5477119660931, 463.33458946831735, 270.4123024512214, 288.2225590901995, 461.98446249511824, 166.91146162558837, 349.641839559086, 605.8526830181781, 572.8790977681126, 488.7745305856615, 489.4292904248242, 325.49451340838107, 315.52152208093503, 532.8966988257736, 377.6914413574885, 600.6633414383459, 460.0788657404646, 435.0740928528097, 556.8888760146177, 408.45215165624256, 332.950603512872, 415.04199957956945, 373.06919626686584, 251.89654661431166, 492.40914525628, 395.6678943167038, 550.818882713361, 450.47601335169264, 358.35398598072925, 475.3895541415213, 530.512324816685, 463.7982539743561, 474.53897449113697, 261.5006089112159, 363.1185698426559, 368.1960570302946, 257.2626733262592, 440.28970777817415, 563.7478725284096, 528.0156320184497, 554.0554763171109, 608.4274179816123, 534.0254694369311, 582.1332990620506, 254.30664896673713, 483.62176328938455, 443.79199467859536, 466.24998971890415, 356.3304152299173, 344.26130260872, 473.2458996619951, 397.4520736888611, 507.4196846108263, 436.39046735639715, 260.50909443832296, 444.8909151428674, 355.48340050095845, 439.1413924845851, 155.02842573595157, 601.935830867164, 469.93629206428494, 467.5534744871405, 611.3374319704045, 415.21002856089046, 455.29465035630847, 197.35683256616656, 476.23688562506834, 534.6025276765735, 443.6675709267234, 360.6183817256613, 411.84734515342615, 633.8919184392673, 506.62322998940664, 545.4551672289896, 736.1770968953147, 500.54192754452146, 373.23531882047774, 660.4930751574857, 340.7661088415221, 576.5576231764168, 224.33089264625002, 424.42579093487495, 553.5512474524022, 354.71726718111137, 384.3220226232693, 598.0474880108848, 403.07396546381653, 441.1616359351713, 467.24168533302344, 350.54504117498277, 323.51392202789975, 320.8264644704909, 561.9989507634639, 557.4892955565699, 392.6331608069827, 386.605367302981, 319.44116444505414, 209.4701596968063, 341.712019597548, 401.33236576379994, 512.4362032922911, 370.2614990635138, 604.6738089182901, 553.0848254768069, 389.92604040646853, 315.6604888462986, 383.0769254432993, 512.6234651605284, 381.0578055880361, 216.12000559272607, 521.0929615427254, 390.7066400380856, 690.9107588431146, 391.3026671140713, 243.9962772765606, 511.6301029564271, 544.960690682953, 603.7540932241802, 329.0474087652403, 558.4312728912867, 450.7671531782966, 638.7886276168243, 600.9352827412035, 385.45736315239924, 631.1726198988323, 403.29498346580016, 610.5526545461796, 387.9097395326821, 426.0894426215957, 512.2031031594246, 328.9971018023313, 368.2828360650995, 333.4869047380413], "policy_predator_policy_reward": [602.607911071588, 547.3269895591039, 668.192743316791, 473.62923761524786, 587.9022402096771, 552.5491116217347, 450.72811228025193, 468.76827165329445, 505.0218102814607, 530.6437100648993, 418.5087208267455, 566.3794283465999, 413.9694251787041, 553.3099933759783, 434.0655586511599, 625.6354441944535, 558.5934452191234, 428.88971589884824, 449.26435962249315, 453.9347469773197, 343.6788026991608, 466.8499591089385, 510.6446358222525, 465.05307897693245, 432.8091841909461, 209.03315484721554, 440.4140663238102, 369.3825450168792, 549.9253830000489, 372.336257428526, 498.44406672789955, 619.3217898110272, 714.150275317944, 561.6797736571237, 455.5150629494257, 517.6902074394311, 492.5122375554803, 339.7087514325197, 334.9052990865528, 413.423065527211, 495.91801785082276, 564.6061989014694, 516.0844480691018, 478.52752757427595, 491.1545032192447, 434.3573675381029, 616.2714118772795, 535.3144617575078, 465.95513754162397, 624.7828101263065, 494.46803302957017, 378.97507005600426, 463.25419878271447, 356.5497613642159, 460.10035460072646, 443.3379333311835, 439.11912163421675, 519.7665377706078, 324.0007320874567, 353.9533667138909, 361.6581899202559, 404.7794148499442, 417.9378805969885, 486.0307105537317, 384.0257614639017, 307.7358388859915, 390.2679294300346, 367.85133493588603, 563.3110784266804, 604.8904801700345, 523.5327149051257, 482.39118804344884, 667.917460855774, 651.38882267549, 449.18197554262406, 422.637978111245, 404.37051114110125, 350.04131289774705, 468.0773880858188, 530.8653686992162, 527.445768084514, 423.0819560255486, 215.63661438968248, 308.7134632009665, 419.8666404437247, 309.66169222173664, 545.6140620406799, 514.1966784391626, 379.468102245574, 560.6633323993265, 170.97937412777503, 209.71971858406548, 527.3141881404963, 516.1898263684349, 460.9634371484354, 439.0349362414493, 438.3592951999254, 375.23294740325383, 455.9388106763344, 389.6112997868979, 685.3279329771373, 467.4814616211082, 645.5501411457709, 477.96931119546156, 501.30059594491746, 323.79461771999956, 489.0329039083036, 402.2606714619142, 311.0548853741983, 281.09689211135304, 546.474707357192, 615.9487271620872, 456.5830435806785, 337.4496890869452, 550.6901770471961, 399.9130576252979, 542.9395869920909, 598.5861674228485, 552.8940538492213, 474.23511475576714, 286.69757537098144, 413.4406539009932, 519.1261973666464, 577.8032373488219, 671.5882692242031, 657.9713056447804, 471.20216547922405, 314.56225314026074, 294.8359297774518, 305.95955588825746, 120.71618599100069, 145.41514068324142, 442.36610013847815, 470.1305446387487, 377.7902660132536, 508.7441646947072, 492.1622389200312, 593.7542355727, 417.94383265849854, 323.67762135438505, 312.52892492772804, 324.0898592143192, 549.5991431865818, 454.9698773952003, 481.6642300942783, 378.8418428941503, 634.1929264653622, 528.3099903941276, 234.55060319509644, 406.68536246509376, 392.7788168319345, 341.95768803662577, 292.97340966625677, 282.1613625393085, 322.68623974116593, 229.21479752622315, 221.9249012100375, 140.00306471782986, 508.9657745433332, 493.30865944002807, 436.33626958325704, 391.604705303499, 364.05781880286537, 254.84272581208432, 462.1974053618091, 582.1830096339114, 313.2928256243009, 224.05255125835686, 526.7850064423574, 343.96388971546384, 463.6036860203111, 502.7393085848451, 462.6785097087551, 385.70026151551133, 652.7670991074308, 481.2133884705131, 532.5950231850113, 592.2765793851244, 232.12266520006088, 168.17976617048248, 590.6496144891529, 681.9274243746545, 492.2503129843018, 488.56905297280116, 426.092480493423, 551.7224586686808, 428.0210377015467, 479.8805138994621, 280.693073622217, 207.17242842142883, 474.9862160155373, 470.73174982316425, 436.0319163392741, 551.7139121153718, 268.3536202906326, 523.2087963652915, 398.168333505962, 563.0913142298756, 598.0625331193207, 562.5168563986608]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.574623324214895, "mean_inference_ms": 6.779169913232225, "mean_action_processing_ms": 1.1021475194953265, "mean_env_wait_ms": 0.9606637602202255, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03629159927368164, "StateBufferConnector_ms": 0.008836627006530762, "ViewRequirementAgentConnector_ms": 0.5995197296142578}, "num_episodes": 18, "episode_return_max": 2050.5517344401574, "episode_return_min": 1035.9869291307502, "episode_return_mean": 1792.2355990353794, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 136.30673226507886, "num_env_steps_trained_throughput_per_sec": 136.30673226507886, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 31417.744, "restore_workers_time_ms": 0.024, "training_step_time_ms": 31417.667, "sample_time_ms": 7173.769, "learn_time_ms": 24209.877, "learn_throughput": 165.222, "synch_weights_time_ms": 32.672}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "479e5_00000", "date": "2024-08-16_12-04-01", "timestamp": 1723790041, "time_this_iter_s": 29.352966785430908, "time_total_s": 2232.6340777873993, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7901e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2232.6340777873993, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 42.37857142857143, "ram_util_percent": 73.54761904761905}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.022257916984104, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.601388511960469, "policy_loss": -0.004204424922157414, "vf_loss": 9.604458918899455, "vf_explained_var": -0.013095149602839556, "kl": 0.010080047492920852, "entropy": 1.263176956757036, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.309238240564311, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.534515438382588, "policy_loss": -0.0009170137407386272, "vf_loss": 9.534843456934368, "vf_explained_var": -0.012845673195268742, "kl": 0.005235793667696058, "entropy": 0.8271798073930084, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 2050.5517344401574, "episode_reward_min": 1035.9869291307502, "episode_reward_mean": 1766.564044321565, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -122.02724071284037, "predator_policy": 16.707985549070223}, "policy_reward_max": {"prey_policy": 736.1770968953147, "predator_policy": 812.9987742816393}, "policy_reward_mean": {"prey_policy": 447.7165986103438, "predator_policy": 435.56542355043877}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1897.92508968816, 1776.6066049774356, 1972.710823055722, 1802.5486049611295, 1869.3094408755833, 1980.6056763791933, 1832.2529686658631, 2029.9400621211414, 1786.4823961039035, 1932.8870470666157, 1824.36433266957, 1940.6914671185716, 1744.8948875466006, 1744.5335617689677, 1880.42882691514, 1806.4151925888407, 1901.9484505162557, 1756.130924533893, 1835.8595847159384, 2050.5517344401574, 1732.6156450493313, 1639.9587922743515, 1861.1158642933253, 1585.092284769457, 1721.4913015328884, 1801.2134956489567, 1728.2426304913338, 1125.0047845824317, 1989.990791538992, 1708.8283727223063, 1819.4941215613842, 1783.8873389287266, 1777.4285733521185, 1748.9781826977865, 1829.1327939714997, 1973.3646837057756, 1734.6046649040973, 1998.8633825480665, 1721.4464906356027, 1773.1836396213173, 1959.0329566856553, 1932.000926904674, 1397.0377910666946, 1897.3037503592925, 1923.7293930895175, 1857.636541550933, 1679.686392123253, 1136.6360055914413, 1586.0903629684624, 1864.804529311258, 1858.382201371818, 1882.136602441557, 1918.251048266355, 1878.3462669467815, 1861.765256987439, 1963.3914326821573, 1619.213004047467, 1473.7757946729403, 1576.2562256802646, 1460.3043585355824, 1035.9869291307502, 1885.09984921732, 1778.0634312503078, 1324.9470763629847, 1595.5625942900713, 1451.1139459387482, 1845.6842041396258, 1909.3538604884295, 1547.1161855138641, 2027.6617583265077, 1862.0845697055872, 1481.9198302517427, 1907.87598325444, 2037.4101595964828, 1910.6164411515254, 1917.0999776705896, 1727.5894124016731, 1962.3479488899313, 2001.5934664666265, 1605.561598810201, 1802.4598526975924, 1862.3491303211197, 1909.210299041548, 1903.072910857958, 1978.5919256825603, 2040.7480866929739, 1780.700632367987, 1946.1042581731174, 1229.820865011206, 1487.0369757633127, 1321.0967964654362, 1574.415755983612, 1818.8594400753584, 1917.7070673749915, 1479.7244211343093, 1523.009504368078, 1726.6067164067936, 1719.9803197378537, 1848.0970696458162, 1825.3168286754833], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [528.2852825943684, 537.4188181057913, 590.180590779919, 438.0976495837523, 725.0591142868984, 187.12749201652642, 472.0914152074715, 335.8452141102802, 513.0677355288868, 430.7298345893502, 251.7422524058762, 577.2775503385272, 507.54066971874664, 233.97435127918652, 590.6153259144115, 565.8816331211572, 520.6743624639262, 446.0040734930479, 463.78440600357965, 565.6643531311238, 567.3763077353383, 298.10236552940665, 663.9860395508025, 598.7513287664171, 453.16526400282333, 525.2920187735781, 463.94366436759503, 376.62130625065186, 608.7618473863479, 579.9053791788973, 454.74821625682665, 593.5477119660931, 463.33458946831735, 270.4123024512214, 288.2225590901995, 461.98446249511824, 166.91146162558837, 349.641839559086, 605.8526830181781, 572.8790977681126, 488.7745305856615, 489.4292904248242, 325.49451340838107, 315.52152208093503, 532.8966988257736, 377.6914413574885, 600.6633414383459, 460.0788657404646, 435.0740928528097, 556.8888760146177, 408.45215165624256, 332.950603512872, 415.04199957956945, 373.06919626686584, 251.89654661431166, 492.40914525628, 395.6678943167038, 550.818882713361, 450.47601335169264, 358.35398598072925, 475.3895541415213, 530.512324816685, 463.7982539743561, 474.53897449113697, 261.5006089112159, 363.1185698426559, 368.1960570302946, 257.2626733262592, 440.28970777817415, 563.7478725284096, 528.0156320184497, 554.0554763171109, 608.4274179816123, 534.0254694369311, 582.1332990620506, 254.30664896673713, 483.62176328938455, 443.79199467859536, 466.24998971890415, 356.3304152299173, 344.26130260872, 473.2458996619951, 397.4520736888611, 507.4196846108263, 436.39046735639715, 260.50909443832296, 444.8909151428674, 355.48340050095845, 439.1413924845851, 155.02842573595157, 601.935830867164, 469.93629206428494, 467.5534744871405, 611.3374319704045, 415.21002856089046, 455.29465035630847, 197.35683256616656, 476.23688562506834, 534.6025276765735, 443.6675709267234, 360.6183817256613, 411.84734515342615, 633.8919184392673, 506.62322998940664, 545.4551672289896, 736.1770968953147, 500.54192754452146, 373.23531882047774, 660.4930751574857, 340.7661088415221, 576.5576231764168, 224.33089264625002, 424.42579093487495, 553.5512474524022, 354.71726718111137, 384.3220226232693, 598.0474880108848, 403.07396546381653, 441.1616359351713, 467.24168533302344, 350.54504117498277, 323.51392202789975, 320.8264644704909, 561.9989507634639, 557.4892955565699, 392.6331608069827, 386.605367302981, 319.44116444505414, 209.4701596968063, 341.712019597548, 401.33236576379994, 512.4362032922911, 370.2614990635138, 604.6738089182901, 553.0848254768069, 389.92604040646853, 315.6604888462986, 383.0769254432993, 512.6234651605284, 381.0578055880361, 216.12000559272607, 521.0929615427254, 390.7066400380856, 690.9107588431146, 391.3026671140713, 243.9962772765606, 511.6301029564271, 544.960690682953, 603.7540932241802, 329.0474087652403, 558.4312728912867, 450.7671531782966, 638.7886276168243, 600.9352827412035, 385.45736315239924, 631.1726198988323, 403.29498346580016, 610.5526545461796, 387.9097395326821, 426.0894426215957, 512.2031031594246, 328.9971018023313, 368.2828360650995, 333.4869047380413, 653.7134006866438, 366.28408129035705, 369.13493948025354, 207.09129177089534, 545.941757176828, 488.3895262557735, 422.5225066255367, 362.8978154513501, 371.9234460251124, 145.93618034647014, 423.53530336568326, 227.21976869047492, 420.6486361696472, 476.82106600739013, 302.4902285690971, 527.1945831461486, 526.1939170382118, 495.43644014865095, 448.40532234145746, 483.0553932683239, 623.4820430510882, 617.998054685305, 449.2923376892506, 486.7698333979061, 665.1393471135104, 408.0803369490007, 524.058957978469, 634.261404177459, -122.02724071284037, 445.11889485948376, 491.45905098248454, 561.3748313688141, 471.8572182979999, 484.46358497109605, 299.66751941902567, 519.7300434229439], "policy_predator_policy_reward": [492.5122375554803, 339.7087514325197, 334.9052990865528, 413.423065527211, 495.91801785082276, 564.6061989014694, 516.0844480691018, 478.52752757427595, 491.1545032192447, 434.3573675381029, 616.2714118772795, 535.3144617575078, 465.95513754162397, 624.7828101263065, 494.46803302957017, 378.97507005600426, 463.25419878271447, 356.5497613642159, 460.10035460072646, 443.3379333311835, 439.11912163421675, 519.7665377706078, 324.0007320874567, 353.9533667138909, 361.6581899202559, 404.7794148499442, 417.9378805969885, 486.0307105537317, 384.0257614639017, 307.7358388859915, 390.2679294300346, 367.85133493588603, 563.3110784266804, 604.8904801700345, 523.5327149051257, 482.39118804344884, 667.917460855774, 651.38882267549, 449.18197554262406, 422.637978111245, 404.37051114110125, 350.04131289774705, 468.0773880858188, 530.8653686992162, 527.445768084514, 423.0819560255486, 215.63661438968248, 308.7134632009665, 419.8666404437247, 309.66169222173664, 545.6140620406799, 514.1966784391626, 379.468102245574, 560.6633323993265, 170.97937412777503, 209.71971858406548, 527.3141881404963, 516.1898263684349, 460.9634371484354, 439.0349362414493, 438.3592951999254, 375.23294740325383, 455.9388106763344, 389.6112997868979, 685.3279329771373, 467.4814616211082, 645.5501411457709, 477.96931119546156, 501.30059594491746, 323.79461771999956, 489.0329039083036, 402.2606714619142, 311.0548853741983, 281.09689211135304, 546.474707357192, 615.9487271620872, 456.5830435806785, 337.4496890869452, 550.6901770471961, 399.9130576252979, 542.9395869920909, 598.5861674228485, 552.8940538492213, 474.23511475576714, 286.69757537098144, 413.4406539009932, 519.1261973666464, 577.8032373488219, 671.5882692242031, 657.9713056447804, 471.20216547922405, 314.56225314026074, 294.8359297774518, 305.95955588825746, 120.71618599100069, 145.41514068324142, 442.36610013847815, 470.1305446387487, 377.7902660132536, 508.7441646947072, 492.1622389200312, 593.7542355727, 417.94383265849854, 323.67762135438505, 312.52892492772804, 324.0898592143192, 549.5991431865818, 454.9698773952003, 481.6642300942783, 378.8418428941503, 634.1929264653622, 528.3099903941276, 234.55060319509644, 406.68536246509376, 392.7788168319345, 341.95768803662577, 292.97340966625677, 282.1613625393085, 322.68623974116593, 229.21479752622315, 221.9249012100375, 140.00306471782986, 508.9657745433332, 493.30865944002807, 436.33626958325704, 391.604705303499, 364.05781880286537, 254.84272581208432, 462.1974053618091, 582.1830096339114, 313.2928256243009, 224.05255125835686, 526.7850064423574, 343.96388971546384, 463.6036860203111, 502.7393085848451, 462.6785097087551, 385.70026151551133, 652.7670991074308, 481.2133884705131, 532.5950231850113, 592.2765793851244, 232.12266520006088, 168.17976617048248, 590.6496144891529, 681.9274243746545, 492.2503129843018, 488.56905297280116, 426.092480493423, 551.7224586686808, 428.0210377015467, 479.8805138994621, 280.693073622217, 207.17242842142883, 474.9862160155373, 470.73174982316425, 436.0319163392741, 551.7139121153718, 268.3536202906326, 523.2087963652915, 398.168333505962, 563.0913142298756, 598.0625331193207, 562.5168563986608, 412.44444056551, 476.76837649903837, 624.253326138558, 702.5933534682532, 519.9600523033008, 424.3005899466602, 627.2051925457599, 628.1225720703285, 616.8782421402443, 645.9627638561599, 665.2773714951137, 630.0718146218449, 198.10993644054045, 134.2412263936279, 309.2642916615331, 348.08787238653485, 184.5523363830826, 114.91410289549181, 626.2470548247594, 16.707985549070223, 287.25456804560946, 290.1247742933543, 510.30672824486805, 471.33816804296777, 188.55664332691998, 217.94809374487977, 167.22898045075388, 197.46016176139665, 812.9987742816393, 590.5162879785146, 407.84250052853935, 259.3039368580135, 464.51868608906625, 427.2575802876527, 523.0244305812482, 482.89483525226336]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.583688088170698, "mean_inference_ms": 6.8024831827553776, "mean_action_processing_ms": 1.10608353533838, "mean_env_wait_ms": 0.962974363309539, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03770601749420166, "StateBufferConnector_ms": 0.009411096572875977, "ViewRequirementAgentConnector_ms": 0.5939410924911499}, "num_episodes": 18, "episode_return_max": 2050.5517344401574, "episode_return_min": 1035.9869291307502, "episode_return_mean": 1766.564044321565, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 128.35670319199357, "num_env_steps_trained_throughput_per_sec": 128.35670319199357, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 30168.86, "restore_workers_time_ms": 0.021, "training_step_time_ms": 30168.791, "sample_time_ms": 6623.686, "learn_time_ms": 23511.098, "learn_throughput": 170.132, "synch_weights_time_ms": 32.686}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "479e5_00000", "date": "2024-08-16_12-04-32", "timestamp": 1723790072, "time_this_iter_s": 31.170485973358154, "time_total_s": 2263.8045637607574, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78b9af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2263.8045637607574, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 43.95909090909091, "ram_util_percent": 73.74545454545454}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9922194111914862, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.599694810594832, "policy_loss": -0.005989119633613401, "vf_loss": 9.604337667535853, "vf_explained_var": -0.03146738911431933, "kl": 0.011966678708677483, "entropy": 1.2394897788920731, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2911044953519073, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.573428682801584, "policy_loss": 0.00019036003452523677, "vf_loss": 9.57248427880504, "vf_explained_var": 0.0018695760340917678, "kl": 0.006702608342898811, "entropy": 0.8205567030364244, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 2040.7480866929739, "episode_reward_min": 1035.9869291307502, "episode_reward_mean": 1724.222089682206, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -122.02724071284037, "predator_policy": 16.707985549070223}, "policy_reward_max": {"prey_policy": 759.845564696208, "predator_policy": 812.9987742816393}, "policy_reward_mean": {"prey_policy": 442.8868629522819, "predator_policy": 419.2241818888212}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1861.1158642933253, 1585.092284769457, 1721.4913015328884, 1801.2134956489567, 1728.2426304913338, 1125.0047845824317, 1989.990791538992, 1708.8283727223063, 1819.4941215613842, 1783.8873389287266, 1777.4285733521185, 1748.9781826977865, 1829.1327939714997, 1973.3646837057756, 1734.6046649040973, 1998.8633825480665, 1721.4464906356027, 1773.1836396213173, 1959.0329566856553, 1932.000926904674, 1397.0377910666946, 1897.3037503592925, 1923.7293930895175, 1857.636541550933, 1679.686392123253, 1136.6360055914413, 1586.0903629684624, 1864.804529311258, 1858.382201371818, 1882.136602441557, 1918.251048266355, 1878.3462669467815, 1861.765256987439, 1963.3914326821573, 1619.213004047467, 1473.7757946729403, 1576.2562256802646, 1460.3043585355824, 1035.9869291307502, 1885.09984921732, 1778.0634312503078, 1324.9470763629847, 1595.5625942900713, 1451.1139459387482, 1845.6842041396258, 1909.3538604884295, 1547.1161855138641, 2027.6617583265077, 1862.0845697055872, 1481.9198302517427, 1907.87598325444, 2037.4101595964828, 1910.6164411515254, 1917.0999776705896, 1727.5894124016731, 1962.3479488899313, 2001.5934664666265, 1605.561598810201, 1802.4598526975924, 1862.3491303211197, 1909.210299041548, 1903.072910857958, 1978.5919256825603, 2040.7480866929739, 1780.700632367987, 1946.1042581731174, 1229.820865011206, 1487.0369757633127, 1321.0967964654362, 1574.415755983612, 1818.8594400753584, 1917.7070673749915, 1479.7244211343093, 1523.009504368078, 1726.6067164067936, 1719.9803197378537, 1848.0970696458162, 1825.3168286754833, 1558.3934779989145, 1797.284282955027, 1569.0103285189914, 1286.9327170097035, 1597.3796479983778, 1833.221226047633, 1707.4426743412723, 1587.9444590937478, 1595.1348520049794, 1797.8554125809628, 1603.8739503510535, 1893.8267847202555, 1977.098465878832, 1571.1672864021862, 1799.2441554224026, 1850.7818628545028, 1775.8694364388282, 1737.2522614358595, 1318.7641954615779, 1295.6430549199933, 1865.6727159629697, 1485.6734016983878], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [532.8966988257736, 377.6914413574885, 600.6633414383459, 460.0788657404646, 435.0740928528097, 556.8888760146177, 408.45215165624256, 332.950603512872, 415.04199957956945, 373.06919626686584, 251.89654661431166, 492.40914525628, 395.6678943167038, 550.818882713361, 450.47601335169264, 358.35398598072925, 475.3895541415213, 530.512324816685, 463.7982539743561, 474.53897449113697, 261.5006089112159, 363.1185698426559, 368.1960570302946, 257.2626733262592, 440.28970777817415, 563.7478725284096, 528.0156320184497, 554.0554763171109, 608.4274179816123, 534.0254694369311, 582.1332990620506, 254.30664896673713, 483.62176328938455, 443.79199467859536, 466.24998971890415, 356.3304152299173, 344.26130260872, 473.2458996619951, 397.4520736888611, 507.4196846108263, 436.39046735639715, 260.50909443832296, 444.8909151428674, 355.48340050095845, 439.1413924845851, 155.02842573595157, 601.935830867164, 469.93629206428494, 467.5534744871405, 611.3374319704045, 415.21002856089046, 455.29465035630847, 197.35683256616656, 476.23688562506834, 534.6025276765735, 443.6675709267234, 360.6183817256613, 411.84734515342615, 633.8919184392673, 506.62322998940664, 545.4551672289896, 736.1770968953147, 500.54192754452146, 373.23531882047774, 660.4930751574857, 340.7661088415221, 576.5576231764168, 224.33089264625002, 424.42579093487495, 553.5512474524022, 354.71726718111137, 384.3220226232693, 598.0474880108848, 403.07396546381653, 441.1616359351713, 467.24168533302344, 350.54504117498277, 323.51392202789975, 320.8264644704909, 561.9989507634639, 557.4892955565699, 392.6331608069827, 386.605367302981, 319.44116444505414, 209.4701596968063, 341.712019597548, 401.33236576379994, 512.4362032922911, 370.2614990635138, 604.6738089182901, 553.0848254768069, 389.92604040646853, 315.6604888462986, 383.0769254432993, 512.6234651605284, 381.0578055880361, 216.12000559272607, 521.0929615427254, 390.7066400380856, 690.9107588431146, 391.3026671140713, 243.9962772765606, 511.6301029564271, 544.960690682953, 603.7540932241802, 329.0474087652403, 558.4312728912867, 450.7671531782966, 638.7886276168243, 600.9352827412035, 385.45736315239924, 631.1726198988323, 403.29498346580016, 610.5526545461796, 387.9097395326821, 426.0894426215957, 512.2031031594246, 328.9971018023313, 368.2828360650995, 333.4869047380413, 653.7134006866438, 366.28408129035705, 369.13493948025354, 207.09129177089534, 545.941757176828, 488.3895262557735, 422.5225066255367, 362.8978154513501, 371.9234460251124, 145.93618034647014, 423.53530336568326, 227.21976869047492, 420.6486361696472, 476.82106600739013, 302.4902285690971, 527.1945831461486, 526.1939170382118, 495.43644014865095, 448.40532234145746, 483.0553932683239, 623.4820430510882, 617.998054685305, 449.2923376892506, 486.7698333979061, 665.1393471135104, 408.0803369490007, 524.058957978469, 634.261404177459, -122.02724071284037, 445.11889485948376, 491.45905098248454, 561.3748313688141, 471.8572182979999, 484.46358497109605, 299.66751941902567, 519.7300434229439, 300.05154779966495, 423.35458696970903, 409.5555270470059, 543.4830643343347, 535.3053233960529, 549.7877366542731, 489.39507362123203, 567.752464236438, 618.3100591986223, 452.97238985941016, 241.63836673796, 421.03261404631587, 188.21433892600024, 41.49999322248226, 408.24106808002966, 424.6032848449571, 505.66757206359375, 451.22383798449613, 569.7172743980832, 319.06611778019885, 430.9783224539826, 161.4142405827497, 555.2413668823536, 369.74215047832246, 748.4147472993075, 541.5796318478546, 153.47744017104526, 437.68984294502326, 618.6613897764652, 532.5246394971172, 193.01543366223905, 344.34343190257727, 430.23325131768917, 593.4936577500565, 361.7123690925054, 440.7310613801982, 388.7423564993517, 759.845564696208, 471.6863672827794, 514.4418186288542, 416.45888690536674, 537.0298903146938, 542.8260628607609, 492.619129372488], "policy_predator_policy_reward": [527.445768084514, 423.0819560255486, 215.63661438968248, 308.7134632009665, 419.8666404437247, 309.66169222173664, 545.6140620406799, 514.1966784391626, 379.468102245574, 560.6633323993265, 170.97937412777503, 209.71971858406548, 527.3141881404963, 516.1898263684349, 460.9634371484354, 439.0349362414493, 438.3592951999254, 375.23294740325383, 455.9388106763344, 389.6112997868979, 685.3279329771373, 467.4814616211082, 645.5501411457709, 477.96931119546156, 501.30059594491746, 323.79461771999956, 489.0329039083036, 402.2606714619142, 311.0548853741983, 281.09689211135304, 546.474707357192, 615.9487271620872, 456.5830435806785, 337.4496890869452, 550.6901770471961, 399.9130576252979, 542.9395869920909, 598.5861674228485, 552.8940538492213, 474.23511475576714, 286.69757537098144, 413.4406539009932, 519.1261973666464, 577.8032373488219, 671.5882692242031, 657.9713056447804, 471.20216547922405, 314.56225314026074, 294.8359297774518, 305.95955588825746, 120.71618599100069, 145.41514068324142, 442.36610013847815, 470.1305446387487, 377.7902660132536, 508.7441646947072, 492.1622389200312, 593.7542355727, 417.94383265849854, 323.67762135438505, 312.52892492772804, 324.0898592143192, 549.5991431865818, 454.9698773952003, 481.6642300942783, 378.8418428941503, 634.1929264653622, 528.3099903941276, 234.55060319509644, 406.68536246509376, 392.7788168319345, 341.95768803662577, 292.97340966625677, 282.1613625393085, 322.68623974116593, 229.21479752622315, 221.9249012100375, 140.00306471782986, 508.9657745433332, 493.30865944002807, 436.33626958325704, 391.604705303499, 364.05781880286537, 254.84272581208432, 462.1974053618091, 582.1830096339114, 313.2928256243009, 224.05255125835686, 526.7850064423574, 343.96388971546384, 463.6036860203111, 502.7393085848451, 462.6785097087551, 385.70026151551133, 652.7670991074308, 481.2133884705131, 532.5950231850113, 592.2765793851244, 232.12266520006088, 168.17976617048248, 590.6496144891529, 681.9274243746545, 492.2503129843018, 488.56905297280116, 426.092480493423, 551.7224586686808, 428.0210377015467, 479.8805138994621, 280.693073622217, 207.17242842142883, 474.9862160155373, 470.73174982316425, 436.0319163392741, 551.7139121153718, 268.3536202906326, 523.2087963652915, 398.168333505962, 563.0913142298756, 598.0625331193207, 562.5168563986608, 412.44444056551, 476.76837649903837, 624.253326138558, 702.5933534682532, 519.9600523033008, 424.3005899466602, 627.2051925457599, 628.1225720703285, 616.8782421402443, 645.9627638561599, 665.2773714951137, 630.0718146218449, 198.10993644054045, 134.2412263936279, 309.2642916615331, 348.08787238653485, 184.5523363830826, 114.91410289549181, 626.2470548247594, 16.707985549070223, 287.25456804560946, 290.1247742933543, 510.30672824486805, 471.33816804296777, 188.55664332691998, 217.94809374487977, 167.22898045075388, 197.46016176139665, 812.9987742816393, 590.5162879785146, 407.84250052853935, 259.3039368580135, 464.51868608906625, 427.2575802876527, 523.0244305812482, 482.89483525226336, 357.0072942079231, 477.9800490216162, 408.32866116826375, 435.9170304054184, 223.2422374677692, 260.6750310008964, 132.76367787403197, 97.02150127800188, 367.60650898527933, 158.49068995506556, 503.6093930654515, 666.9408521979047, 748.6089783554024, 729.1193638373871, 529.6741091534391, 225.42599701531992, 353.6969266924332, 284.5465152644581, 426.14729680512283, 482.92472359755806, 526.4393390541292, 485.0420482601929, 436.24389728708053, 532.599370072498, 345.9438398716305, 341.1602468600363, 612.6062738795428, 367.3937294065745, 368.6552586373062, 279.4028675115138, 646.9435414107925, 666.479455878893, 353.92941337143117, 398.21311399965316, 576.4020085810889, 358.406822382069, 128.79815696028433, 41.37811730573457, 139.62253938355852, 169.89232962480176, 414.5196633299502, 497.6642754129573, 269.36512125285583, 180.8630882122819]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.59247742336358, "mean_inference_ms": 6.822943482157958, "mean_action_processing_ms": 1.1104381924844424, "mean_env_wait_ms": 0.9652738032299186, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02522110939025879, "StateBufferConnector_ms": 0.011253714561462402, "ViewRequirementAgentConnector_ms": 0.577792763710022}, "num_episodes": 22, "episode_return_max": 2040.7480866929739, "episode_return_min": 1035.9869291307502, "episode_return_mean": 1724.222089682206, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 134.00005081345577, "num_env_steps_trained_throughput_per_sec": 134.00005081345577, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 29948.043, "restore_workers_time_ms": 0.02, "training_step_time_ms": 29947.973, "sample_time_ms": 6239.801, "learn_time_ms": 23673.894, "learn_throughput": 168.962, "synch_weights_time_ms": 32.938}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "479e5_00000", "date": "2024-08-16_12-05-02", "timestamp": 1723790102, "time_this_iter_s": 29.863397121429443, "time_total_s": 2293.667960882187, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78cc700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2293.667960882187, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 42.878571428571426, "ram_util_percent": 73.66666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.894007263990937, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.551023851626764, "policy_loss": -0.0002871455321650183, "vf_loss": 9.55009755886421, "vf_explained_var": -0.012946237741954743, "kl": 0.010786251774970973, "entropy": 1.2608044021974796, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.130984098712603, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.529956889278674, "policy_loss": -0.0021937410176544395, "vf_loss": 9.53141842847148, "vf_explained_var": -0.028121383291072947, "kl": 0.006508370356086941, "entropy": 0.8197629675978706, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 2075.8687328720493, "episode_reward_min": 1035.9869291307502, "episode_reward_mean": 1729.3638773262328, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -122.02724071284037, "predator_policy": 16.707985549070223}, "policy_reward_max": {"prey_policy": 759.845564696208, "predator_policy": 812.9987742816393}, "policy_reward_mean": {"prey_policy": 438.9503853137709, "predator_policy": 425.73155334934563}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1959.0329566856553, 1932.000926904674, 1397.0377910666946, 1897.3037503592925, 1923.7293930895175, 1857.636541550933, 1679.686392123253, 1136.6360055914413, 1586.0903629684624, 1864.804529311258, 1858.382201371818, 1882.136602441557, 1918.251048266355, 1878.3462669467815, 1861.765256987439, 1963.3914326821573, 1619.213004047467, 1473.7757946729403, 1576.2562256802646, 1460.3043585355824, 1035.9869291307502, 1885.09984921732, 1778.0634312503078, 1324.9470763629847, 1595.5625942900713, 1451.1139459387482, 1845.6842041396258, 1909.3538604884295, 1547.1161855138641, 2027.6617583265077, 1862.0845697055872, 1481.9198302517427, 1907.87598325444, 2037.4101595964828, 1910.6164411515254, 1917.0999776705896, 1727.5894124016731, 1962.3479488899313, 2001.5934664666265, 1605.561598810201, 1802.4598526975924, 1862.3491303211197, 1909.210299041548, 1903.072910857958, 1978.5919256825603, 2040.7480866929739, 1780.700632367987, 1946.1042581731174, 1229.820865011206, 1487.0369757633127, 1321.0967964654362, 1574.415755983612, 1818.8594400753584, 1917.7070673749915, 1479.7244211343093, 1523.009504368078, 1726.6067164067936, 1719.9803197378537, 1848.0970696458162, 1825.3168286754833, 1558.3934779989145, 1797.284282955027, 1569.0103285189914, 1286.9327170097035, 1597.3796479983778, 1833.221226047633, 1707.4426743412723, 1587.9444590937478, 1595.1348520049794, 1797.8554125809628, 1603.8739503510535, 1893.8267847202555, 1977.098465878832, 1571.1672864021862, 1799.2441554224026, 1850.7818628545028, 1775.8694364388282, 1737.2522614358595, 1318.7641954615779, 1295.6430549199933, 1865.6727159629697, 1485.6734016983878, 1458.4899053358913, 1930.2146333174267, 1774.3257030817715, 1947.6491657851025, 2011.1075266525288, 1814.354079290576, 1654.518204283191, 1938.4287748065515, 1622.1207845432036, 1820.7823938520391, 1934.6870030237606, 1882.6375559592154, 1737.1121591755573, 1657.4770730886346, 1780.5434734070645, 2075.8687328720493, 1458.7543374162294, 1696.4706560179789], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [344.26130260872, 473.2458996619951, 397.4520736888611, 507.4196846108263, 436.39046735639715, 260.50909443832296, 444.8909151428674, 355.48340050095845, 439.1413924845851, 155.02842573595157, 601.935830867164, 469.93629206428494, 467.5534744871405, 611.3374319704045, 415.21002856089046, 455.29465035630847, 197.35683256616656, 476.23688562506834, 534.6025276765735, 443.6675709267234, 360.6183817256613, 411.84734515342615, 633.8919184392673, 506.62322998940664, 545.4551672289896, 736.1770968953147, 500.54192754452146, 373.23531882047774, 660.4930751574857, 340.7661088415221, 576.5576231764168, 224.33089264625002, 424.42579093487495, 553.5512474524022, 354.71726718111137, 384.3220226232693, 598.0474880108848, 403.07396546381653, 441.1616359351713, 467.24168533302344, 350.54504117498277, 323.51392202789975, 320.8264644704909, 561.9989507634639, 557.4892955565699, 392.6331608069827, 386.605367302981, 319.44116444505414, 209.4701596968063, 341.712019597548, 401.33236576379994, 512.4362032922911, 370.2614990635138, 604.6738089182901, 553.0848254768069, 389.92604040646853, 315.6604888462986, 383.0769254432993, 512.6234651605284, 381.0578055880361, 216.12000559272607, 521.0929615427254, 390.7066400380856, 690.9107588431146, 391.3026671140713, 243.9962772765606, 511.6301029564271, 544.960690682953, 603.7540932241802, 329.0474087652403, 558.4312728912867, 450.7671531782966, 638.7886276168243, 600.9352827412035, 385.45736315239924, 631.1726198988323, 403.29498346580016, 610.5526545461796, 387.9097395326821, 426.0894426215957, 512.2031031594246, 328.9971018023313, 368.2828360650995, 333.4869047380413, 653.7134006866438, 366.28408129035705, 369.13493948025354, 207.09129177089534, 545.941757176828, 488.3895262557735, 422.5225066255367, 362.8978154513501, 371.9234460251124, 145.93618034647014, 423.53530336568326, 227.21976869047492, 420.6486361696472, 476.82106600739013, 302.4902285690971, 527.1945831461486, 526.1939170382118, 495.43644014865095, 448.40532234145746, 483.0553932683239, 623.4820430510882, 617.998054685305, 449.2923376892506, 486.7698333979061, 665.1393471135104, 408.0803369490007, 524.058957978469, 634.261404177459, -122.02724071284037, 445.11889485948376, 491.45905098248454, 561.3748313688141, 471.8572182979999, 484.46358497109605, 299.66751941902567, 519.7300434229439, 300.05154779966495, 423.35458696970903, 409.5555270470059, 543.4830643343347, 535.3053233960529, 549.7877366542731, 489.39507362123203, 567.752464236438, 618.3100591986223, 452.97238985941016, 241.63836673796, 421.03261404631587, 188.21433892600024, 41.49999322248226, 408.24106808002966, 424.6032848449571, 505.66757206359375, 451.22383798449613, 569.7172743980832, 319.06611778019885, 430.9783224539826, 161.4142405827497, 555.2413668823536, 369.74215047832246, 748.4147472993075, 541.5796318478546, 153.47744017104526, 437.68984294502326, 618.6613897764652, 532.5246394971172, 193.01543366223905, 344.34343190257727, 430.23325131768917, 593.4936577500565, 361.7123690925054, 440.7310613801982, 388.7423564993517, 759.845564696208, 471.6863672827794, 514.4418186288542, 416.45888690536674, 537.0298903146938, 542.8260628607609, 492.619129372488, 379.1773387377685, 579.5218701370973, 365.3169910973639, 418.3720243878905, 511.3889938436925, 613.522683998646, 659.7620716452076, 278.5114439765173, 266.24641456679296, 429.25871322367755, 452.4896769768795, 444.14517113418844, 562.801527167956, 253.19594007905445, 628.3198177985053, 285.42387809734953, 542.3086777451693, 450.6754896648887, 385.1284155780023, 625.9270704251044, 629.0453711053705, 432.5350970713704, 379.55398648745853, 433.2600694444777, 313.66249308393196, 419.96141600789866, 642.2103186952752, 547.0578934910068, 123.86857610192601, 190.7937640914536, 563.9699231099786, 309.1374704031947, 189.25680586036165, 405.64582762154157, 425.0831099093461, 77.91057854998145], "policy_predator_policy_reward": [542.9395869920909, 598.5861674228485, 552.8940538492213, 474.23511475576714, 286.69757537098144, 413.4406539009932, 519.1261973666464, 577.8032373488219, 671.5882692242031, 657.9713056447804, 471.20216547922405, 314.56225314026074, 294.8359297774518, 305.95955588825746, 120.71618599100069, 145.41514068324142, 442.36610013847815, 470.1305446387487, 377.7902660132536, 508.7441646947072, 492.1622389200312, 593.7542355727, 417.94383265849854, 323.67762135438505, 312.52892492772804, 324.0898592143192, 549.5991431865818, 454.9698773952003, 481.6642300942783, 378.8418428941503, 634.1929264653622, 528.3099903941276, 234.55060319509644, 406.68536246509376, 392.7788168319345, 341.95768803662577, 292.97340966625677, 282.1613625393085, 322.68623974116593, 229.21479752622315, 221.9249012100375, 140.00306471782986, 508.9657745433332, 493.30865944002807, 436.33626958325704, 391.604705303499, 364.05781880286537, 254.84272581208432, 462.1974053618091, 582.1830096339114, 313.2928256243009, 224.05255125835686, 526.7850064423574, 343.96388971546384, 463.6036860203111, 502.7393085848451, 462.6785097087551, 385.70026151551133, 652.7670991074308, 481.2133884705131, 532.5950231850113, 592.2765793851244, 232.12266520006088, 168.17976617048248, 590.6496144891529, 681.9274243746545, 492.2503129843018, 488.56905297280116, 426.092480493423, 551.7224586686808, 428.0210377015467, 479.8805138994621, 280.693073622217, 207.17242842142883, 474.9862160155373, 470.73174982316425, 436.0319163392741, 551.7139121153718, 268.3536202906326, 523.2087963652915, 398.168333505962, 563.0913142298756, 598.0625331193207, 562.5168563986608, 412.44444056551, 476.76837649903837, 624.253326138558, 702.5933534682532, 519.9600523033008, 424.3005899466602, 627.2051925457599, 628.1225720703285, 616.8782421402443, 645.9627638561599, 665.2773714951137, 630.0718146218449, 198.10993644054045, 134.2412263936279, 309.2642916615331, 348.08787238653485, 184.5523363830826, 114.91410289549181, 626.2470548247594, 16.707985549070223, 287.25456804560946, 290.1247742933543, 510.30672824486805, 471.33816804296777, 188.55664332691998, 217.94809374487977, 167.22898045075388, 197.46016176139665, 812.9987742816393, 590.5162879785146, 407.84250052853935, 259.3039368580135, 464.51868608906625, 427.2575802876527, 523.0244305812482, 482.89483525226336, 357.0072942079231, 477.9800490216162, 408.32866116826375, 435.9170304054184, 223.2422374677692, 260.6750310008964, 132.76367787403197, 97.02150127800188, 367.60650898527933, 158.49068995506556, 503.6093930654515, 666.9408521979047, 748.6089783554024, 729.1193638373871, 529.6741091534391, 225.42599701531992, 353.6969266924332, 284.5465152644581, 426.14729680512283, 482.92472359755806, 526.4393390541292, 485.0420482601929, 436.24389728708053, 532.599370072498, 345.9438398716305, 341.1602468600363, 612.6062738795428, 367.3937294065745, 368.6552586373062, 279.4028675115138, 646.9435414107925, 666.479455878893, 353.92941337143117, 398.21311399965316, 576.4020085810889, 358.406822382069, 128.79815696028433, 41.37811730573457, 139.62253938355852, 169.89232962480176, 414.5196633299502, 497.6642754129573, 269.36512125285583, 180.8630882122819, 347.58705994573137, 152.20363651529348, 574.2126072122618, 572.3130106199105, 305.3721746927923, 344.0418505466386, 428.47645665802304, 580.8991935053576, 651.6137538482416, 663.9886450138137, 514.9461927876241, 402.7730383918839, 468.1621453265693, 370.3585917096117, 509.3206389417023, 515.364439968996, 334.1670027458879, 294.9696143872579, 353.6876874202434, 456.03922042869084, 425.6369385720125, 447.4695962750055, 525.1938375516387, 544.629662475642, 598.1384140393917, 405.3498360443361, 206.37492379426783, 261.8339371080856, 701.617790349382, 764.2633428643009, 572.0198492077884, 630.7414901510838, 405.5941126664607, 458.2575912678646, 712.9355673493393, 480.5414002093098]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.600547780534531, "mean_inference_ms": 6.843586071352945, "mean_action_processing_ms": 1.1139223651103063, "mean_env_wait_ms": 0.9669308400047995, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02546548843383789, "StateBufferConnector_ms": 0.011384367942810059, "ViewRequirementAgentConnector_ms": 0.5836277008056641}, "num_episodes": 18, "episode_return_max": 2075.8687328720493, "episode_return_min": 1035.9869291307502, "episode_return_mean": 1729.3638773262328, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 130.29889390811857, "num_env_steps_trained_throughput_per_sec": 130.29889390811857, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 29856.165, "restore_workers_time_ms": 0.021, "training_step_time_ms": 29856.094, "sample_time_ms": 5984.886, "learn_time_ms": 23836.697, "learn_throughput": 167.808, "synch_weights_time_ms": 33.159}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "479e5_00000", "date": "2024-08-16_12-05-33", "timestamp": 1723790133, "time_this_iter_s": 30.70551300048828, "time_total_s": 2324.373473882675, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7901430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2324.373473882675, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 42.77906976744187, "ram_util_percent": 73.87674418604652}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8227101516313653, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.669430938599602, "policy_loss": -0.00287908973990294, "vf_loss": 9.671238935056818, "vf_explained_var": -0.0010816831752736733, "kl": 0.009520892664941185, "entropy": 1.2495903118577585, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.467483640931271, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.436008992270818, "policy_loss": -0.0018514146821366417, "vf_loss": 9.436911649048014, "vf_explained_var": -0.0027950026686229404, "kl": 0.00843334235311899, "entropy": 0.8333997911246366, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 2075.8687328720493, "episode_reward_min": 547.839950255365, "episode_reward_mean": 1726.9372057716819, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -122.02724071284037, "predator_policy": 2.0944039560470378}, "policy_reward_max": {"prey_policy": 759.845564696208, "predator_policy": 821.0596555498161}, "policy_reward_mean": {"prey_policy": 430.0197437045473, "predator_policy": 433.44885918129336}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1324.9470763629847, 1595.5625942900713, 1451.1139459387482, 1845.6842041396258, 1909.3538604884295, 1547.1161855138641, 2027.6617583265077, 1862.0845697055872, 1481.9198302517427, 1907.87598325444, 2037.4101595964828, 1910.6164411515254, 1917.0999776705896, 1727.5894124016731, 1962.3479488899313, 2001.5934664666265, 1605.561598810201, 1802.4598526975924, 1862.3491303211197, 1909.210299041548, 1903.072910857958, 1978.5919256825603, 2040.7480866929739, 1780.700632367987, 1946.1042581731174, 1229.820865011206, 1487.0369757633127, 1321.0967964654362, 1574.415755983612, 1818.8594400753584, 1917.7070673749915, 1479.7244211343093, 1523.009504368078, 1726.6067164067936, 1719.9803197378537, 1848.0970696458162, 1825.3168286754833, 1558.3934779989145, 1797.284282955027, 1569.0103285189914, 1286.9327170097035, 1597.3796479983778, 1833.221226047633, 1707.4426743412723, 1587.9444590937478, 1595.1348520049794, 1797.8554125809628, 1603.8739503510535, 1893.8267847202555, 1977.098465878832, 1571.1672864021862, 1799.2441554224026, 1850.7818628545028, 1775.8694364388282, 1737.2522614358595, 1318.7641954615779, 1295.6430549199933, 1865.6727159629697, 1485.6734016983878, 1458.4899053358913, 1930.2146333174267, 1774.3257030817715, 1947.6491657851025, 2011.1075266525288, 1814.354079290576, 1654.518204283191, 1938.4287748065515, 1622.1207845432036, 1820.7823938520391, 1934.6870030237606, 1882.6375559592154, 1737.1121591755573, 1657.4770730886346, 1780.5434734070645, 2075.8687328720493, 1458.7543374162294, 1696.4706560179789, 1736.592692393949, 1586.968693395828, 1894.1973620154129, 1953.0221177853543, 1860.451140873224, 1870.1366844696304, 1822.5153982973225, 1895.4282529716932, 1775.9038404442435, 1647.0974536302951, 1955.7598630268556, 1875.2273039751617, 1853.5926986593574, 1760.1570904490436, 1468.2160956172972, 1403.3114483393852, 1892.1089669537175, 2032.1392023694077, 547.839950255365, 736.2080272151107, 1768.4765933492329, 1979.5947281570557, 1867.3182907828175], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [386.605367302981, 319.44116444505414, 209.4701596968063, 341.712019597548, 401.33236576379994, 512.4362032922911, 370.2614990635138, 604.6738089182901, 553.0848254768069, 389.92604040646853, 315.6604888462986, 383.0769254432993, 512.6234651605284, 381.0578055880361, 216.12000559272607, 521.0929615427254, 390.7066400380856, 690.9107588431146, 391.3026671140713, 243.9962772765606, 511.6301029564271, 544.960690682953, 603.7540932241802, 329.0474087652403, 558.4312728912867, 450.7671531782966, 638.7886276168243, 600.9352827412035, 385.45736315239924, 631.1726198988323, 403.29498346580016, 610.5526545461796, 387.9097395326821, 426.0894426215957, 512.2031031594246, 328.9971018023313, 368.2828360650995, 333.4869047380413, 653.7134006866438, 366.28408129035705, 369.13493948025354, 207.09129177089534, 545.941757176828, 488.3895262557735, 422.5225066255367, 362.8978154513501, 371.9234460251124, 145.93618034647014, 423.53530336568326, 227.21976869047492, 420.6486361696472, 476.82106600739013, 302.4902285690971, 527.1945831461486, 526.1939170382118, 495.43644014865095, 448.40532234145746, 483.0553932683239, 623.4820430510882, 617.998054685305, 449.2923376892506, 486.7698333979061, 665.1393471135104, 408.0803369490007, 524.058957978469, 634.261404177459, -122.02724071284037, 445.11889485948376, 491.45905098248454, 561.3748313688141, 471.8572182979999, 484.46358497109605, 299.66751941902567, 519.7300434229439, 300.05154779966495, 423.35458696970903, 409.5555270470059, 543.4830643343347, 535.3053233960529, 549.7877366542731, 489.39507362123203, 567.752464236438, 618.3100591986223, 452.97238985941016, 241.63836673796, 421.03261404631587, 188.21433892600024, 41.49999322248226, 408.24106808002966, 424.6032848449571, 505.66757206359375, 451.22383798449613, 569.7172743980832, 319.06611778019885, 430.9783224539826, 161.4142405827497, 555.2413668823536, 369.74215047832246, 748.4147472993075, 541.5796318478546, 153.47744017104526, 437.68984294502326, 618.6613897764652, 532.5246394971172, 193.01543366223905, 344.34343190257727, 430.23325131768917, 593.4936577500565, 361.7123690925054, 440.7310613801982, 388.7423564993517, 759.845564696208, 471.6863672827794, 514.4418186288542, 416.45888690536674, 537.0298903146938, 542.8260628607609, 492.619129372488, 379.1773387377685, 579.5218701370973, 365.3169910973639, 418.3720243878905, 511.3889938436925, 613.522683998646, 659.7620716452076, 278.5114439765173, 266.24641456679296, 429.25871322367755, 452.4896769768795, 444.14517113418844, 562.801527167956, 253.19594007905445, 628.3198177985053, 285.42387809734953, 542.3086777451693, 450.6754896648887, 385.1284155780023, 625.9270704251044, 629.0453711053705, 432.5350970713704, 379.55398648745853, 433.2600694444777, 313.66249308393196, 419.96141600789866, 642.2103186952752, 547.0578934910068, 123.86857610192601, 190.7937640914536, 563.9699231099786, 309.1374704031947, 189.25680586036165, 405.64582762154157, 425.0831099093461, 77.91057854998145, 370.6706422539536, 445.5824647052186, 330.5498623431112, 393.2898528669319, 468.28222642203013, 540.5922602561228, 428.9179102830497, 246.94759772219325, 474.55834938993723, 378.3531944376512, 488.31573898963234, -14.074925126897964, 567.6083175749635, 308.15260511834066, 577.2058844041954, 206.03404245236814, 502.2453635771054, 496.363604467272, 395.54703871652515, 682.4267274826138, 694.6179233095507, 495.75563254475856, 598.8757876570999, 532.8299474474305, 344.384308388102, 400.675188696859, 465.5204915032366, 461.6320525351749, 393.6332348450882, 326.6913827007995, 440.58547017728165, 307.1934174387888, 148.91377750670247, 262.45916500514727, 437.41755490516636, 431.79605777984045, 283.19272087208196, 197.39402764261044, 309.2701789382766, 262.40979479702764, 475.3401400183404, 528.5084112370711, 350.87040573135164, 473.21808026859526, 223.66751766296434, 570.4904548935222], "policy_predator_policy_reward": [364.05781880286537, 254.84272581208432, 462.1974053618091, 582.1830096339114, 313.2928256243009, 224.05255125835686, 526.7850064423574, 343.96388971546384, 463.6036860203111, 502.7393085848451, 462.6785097087551, 385.70026151551133, 652.7670991074308, 481.2133884705131, 532.5950231850113, 592.2765793851244, 232.12266520006088, 168.17976617048248, 590.6496144891529, 681.9274243746545, 492.2503129843018, 488.56905297280116, 426.092480493423, 551.7224586686808, 428.0210377015467, 479.8805138994621, 280.693073622217, 207.17242842142883, 474.9862160155373, 470.73174982316425, 436.0319163392741, 551.7139121153718, 268.3536202906326, 523.2087963652915, 398.168333505962, 563.0913142298756, 598.0625331193207, 562.5168563986608, 412.44444056551, 476.76837649903837, 624.253326138558, 702.5933534682532, 519.9600523033008, 424.3005899466602, 627.2051925457599, 628.1225720703285, 616.8782421402443, 645.9627638561599, 665.2773714951137, 630.0718146218449, 198.10993644054045, 134.2412263936279, 309.2642916615331, 348.08787238653485, 184.5523363830826, 114.91410289549181, 626.2470548247594, 16.707985549070223, 287.25456804560946, 290.1247742933543, 510.30672824486805, 471.33816804296777, 188.55664332691998, 217.94809374487977, 167.22898045075388, 197.46016176139665, 812.9987742816393, 590.5162879785146, 407.84250052853935, 259.3039368580135, 464.51868608906625, 427.2575802876527, 523.0244305812482, 482.89483525226336, 357.0072942079231, 477.9800490216162, 408.32866116826375, 435.9170304054184, 223.2422374677692, 260.6750310008964, 132.76367787403197, 97.02150127800188, 367.60650898527933, 158.49068995506556, 503.6093930654515, 666.9408521979047, 748.6089783554024, 729.1193638373871, 529.6741091534391, 225.42599701531992, 353.6969266924332, 284.5465152644581, 426.14729680512283, 482.92472359755806, 526.4393390541292, 485.0420482601929, 436.24389728708053, 532.599370072498, 345.9438398716305, 341.1602468600363, 612.6062738795428, 367.3937294065745, 368.6552586373062, 279.4028675115138, 646.9435414107925, 666.479455878893, 353.92941337143117, 398.21311399965316, 576.4020085810889, 358.406822382069, 128.79815696028433, 41.37811730573457, 139.62253938355852, 169.89232962480176, 414.5196633299502, 497.6642754129573, 269.36512125285583, 180.8630882122819, 347.58705994573137, 152.20363651529348, 574.2126072122618, 572.3130106199105, 305.3721746927923, 344.0418505466386, 428.47645665802304, 580.8991935053576, 651.6137538482416, 663.9886450138137, 514.9461927876241, 402.7730383918839, 468.1621453265693, 370.3585917096117, 509.3206389417023, 515.364439968996, 334.1670027458879, 294.9696143872579, 353.6876874202434, 456.03922042869084, 425.6369385720125, 447.4695962750055, 525.1938375516387, 544.629662475642, 598.1384140393917, 405.3498360443361, 206.37492379426783, 261.8339371080856, 701.617790349382, 764.2633428643009, 572.0198492077884, 630.7414901510838, 405.5941126664607, 458.2575912678646, 712.9355673493393, 480.5414002093098, 528.621541334426, 391.71804410035406, 508.6873164383045, 354.4416617474824, 361.5392842453415, 523.7835910919155, 672.229503737214, 604.9271060428937, 543.0597699118762, 464.4798271337597, 676.7014432218647, 719.1944273850291, 538.7011752918553, 408.0533003121635, 658.7258586205912, 453.46246749454133, 382.28603226927254, 395.0088401305941, 313.0816794600876, 256.0420079710684, 356.18359056929216, 409.20271660325284, 413.77214879755286, 329.74942007307754, 563.3969058414278, 545.1362957329693, 342.2839710729475, 490.7205753376855, 337.73101108182715, 410.1604669895823, 305.84928912775973, 349.68327159555395, 821.0596555498161, 659.6763688920518, 595.5487718518647, 567.376817832536, 65.15879778462693, 2.0944039560470378, 41.96076905485777, 122.56728442494887, 352.1068602848362, 412.5211818089867, 514.2024845403372, 641.3037576167711, 480.1750643469773, 592.9852538793566]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.610533191113098, "mean_inference_ms": 6.862790593099243, "mean_action_processing_ms": 1.1174854760986357, "mean_env_wait_ms": 0.9685925046537398, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014567136764526367, "StateBufferConnector_ms": 0.011136770248413086, "ViewRequirementAgentConnector_ms": 0.46528589725494385}, "num_episodes": 23, "episode_return_max": 2075.8687328720493, "episode_return_min": 547.839950255365, "episode_return_mean": 1726.9372057716819, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 133.0632995547358, "num_env_steps_trained_throughput_per_sec": 133.0632995547358, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 29951.854, "restore_workers_time_ms": 0.021, "training_step_time_ms": 29951.783, "sample_time_ms": 6084.663, "learn_time_ms": 23826.945, "learn_throughput": 167.877, "synch_weights_time_ms": 38.105}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "479e5_00000", "date": "2024-08-16_12-06-03", "timestamp": 1723790163, "time_this_iter_s": 30.146784782409668, "time_total_s": 2354.520258665085, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7f2c670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2354.520258665085, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 47.227500000000006, "ram_util_percent": 74.0625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7770864861036735, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.600114826424411, "policy_loss": -0.0041318575740747505, "vf_loss": 9.603269664320365, "vf_explained_var": -0.04008526344778676, "kl": 0.008684837798361355, "entropy": 1.27299908588803, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1580664703927974, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.557173853071909, "policy_loss": -0.0026468892936550434, "vf_loss": 9.559258353016364, "vf_explained_var": -0.04047395738344344, "kl": 0.00499915836323929, "entropy": 0.8236772273583387, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 2075.8687328720493, "episode_reward_min": 547.839950255365, "episode_reward_mean": 1722.376702901448, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -122.02724071284037, "predator_policy": 2.0944039560470378}, "policy_reward_max": {"prey_policy": 759.845564696208, "predator_policy": 821.0596555498161}, "policy_reward_mean": {"prey_policy": 431.88106824113726, "predator_policy": 429.30728320958667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1862.3491303211197, 1909.210299041548, 1903.072910857958, 1978.5919256825603, 2040.7480866929739, 1780.700632367987, 1946.1042581731174, 1229.820865011206, 1487.0369757633127, 1321.0967964654362, 1574.415755983612, 1818.8594400753584, 1917.7070673749915, 1479.7244211343093, 1523.009504368078, 1726.6067164067936, 1719.9803197378537, 1848.0970696458162, 1825.3168286754833, 1558.3934779989145, 1797.284282955027, 1569.0103285189914, 1286.9327170097035, 1597.3796479983778, 1833.221226047633, 1707.4426743412723, 1587.9444590937478, 1595.1348520049794, 1797.8554125809628, 1603.8739503510535, 1893.8267847202555, 1977.098465878832, 1571.1672864021862, 1799.2441554224026, 1850.7818628545028, 1775.8694364388282, 1737.2522614358595, 1318.7641954615779, 1295.6430549199933, 1865.6727159629697, 1485.6734016983878, 1458.4899053358913, 1930.2146333174267, 1774.3257030817715, 1947.6491657851025, 2011.1075266525288, 1814.354079290576, 1654.518204283191, 1938.4287748065515, 1622.1207845432036, 1820.7823938520391, 1934.6870030237606, 1882.6375559592154, 1737.1121591755573, 1657.4770730886346, 1780.5434734070645, 2075.8687328720493, 1458.7543374162294, 1696.4706560179789, 1736.592692393949, 1586.968693395828, 1894.1973620154129, 1953.0221177853543, 1860.451140873224, 1870.1366844696304, 1822.5153982973225, 1895.4282529716932, 1775.9038404442435, 1647.0974536302951, 1955.7598630268556, 1875.2273039751617, 1853.5926986593574, 1760.1570904490436, 1468.2160956172972, 1403.3114483393852, 1892.1089669537175, 2032.1392023694077, 547.839950255365, 736.2080272151107, 1768.4765933492329, 1979.5947281570557, 1867.3182907828175, 1855.6603413398846, 1575.897538174212, 1950.3884938546998, 1985.1501353055057, 1713.716670024336, 1391.0758524601035, 1593.5077148302087, 1842.0501891420406, 1881.8327151048354, 1890.4711249546206, 1846.6452794536801, 1748.6430479782307, 1458.8920782294342, 1755.3309539937798, 1781.939718922886, 1634.9920196582093, 1915.1991651819922, 1640.5555403246137], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [368.2828360650995, 333.4869047380413, 653.7134006866438, 366.28408129035705, 369.13493948025354, 207.09129177089534, 545.941757176828, 488.3895262557735, 422.5225066255367, 362.8978154513501, 371.9234460251124, 145.93618034647014, 423.53530336568326, 227.21976869047492, 420.6486361696472, 476.82106600739013, 302.4902285690971, 527.1945831461486, 526.1939170382118, 495.43644014865095, 448.40532234145746, 483.0553932683239, 623.4820430510882, 617.998054685305, 449.2923376892506, 486.7698333979061, 665.1393471135104, 408.0803369490007, 524.058957978469, 634.261404177459, -122.02724071284037, 445.11889485948376, 491.45905098248454, 561.3748313688141, 471.8572182979999, 484.46358497109605, 299.66751941902567, 519.7300434229439, 300.05154779966495, 423.35458696970903, 409.5555270470059, 543.4830643343347, 535.3053233960529, 549.7877366542731, 489.39507362123203, 567.752464236438, 618.3100591986223, 452.97238985941016, 241.63836673796, 421.03261404631587, 188.21433892600024, 41.49999322248226, 408.24106808002966, 424.6032848449571, 505.66757206359375, 451.22383798449613, 569.7172743980832, 319.06611778019885, 430.9783224539826, 161.4142405827497, 555.2413668823536, 369.74215047832246, 748.4147472993075, 541.5796318478546, 153.47744017104526, 437.68984294502326, 618.6613897764652, 532.5246394971172, 193.01543366223905, 344.34343190257727, 430.23325131768917, 593.4936577500565, 361.7123690925054, 440.7310613801982, 388.7423564993517, 759.845564696208, 471.6863672827794, 514.4418186288542, 416.45888690536674, 537.0298903146938, 542.8260628607609, 492.619129372488, 379.1773387377685, 579.5218701370973, 365.3169910973639, 418.3720243878905, 511.3889938436925, 613.522683998646, 659.7620716452076, 278.5114439765173, 266.24641456679296, 429.25871322367755, 452.4896769768795, 444.14517113418844, 562.801527167956, 253.19594007905445, 628.3198177985053, 285.42387809734953, 542.3086777451693, 450.6754896648887, 385.1284155780023, 625.9270704251044, 629.0453711053705, 432.5350970713704, 379.55398648745853, 433.2600694444777, 313.66249308393196, 419.96141600789866, 642.2103186952752, 547.0578934910068, 123.86857610192601, 190.7937640914536, 563.9699231099786, 309.1374704031947, 189.25680586036165, 405.64582762154157, 425.0831099093461, 77.91057854998145, 370.6706422539536, 445.5824647052186, 330.5498623431112, 393.2898528669319, 468.28222642203013, 540.5922602561228, 428.9179102830497, 246.94759772219325, 474.55834938993723, 378.3531944376512, 488.31573898963234, -14.074925126897964, 567.6083175749635, 308.15260511834066, 577.2058844041954, 206.03404245236814, 502.2453635771054, 496.363604467272, 395.54703871652515, 682.4267274826138, 694.6179233095507, 495.75563254475856, 598.8757876570999, 532.8299474474305, 344.384308388102, 400.675188696859, 465.5204915032366, 461.6320525351749, 393.6332348450882, 326.6913827007995, 440.58547017728165, 307.1934174387888, 148.91377750670247, 262.45916500514727, 437.41755490516636, 431.79605777984045, 283.19272087208196, 197.39402764261044, 309.2701789382766, 262.40979479702764, 475.3401400183404, 528.5084112370711, 350.87040573135164, 473.21808026859526, 223.66751766296434, 570.4904548935222, 592.4861464436857, 223.73747817037312, 438.04888744971686, 505.92636556921974, 566.5556090123877, 495.37790978596786, 530.8482018020985, 574.1480643590414, 505.0964188877602, 552.206156992908, 401.41075258365754, 482.2763891287963, 464.0510549589909, 569.1564566412196, 459.2747258870282, 395.185405333585, 53.21203123920391, 590.0861314037452, 655.0994519702849, 175.9385427849951, 342.0145556601234, 414.74362462260996, 500.0987044725467, 639.3794345876954, 507.9238663611858, 298.4217280799747, 397.684708701711, 425.0463962284651, 605.5338887449844, 363.83616542112304, 426.8479541337015, 461.03373893704816, 170.3273865455163, 501.10765913792306, 555.8503413897952, 591.7756635335747], "policy_predator_policy_reward": [598.0625331193207, 562.5168563986608, 412.44444056551, 476.76837649903837, 624.253326138558, 702.5933534682532, 519.9600523033008, 424.3005899466602, 627.2051925457599, 628.1225720703285, 616.8782421402443, 645.9627638561599, 665.2773714951137, 630.0718146218449, 198.10993644054045, 134.2412263936279, 309.2642916615331, 348.08787238653485, 184.5523363830826, 114.91410289549181, 626.2470548247594, 16.707985549070223, 287.25456804560946, 290.1247742933543, 510.30672824486805, 471.33816804296777, 188.55664332691998, 217.94809374487977, 167.22898045075388, 197.46016176139665, 812.9987742816393, 590.5162879785146, 407.84250052853935, 259.3039368580135, 464.51868608906625, 427.2575802876527, 523.0244305812482, 482.89483525226336, 357.0072942079231, 477.9800490216162, 408.32866116826375, 435.9170304054184, 223.2422374677692, 260.6750310008964, 132.76367787403197, 97.02150127800188, 367.60650898527933, 158.49068995506556, 503.6093930654515, 666.9408521979047, 748.6089783554024, 729.1193638373871, 529.6741091534391, 225.42599701531992, 353.6969266924332, 284.5465152644581, 426.14729680512283, 482.92472359755806, 526.4393390541292, 485.0420482601929, 436.24389728708053, 532.599370072498, 345.9438398716305, 341.1602468600363, 612.6062738795428, 367.3937294065745, 368.6552586373062, 279.4028675115138, 646.9435414107925, 666.479455878893, 353.92941337143117, 398.21311399965316, 576.4020085810889, 358.406822382069, 128.79815696028433, 41.37811730573457, 139.62253938355852, 169.89232962480176, 414.5196633299502, 497.6642754129573, 269.36512125285583, 180.8630882122819, 347.58705994573137, 152.20363651529348, 574.2126072122618, 572.3130106199105, 305.3721746927923, 344.0418505466386, 428.47645665802304, 580.8991935053576, 651.6137538482416, 663.9886450138137, 514.9461927876241, 402.7730383918839, 468.1621453265693, 370.3585917096117, 509.3206389417023, 515.364439968996, 334.1670027458879, 294.9696143872579, 353.6876874202434, 456.03922042869084, 425.6369385720125, 447.4695962750055, 525.1938375516387, 544.629662475642, 598.1384140393917, 405.3498360443361, 206.37492379426783, 261.8339371080856, 701.617790349382, 764.2633428643009, 572.0198492077884, 630.7414901510838, 405.5941126664607, 458.2575912678646, 712.9355673493393, 480.5414002093098, 528.621541334426, 391.71804410035406, 508.6873164383045, 354.4416617474824, 361.5392842453415, 523.7835910919155, 672.229503737214, 604.9271060428937, 543.0597699118762, 464.4798271337597, 676.7014432218647, 719.1944273850291, 538.7011752918553, 408.0533003121635, 658.7258586205912, 453.46246749454133, 382.28603226927254, 395.0088401305941, 313.0816794600876, 256.0420079710684, 356.18359056929216, 409.20271660325284, 413.77214879755286, 329.74942007307754, 563.3969058414278, 545.1362957329693, 342.2839710729475, 490.7205753376855, 337.73101108182715, 410.1604669895823, 305.84928912775973, 349.68327159555395, 821.0596555498161, 659.6763688920518, 595.5487718518647, 567.376817832536, 65.15879778462693, 2.0944039560470378, 41.96076905485777, 122.56728442494887, 352.1068602848362, 412.5211818089867, 514.2024845403372, 641.3037576167711, 480.1750643469773, 592.9852538793566, 500.52388063455606, 538.9128360912687, 342.61499047490423, 289.3072946803703, 355.9493592886659, 532.5056157676802, 459.3009498915623, 420.8529192528041, 365.4983336905043, 290.9157604531625, 196.53378140489968, 310.85492934275027, 244.53273623509006, 315.76746699491065, 466.80616209792487, 520.7838958235017, 604.0349844312099, 634.4995680306766, 611.2017219777925, 448.2314082215504, 535.2522961226578, 554.634803048289, 389.44313905847673, 219.72176985951367, 299.7363619087853, 352.81012187948863, 386.91832830246403, 545.6815207611396, 382.62251675339496, 429.9471480033829, 416.89103641891757, 330.21929016854403, 536.3767894570865, 707.3873300414655, 287.03764643400353, 205.89188896723996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.6252421229723253, "mean_inference_ms": 6.9015371374265415, "mean_action_processing_ms": 1.123767743438047, "mean_env_wait_ms": 0.9724950810052028, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013472914695739746, "StateBufferConnector_ms": 0.011097431182861328, "ViewRequirementAgentConnector_ms": 0.542227029800415}, "num_episodes": 18, "episode_return_max": 2075.8687328720493, "episode_return_min": 547.839950255365, "episode_return_mean": 1722.376702901448, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.7241052716337375, "num_env_steps_trained_throughput_per_sec": 4.7241052716337375, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 111717.425, "restore_workers_time_ms": 0.021, "training_step_time_ms": 111717.355, "sample_time_ms": 6645.185, "learn_time_ms": 105029.96, "learn_throughput": 38.084, "synch_weights_time_ms": 40.15}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "479e5_00000", "date": "2024-08-16_12-20-10", "timestamp": 1723791010, "time_this_iter_s": 846.7813668251038, "time_total_s": 3201.3016254901886, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78914c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3201.3016254901886, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 44.284210526315796, "ram_util_percent": 74.48070175438598}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.017909593225787, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.56807388931355, "policy_loss": -0.0009660314274557605, "vf_loss": 9.567368630000523, "vf_explained_var": -0.07229833293844153, "kl": 0.014856088498996597, "entropy": 1.226583227152547, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.103496552081335, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.479915809126759, "policy_loss": -0.0007207186170730483, "vf_loss": 9.480083171400443, "vf_explained_var": -0.04187739425235325, "kl": 0.009837246306391061, "entropy": 0.8998033187376759, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 2075.8687328720493, "episode_reward_min": 547.839950255365, "episode_reward_mean": 1742.0617228396889, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -14.074925126897964, "predator_policy": 2.0944039560470378}, "policy_reward_max": {"prey_policy": 759.845564696208, "predator_policy": 821.0596555498161}, "policy_reward_mean": {"prey_policy": 440.4315904550903, "predator_policy": 430.5992709647541}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1825.3168286754833, 1558.3934779989145, 1797.284282955027, 1569.0103285189914, 1286.9327170097035, 1597.3796479983778, 1833.221226047633, 1707.4426743412723, 1587.9444590937478, 1595.1348520049794, 1797.8554125809628, 1603.8739503510535, 1893.8267847202555, 1977.098465878832, 1571.1672864021862, 1799.2441554224026, 1850.7818628545028, 1775.8694364388282, 1737.2522614358595, 1318.7641954615779, 1295.6430549199933, 1865.6727159629697, 1485.6734016983878, 1458.4899053358913, 1930.2146333174267, 1774.3257030817715, 1947.6491657851025, 2011.1075266525288, 1814.354079290576, 1654.518204283191, 1938.4287748065515, 1622.1207845432036, 1820.7823938520391, 1934.6870030237606, 1882.6375559592154, 1737.1121591755573, 1657.4770730886346, 1780.5434734070645, 2075.8687328720493, 1458.7543374162294, 1696.4706560179789, 1736.592692393949, 1586.968693395828, 1894.1973620154129, 1953.0221177853543, 1860.451140873224, 1870.1366844696304, 1822.5153982973225, 1895.4282529716932, 1775.9038404442435, 1647.0974536302951, 1955.7598630268556, 1875.2273039751617, 1853.5926986593574, 1760.1570904490436, 1468.2160956172972, 1403.3114483393852, 1892.1089669537175, 2032.1392023694077, 547.839950255365, 736.2080272151107, 1768.4765933492329, 1979.5947281570557, 1867.3182907828175, 1855.6603413398846, 1575.897538174212, 1950.3884938546998, 1985.1501353055057, 1713.716670024336, 1391.0758524601035, 1593.5077148302087, 1842.0501891420406, 1881.8327151048354, 1890.4711249546206, 1846.6452794536801, 1748.6430479782307, 1458.8920782294342, 1755.3309539937798, 1781.939718922886, 1634.9920196582093, 1915.1991651819922, 1640.5555403246137, 1970.6056643499173, 1855.1057974216458, 1659.0008496712574, 1668.9361217102266, 1789.3459796781217, 1990.344758239291, 1622.3260167245828, 1869.7375191869462, 2026.2917985183824, 2059.3960925061488, 1939.9472575991158, 1537.7970668362182, 1722.5960827541219, 1959.8515332692582, 1829.9206117448957, 1912.5754707582703, 1766.84067722291, 1855.0148707368485], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [299.66751941902567, 519.7300434229439, 300.05154779966495, 423.35458696970903, 409.5555270470059, 543.4830643343347, 535.3053233960529, 549.7877366542731, 489.39507362123203, 567.752464236438, 618.3100591986223, 452.97238985941016, 241.63836673796, 421.03261404631587, 188.21433892600024, 41.49999322248226, 408.24106808002966, 424.6032848449571, 505.66757206359375, 451.22383798449613, 569.7172743980832, 319.06611778019885, 430.9783224539826, 161.4142405827497, 555.2413668823536, 369.74215047832246, 748.4147472993075, 541.5796318478546, 153.47744017104526, 437.68984294502326, 618.6613897764652, 532.5246394971172, 193.01543366223905, 344.34343190257727, 430.23325131768917, 593.4936577500565, 361.7123690925054, 440.7310613801982, 388.7423564993517, 759.845564696208, 471.6863672827794, 514.4418186288542, 416.45888690536674, 537.0298903146938, 542.8260628607609, 492.619129372488, 379.1773387377685, 579.5218701370973, 365.3169910973639, 418.3720243878905, 511.3889938436925, 613.522683998646, 659.7620716452076, 278.5114439765173, 266.24641456679296, 429.25871322367755, 452.4896769768795, 444.14517113418844, 562.801527167956, 253.19594007905445, 628.3198177985053, 285.42387809734953, 542.3086777451693, 450.6754896648887, 385.1284155780023, 625.9270704251044, 629.0453711053705, 432.5350970713704, 379.55398648745853, 433.2600694444777, 313.66249308393196, 419.96141600789866, 642.2103186952752, 547.0578934910068, 123.86857610192601, 190.7937640914536, 563.9699231099786, 309.1374704031947, 189.25680586036165, 405.64582762154157, 425.0831099093461, 77.91057854998145, 370.6706422539536, 445.5824647052186, 330.5498623431112, 393.2898528669319, 468.28222642203013, 540.5922602561228, 428.9179102830497, 246.94759772219325, 474.55834938993723, 378.3531944376512, 488.31573898963234, -14.074925126897964, 567.6083175749635, 308.15260511834066, 577.2058844041954, 206.03404245236814, 502.2453635771054, 496.363604467272, 395.54703871652515, 682.4267274826138, 694.6179233095507, 495.75563254475856, 598.8757876570999, 532.8299474474305, 344.384308388102, 400.675188696859, 465.5204915032366, 461.6320525351749, 393.6332348450882, 326.6913827007995, 440.58547017728165, 307.1934174387888, 148.91377750670247, 262.45916500514727, 437.41755490516636, 431.79605777984045, 283.19272087208196, 197.39402764261044, 309.2701789382766, 262.40979479702764, 475.3401400183404, 528.5084112370711, 350.87040573135164, 473.21808026859526, 223.66751766296434, 570.4904548935222, 592.4861464436857, 223.73747817037312, 438.04888744971686, 505.92636556921974, 566.5556090123877, 495.37790978596786, 530.8482018020985, 574.1480643590414, 505.0964188877602, 552.206156992908, 401.41075258365754, 482.2763891287963, 464.0510549589909, 569.1564566412196, 459.2747258870282, 395.185405333585, 53.21203123920391, 590.0861314037452, 655.0994519702849, 175.9385427849951, 342.0145556601234, 414.74362462260996, 500.0987044725467, 639.3794345876954, 507.9238663611858, 298.4217280799747, 397.684708701711, 425.0463962284651, 605.5338887449844, 363.83616542112304, 426.8479541337015, 461.03373893704816, 170.3273865455163, 501.10765913792306, 555.8503413897952, 591.7756635335747, 435.03725619033565, 491.8331969267789, 353.0835856472796, 325.0018174115812, 341.44327241261925, 626.7364393908014, 570.031987332271, 549.2838116853138, 604.2922371509494, 413.57246775045485, 562.7047832678476, 510.3070309183365, 437.19974946306843, 493.4615645912121, 242.7124491087732, 574.3853145785437, 614.733570986216, 144.35396143398773, 429.6836709992633, 618.4737229111948, 510.9104990365343, 549.3169637429521, 370.37977535302946, 373.2237548811056, 560.6549750302037, 526.4991809924484, 353.29907336908155, 542.6785358554978, 587.260031089174, 578.296663285684, 511.4201716269978, 517.4460092286629, 445.14131217045724, 502.83023094657443, 570.1238779826047, 580.2254975092634], "policy_predator_policy_reward": [523.0244305812482, 482.89483525226336, 357.0072942079231, 477.9800490216162, 408.32866116826375, 435.9170304054184, 223.2422374677692, 260.6750310008964, 132.76367787403197, 97.02150127800188, 367.60650898527933, 158.49068995506556, 503.6093930654515, 666.9408521979047, 748.6089783554024, 729.1193638373871, 529.6741091534391, 225.42599701531992, 353.6969266924332, 284.5465152644581, 426.14729680512283, 482.92472359755806, 526.4393390541292, 485.0420482601929, 436.24389728708053, 532.599370072498, 345.9438398716305, 341.1602468600363, 612.6062738795428, 367.3937294065745, 368.6552586373062, 279.4028675115138, 646.9435414107925, 666.479455878893, 353.92941337143117, 398.21311399965316, 576.4020085810889, 358.406822382069, 128.79815696028433, 41.37811730573457, 139.62253938355852, 169.89232962480176, 414.5196633299502, 497.6642754129573, 269.36512125285583, 180.8630882122819, 347.58705994573137, 152.20363651529348, 574.2126072122618, 572.3130106199105, 305.3721746927923, 344.0418505466386, 428.47645665802304, 580.8991935053576, 651.6137538482416, 663.9886450138137, 514.9461927876241, 402.7730383918839, 468.1621453265693, 370.3585917096117, 509.3206389417023, 515.364439968996, 334.1670027458879, 294.9696143872579, 353.6876874202434, 456.03922042869084, 425.6369385720125, 447.4695962750055, 525.1938375516387, 544.629662475642, 598.1384140393917, 405.3498360443361, 206.37492379426783, 261.8339371080856, 701.617790349382, 764.2633428643009, 572.0198492077884, 630.7414901510838, 405.5941126664607, 458.2575912678646, 712.9355673493393, 480.5414002093098, 528.621541334426, 391.71804410035406, 508.6873164383045, 354.4416617474824, 361.5392842453415, 523.7835910919155, 672.229503737214, 604.9271060428937, 543.0597699118762, 464.4798271337597, 676.7014432218647, 719.1944273850291, 538.7011752918553, 408.0533003121635, 658.7258586205912, 453.46246749454133, 382.28603226927254, 395.0088401305941, 313.0816794600876, 256.0420079710684, 356.18359056929216, 409.20271660325284, 413.77214879755286, 329.74942007307754, 563.3969058414278, 545.1362957329693, 342.2839710729475, 490.7205753376855, 337.73101108182715, 410.1604669895823, 305.84928912775973, 349.68327159555395, 821.0596555498161, 659.6763688920518, 595.5487718518647, 567.376817832536, 65.15879778462693, 2.0944039560470378, 41.96076905485777, 122.56728442494887, 352.1068602848362, 412.5211818089867, 514.2024845403372, 641.3037576167711, 480.1750643469773, 592.9852538793566, 500.52388063455606, 538.9128360912687, 342.61499047490423, 289.3072946803703, 355.9493592886659, 532.5056157676802, 459.3009498915623, 420.8529192528041, 365.4983336905043, 290.9157604531625, 196.53378140489968, 310.85492934275027, 244.53273623509006, 315.76746699491065, 466.80616209792487, 520.7838958235017, 604.0349844312099, 634.4995680306766, 611.2017219777925, 448.2314082215504, 535.2522961226578, 554.634803048289, 389.44313905847673, 219.72176985951367, 299.7363619087853, 352.81012187948863, 386.91832830246403, 545.6815207611396, 382.62251675339496, 429.9471480033829, 416.89103641891757, 330.21929016854403, 536.3767894570865, 707.3873300414655, 287.03764643400353, 205.89188896723996, 521.4534783160237, 522.2817329167796, 567.0366985859546, 609.9836957768322, 441.40612820406534, 249.41500966377146, 251.72756148978854, 297.8927612028524, 546.0209601251063, 225.46031465160945, 561.3135546312387, 356.01938942186905, 315.0605986106615, 376.6041040596407, 672.6766230009717, 379.96313249865796, 539.6463920841745, 727.5578740139994, 555.011402258582, 456.2272963371089, 428.4911890326829, 451.22860578694565, 395.5864544039861, 398.60708219809453, 359.03021352196254, 276.41171320950576, 481.25405914691845, 582.6198648977602, 362.4065489108119, 301.9573684592253, 461.4506271865525, 422.2586627160571, 480.0654672337812, 338.8036668720972, 341.37770049361444, 363.2877947513676]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.6329977349928284, "mean_inference_ms": 6.92095632544796, "mean_action_processing_ms": 1.1267344268673247, "mean_env_wait_ms": 0.9739154862413865, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011160850524902344, "StateBufferConnector_ms": 0.009708166122436523, "ViewRequirementAgentConnector_ms": 0.5031070709228516}, "num_episodes": 18, "episode_return_max": 2075.8687328720493, "episode_return_min": 547.839950255365, "episode_return_mean": 1742.0617228396889, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.1811343853346, "num_env_steps_trained_throughput_per_sec": 316.1811343853346, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 110075.406, "restore_workers_time_ms": 0.021, "training_step_time_ms": 110075.338, "sample_time_ms": 6297.326, "learn_time_ms": 103739.852, "learn_throughput": 38.558, "synch_weights_time_ms": 36.178}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "479e5_00000", "date": "2024-08-16_12-20-22", "timestamp": 1723791022, "time_this_iter_s": 12.661092758178711, "time_total_s": 3213.9627182483673, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7891700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3213.9627182483673, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 57.83888888888888, "ram_util_percent": 79.03333333333336}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9193994439625865, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.530307450874773, "policy_loss": -0.007347872788111172, "vf_loss": 9.536506318793725, "vf_explained_var": -0.030655268197337156, "kl": 0.01021324450263598, "entropy": 1.2259153372396236, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0254714967081786, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.484289977664039, "policy_loss": -0.002572325601922496, "vf_loss": 9.486205524868435, "vf_explained_var": -0.07047447382457672, "kl": 0.011675248499822141, "entropy": 0.8468327329587684, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 2075.8687328720493, "episode_reward_min": 547.839950255365, "episode_reward_mean": 1760.3810485788783, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -14.074925126897964, "predator_policy": 2.0944039560470378}, "policy_reward_max": {"prey_policy": 694.6179233095507, "predator_policy": 821.0596555498161}, "policy_reward_mean": {"prey_policy": 449.20301035229926, "predator_policy": 430.98751393714}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1485.6734016983878, 1458.4899053358913, 1930.2146333174267, 1774.3257030817715, 1947.6491657851025, 2011.1075266525288, 1814.354079290576, 1654.518204283191, 1938.4287748065515, 1622.1207845432036, 1820.7823938520391, 1934.6870030237606, 1882.6375559592154, 1737.1121591755573, 1657.4770730886346, 1780.5434734070645, 2075.8687328720493, 1458.7543374162294, 1696.4706560179789, 1736.592692393949, 1586.968693395828, 1894.1973620154129, 1953.0221177853543, 1860.451140873224, 1870.1366844696304, 1822.5153982973225, 1895.4282529716932, 1775.9038404442435, 1647.0974536302951, 1955.7598630268556, 1875.2273039751617, 1853.5926986593574, 1760.1570904490436, 1468.2160956172972, 1403.3114483393852, 1892.1089669537175, 2032.1392023694077, 547.839950255365, 736.2080272151107, 1768.4765933492329, 1979.5947281570557, 1867.3182907828175, 1855.6603413398846, 1575.897538174212, 1950.3884938546998, 1985.1501353055057, 1713.716670024336, 1391.0758524601035, 1593.5077148302087, 1842.0501891420406, 1881.8327151048354, 1890.4711249546206, 1846.6452794536801, 1748.6430479782307, 1458.8920782294342, 1755.3309539937798, 1781.939718922886, 1634.9920196582093, 1915.1991651819922, 1640.5555403246137, 1970.6056643499173, 1855.1057974216458, 1659.0008496712574, 1668.9361217102266, 1789.3459796781217, 1990.344758239291, 1622.3260167245828, 1869.7375191869462, 2026.2917985183824, 2059.3960925061488, 1939.9472575991158, 1537.7970668362182, 1722.5960827541219, 1959.8515332692582, 1829.9206117448957, 1912.5754707582703, 1766.84067722291, 1855.0148707368485, 1834.8652449724746, 1760.7484689342036, 1553.2432147353022, 1806.412651059457, 1734.5881223527115, 1936.4458036288356, 1842.9921707488124, 1710.767317761275, 1869.3687750299698, 1649.2662300238276, 1552.47988614046, 1929.015444336107, 1879.0962206947968, 1718.1680452374242, 1597.8394694549859, 1557.7948885324545, 1743.121963017379, 1905.5342797283906, 1648.5652135270063, 1953.720645680794, 1623.5726869849166, 1869.4359084109194], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [542.8260628607609, 492.619129372488, 379.1773387377685, 579.5218701370973, 365.3169910973639, 418.3720243878905, 511.3889938436925, 613.522683998646, 659.7620716452076, 278.5114439765173, 266.24641456679296, 429.25871322367755, 452.4896769768795, 444.14517113418844, 562.801527167956, 253.19594007905445, 628.3198177985053, 285.42387809734953, 542.3086777451693, 450.6754896648887, 385.1284155780023, 625.9270704251044, 629.0453711053705, 432.5350970713704, 379.55398648745853, 433.2600694444777, 313.66249308393196, 419.96141600789866, 642.2103186952752, 547.0578934910068, 123.86857610192601, 190.7937640914536, 563.9699231099786, 309.1374704031947, 189.25680586036165, 405.64582762154157, 425.0831099093461, 77.91057854998145, 370.6706422539536, 445.5824647052186, 330.5498623431112, 393.2898528669319, 468.28222642203013, 540.5922602561228, 428.9179102830497, 246.94759772219325, 474.55834938993723, 378.3531944376512, 488.31573898963234, -14.074925126897964, 567.6083175749635, 308.15260511834066, 577.2058844041954, 206.03404245236814, 502.2453635771054, 496.363604467272, 395.54703871652515, 682.4267274826138, 694.6179233095507, 495.75563254475856, 598.8757876570999, 532.8299474474305, 344.384308388102, 400.675188696859, 465.5204915032366, 461.6320525351749, 393.6332348450882, 326.6913827007995, 440.58547017728165, 307.1934174387888, 148.91377750670247, 262.45916500514727, 437.41755490516636, 431.79605777984045, 283.19272087208196, 197.39402764261044, 309.2701789382766, 262.40979479702764, 475.3401400183404, 528.5084112370711, 350.87040573135164, 473.21808026859526, 223.66751766296434, 570.4904548935222, 592.4861464436857, 223.73747817037312, 438.04888744971686, 505.92636556921974, 566.5556090123877, 495.37790978596786, 530.8482018020985, 574.1480643590414, 505.0964188877602, 552.206156992908, 401.41075258365754, 482.2763891287963, 464.0510549589909, 569.1564566412196, 459.2747258870282, 395.185405333585, 53.21203123920391, 590.0861314037452, 655.0994519702849, 175.9385427849951, 342.0145556601234, 414.74362462260996, 500.0987044725467, 639.3794345876954, 507.9238663611858, 298.4217280799747, 397.684708701711, 425.0463962284651, 605.5338887449844, 363.83616542112304, 426.8479541337015, 461.03373893704816, 170.3273865455163, 501.10765913792306, 555.8503413897952, 591.7756635335747, 435.03725619033565, 491.8331969267789, 353.0835856472796, 325.0018174115812, 341.44327241261925, 626.7364393908014, 570.031987332271, 549.2838116853138, 604.2922371509494, 413.57246775045485, 562.7047832678476, 510.3070309183365, 437.19974946306843, 493.4615645912121, 242.7124491087732, 574.3853145785437, 614.733570986216, 144.35396143398773, 429.6836709992633, 618.4737229111948, 510.9104990365343, 549.3169637429521, 370.37977535302946, 373.2237548811056, 560.6549750302037, 526.4991809924484, 353.29907336908155, 542.6785358554978, 587.260031089174, 578.296663285684, 511.4201716269978, 517.4460092286629, 445.14131217045724, 502.83023094657443, 570.1238779826047, 580.2254975092634, 611.3964573735848, 295.2661944458679, 247.77687332749227, 472.83932664425254, 532.1092877374593, 536.5827350159578, 494.92778807148756, 535.3516065944807, 337.077707652894, 198.44064381977424, 573.6617114789176, 511.7073861376649, 497.17324865409074, 624.668780872266, 486.8687235178414, 492.8371809264792, 552.3350070370972, 662.8449818618842, 425.6438696088776, 315.6140474631281, 468.73404638665835, 540.2696896569163, 556.1889262254733, 194.20859913718363, 647.4303833022751, 488.9205770825508, 652.5798425176692, 595.1607983412549, 325.68398034353436, 470.791848518102, 408.9418466809187, 405.16579739093044, 569.6039653337689, 415.4233445267428, 595.2024858269651, 602.2012465601752, 337.3252414475588, 266.51441573339264, 570.4721218723547, 569.2445592247485, 523.3215243215529, 426.0172638823693, 386.77952691505925, 614.7060553816855], "policy_predator_policy_reward": [269.36512125285583, 180.8630882122819, 347.58705994573137, 152.20363651529348, 574.2126072122618, 572.3130106199105, 305.3721746927923, 344.0418505466386, 428.47645665802304, 580.8991935053576, 651.6137538482416, 663.9886450138137, 514.9461927876241, 402.7730383918839, 468.1621453265693, 370.3585917096117, 509.3206389417023, 515.364439968996, 334.1670027458879, 294.9696143872579, 353.6876874202434, 456.03922042869084, 425.6369385720125, 447.4695962750055, 525.1938375516387, 544.629662475642, 598.1384140393917, 405.3498360443361, 206.37492379426783, 261.8339371080856, 701.617790349382, 764.2633428643009, 572.0198492077884, 630.7414901510838, 405.5941126664607, 458.2575912678646, 712.9355673493393, 480.5414002093098, 528.621541334426, 391.71804410035406, 508.6873164383045, 354.4416617474824, 361.5392842453415, 523.7835910919155, 672.229503737214, 604.9271060428937, 543.0597699118762, 464.4798271337597, 676.7014432218647, 719.1944273850291, 538.7011752918553, 408.0533003121635, 658.7258586205912, 453.46246749454133, 382.28603226927254, 395.0088401305941, 313.0816794600876, 256.0420079710684, 356.18359056929216, 409.20271660325284, 413.77214879755286, 329.74942007307754, 563.3969058414278, 545.1362957329693, 342.2839710729475, 490.7205753376855, 337.73101108182715, 410.1604669895823, 305.84928912775973, 349.68327159555395, 821.0596555498161, 659.6763688920518, 595.5487718518647, 567.376817832536, 65.15879778462693, 2.0944039560470378, 41.96076905485777, 122.56728442494887, 352.1068602848362, 412.5211818089867, 514.2024845403372, 641.3037576167711, 480.1750643469773, 592.9852538793566, 500.52388063455606, 538.9128360912687, 342.61499047490423, 289.3072946803703, 355.9493592886659, 532.5056157676802, 459.3009498915623, 420.8529192528041, 365.4983336905043, 290.9157604531625, 196.53378140489968, 310.85492934275027, 244.53273623509006, 315.76746699491065, 466.80616209792487, 520.7838958235017, 604.0349844312099, 634.4995680306766, 611.2017219777925, 448.2314082215504, 535.2522961226578, 554.634803048289, 389.44313905847673, 219.72176985951367, 299.7363619087853, 352.81012187948863, 386.91832830246403, 545.6815207611396, 382.62251675339496, 429.9471480033829, 416.89103641891757, 330.21929016854403, 536.3767894570865, 707.3873300414655, 287.03764643400353, 205.89188896723996, 521.4534783160237, 522.2817329167796, 567.0366985859546, 609.9836957768322, 441.40612820406534, 249.41500966377146, 251.72756148978854, 297.8927612028524, 546.0209601251063, 225.46031465160945, 561.3135546312387, 356.01938942186905, 315.0605986106615, 376.6041040596407, 672.6766230009717, 379.96313249865796, 539.6463920841745, 727.5578740139994, 555.011402258582, 456.2272963371089, 428.4911890326829, 451.22860578694565, 395.5864544039861, 398.60708219809453, 359.03021352196254, 276.41171320950576, 481.25405914691845, 582.6198648977602, 362.4065489108119, 301.9573684592253, 461.4506271865525, 422.2586627160571, 480.0654672337812, 338.8036668720972, 341.37770049361444, 363.2877947513676, 426.38122153489894, 501.82137161812295, 583.2743404856552, 456.85792847680244, 312.75315061692066, 171.79804136496463, 560.6140079423192, 215.5192484511685, 747.1706240696662, 451.899146810377, 391.0701407056279, 460.00656530662576, 358.1903415145272, 362.9597997079267, 366.85601953101474, 364.20539378593895, 273.5248020061797, 380.66398412480805, 414.45806885271656, 493.5502440991037, 188.73392675692992, 354.7422233399557, 577.541635504052, 601.0762834693982, 444.2762658605216, 298.46899444944836, 159.4798015594909, 310.9476028190095, 470.2129261082981, 331.1507144850533, 376.1394404921156, 367.5478039684901, 214.76425953244083, 543.330393624427, 226.30044887248312, 481.8300984687691, 421.1916589481138, 623.533897397941, 473.97516311095137, 340.02880147274186, 354.4564492116435, 319.7774495693507, 340.4956961331792, 527.4546299809983]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.636499921868099, "mean_inference_ms": 6.928956288939937, "mean_action_processing_ms": 1.1276538210999336, "mean_env_wait_ms": 0.9734932100746084, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007903575897216797, "StateBufferConnector_ms": 0.006621003150939941, "ViewRequirementAgentConnector_ms": 0.41946303844451904}, "num_episodes": 22, "episode_return_max": 2075.8687328720493, "episode_return_min": 547.839950255365, "episode_return_mean": 1760.3810485788783, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.4217281236541, "num_env_steps_trained_throughput_per_sec": 310.4217281236541, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 108387.727, "restore_workers_time_ms": 0.019, "training_step_time_ms": 108387.663, "sample_time_ms": 5858.565, "learn_time_ms": 102491.933, "learn_throughput": 39.027, "synch_weights_time_ms": 35.21}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "479e5_00000", "date": "2024-08-16_12-20-35", "timestamp": 1723791035, "time_this_iter_s": 12.89071011543274, "time_total_s": 3226.8534283638, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78a0700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3226.8534283638, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 50.40555555555555, "ram_util_percent": 78.27777777777777}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0223500764874554, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.5332765998033, "policy_loss": -0.003398418784629376, "vf_loss": 9.535674503366783, "vf_explained_var": -0.022697688158227022, "kl": 0.00889343606124882, "entropy": 1.2215362264996483, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1202309715527075, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.508115990452035, "policy_loss": -0.0025687164487809967, "vf_loss": 9.510285223602619, "vf_explained_var": -0.06892224200188167, "kl": 0.007101729373232196, "entropy": 0.8289352170058659, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 2059.3960925061488, "episode_reward_min": 547.839950255365, "episode_reward_mean": 1763.3584186123628, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -14.074925126897964, "predator_policy": 2.0944039560470378}, "policy_reward_max": {"prey_policy": 694.6179233095507, "predator_policy": 821.0596555498161}, "policy_reward_mean": {"prey_policy": 454.803672574792, "predator_policy": 426.87553673138956}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1860.451140873224, 1870.1366844696304, 1822.5153982973225, 1895.4282529716932, 1775.9038404442435, 1647.0974536302951, 1955.7598630268556, 1875.2273039751617, 1853.5926986593574, 1760.1570904490436, 1468.2160956172972, 1403.3114483393852, 1892.1089669537175, 2032.1392023694077, 547.839950255365, 736.2080272151107, 1768.4765933492329, 1979.5947281570557, 1867.3182907828175, 1855.6603413398846, 1575.897538174212, 1950.3884938546998, 1985.1501353055057, 1713.716670024336, 1391.0758524601035, 1593.5077148302087, 1842.0501891420406, 1881.8327151048354, 1890.4711249546206, 1846.6452794536801, 1748.6430479782307, 1458.8920782294342, 1755.3309539937798, 1781.939718922886, 1634.9920196582093, 1915.1991651819922, 1640.5555403246137, 1970.6056643499173, 1855.1057974216458, 1659.0008496712574, 1668.9361217102266, 1789.3459796781217, 1990.344758239291, 1622.3260167245828, 1869.7375191869462, 2026.2917985183824, 2059.3960925061488, 1939.9472575991158, 1537.7970668362182, 1722.5960827541219, 1959.8515332692582, 1829.9206117448957, 1912.5754707582703, 1766.84067722291, 1855.0148707368485, 1834.8652449724746, 1760.7484689342036, 1553.2432147353022, 1806.412651059457, 1734.5881223527115, 1936.4458036288356, 1842.9921707488124, 1710.767317761275, 1869.3687750299698, 1649.2662300238276, 1552.47988614046, 1929.015444336107, 1879.0962206947968, 1718.1680452374242, 1597.8394694549859, 1557.7948885324545, 1743.121963017379, 1905.5342797283906, 1648.5652135270063, 1953.720645680794, 1623.5726869849166, 1869.4359084109194, 1512.30794148709, 1984.6133781543297, 1872.9945658999961, 1878.3216108748982, 1876.9631265122657, 2058.0304765849887, 1846.9489384437268, 1961.7719216103753, 1558.572560867137, 1729.8133371411484, 1849.2647489072733, 1578.1737884004815, 1580.8848955239262, 1659.409030916329, 1902.7400456623009, 1922.0189807078914, 1838.3531823474589, 1774.3339700015117, 1795.4710770224258, 1886.875478306446, 1711.2349407809452, 1820.7328061253525, 1549.9026302678496], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [474.55834938993723, 378.3531944376512, 488.31573898963234, -14.074925126897964, 567.6083175749635, 308.15260511834066, 577.2058844041954, 206.03404245236814, 502.2453635771054, 496.363604467272, 395.54703871652515, 682.4267274826138, 694.6179233095507, 495.75563254475856, 598.8757876570999, 532.8299474474305, 344.384308388102, 400.675188696859, 465.5204915032366, 461.6320525351749, 393.6332348450882, 326.6913827007995, 440.58547017728165, 307.1934174387888, 148.91377750670247, 262.45916500514727, 437.41755490516636, 431.79605777984045, 283.19272087208196, 197.39402764261044, 309.2701789382766, 262.40979479702764, 475.3401400183404, 528.5084112370711, 350.87040573135164, 473.21808026859526, 223.66751766296434, 570.4904548935222, 592.4861464436857, 223.73747817037312, 438.04888744971686, 505.92636556921974, 566.5556090123877, 495.37790978596786, 530.8482018020985, 574.1480643590414, 505.0964188877602, 552.206156992908, 401.41075258365754, 482.2763891287963, 464.0510549589909, 569.1564566412196, 459.2747258870282, 395.185405333585, 53.21203123920391, 590.0861314037452, 655.0994519702849, 175.9385427849951, 342.0145556601234, 414.74362462260996, 500.0987044725467, 639.3794345876954, 507.9238663611858, 298.4217280799747, 397.684708701711, 425.0463962284651, 605.5338887449844, 363.83616542112304, 426.8479541337015, 461.03373893704816, 170.3273865455163, 501.10765913792306, 555.8503413897952, 591.7756635335747, 435.03725619033565, 491.8331969267789, 353.0835856472796, 325.0018174115812, 341.44327241261925, 626.7364393908014, 570.031987332271, 549.2838116853138, 604.2922371509494, 413.57246775045485, 562.7047832678476, 510.3070309183365, 437.19974946306843, 493.4615645912121, 242.7124491087732, 574.3853145785437, 614.733570986216, 144.35396143398773, 429.6836709992633, 618.4737229111948, 510.9104990365343, 549.3169637429521, 370.37977535302946, 373.2237548811056, 560.6549750302037, 526.4991809924484, 353.29907336908155, 542.6785358554978, 587.260031089174, 578.296663285684, 511.4201716269978, 517.4460092286629, 445.14131217045724, 502.83023094657443, 570.1238779826047, 580.2254975092634, 611.3964573735848, 295.2661944458679, 247.77687332749227, 472.83932664425254, 532.1092877374593, 536.5827350159578, 494.92778807148756, 535.3516065944807, 337.077707652894, 198.44064381977424, 573.6617114789176, 511.7073861376649, 497.17324865409074, 624.668780872266, 486.8687235178414, 492.8371809264792, 552.3350070370972, 662.8449818618842, 425.6438696088776, 315.6140474631281, 468.73404638665835, 540.2696896569163, 556.1889262254733, 194.20859913718363, 647.4303833022751, 488.9205770825508, 652.5798425176692, 595.1607983412549, 325.68398034353436, 470.791848518102, 408.9418466809187, 405.16579739093044, 569.6039653337689, 415.4233445267428, 595.2024858269651, 602.2012465601752, 337.3252414475588, 266.51441573339264, 570.4721218723547, 569.2445592247485, 523.3215243215529, 426.0172638823693, 386.77952691505925, 614.7060553816855, 498.6918476426218, 539.8775259071517, 618.8023318587177, 390.4374479226027, 401.7207097929614, 325.47276551764077, 262.296821818452, 388.6320199394144, 348.01787733193356, 599.3375430141216, 511.83452568702654, 325.36564897834097, 514.6094157735905, 561.0498119096088, 654.6928291972657, 378.05905621374745, 149.51296618198347, 299.9988149325261, 486.59959278145453, 464.86474778590144, 513.5049801131704, 365.538037702396, 513.8646740909857, 534.4844752052381, 71.77423120815207, 437.2158363674901, 580.030419978105, 474.7429292379386, 602.1086274483905, 507.73610492714886, 512.8876341893241, 391.8222799645556, 411.9175700471113, 307.8510696228271, 336.9897277315033, 493.037982265027, 608.7085157069222, 489.4562662257554, 601.8691427640432, 635.9990322830903, 486.932917986894, 606.9460820569801, 388.6196892699685, 341.12883818141626, 394.0147794915534, 265.8012206477068], "policy_predator_policy_reward": [543.0597699118762, 464.4798271337597, 676.7014432218647, 719.1944273850291, 538.7011752918553, 408.0533003121635, 658.7258586205912, 453.46246749454133, 382.28603226927254, 395.0088401305941, 313.0816794600876, 256.0420079710684, 356.18359056929216, 409.20271660325284, 413.77214879755286, 329.74942007307754, 563.3969058414278, 545.1362957329693, 342.2839710729475, 490.7205753376855, 337.73101108182715, 410.1604669895823, 305.84928912775973, 349.68327159555395, 821.0596555498161, 659.6763688920518, 595.5487718518647, 567.376817832536, 65.15879778462693, 2.0944039560470378, 41.96076905485777, 122.56728442494887, 352.1068602848362, 412.5211818089867, 514.2024845403372, 641.3037576167711, 480.1750643469773, 592.9852538793566, 500.52388063455606, 538.9128360912687, 342.61499047490423, 289.3072946803703, 355.9493592886659, 532.5056157676802, 459.3009498915623, 420.8529192528041, 365.4983336905043, 290.9157604531625, 196.53378140489968, 310.85492934275027, 244.53273623509006, 315.76746699491065, 466.80616209792487, 520.7838958235017, 604.0349844312099, 634.4995680306766, 611.2017219777925, 448.2314082215504, 535.2522961226578, 554.634803048289, 389.44313905847673, 219.72176985951367, 299.7363619087853, 352.81012187948863, 386.91832830246403, 545.6815207611396, 382.62251675339496, 429.9471480033829, 416.89103641891757, 330.21929016854403, 536.3767894570865, 707.3873300414655, 287.03764643400353, 205.89188896723996, 521.4534783160237, 522.2817329167796, 567.0366985859546, 609.9836957768322, 441.40612820406534, 249.41500966377146, 251.72756148978854, 297.8927612028524, 546.0209601251063, 225.46031465160945, 561.3135546312387, 356.01938942186905, 315.0605986106615, 376.6041040596407, 672.6766230009717, 379.96313249865796, 539.6463920841745, 727.5578740139994, 555.011402258582, 456.2272963371089, 428.4911890326829, 451.22860578694565, 395.5864544039861, 398.60708219809453, 359.03021352196254, 276.41171320950576, 481.25405914691845, 582.6198648977602, 362.4065489108119, 301.9573684592253, 461.4506271865525, 422.2586627160571, 480.0654672337812, 338.8036668720972, 341.37770049361444, 363.2877947513676, 426.38122153489894, 501.82137161812295, 583.2743404856552, 456.85792847680244, 312.75315061692066, 171.79804136496463, 560.6140079423192, 215.5192484511685, 747.1706240696662, 451.899146810377, 391.0701407056279, 460.00656530662576, 358.1903415145272, 362.9597997079267, 366.85601953101474, 364.20539378593895, 273.5248020061797, 380.66398412480805, 414.45806885271656, 493.5502440991037, 188.73392675692992, 354.7422233399557, 577.541635504052, 601.0762834693982, 444.2762658605216, 298.46899444944836, 159.4798015594909, 310.9476028190095, 470.2129261082981, 331.1507144850533, 376.1394404921156, 367.5478039684901, 214.76425953244083, 543.330393624427, 226.30044887248312, 481.8300984687691, 421.1916589481138, 623.533897397941, 473.97516311095137, 340.02880147274186, 354.4564492116435, 319.7774495693507, 340.4956961331792, 527.4546299809983, 331.04863107892794, 142.6899368583899, 532.0546022751006, 443.3189960979083, 576.0933115847336, 569.7077790046607, 638.8895026483391, 588.5032664686921, 527.3065453671194, 402.3011607990903, 586.0318458493258, 634.798456070295, 436.9850887733241, 334.304621987202, 494.89863391947057, 434.1214022798925, 370.6082411990752, 738.4525385535534, 206.79885603771334, 571.5501405360833, 488.09635938142185, 482.12537171028686, 338.57801708324496, 191.24662202101214, 470.8295216785769, 601.0653062697089, 278.26214680018705, 326.373534900099, 318.1206716278725, 474.7746416588913, 531.3651226508041, 485.9439439032081, 550.8431817952592, 567.7413608822621, 506.34233483235704, 437.96392517262547, 321.93839850966447, 375.3678965800853, 299.306825392497, 349.7004778668161, 226.25912942007915, 391.0968113169909, 652.7544845391839, 438.22979413478356, 570.1107884544155, 319.9758416741734]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.6325218391151965, "mean_inference_ms": 6.914109677119809, "mean_action_processing_ms": 1.1257344759289725, "mean_env_wait_ms": 0.9692125387542612, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0066297054290771484, "StateBufferConnector_ms": 0.005719184875488281, "ViewRequirementAgentConnector_ms": 0.32354509830474854}, "num_episodes": 23, "episode_return_max": 2059.3960925061488, "episode_return_min": 547.839950255365, "episode_return_mean": 1763.3584186123628, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.027956651928, "num_env_steps_trained_throughput_per_sec": 316.027956651928, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 106692.581, "restore_workers_time_ms": 0.018, "training_step_time_ms": 106692.519, "sample_time_ms": 5516.488, "learn_time_ms": 101138.567, "learn_throughput": 39.55, "synch_weights_time_ms": 35.504}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "479e5_00000", "date": "2024-08-16_12-20-48", "timestamp": 1723791048, "time_this_iter_s": 12.66934871673584, "time_total_s": 3239.522777080536, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78a0820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3239.522777080536, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 42.161111111111104, "ram_util_percent": 76.01666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8656360831367906, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.711798290979294, "policy_loss": -0.002537690212324301, "vf_loss": 9.713413637655753, "vf_explained_var": 0.01706256257793891, "kl": 0.00819869431683523, "entropy": 1.225178241603589, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.085183632499957, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.463720161700374, "policy_loss": -0.005027286309955849, "vf_loss": 9.468160700419592, "vf_explained_var": -0.0878421080806268, "kl": 0.01043114325880269, "entropy": 0.8076763832379901, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 2144.813213891471, "episode_reward_min": 1391.0758524601035, "episode_reward_mean": 1800.330492173041, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 53.21203123920391, "predator_policy": 2.8216650697625005}, "policy_reward_max": {"prey_policy": 699.7304521619884, "predator_policy": 764.1157359067766}, "policy_reward_mean": {"prey_policy": 465.19169326550224, "predator_policy": 434.97355282101836}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1867.3182907828175, 1855.6603413398846, 1575.897538174212, 1950.3884938546998, 1985.1501353055057, 1713.716670024336, 1391.0758524601035, 1593.5077148302087, 1842.0501891420406, 1881.8327151048354, 1890.4711249546206, 1846.6452794536801, 1748.6430479782307, 1458.8920782294342, 1755.3309539937798, 1781.939718922886, 1634.9920196582093, 1915.1991651819922, 1640.5555403246137, 1970.6056643499173, 1855.1057974216458, 1659.0008496712574, 1668.9361217102266, 1789.3459796781217, 1990.344758239291, 1622.3260167245828, 1869.7375191869462, 2026.2917985183824, 2059.3960925061488, 1939.9472575991158, 1537.7970668362182, 1722.5960827541219, 1959.8515332692582, 1829.9206117448957, 1912.5754707582703, 1766.84067722291, 1855.0148707368485, 1834.8652449724746, 1760.7484689342036, 1553.2432147353022, 1806.412651059457, 1734.5881223527115, 1936.4458036288356, 1842.9921707488124, 1710.767317761275, 1869.3687750299698, 1649.2662300238276, 1552.47988614046, 1929.015444336107, 1879.0962206947968, 1718.1680452374242, 1597.8394694549859, 1557.7948885324545, 1743.121963017379, 1905.5342797283906, 1648.5652135270063, 1953.720645680794, 1623.5726869849166, 1869.4359084109194, 1512.30794148709, 1984.6133781543297, 1872.9945658999961, 1878.3216108748982, 1876.9631265122657, 2058.0304765849887, 1846.9489384437268, 1961.7719216103753, 1558.572560867137, 1729.8133371411484, 1849.2647489072733, 1578.1737884004815, 1580.8848955239262, 1659.409030916329, 1902.7400456623009, 1922.0189807078914, 1838.3531823474589, 1774.3339700015117, 1795.4710770224258, 1886.875478306446, 1711.2349407809452, 1820.7328061253525, 1549.9026302678496, 1525.8132876878492, 1882.7546880922544, 1979.1825247505374, 1777.0667362139304, 2144.813213891471, 1911.5559219542147, 1880.328603150635, 1930.7837714715884, 2000.158927003762, 1942.8943202283683, 1916.4318130996803, 1932.4567482347127, 1935.992750425095, 1783.7128147806445, 1872.9468637185696, 1600.0788470682494, 2110.3641941311607, 1714.0360692184909], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [223.66751766296434, 570.4904548935222, 592.4861464436857, 223.73747817037312, 438.04888744971686, 505.92636556921974, 566.5556090123877, 495.37790978596786, 530.8482018020985, 574.1480643590414, 505.0964188877602, 552.206156992908, 401.41075258365754, 482.2763891287963, 464.0510549589909, 569.1564566412196, 459.2747258870282, 395.185405333585, 53.21203123920391, 590.0861314037452, 655.0994519702849, 175.9385427849951, 342.0145556601234, 414.74362462260996, 500.0987044725467, 639.3794345876954, 507.9238663611858, 298.4217280799747, 397.684708701711, 425.0463962284651, 605.5338887449844, 363.83616542112304, 426.8479541337015, 461.03373893704816, 170.3273865455163, 501.10765913792306, 555.8503413897952, 591.7756635335747, 435.03725619033565, 491.8331969267789, 353.0835856472796, 325.0018174115812, 341.44327241261925, 626.7364393908014, 570.031987332271, 549.2838116853138, 604.2922371509494, 413.57246775045485, 562.7047832678476, 510.3070309183365, 437.19974946306843, 493.4615645912121, 242.7124491087732, 574.3853145785437, 614.733570986216, 144.35396143398773, 429.6836709992633, 618.4737229111948, 510.9104990365343, 549.3169637429521, 370.37977535302946, 373.2237548811056, 560.6549750302037, 526.4991809924484, 353.29907336908155, 542.6785358554978, 587.260031089174, 578.296663285684, 511.4201716269978, 517.4460092286629, 445.14131217045724, 502.83023094657443, 570.1238779826047, 580.2254975092634, 611.3964573735848, 295.2661944458679, 247.77687332749227, 472.83932664425254, 532.1092877374593, 536.5827350159578, 494.92778807148756, 535.3516065944807, 337.077707652894, 198.44064381977424, 573.6617114789176, 511.7073861376649, 497.17324865409074, 624.668780872266, 486.8687235178414, 492.8371809264792, 552.3350070370972, 662.8449818618842, 425.6438696088776, 315.6140474631281, 468.73404638665835, 540.2696896569163, 556.1889262254733, 194.20859913718363, 647.4303833022751, 488.9205770825508, 652.5798425176692, 595.1607983412549, 325.68398034353436, 470.791848518102, 408.9418466809187, 405.16579739093044, 569.6039653337689, 415.4233445267428, 595.2024858269651, 602.2012465601752, 337.3252414475588, 266.51441573339264, 570.4721218723547, 569.2445592247485, 523.3215243215529, 426.0172638823693, 386.77952691505925, 614.7060553816855, 498.6918476426218, 539.8775259071517, 618.8023318587177, 390.4374479226027, 401.7207097929614, 325.47276551764077, 262.296821818452, 388.6320199394144, 348.01787733193356, 599.3375430141216, 511.83452568702654, 325.36564897834097, 514.6094157735905, 561.0498119096088, 654.6928291972657, 378.05905621374745, 149.51296618198347, 299.9988149325261, 486.59959278145453, 464.86474778590144, 513.5049801131704, 365.538037702396, 513.8646740909857, 534.4844752052381, 71.77423120815207, 437.2158363674901, 580.030419978105, 474.7429292379386, 602.1086274483905, 507.73610492714886, 512.8876341893241, 391.8222799645556, 411.9175700471113, 307.8510696228271, 336.9897277315033, 493.037982265027, 608.7085157069222, 489.4562662257554, 601.8691427640432, 635.9990322830903, 486.932917986894, 606.9460820569801, 388.6196892699685, 341.12883818141626, 394.0147794915534, 265.8012206477068, 524.9109125120758, 514.3437835705698, 119.94562641636139, 405.9256976654255, 580.7817744178884, 289.7863788418258, 327.66461174806375, 501.9587226592792, 699.7304521619884, 389.32309668648765, 499.74069713728665, 367.61459642047794, 622.9050070118368, 544.9978952909332, 545.1356614900891, 446.85892892751633, 653.8006644143925, 343.4036663087354, 522.3264935896425, 485.5295322686956, 520.726720229568, 447.5356408450753, 413.1878568009842, 415.2915701728469, 656.9238527048371, 242.6471939373188, 543.1995249347457, 649.2989571450365, 485.90978524923287, 433.4727893697481, 477.9251010560891, 442.04334966694466, 435.35342846284453, 438.4101871973113, 354.6743132532281, 420.2407610067454], "policy_predator_policy_reward": [480.1750643469773, 592.9852538793566, 500.52388063455606, 538.9128360912687, 342.61499047490423, 289.3072946803703, 355.9493592886659, 532.5056157676802, 459.3009498915623, 420.8529192528041, 365.4983336905043, 290.9157604531625, 196.53378140489968, 310.85492934275027, 244.53273623509006, 315.76746699491065, 466.80616209792487, 520.7838958235017, 604.0349844312099, 634.4995680306766, 611.2017219777925, 448.2314082215504, 535.2522961226578, 554.634803048289, 389.44313905847673, 219.72176985951367, 299.7363619087853, 352.81012187948863, 386.91832830246403, 545.6815207611396, 382.62251675339496, 429.9471480033829, 416.89103641891757, 330.21929016854403, 536.3767894570865, 707.3873300414655, 287.03764643400353, 205.89188896723996, 521.4534783160237, 522.2817329167796, 567.0366985859546, 609.9836957768322, 441.40612820406534, 249.41500966377146, 251.72756148978854, 297.8927612028524, 546.0209601251063, 225.46031465160945, 561.3135546312387, 356.01938942186905, 315.0605986106615, 376.6041040596407, 672.6766230009717, 379.96313249865796, 539.6463920841745, 727.5578740139994, 555.011402258582, 456.2272963371089, 428.4911890326829, 451.22860578694565, 395.5864544039861, 398.60708219809453, 359.03021352196254, 276.41171320950576, 481.25405914691845, 582.6198648977602, 362.4065489108119, 301.9573684592253, 461.4506271865525, 422.2586627160571, 480.0654672337812, 338.8036668720972, 341.37770049361444, 363.2877947513676, 426.38122153489894, 501.82137161812295, 583.2743404856552, 456.85792847680244, 312.75315061692066, 171.79804136496463, 560.6140079423192, 215.5192484511685, 747.1706240696662, 451.899146810377, 391.0701407056279, 460.00656530662576, 358.1903415145272, 362.9597997079267, 366.85601953101474, 364.20539378593895, 273.5248020061797, 380.66398412480805, 414.45806885271656, 493.5502440991037, 188.73392675692992, 354.7422233399557, 577.541635504052, 601.0762834693982, 444.2762658605216, 298.46899444944836, 159.4798015594909, 310.9476028190095, 470.2129261082981, 331.1507144850533, 376.1394404921156, 367.5478039684901, 214.76425953244083, 543.330393624427, 226.30044887248312, 481.8300984687691, 421.1916589481138, 623.533897397941, 473.97516311095137, 340.02880147274186, 354.4564492116435, 319.7774495693507, 340.4956961331792, 527.4546299809983, 331.04863107892794, 142.6899368583899, 532.0546022751006, 443.3189960979083, 576.0933115847336, 569.7077790046607, 638.8895026483391, 588.5032664686921, 527.3065453671194, 402.3011607990903, 586.0318458493258, 634.798456070295, 436.9850887733241, 334.304621987202, 494.89863391947057, 434.1214022798925, 370.6082411990752, 738.4525385535534, 206.79885603771334, 571.5501405360833, 488.09635938142185, 482.12537171028686, 338.57801708324496, 191.24662202101214, 470.8295216785769, 601.0653062697089, 278.26214680018705, 326.373534900099, 318.1206716278725, 474.7746416588913, 531.3651226508041, 485.9439439032081, 550.8431817952592, 567.7413608822621, 506.34233483235704, 437.96392517262547, 321.93839850966447, 375.3678965800853, 299.306825392497, 349.7004778668161, 226.25912942007915, 391.0968113169909, 652.7544845391839, 438.22979413478356, 570.1107884544155, 319.9758416741734, 2.8216650697625005, 483.73692653544185, 764.1157359067766, 592.7676281036904, 583.0048324199144, 525.6095390709115, 666.6271463079402, 280.8162554986454, 496.87202871963797, 558.8876363233567, 572.871789780044, 471.3288386164071, 363.88546472846207, 348.54023611940454, 430.02431518230117, 508.76486587168034, 594.2168249667582, 408.73777131387305, 480.1697965384279, 454.86849783160295, 448.5543051564359, 499.61514686860016, 576.539144724242, 527.4381765366409, 583.5817535613004, 452.8399502216411, 313.57273158581165, 277.6416011150507, 463.66469723019236, 489.8995918693955, 421.58768628099705, 258.52271006421864, 615.2234949583993, 621.3770835126088, 402.7527048032558, 536.3682901552604]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.6192561868534217, "mean_inference_ms": 6.8894942532139725, "mean_action_processing_ms": 1.1205112256813505, "mean_env_wait_ms": 0.9647691613788143, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005835533142089844, "StateBufferConnector_ms": 0.004750251770019531, "ViewRequirementAgentConnector_ms": 0.27560651302337646}, "num_episodes": 18, "episode_return_max": 2144.813213891471, "episode_return_min": 1391.0758524601035, "episode_return_mean": 1800.330492173041, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 322.7137443220222, "num_env_steps_trained_throughput_per_sec": 322.7137443220222, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 104842.896, "restore_workers_time_ms": 0.019, "training_step_time_ms": 104842.832, "sample_time_ms": 4978.413, "learn_time_ms": 99827.764, "learn_throughput": 40.069, "synch_weights_time_ms": 34.599}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "479e5_00000", "date": "2024-08-16_12-21-00", "timestamp": 1723791060, "time_this_iter_s": 12.403618812561035, "time_total_s": 3251.926395893097, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7901e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3251.926395893097, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 41.817647058823525, "ram_util_percent": 76.0}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.026486181266724, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.633497959722288, "policy_loss": -0.0014477326379468043, "vf_loss": 9.633677943295272, "vf_explained_var": -0.023657425780775686, "kl": 0.011268933054101178, "entropy": 1.2273045351896337, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.968853144544773, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.619930973759404, "policy_loss": -0.00460575675128629, "vf_loss": 9.623985804704132, "vf_explained_var": -0.0425315018684145, "kl": 0.009794315048896076, "entropy": 0.8090971329540172, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 2144.813213891471, "episode_reward_min": 1512.30794148709, "episode_reward_mean": 1824.8365978130212, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 71.77423120815207, "predator_policy": 2.8216650697625005}, "policy_reward_max": {"prey_policy": 699.7304521619884, "predator_policy": 764.1157359067766}, "policy_reward_mean": {"prey_policy": 473.8086891901011, "predator_policy": 438.60960971640964}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1640.5555403246137, 1970.6056643499173, 1855.1057974216458, 1659.0008496712574, 1668.9361217102266, 1789.3459796781217, 1990.344758239291, 1622.3260167245828, 1869.7375191869462, 2026.2917985183824, 2059.3960925061488, 1939.9472575991158, 1537.7970668362182, 1722.5960827541219, 1959.8515332692582, 1829.9206117448957, 1912.5754707582703, 1766.84067722291, 1855.0148707368485, 1834.8652449724746, 1760.7484689342036, 1553.2432147353022, 1806.412651059457, 1734.5881223527115, 1936.4458036288356, 1842.9921707488124, 1710.767317761275, 1869.3687750299698, 1649.2662300238276, 1552.47988614046, 1929.015444336107, 1879.0962206947968, 1718.1680452374242, 1597.8394694549859, 1557.7948885324545, 1743.121963017379, 1905.5342797283906, 1648.5652135270063, 1953.720645680794, 1623.5726869849166, 1869.4359084109194, 1512.30794148709, 1984.6133781543297, 1872.9945658999961, 1878.3216108748982, 1876.9631265122657, 2058.0304765849887, 1846.9489384437268, 1961.7719216103753, 1558.572560867137, 1729.8133371411484, 1849.2647489072733, 1578.1737884004815, 1580.8848955239262, 1659.409030916329, 1902.7400456623009, 1922.0189807078914, 1838.3531823474589, 1774.3339700015117, 1795.4710770224258, 1886.875478306446, 1711.2349407809452, 1820.7328061253525, 1549.9026302678496, 1525.8132876878492, 1882.7546880922544, 1979.1825247505374, 1777.0667362139304, 2144.813213891471, 1911.5559219542147, 1880.328603150635, 1930.7837714715884, 2000.158927003762, 1942.8943202283683, 1916.4318130996803, 1932.4567482347127, 1935.992750425095, 1783.7128147806445, 1872.9468637185696, 1600.0788470682494, 2110.3641941311607, 1714.0360692184909, 2070.2245467921443, 1935.9755847151662, 1952.98434854667, 1980.6797672494993, 1811.587823795224, 1982.6645087087875, 1746.5591487202528, 1971.7029181627609, 1908.6716541025419, 1959.0192487155712, 1871.053319624856, 1922.9075941140263, 1667.360244234089, 1858.6840112415362, 2005.0531402765205, 1662.1048723713127, 1796.3307789623195, 2035.7583830562196], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [555.8503413897952, 591.7756635335747, 435.03725619033565, 491.8331969267789, 353.0835856472796, 325.0018174115812, 341.44327241261925, 626.7364393908014, 570.031987332271, 549.2838116853138, 604.2922371509494, 413.57246775045485, 562.7047832678476, 510.3070309183365, 437.19974946306843, 493.4615645912121, 242.7124491087732, 574.3853145785437, 614.733570986216, 144.35396143398773, 429.6836709992633, 618.4737229111948, 510.9104990365343, 549.3169637429521, 370.37977535302946, 373.2237548811056, 560.6549750302037, 526.4991809924484, 353.29907336908155, 542.6785358554978, 587.260031089174, 578.296663285684, 511.4201716269978, 517.4460092286629, 445.14131217045724, 502.83023094657443, 570.1238779826047, 580.2254975092634, 611.3964573735848, 295.2661944458679, 247.77687332749227, 472.83932664425254, 532.1092877374593, 536.5827350159578, 494.92778807148756, 535.3516065944807, 337.077707652894, 198.44064381977424, 573.6617114789176, 511.7073861376649, 497.17324865409074, 624.668780872266, 486.8687235178414, 492.8371809264792, 552.3350070370972, 662.8449818618842, 425.6438696088776, 315.6140474631281, 468.73404638665835, 540.2696896569163, 556.1889262254733, 194.20859913718363, 647.4303833022751, 488.9205770825508, 652.5798425176692, 595.1607983412549, 325.68398034353436, 470.791848518102, 408.9418466809187, 405.16579739093044, 569.6039653337689, 415.4233445267428, 595.2024858269651, 602.2012465601752, 337.3252414475588, 266.51441573339264, 570.4721218723547, 569.2445592247485, 523.3215243215529, 426.0172638823693, 386.77952691505925, 614.7060553816855, 498.6918476426218, 539.8775259071517, 618.8023318587177, 390.4374479226027, 401.7207097929614, 325.47276551764077, 262.296821818452, 388.6320199394144, 348.01787733193356, 599.3375430141216, 511.83452568702654, 325.36564897834097, 514.6094157735905, 561.0498119096088, 654.6928291972657, 378.05905621374745, 149.51296618198347, 299.9988149325261, 486.59959278145453, 464.86474778590144, 513.5049801131704, 365.538037702396, 513.8646740909857, 534.4844752052381, 71.77423120815207, 437.2158363674901, 580.030419978105, 474.7429292379386, 602.1086274483905, 507.73610492714886, 512.8876341893241, 391.8222799645556, 411.9175700471113, 307.8510696228271, 336.9897277315033, 493.037982265027, 608.7085157069222, 489.4562662257554, 601.8691427640432, 635.9990322830903, 486.932917986894, 606.9460820569801, 388.6196892699685, 341.12883818141626, 394.0147794915534, 265.8012206477068, 524.9109125120758, 514.3437835705698, 119.94562641636139, 405.9256976654255, 580.7817744178884, 289.7863788418258, 327.66461174806375, 501.9587226592792, 699.7304521619884, 389.32309668648765, 499.74069713728665, 367.61459642047794, 622.9050070118368, 544.9978952909332, 545.1356614900891, 446.85892892751633, 653.8006644143925, 343.4036663087354, 522.3264935896425, 485.5295322686956, 520.726720229568, 447.5356408450753, 413.1878568009842, 415.2915701728469, 656.9238527048371, 242.6471939373188, 543.1995249347457, 649.2989571450365, 485.90978524923287, 433.4727893697481, 477.9251010560891, 442.04334966694466, 435.35342846284453, 438.4101871973113, 354.6743132532281, 420.2407610067454, 617.1237115123015, 304.8018619467813, 610.1751469162415, 572.117397942761, 531.8499793880942, 636.9989423784859, 577.8565401401974, 194.49030995818816, 602.5560809635953, 551.001673092807, 685.3603257894907, 290.453943110272, 182.50797390255948, 534.107106044032, 608.9322389746319, 249.07746574269981, 350.19506576187723, 532.1753490313114, 644.6353978579369, 614.0856916861727, 560.7031243114066, 543.6490208726273, 442.8029906940694, 663.2845870313247, 641.8007737290828, 490.97064711250624, 472.58301477927665, 327.0866170125645, 386.36566609718204, 647.5559511041787, 364.2170317484451, 328.60159844274216, 465.557824388286, 565.4928629734727, 400.85769180799906, 609.6475452699403], "policy_predator_policy_reward": [287.03764643400353, 205.89188896723996, 521.4534783160237, 522.2817329167796, 567.0366985859546, 609.9836957768322, 441.40612820406534, 249.41500966377146, 251.72756148978854, 297.8927612028524, 546.0209601251063, 225.46031465160945, 561.3135546312387, 356.01938942186905, 315.0605986106615, 376.6041040596407, 672.6766230009717, 379.96313249865796, 539.6463920841745, 727.5578740139994, 555.011402258582, 456.2272963371089, 428.4911890326829, 451.22860578694565, 395.5864544039861, 398.60708219809453, 359.03021352196254, 276.41171320950576, 481.25405914691845, 582.6198648977602, 362.4065489108119, 301.9573684592253, 461.4506271865525, 422.2586627160571, 480.0654672337812, 338.8036668720972, 341.37770049361444, 363.2877947513676, 426.38122153489894, 501.82137161812295, 583.2743404856552, 456.85792847680244, 312.75315061692066, 171.79804136496463, 560.6140079423192, 215.5192484511685, 747.1706240696662, 451.899146810377, 391.0701407056279, 460.00656530662576, 358.1903415145272, 362.9597997079267, 366.85601953101474, 364.20539378593895, 273.5248020061797, 380.66398412480805, 414.45806885271656, 493.5502440991037, 188.73392675692992, 354.7422233399557, 577.541635504052, 601.0762834693982, 444.2762658605216, 298.46899444944836, 159.4798015594909, 310.9476028190095, 470.2129261082981, 331.1507144850533, 376.1394404921156, 367.5478039684901, 214.76425953244083, 543.330393624427, 226.30044887248312, 481.8300984687691, 421.1916589481138, 623.533897397941, 473.97516311095137, 340.02880147274186, 354.4564492116435, 319.7774495693507, 340.4956961331792, 527.4546299809983, 331.04863107892794, 142.6899368583899, 532.0546022751006, 443.3189960979083, 576.0933115847336, 569.7077790046607, 638.8895026483391, 588.5032664686921, 527.3065453671194, 402.3011607990903, 586.0318458493258, 634.798456070295, 436.9850887733241, 334.304621987202, 494.89863391947057, 434.1214022798925, 370.6082411990752, 738.4525385535534, 206.79885603771334, 571.5501405360833, 488.09635938142185, 482.12537171028686, 338.57801708324496, 191.24662202101214, 470.8295216785769, 601.0653062697089, 278.26214680018705, 326.373534900099, 318.1206716278725, 474.7746416588913, 531.3651226508041, 485.9439439032081, 550.8431817952592, 567.7413608822621, 506.34233483235704, 437.96392517262547, 321.93839850966447, 375.3678965800853, 299.306825392497, 349.7004778668161, 226.25912942007915, 391.0968113169909, 652.7544845391839, 438.22979413478356, 570.1107884544155, 319.9758416741734, 2.8216650697625005, 483.73692653544185, 764.1157359067766, 592.7676281036904, 583.0048324199144, 525.6095390709115, 666.6271463079402, 280.8162554986454, 496.87202871963797, 558.8876363233567, 572.871789780044, 471.3288386164071, 363.88546472846207, 348.54023611940454, 430.02431518230117, 508.76486587168034, 594.2168249667582, 408.73777131387305, 480.1697965384279, 454.86849783160295, 448.5543051564359, 499.61514686860016, 576.539144724242, 527.4381765366409, 583.5817535613004, 452.8399502216411, 313.57273158581165, 277.6416011150507, 463.66469723019236, 489.8995918693955, 421.58768628099705, 258.52271006421864, 615.2234949583993, 621.3770835126088, 402.7527048032558, 536.3682901552604, 501.1647775879083, 647.134195745149, 338.7599204790262, 414.9231193771388, 389.9955189401214, 394.13990783996877, 613.4324118130777, 594.9005053380369, 296.5477649981731, 361.4823047406484, 497.2806177708267, 509.56962203819904, 670.88116572107, 359.06290305259324, 545.3939049965513, 568.2993084488802, 472.2438078232113, 554.0574314861425, 354.3825467640456, 345.9156124074164, 371.07324282179934, 395.6279316190216, 384.3137093407851, 432.50630704784766, 286.00882489771686, 248.57999849478, 567.5933447240644, 491.4210347256305, 479.27629955599457, 491.85522351916967, 504.1647399047767, 465.12150227534687, 396.45012513934387, 368.8299664612184, 485.6635382278351, 539.5896077504444]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.5962145246084276, "mean_inference_ms": 6.829423834463224, "mean_action_processing_ms": 1.1107759454179125, "mean_env_wait_ms": 0.956169146306524, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004684090614318848, "StateBufferConnector_ms": 0.003789663314819336, "ViewRequirementAgentConnector_ms": 0.1526350975036621}, "num_episodes": 18, "episode_return_max": 2144.813213891471, "episode_return_min": 1512.30794148709, "episode_return_mean": 1824.8365978130212, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 314.2178398894459, "num_env_steps_trained_throughput_per_sec": 314.2178398894459, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 103181.34, "restore_workers_time_ms": 0.019, "training_step_time_ms": 103181.278, "sample_time_ms": 4658.78, "learn_time_ms": 98485.144, "learn_throughput": 40.615, "synch_weights_time_ms": 35.318}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "479e5_00000", "date": "2024-08-16_12-21-13", "timestamp": 1723791073, "time_this_iter_s": 12.743938684463501, "time_total_s": 3264.6703345775604, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7901160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3264.6703345775604, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 40.99444444444444, "ram_util_percent": 75.92222222222222}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5983132903222685, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.497259775292937, "policy_loss": 0.0004915613157516986, "vf_loss": 9.495876740652417, "vf_explained_var": -0.05487498212112951, "kl": 0.007924128474989928, "entropy": 1.181214944332365, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8204785643431245, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.648718024057056, "policy_loss": -0.002883878762577537, "vf_loss": 9.651075381324405, "vf_explained_var": -0.0701679545735556, "kl": 0.009360427806605795, "entropy": 0.6882226131265126, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 2144.813213891471, "episode_reward_min": 1277.6251860740372, "episode_reward_mean": 1804.5516236465905, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 71.77423120815207, "predator_policy": -45.37674958659326}, "policy_reward_max": {"prey_policy": 791.1480846905233, "predator_policy": 764.1157359067766}, "policy_reward_mean": {"prey_policy": 489.43496200132677, "predator_policy": 412.8408498219687}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1806.412651059457, 1734.5881223527115, 1936.4458036288356, 1842.9921707488124, 1710.767317761275, 1869.3687750299698, 1649.2662300238276, 1552.47988614046, 1929.015444336107, 1879.0962206947968, 1718.1680452374242, 1597.8394694549859, 1557.7948885324545, 1743.121963017379, 1905.5342797283906, 1648.5652135270063, 1953.720645680794, 1623.5726869849166, 1869.4359084109194, 1512.30794148709, 1984.6133781543297, 1872.9945658999961, 1878.3216108748982, 1876.9631265122657, 2058.0304765849887, 1846.9489384437268, 1961.7719216103753, 1558.572560867137, 1729.8133371411484, 1849.2647489072733, 1578.1737884004815, 1580.8848955239262, 1659.409030916329, 1902.7400456623009, 1922.0189807078914, 1838.3531823474589, 1774.3339700015117, 1795.4710770224258, 1886.875478306446, 1711.2349407809452, 1820.7328061253525, 1549.9026302678496, 1525.8132876878492, 1882.7546880922544, 1979.1825247505374, 1777.0667362139304, 2144.813213891471, 1911.5559219542147, 1880.328603150635, 1930.7837714715884, 2000.158927003762, 1942.8943202283683, 1916.4318130996803, 1932.4567482347127, 1935.992750425095, 1783.7128147806445, 1872.9468637185696, 1600.0788470682494, 2110.3641941311607, 1714.0360692184909, 2070.2245467921443, 1935.9755847151662, 1952.98434854667, 1980.6797672494993, 1811.587823795224, 1982.6645087087875, 1746.5591487202528, 1971.7029181627609, 1908.6716541025419, 1959.0192487155712, 1871.053319624856, 1922.9075941140263, 1667.360244234089, 1858.6840112415362, 2005.0531402765205, 1662.1048723713127, 1796.3307789623195, 2035.7583830562196, 1980.1733115045558, 1663.5130571156983, 1277.6251860740372, 2037.662720455204, 1601.2004304271888, 1904.1626203452436, 1576.6841491370408, 1563.4797395314472, 1496.580288429551, 1547.5866262722068, 1675.8997932658692, 1954.8499727883463, 1337.2132777423299, 1801.798212458211, 1926.6875481094337, 1742.4395572818098, 1953.1305864570963, 1813.9087658610927, 2015.572437352726, 1784.7938448390107, 1510.50387303797, 1631.0832227655999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [494.92778807148756, 535.3516065944807, 337.077707652894, 198.44064381977424, 573.6617114789176, 511.7073861376649, 497.17324865409074, 624.668780872266, 486.8687235178414, 492.8371809264792, 552.3350070370972, 662.8449818618842, 425.6438696088776, 315.6140474631281, 468.73404638665835, 540.2696896569163, 556.1889262254733, 194.20859913718363, 647.4303833022751, 488.9205770825508, 652.5798425176692, 595.1607983412549, 325.68398034353436, 470.791848518102, 408.9418466809187, 405.16579739093044, 569.6039653337689, 415.4233445267428, 595.2024858269651, 602.2012465601752, 337.3252414475588, 266.51441573339264, 570.4721218723547, 569.2445592247485, 523.3215243215529, 426.0172638823693, 386.77952691505925, 614.7060553816855, 498.6918476426218, 539.8775259071517, 618.8023318587177, 390.4374479226027, 401.7207097929614, 325.47276551764077, 262.296821818452, 388.6320199394144, 348.01787733193356, 599.3375430141216, 511.83452568702654, 325.36564897834097, 514.6094157735905, 561.0498119096088, 654.6928291972657, 378.05905621374745, 149.51296618198347, 299.9988149325261, 486.59959278145453, 464.86474778590144, 513.5049801131704, 365.538037702396, 513.8646740909857, 534.4844752052381, 71.77423120815207, 437.2158363674901, 580.030419978105, 474.7429292379386, 602.1086274483905, 507.73610492714886, 512.8876341893241, 391.8222799645556, 411.9175700471113, 307.8510696228271, 336.9897277315033, 493.037982265027, 608.7085157069222, 489.4562662257554, 601.8691427640432, 635.9990322830903, 486.932917986894, 606.9460820569801, 388.6196892699685, 341.12883818141626, 394.0147794915534, 265.8012206477068, 524.9109125120758, 514.3437835705698, 119.94562641636139, 405.9256976654255, 580.7817744178884, 289.7863788418258, 327.66461174806375, 501.9587226592792, 699.7304521619884, 389.32309668648765, 499.74069713728665, 367.61459642047794, 622.9050070118368, 544.9978952909332, 545.1356614900891, 446.85892892751633, 653.8006644143925, 343.4036663087354, 522.3264935896425, 485.5295322686956, 520.726720229568, 447.5356408450753, 413.1878568009842, 415.2915701728469, 656.9238527048371, 242.6471939373188, 543.1995249347457, 649.2989571450365, 485.90978524923287, 433.4727893697481, 477.9251010560891, 442.04334966694466, 435.35342846284453, 438.4101871973113, 354.6743132532281, 420.2407610067454, 617.1237115123015, 304.8018619467813, 610.1751469162415, 572.117397942761, 531.8499793880942, 636.9989423784859, 577.8565401401974, 194.49030995818816, 602.5560809635953, 551.001673092807, 685.3603257894907, 290.453943110272, 182.50797390255948, 534.107106044032, 608.9322389746319, 249.07746574269981, 350.19506576187723, 532.1753490313114, 644.6353978579369, 614.0856916861727, 560.7031243114066, 543.6490208726273, 442.8029906940694, 663.2845870313247, 641.8007737290828, 490.97064711250624, 472.58301477927665, 327.0866170125645, 386.36566609718204, 647.5559511041787, 364.2170317484451, 328.60159844274216, 465.557824388286, 565.4928629734727, 400.85769180799906, 609.6475452699403, 418.31194125154326, 463.6133855514327, 593.1621931712223, 482.3137568869074, 556.5589703512179, 714.4662788023263, 695.8294025119808, 226.04336429918123, 721.0956292090109, 328.2026859389326, 498.66457927649213, 723.8599273628562, 406.88294260202326, 466.02916508250115, 515.0600320166081, 552.7800482772357, 534.187614244948, 611.2063891211762, 574.1058829946436, 464.57848866850765, 611.2306801317012, 654.3743249930369, 655.8115452569799, 484.7156707164783, 431.61436639896687, 788.7222573317233, 389.8185065217855, 791.1480846905233, 566.0430127595893, 196.27322097230146, 650.6879874359157, 713.9193598920745, 644.97436759182, 405.9229952389032, 680.7029071379618, 606.2446287991443, 519.1413833124938, 432.858888597752, 576.652252345987, 777.1139065435048, 617.9263956867127, 614.0234279150727, 446.03768912582575, 583.9793469532071], "policy_predator_policy_reward": [560.6140079423192, 215.5192484511685, 747.1706240696662, 451.899146810377, 391.0701407056279, 460.00656530662576, 358.1903415145272, 362.9597997079267, 366.85601953101474, 364.20539378593895, 273.5248020061797, 380.66398412480805, 414.45806885271656, 493.5502440991037, 188.73392675692992, 354.7422233399557, 577.541635504052, 601.0762834693982, 444.2762658605216, 298.46899444944836, 159.4798015594909, 310.9476028190095, 470.2129261082981, 331.1507144850533, 376.1394404921156, 367.5478039684901, 214.76425953244083, 543.330393624427, 226.30044887248312, 481.8300984687691, 421.1916589481138, 623.533897397941, 473.97516311095137, 340.02880147274186, 354.4564492116435, 319.7774495693507, 340.4956961331792, 527.4546299809983, 331.04863107892794, 142.6899368583899, 532.0546022751006, 443.3189960979083, 576.0933115847336, 569.7077790046607, 638.8895026483391, 588.5032664686921, 527.3065453671194, 402.3011607990903, 586.0318458493258, 634.798456070295, 436.9850887733241, 334.304621987202, 494.89863391947057, 434.1214022798925, 370.6082411990752, 738.4525385535534, 206.79885603771334, 571.5501405360833, 488.09635938142185, 482.12537171028686, 338.57801708324496, 191.24662202101214, 470.8295216785769, 601.0653062697089, 278.26214680018705, 326.373534900099, 318.1206716278725, 474.7746416588913, 531.3651226508041, 485.9439439032081, 550.8431817952592, 567.7413608822621, 506.34233483235704, 437.96392517262547, 321.93839850966447, 375.3678965800853, 299.306825392497, 349.7004778668161, 226.25912942007915, 391.0968113169909, 652.7544845391839, 438.22979413478356, 570.1107884544155, 319.9758416741734, 2.8216650697625005, 483.73692653544185, 764.1157359067766, 592.7676281036904, 583.0048324199144, 525.6095390709115, 666.6271463079402, 280.8162554986454, 496.87202871963797, 558.8876363233567, 572.871789780044, 471.3288386164071, 363.88546472846207, 348.54023611940454, 430.02431518230117, 508.76486587168034, 594.2168249667582, 408.73777131387305, 480.1697965384279, 454.86849783160295, 448.5543051564359, 499.61514686860016, 576.539144724242, 527.4381765366409, 583.5817535613004, 452.8399502216411, 313.57273158581165, 277.6416011150507, 463.66469723019236, 489.8995918693955, 421.58768628099705, 258.52271006421864, 615.2234949583993, 621.3770835126088, 402.7527048032558, 536.3682901552604, 501.1647775879083, 647.134195745149, 338.7599204790262, 414.9231193771388, 389.9955189401214, 394.13990783996877, 613.4324118130777, 594.9005053380369, 296.5477649981731, 361.4823047406484, 497.2806177708267, 509.56962203819904, 670.88116572107, 359.06290305259324, 545.3939049965513, 568.2993084488802, 472.2438078232113, 554.0574314861425, 354.3825467640456, 345.9156124074164, 371.07324282179934, 395.6279316190216, 384.3137093407851, 432.50630704784766, 286.00882489771686, 248.57999849478, 567.5933447240644, 491.4210347256305, 479.27629955599457, 491.85522351916967, 504.1647399047767, 465.12150227534687, 396.45012513934387, 368.8299664612184, 485.6635382278351, 539.5896077504444, 538.8470772182039, 559.4009074833749, 195.97740429785077, 392.05970275971674, -45.37674958659326, 51.976686507086725, 606.017199540605, 509.7727541034386, 257.848806669779, 294.0533086094675, 418.9347828799433, 262.7033308259501, 298.88615907528384, 404.88588237723474, 272.53587557757015, 223.10378366003397, 238.18983116004992, 112.99645390337749, 290.58777105391516, 218.3144835551411, 249.60833703888486, 160.68645110225086, 400.0627862214919, 414.2599705934, 36.667695110431325, 80.20895890120904, 285.49483107199444, 335.3367901739082, 581.761730841487, 582.6095835360547, 186.66853718885673, 191.16367276496848, 592.6512011147793, 309.58202251159514, 310.8873288113018, 216.07390111268415, 567.6513633228358, 495.9208021196435, 347.8899416980413, 83.13774425147884, 189.43244373790245, 89.1216056982809, 343.99508086158, 257.0711058249878]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.5704308497750477, "mean_inference_ms": 6.7574546068049735, "mean_action_processing_ms": 1.0995376818763194, "mean_env_wait_ms": 0.946658917594641, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004547119140625, "StateBufferConnector_ms": 0.0038262605667114258, "ViewRequirementAgentConnector_ms": 0.13971936702728271}, "num_episodes": 22, "episode_return_max": 2144.813213891471, "episode_return_min": 1277.6251860740372, "episode_return_mean": 1804.5516236465905, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 327.49108497666435, "num_env_steps_trained_throughput_per_sec": 327.49108497666435, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 101286.433, "restore_workers_time_ms": 0.02, "training_step_time_ms": 101286.368, "sample_time_ms": 4197.709, "learn_time_ms": 97052.336, "learn_throughput": 41.215, "synch_weights_time_ms": 34.224}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "479e5_00000", "date": "2024-08-16_12-21-25", "timestamp": 1723791085, "time_this_iter_s": 12.2188720703125, "time_total_s": 3276.889206647873, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78b94c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3276.889206647873, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 39.87222222222222, "ram_util_percent": 75.97222222222223}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.268346347316863, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.566663976699587, "policy_loss": -0.0025504192145216088, "vf_loss": 9.56805548945432, "vf_explained_var": -0.032856866196980555, "kl": 0.01030150451907482, "entropy": 1.2072929633357536, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7664144184538928, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.697510501821204, "policy_loss": 0.00045936454245180047, "vf_loss": 9.696438348860967, "vf_explained_var": -0.026802655376454508, "kl": 0.010893798026213227, "entropy": 0.6663473432656949, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 2144.813213891471, "episode_reward_min": 1277.6251860740372, "episode_reward_mean": 1785.664367593915, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 71.77423120815207, "predator_policy": -45.37674958659326}, "policy_reward_max": {"prey_policy": 793.6129413775842, "predator_policy": 764.1157359067766}, "policy_reward_mean": {"prey_policy": 511.5752133441996, "predator_policy": 381.25697045275797}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1869.4359084109194, 1512.30794148709, 1984.6133781543297, 1872.9945658999961, 1878.3216108748982, 1876.9631265122657, 2058.0304765849887, 1846.9489384437268, 1961.7719216103753, 1558.572560867137, 1729.8133371411484, 1849.2647489072733, 1578.1737884004815, 1580.8848955239262, 1659.409030916329, 1902.7400456623009, 1922.0189807078914, 1838.3531823474589, 1774.3339700015117, 1795.4710770224258, 1886.875478306446, 1711.2349407809452, 1820.7328061253525, 1549.9026302678496, 1525.8132876878492, 1882.7546880922544, 1979.1825247505374, 1777.0667362139304, 2144.813213891471, 1911.5559219542147, 1880.328603150635, 1930.7837714715884, 2000.158927003762, 1942.8943202283683, 1916.4318130996803, 1932.4567482347127, 1935.992750425095, 1783.7128147806445, 1872.9468637185696, 1600.0788470682494, 2110.3641941311607, 1714.0360692184909, 2070.2245467921443, 1935.9755847151662, 1952.98434854667, 1980.6797672494993, 1811.587823795224, 1982.6645087087875, 1746.5591487202528, 1971.7029181627609, 1908.6716541025419, 1959.0192487155712, 1871.053319624856, 1922.9075941140263, 1667.360244234089, 1858.6840112415362, 2005.0531402765205, 1662.1048723713127, 1796.3307789623195, 2035.7583830562196, 1980.1733115045558, 1663.5130571156983, 1277.6251860740372, 2037.662720455204, 1601.2004304271888, 1904.1626203452436, 1576.6841491370408, 1563.4797395314472, 1496.580288429551, 1547.5866262722068, 1675.8997932658692, 1954.8499727883463, 1337.2132777423299, 1801.798212458211, 1926.6875481094337, 1742.4395572818098, 1953.1305864570963, 1813.9087658610927, 2015.572437352726, 1784.7938448390107, 1510.50387303797, 1631.0832227655999, 1570.070681811539, 1747.8947444557575, 1679.3983547699522, 1620.339994320469, 1595.0575588738984, 1379.054735019245, 1678.9156284304877, 1555.2534230009912, 1622.5555742321026, 1651.4018487551712, 1542.8997583732314, 1614.4317060767942, 1905.8639178621213, 1843.1352144831146, 1692.7141163763083, 1844.4964139399985, 1469.0724904856495, 1757.4680474051809], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [386.77952691505925, 614.7060553816855, 498.6918476426218, 539.8775259071517, 618.8023318587177, 390.4374479226027, 401.7207097929614, 325.47276551764077, 262.296821818452, 388.6320199394144, 348.01787733193356, 599.3375430141216, 511.83452568702654, 325.36564897834097, 514.6094157735905, 561.0498119096088, 654.6928291972657, 378.05905621374745, 149.51296618198347, 299.9988149325261, 486.59959278145453, 464.86474778590144, 513.5049801131704, 365.538037702396, 513.8646740909857, 534.4844752052381, 71.77423120815207, 437.2158363674901, 580.030419978105, 474.7429292379386, 602.1086274483905, 507.73610492714886, 512.8876341893241, 391.8222799645556, 411.9175700471113, 307.8510696228271, 336.9897277315033, 493.037982265027, 608.7085157069222, 489.4562662257554, 601.8691427640432, 635.9990322830903, 486.932917986894, 606.9460820569801, 388.6196892699685, 341.12883818141626, 394.0147794915534, 265.8012206477068, 524.9109125120758, 514.3437835705698, 119.94562641636139, 405.9256976654255, 580.7817744178884, 289.7863788418258, 327.66461174806375, 501.9587226592792, 699.7304521619884, 389.32309668648765, 499.74069713728665, 367.61459642047794, 622.9050070118368, 544.9978952909332, 545.1356614900891, 446.85892892751633, 653.8006644143925, 343.4036663087354, 522.3264935896425, 485.5295322686956, 520.726720229568, 447.5356408450753, 413.1878568009842, 415.2915701728469, 656.9238527048371, 242.6471939373188, 543.1995249347457, 649.2989571450365, 485.90978524923287, 433.4727893697481, 477.9251010560891, 442.04334966694466, 435.35342846284453, 438.4101871973113, 354.6743132532281, 420.2407610067454, 617.1237115123015, 304.8018619467813, 610.1751469162415, 572.117397942761, 531.8499793880942, 636.9989423784859, 577.8565401401974, 194.49030995818816, 602.5560809635953, 551.001673092807, 685.3603257894907, 290.453943110272, 182.50797390255948, 534.107106044032, 608.9322389746319, 249.07746574269981, 350.19506576187723, 532.1753490313114, 644.6353978579369, 614.0856916861727, 560.7031243114066, 543.6490208726273, 442.8029906940694, 663.2845870313247, 641.8007737290828, 490.97064711250624, 472.58301477927665, 327.0866170125645, 386.36566609718204, 647.5559511041787, 364.2170317484451, 328.60159844274216, 465.557824388286, 565.4928629734727, 400.85769180799906, 609.6475452699403, 418.31194125154326, 463.6133855514327, 593.1621931712223, 482.3137568869074, 556.5589703512179, 714.4662788023263, 695.8294025119808, 226.04336429918123, 721.0956292090109, 328.2026859389326, 498.66457927649213, 723.8599273628562, 406.88294260202326, 466.02916508250115, 515.0600320166081, 552.7800482772357, 534.187614244948, 611.2063891211762, 574.1058829946436, 464.57848866850765, 611.2306801317012, 654.3743249930369, 655.8115452569799, 484.7156707164783, 431.61436639896687, 788.7222573317233, 389.8185065217855, 791.1480846905233, 566.0430127595893, 196.27322097230146, 650.6879874359157, 713.9193598920745, 644.97436759182, 405.9229952389032, 680.7029071379618, 606.2446287991443, 519.1413833124938, 432.858888597752, 576.652252345987, 777.1139065435048, 617.9263956867127, 614.0234279150727, 446.03768912582575, 583.9793469532071, 736.7930614603898, 773.1343146177526, 712.6364921802959, 549.0591950942451, 508.60412772812737, 631.7425481053924, 547.3550943690396, 654.2712969906756, 567.9887236853671, 628.7386198312603, 639.397795834693, 533.801413794867, 778.9316723628517, 675.6612744934093, 608.9568330529356, 306.72141016165875, 670.5232445300089, 637.6930521134051, 587.6208389392459, 497.99522642577256, 543.5216921522061, 539.2466513214997, 508.9209667203785, 690.4268574080877, 622.686400842505, 743.06276069258, 642.2745967702805, 598.4348091647257, 505.2566352138205, 565.7824903592676, 713.3642680656901, 681.9410420004303, 612.3392865160152, 302.1868322856625, 455.92098992239823, 793.6129413775842], "policy_predator_policy_reward": [340.4956961331792, 527.4546299809983, 331.04863107892794, 142.6899368583899, 532.0546022751006, 443.3189960979083, 576.0933115847336, 569.7077790046607, 638.8895026483391, 588.5032664686921, 527.3065453671194, 402.3011607990903, 586.0318458493258, 634.798456070295, 436.9850887733241, 334.304621987202, 494.89863391947057, 434.1214022798925, 370.6082411990752, 738.4525385535534, 206.79885603771334, 571.5501405360833, 488.09635938142185, 482.12537171028686, 338.57801708324496, 191.24662202101214, 470.8295216785769, 601.0653062697089, 278.26214680018705, 326.373534900099, 318.1206716278725, 474.7746416588913, 531.3651226508041, 485.9439439032081, 550.8431817952592, 567.7413608822621, 506.34233483235704, 437.96392517262547, 321.93839850966447, 375.3678965800853, 299.306825392497, 349.7004778668161, 226.25912942007915, 391.0968113169909, 652.7544845391839, 438.22979413478356, 570.1107884544155, 319.9758416741734, 2.8216650697625005, 483.73692653544185, 764.1157359067766, 592.7676281036904, 583.0048324199144, 525.6095390709115, 666.6271463079402, 280.8162554986454, 496.87202871963797, 558.8876363233567, 572.871789780044, 471.3288386164071, 363.88546472846207, 348.54023611940454, 430.02431518230117, 508.76486587168034, 594.2168249667582, 408.73777131387305, 480.1697965384279, 454.86849783160295, 448.5543051564359, 499.61514686860016, 576.539144724242, 527.4381765366409, 583.5817535613004, 452.8399502216411, 313.57273158581165, 277.6416011150507, 463.66469723019236, 489.8995918693955, 421.58768628099705, 258.52271006421864, 615.2234949583993, 621.3770835126088, 402.7527048032558, 536.3682901552604, 501.1647775879083, 647.134195745149, 338.7599204790262, 414.9231193771388, 389.9955189401214, 394.13990783996877, 613.4324118130777, 594.9005053380369, 296.5477649981731, 361.4823047406484, 497.2806177708267, 509.56962203819904, 670.88116572107, 359.06290305259324, 545.3939049965513, 568.2993084488802, 472.2438078232113, 554.0574314861425, 354.3825467640456, 345.9156124074164, 371.07324282179934, 395.6279316190216, 384.3137093407851, 432.50630704784766, 286.00882489771686, 248.57999849478, 567.5933447240644, 491.4210347256305, 479.27629955599457, 491.85522351916967, 504.1647399047767, 465.12150227534687, 396.45012513934387, 368.8299664612184, 485.6635382278351, 539.5896077504444, 538.8470772182039, 559.4009074833749, 195.97740429785077, 392.05970275971674, -45.37674958659326, 51.976686507086725, 606.017199540605, 509.7727541034386, 257.848806669779, 294.0533086094675, 418.9347828799433, 262.7033308259501, 298.88615907528384, 404.88588237723474, 272.53587557757015, 223.10378366003397, 238.18983116004992, 112.99645390337749, 290.58777105391516, 218.3144835551411, 249.60833703888486, 160.68645110225086, 400.0627862214919, 414.2599705934, 36.667695110431325, 80.20895890120904, 285.49483107199444, 335.3367901739082, 581.761730841487, 582.6095835360547, 186.66853718885673, 191.16367276496848, 592.6512011147793, 309.58202251159514, 310.8873288113018, 216.07390111268415, 567.6513633228358, 495.9208021196435, 347.8899416980413, 83.13774425147884, 189.43244373790245, 89.1216056982809, 343.99508086158, 257.0711058249878, 87.22158747033008, -27.07828173693531, 263.68901029451854, 222.51004688669818, 289.4190672175043, 249.63261171892535, 230.13111280554855, 188.58249015520505, 206.65573721957986, 191.67447813769297, 100.58112881997017, 105.27439656971495, 140.8674657183008, 83.45521585592522, 204.64542556582188, 434.92975422057657, 190.68335512931156, 123.65592245937923, 366.4585102506107, 199.32727313954382, 324.30520491547287, 135.82620998405477, 238.10668387704186, 176.97719807128738, 287.79266321304624, 252.3220931139902, 265.0073740682382, 337.41843447986867, 345.8556954708102, 275.81929533241214, 240.00630946513178, 209.18479440874484, 220.72711132072334, 333.8192603632483, 268.0759534444399, 239.85816266075517]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.5471145405585798, "mean_inference_ms": 6.700683415062461, "mean_action_processing_ms": 1.0899474645419094, "mean_env_wait_ms": 0.9380969359168045, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004193425178527832, "StateBufferConnector_ms": 0.003569483757019043, "ViewRequirementAgentConnector_ms": 0.1364971399307251}, "num_episodes": 18, "episode_return_max": 2144.813213891471, "episode_return_min": 1277.6251860740372, "episode_return_mean": 1785.664367593915, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 313.1631976438455, "num_env_steps_trained_throughput_per_sec": 313.1631976438455, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 99578.648, "restore_workers_time_ms": 0.02, "training_step_time_ms": 99578.586, "sample_time_ms": 3854.299, "learn_time_ms": 95688.301, "learn_throughput": 41.802, "synch_weights_time_ms": 34.037}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "479e5_00000", "date": "2024-08-16_12-21-38", "timestamp": 1723791098, "time_this_iter_s": 12.788331031799316, "time_total_s": 3289.6775376796722, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78b9d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3289.6775376796722, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 42.32222222222222, "ram_util_percent": 75.62222222222222}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4192886896234342, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.543313558265647, "policy_loss": -0.0016274153973128665, "vf_loss": 9.543537491591518, "vf_explained_var": -0.09311411740287902, "kl": 0.012475356057250014, "entropy": 1.18758654297975, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7678063827532309, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.70393598344591, "policy_loss": -0.0005589566722625581, "vf_loss": 9.704107318353401, "vf_explained_var": -0.03873025737111531, "kl": 0.006891194781953323, "entropy": 0.6422762865111942, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 2144.813213891471, "episode_reward_min": 1255.7478118879228, "episode_reward_mean": 1740.6998028102541, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 119.94562641636139, "predator_policy": -45.37674958659326}, "policy_reward_max": {"prey_policy": 869.966235065884, "predator_policy": 764.1157359067766}, "policy_reward_mean": {"prey_policy": 542.2615502434414, "predator_policy": 328.08835116168564}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1549.9026302678496, 1525.8132876878492, 1882.7546880922544, 1979.1825247505374, 1777.0667362139304, 2144.813213891471, 1911.5559219542147, 1880.328603150635, 1930.7837714715884, 2000.158927003762, 1942.8943202283683, 1916.4318130996803, 1932.4567482347127, 1935.992750425095, 1783.7128147806445, 1872.9468637185696, 1600.0788470682494, 2110.3641941311607, 1714.0360692184909, 2070.2245467921443, 1935.9755847151662, 1952.98434854667, 1980.6797672494993, 1811.587823795224, 1982.6645087087875, 1746.5591487202528, 1971.7029181627609, 1908.6716541025419, 1959.0192487155712, 1871.053319624856, 1922.9075941140263, 1667.360244234089, 1858.6840112415362, 2005.0531402765205, 1662.1048723713127, 1796.3307789623195, 2035.7583830562196, 1980.1733115045558, 1663.5130571156983, 1277.6251860740372, 2037.662720455204, 1601.2004304271888, 1904.1626203452436, 1576.6841491370408, 1563.4797395314472, 1496.580288429551, 1547.5866262722068, 1675.8997932658692, 1954.8499727883463, 1337.2132777423299, 1801.798212458211, 1926.6875481094337, 1742.4395572818098, 1953.1305864570963, 1813.9087658610927, 2015.572437352726, 1784.7938448390107, 1510.50387303797, 1631.0832227655999, 1570.070681811539, 1747.8947444557575, 1679.3983547699522, 1620.339994320469, 1595.0575588738984, 1379.054735019245, 1678.9156284304877, 1555.2534230009912, 1622.5555742321026, 1651.4018487551712, 1542.8997583732314, 1614.4317060767942, 1905.8639178621213, 1843.1352144831146, 1692.7141163763083, 1844.4964139399985, 1469.0724904856495, 1757.4680474051809, 1587.7163799566515, 1406.8219893614541, 1668.4816320749585, 1812.7002418132977, 1901.3241511394206, 1452.7438034390166, 1934.4809238038217, 1445.7062175736457, 1468.775122809962, 1603.198452086016, 1481.2912148938722, 1401.9412355316117, 1262.6848315560117, 1458.0581211926253, 1428.6434337063017, 1570.157724225395, 1646.8401343786743, 1908.0800064537427, 1255.7478118879228, 1819.6425492119183, 1922.5069469726493, 1789.5256591694683, 1745.74164908471], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [394.0147794915534, 265.8012206477068, 524.9109125120758, 514.3437835705698, 119.94562641636139, 405.9256976654255, 580.7817744178884, 289.7863788418258, 327.66461174806375, 501.9587226592792, 699.7304521619884, 389.32309668648765, 499.74069713728665, 367.61459642047794, 622.9050070118368, 544.9978952909332, 545.1356614900891, 446.85892892751633, 653.8006644143925, 343.4036663087354, 522.3264935896425, 485.5295322686956, 520.726720229568, 447.5356408450753, 413.1878568009842, 415.2915701728469, 656.9238527048371, 242.6471939373188, 543.1995249347457, 649.2989571450365, 485.90978524923287, 433.4727893697481, 477.9251010560891, 442.04334966694466, 435.35342846284453, 438.4101871973113, 354.6743132532281, 420.2407610067454, 617.1237115123015, 304.8018619467813, 610.1751469162415, 572.117397942761, 531.8499793880942, 636.9989423784859, 577.8565401401974, 194.49030995818816, 602.5560809635953, 551.001673092807, 685.3603257894907, 290.453943110272, 182.50797390255948, 534.107106044032, 608.9322389746319, 249.07746574269981, 350.19506576187723, 532.1753490313114, 644.6353978579369, 614.0856916861727, 560.7031243114066, 543.6490208726273, 442.8029906940694, 663.2845870313247, 641.8007737290828, 490.97064711250624, 472.58301477927665, 327.0866170125645, 386.36566609718204, 647.5559511041787, 364.2170317484451, 328.60159844274216, 465.557824388286, 565.4928629734727, 400.85769180799906, 609.6475452699403, 418.31194125154326, 463.6133855514327, 593.1621931712223, 482.3137568869074, 556.5589703512179, 714.4662788023263, 695.8294025119808, 226.04336429918123, 721.0956292090109, 328.2026859389326, 498.66457927649213, 723.8599273628562, 406.88294260202326, 466.02916508250115, 515.0600320166081, 552.7800482772357, 534.187614244948, 611.2063891211762, 574.1058829946436, 464.57848866850765, 611.2306801317012, 654.3743249930369, 655.8115452569799, 484.7156707164783, 431.61436639896687, 788.7222573317233, 389.8185065217855, 791.1480846905233, 566.0430127595893, 196.27322097230146, 650.6879874359157, 713.9193598920745, 644.97436759182, 405.9229952389032, 680.7029071379618, 606.2446287991443, 519.1413833124938, 432.858888597752, 576.652252345987, 777.1139065435048, 617.9263956867127, 614.0234279150727, 446.03768912582575, 583.9793469532071, 736.7930614603898, 773.1343146177526, 712.6364921802959, 549.0591950942451, 508.60412772812737, 631.7425481053924, 547.3550943690396, 654.2712969906756, 567.9887236853671, 628.7386198312603, 639.397795834693, 533.801413794867, 778.9316723628517, 675.6612744934093, 608.9568330529356, 306.72141016165875, 670.5232445300089, 637.6930521134051, 587.6208389392459, 497.99522642577256, 543.5216921522061, 539.2466513214997, 508.9209667203785, 690.4268574080877, 622.686400842505, 743.06276069258, 642.2745967702805, 598.4348091647257, 505.2566352138205, 565.7824903592676, 713.3642680656901, 681.9410420004303, 612.3392865160152, 302.1868322856625, 455.92098992239823, 793.6129413775842, 594.6932562347595, 709.6337181922152, 569.4085201967437, 515.9195538676656, 632.2582088323251, 535.5265973652253, 621.6248843329206, 749.0393722064746, 690.7598357898663, 710.957609682954, 660.7289977457602, 513.2284224516644, 569.3619240390759, 211.20150808317072, 646.6011619933023, 369.1443998568417, 525.3885814356843, 718.9095961530587, 614.1089446645411, 566.2615418164545, 552.8021481653775, 705.1087928309, 434.8768412863436, 629.9066263494713, 629.3714404029334, 548.2447366953587, 538.265980270666, 630.2194687121284, 564.8566203198567, 580.0489098588946, 498.20141618199824, 614.4600296941226, 869.966235065884, 679.8925426550985, 584.3851615979878, 375.2253931720227, 515.803160728436, 399.7457192031149, 740.7204747186443, 671.2884957891706, 755.8805048360591, 332.2315081999482, 613.0784228511926, 644.354934274802, 586.3335361050748, 653.7685920004388], "policy_predator_policy_reward": [570.1107884544155, 319.9758416741734, 2.8216650697625005, 483.73692653544185, 764.1157359067766, 592.7676281036904, 583.0048324199144, 525.6095390709115, 666.6271463079402, 280.8162554986454, 496.87202871963797, 558.8876363233567, 572.871789780044, 471.3288386164071, 363.88546472846207, 348.54023611940454, 430.02431518230117, 508.76486587168034, 594.2168249667582, 408.73777131387305, 480.1697965384279, 454.86849783160295, 448.5543051564359, 499.61514686860016, 576.539144724242, 527.4381765366409, 583.5817535613004, 452.8399502216411, 313.57273158581165, 277.6416011150507, 463.66469723019236, 489.8995918693955, 421.58768628099705, 258.52271006421864, 615.2234949583993, 621.3770835126088, 402.7527048032558, 536.3682901552604, 501.1647775879083, 647.134195745149, 338.7599204790262, 414.9231193771388, 389.9955189401214, 394.13990783996877, 613.4324118130777, 594.9005053380369, 296.5477649981731, 361.4823047406484, 497.2806177708267, 509.56962203819904, 670.88116572107, 359.06290305259324, 545.3939049965513, 568.2993084488802, 472.2438078232113, 554.0574314861425, 354.3825467640456, 345.9156124074164, 371.07324282179934, 395.6279316190216, 384.3137093407851, 432.50630704784766, 286.00882489771686, 248.57999849478, 567.5933447240644, 491.4210347256305, 479.27629955599457, 491.85522351916967, 504.1647399047767, 465.12150227534687, 396.45012513934387, 368.8299664612184, 485.6635382278351, 539.5896077504444, 538.8470772182039, 559.4009074833749, 195.97740429785077, 392.05970275971674, -45.37674958659326, 51.976686507086725, 606.017199540605, 509.7727541034386, 257.848806669779, 294.0533086094675, 418.9347828799433, 262.7033308259501, 298.88615907528384, 404.88588237723474, 272.53587557757015, 223.10378366003397, 238.18983116004992, 112.99645390337749, 290.58777105391516, 218.3144835551411, 249.60833703888486, 160.68645110225086, 400.0627862214919, 414.2599705934, 36.667695110431325, 80.20895890120904, 285.49483107199444, 335.3367901739082, 581.761730841487, 582.6095835360547, 186.66853718885673, 191.16367276496848, 592.6512011147793, 309.58202251159514, 310.8873288113018, 216.07390111268415, 567.6513633228358, 495.9208021196435, 347.8899416980413, 83.13774425147884, 189.43244373790245, 89.1216056982809, 343.99508086158, 257.0711058249878, 87.22158747033008, -27.07828173693531, 263.68901029451854, 222.51004688669818, 289.4190672175043, 249.63261171892535, 230.13111280554855, 188.58249015520505, 206.65573721957986, 191.67447813769297, 100.58112881997017, 105.27439656971495, 140.8674657183008, 83.45521585592522, 204.64542556582188, 434.92975422057657, 190.68335512931156, 123.65592245937923, 366.4585102506107, 199.32727313954382, 324.30520491547287, 135.82620998405477, 238.10668387704186, 176.97719807128738, 287.79266321304624, 252.3220931139902, 265.0073740682382, 337.41843447986867, 345.8556954708102, 275.81929533241214, 240.00630946513178, 209.18479440874484, 220.72711132072334, 333.8192603632483, 268.0759534444399, 239.85816266075517, 159.95056878280823, 123.43883674686901, 172.53462271649087, 148.9592925805527, 201.4237116778541, 299.2731141995525, 220.93371860897992, 221.10226666492036, 292.8234654716484, 206.78324019495378, 84.82869937285386, 193.95768386874016, 576.2263810954884, 577.6911105860836, 253.5718586102617, 176.3887971132391, 43.691584869197634, 180.78536035202214, 200.30847697686605, 222.5194886281534, 101.9794266181705, 121.40084727942383, 204.9556837390505, 132.20208415674665, 69.49741866740241, 15.571235790317143, 178.71643392600515, 110.85623828382612, 122.1906379963498, 161.54726553120122, 325.7768064526662, 131.71947189661034, 79.2593305662116, 17.722026091484025, 503.3699955398829, 445.09945614384935, 148.49229876284676, 191.7066331935251, 192.27352031352777, 215.360058390576, 344.94794010003596, 489.4469938366054, 302.0712971920352, 230.0210048514409, 285.3304158899379, 220.30910508925496]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.5209358486562805, "mean_inference_ms": 6.634213550191211, "mean_action_processing_ms": 1.078092833096081, "mean_env_wait_ms": 0.9280137180480749, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00603032112121582, "StateBufferConnector_ms": 0.003452777862548828, "ViewRequirementAgentConnector_ms": 0.17006516456604004}, "num_episodes": 23, "episode_return_max": 2144.813213891471, "episode_return_min": 1255.7478118879228, "episode_return_mean": 1740.6998028102541, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 297.63410983133815, "num_env_steps_trained_throughput_per_sec": 297.63410983133815, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 97852.716, "restore_workers_time_ms": 0.021, "training_step_time_ms": 97852.65, "sample_time_ms": 3482.085, "learn_time_ms": 94335.592, "learn_throughput": 42.402, "synch_weights_time_ms": 32.97}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "479e5_00000", "date": "2024-08-16_12-21-52", "timestamp": 1723791112, "time_this_iter_s": 13.445914030075073, "time_total_s": 3303.1234517097473, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78b9c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3303.1234517097473, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 40.97777777777779, "ram_util_percent": 74.92777777777779}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3024323646984404, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.445571898909472, "policy_loss": -0.002701164473084703, "vf_loss": 9.446570101743022, "vf_explained_var": -0.07734081401396051, "kl": 0.015137450502738249, "entropy": 1.1994741164187275, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.656737301628741, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.746177137970294, "policy_loss": -0.002606482470097641, "vf_loss": 9.748426678571752, "vf_explained_var": -0.0481527498790196, "kl": 0.0063454667220178285, "entropy": 0.6263325084454168, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 2070.2245467921443, "episode_reward_min": 1255.7478118879228, "episode_reward_mean": 1717.8181410439647, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 182.50797390255948, "predator_policy": -45.37674958659326}, "policy_reward_max": {"prey_policy": 869.966235065884, "predator_policy": 670.88116572107}, "policy_reward_mean": {"prey_policy": 574.5840111108538, "predator_policy": 284.32505941112885}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1714.0360692184909, 2070.2245467921443, 1935.9755847151662, 1952.98434854667, 1980.6797672494993, 1811.587823795224, 1982.6645087087875, 1746.5591487202528, 1971.7029181627609, 1908.6716541025419, 1959.0192487155712, 1871.053319624856, 1922.9075941140263, 1667.360244234089, 1858.6840112415362, 2005.0531402765205, 1662.1048723713127, 1796.3307789623195, 2035.7583830562196, 1980.1733115045558, 1663.5130571156983, 1277.6251860740372, 2037.662720455204, 1601.2004304271888, 1904.1626203452436, 1576.6841491370408, 1563.4797395314472, 1496.580288429551, 1547.5866262722068, 1675.8997932658692, 1954.8499727883463, 1337.2132777423299, 1801.798212458211, 1926.6875481094337, 1742.4395572818098, 1953.1305864570963, 1813.9087658610927, 2015.572437352726, 1784.7938448390107, 1510.50387303797, 1631.0832227655999, 1570.070681811539, 1747.8947444557575, 1679.3983547699522, 1620.339994320469, 1595.0575588738984, 1379.054735019245, 1678.9156284304877, 1555.2534230009912, 1622.5555742321026, 1651.4018487551712, 1542.8997583732314, 1614.4317060767942, 1905.8639178621213, 1843.1352144831146, 1692.7141163763083, 1844.4964139399985, 1469.0724904856495, 1757.4680474051809, 1587.7163799566515, 1406.8219893614541, 1668.4816320749585, 1812.7002418132977, 1901.3241511394206, 1452.7438034390166, 1934.4809238038217, 1445.7062175736457, 1468.775122809962, 1603.198452086016, 1481.2912148938722, 1401.9412355316117, 1262.6848315560117, 1458.0581211926253, 1428.6434337063017, 1570.157724225395, 1646.8401343786743, 1908.0800064537427, 1255.7478118879228, 1819.6425492119183, 1922.5069469726493, 1789.5256591694683, 1745.74164908471, 1634.640394816767, 1597.863968511613, 1618.884871540745, 1820.0636334190929, 1778.5669471193817, 1697.5344957978764, 1869.6274826172255, 2020.8151200115462, 1988.7684677062477, 1714.9705550445149, 1963.8918290888803, 1764.1026162514852, 1831.0496973606146, 1693.0244057943005, 1793.7039703051344, 1565.5135241234955, 1445.9144579459605, 1590.1360420867989], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [354.6743132532281, 420.2407610067454, 617.1237115123015, 304.8018619467813, 610.1751469162415, 572.117397942761, 531.8499793880942, 636.9989423784859, 577.8565401401974, 194.49030995818816, 602.5560809635953, 551.001673092807, 685.3603257894907, 290.453943110272, 182.50797390255948, 534.107106044032, 608.9322389746319, 249.07746574269981, 350.19506576187723, 532.1753490313114, 644.6353978579369, 614.0856916861727, 560.7031243114066, 543.6490208726273, 442.8029906940694, 663.2845870313247, 641.8007737290828, 490.97064711250624, 472.58301477927665, 327.0866170125645, 386.36566609718204, 647.5559511041787, 364.2170317484451, 328.60159844274216, 465.557824388286, 565.4928629734727, 400.85769180799906, 609.6475452699403, 418.31194125154326, 463.6133855514327, 593.1621931712223, 482.3137568869074, 556.5589703512179, 714.4662788023263, 695.8294025119808, 226.04336429918123, 721.0956292090109, 328.2026859389326, 498.66457927649213, 723.8599273628562, 406.88294260202326, 466.02916508250115, 515.0600320166081, 552.7800482772357, 534.187614244948, 611.2063891211762, 574.1058829946436, 464.57848866850765, 611.2306801317012, 654.3743249930369, 655.8115452569799, 484.7156707164783, 431.61436639896687, 788.7222573317233, 389.8185065217855, 791.1480846905233, 566.0430127595893, 196.27322097230146, 650.6879874359157, 713.9193598920745, 644.97436759182, 405.9229952389032, 680.7029071379618, 606.2446287991443, 519.1413833124938, 432.858888597752, 576.652252345987, 777.1139065435048, 617.9263956867127, 614.0234279150727, 446.03768912582575, 583.9793469532071, 736.7930614603898, 773.1343146177526, 712.6364921802959, 549.0591950942451, 508.60412772812737, 631.7425481053924, 547.3550943690396, 654.2712969906756, 567.9887236853671, 628.7386198312603, 639.397795834693, 533.801413794867, 778.9316723628517, 675.6612744934093, 608.9568330529356, 306.72141016165875, 670.5232445300089, 637.6930521134051, 587.6208389392459, 497.99522642577256, 543.5216921522061, 539.2466513214997, 508.9209667203785, 690.4268574080877, 622.686400842505, 743.06276069258, 642.2745967702805, 598.4348091647257, 505.2566352138205, 565.7824903592676, 713.3642680656901, 681.9410420004303, 612.3392865160152, 302.1868322856625, 455.92098992239823, 793.6129413775842, 594.6932562347595, 709.6337181922152, 569.4085201967437, 515.9195538676656, 632.2582088323251, 535.5265973652253, 621.6248843329206, 749.0393722064746, 690.7598357898663, 710.957609682954, 660.7289977457602, 513.2284224516644, 569.3619240390759, 211.20150808317072, 646.6011619933023, 369.1443998568417, 525.3885814356843, 718.9095961530587, 614.1089446645411, 566.2615418164545, 552.8021481653775, 705.1087928309, 434.8768412863436, 629.9066263494713, 629.3714404029334, 548.2447366953587, 538.265980270666, 630.2194687121284, 564.8566203198567, 580.0489098588946, 498.20141618199824, 614.4600296941226, 869.966235065884, 679.8925426550985, 584.3851615979878, 375.2253931720227, 515.803160728436, 399.7457192031149, 740.7204747186443, 671.2884957891706, 755.8805048360591, 332.2315081999482, 613.0784228511926, 644.354934274802, 586.3335361050748, 653.7685920004388, 610.9882833846109, 862.5778891496558, 675.2781740447415, 609.4931641850784, 735.7106960682003, 647.4051594817752, 594.1123991060873, 560.5017909499413, 724.4948085312751, 666.7406852810731, 585.0898073990345, 593.1744745499391, 682.9005882821162, 710.1392029132539, 788.4320454629934, 498.20928209973283, 693.9591124199433, 534.1505264415497, 601.2080262196657, 731.8786139492814, 769.929681637718, 492.31315216786624, 716.9240286217723, 462.88930934644395, 598.5573572744972, 756.4800082630123, 554.0689084095558, 589.8726966162175, 854.1679148604761, 666.2295944110477, 486.61332891459796, 572.2009683890516, 605.9379096294715, 630.2201392797571, 675.8439009315244, 574.2247022609267], "policy_predator_policy_reward": [402.7527048032558, 536.3682901552604, 501.1647775879083, 647.134195745149, 338.7599204790262, 414.9231193771388, 389.9955189401214, 394.13990783996877, 613.4324118130777, 594.9005053380369, 296.5477649981731, 361.4823047406484, 497.2806177708267, 509.56962203819904, 670.88116572107, 359.06290305259324, 545.3939049965513, 568.2993084488802, 472.2438078232113, 554.0574314861425, 354.3825467640456, 345.9156124074164, 371.07324282179934, 395.6279316190216, 384.3137093407851, 432.50630704784766, 286.00882489771686, 248.57999849478, 567.5933447240644, 491.4210347256305, 479.27629955599457, 491.85522351916967, 504.1647399047767, 465.12150227534687, 396.45012513934387, 368.8299664612184, 485.6635382278351, 539.5896077504444, 538.8470772182039, 559.4009074833749, 195.97740429785077, 392.05970275971674, -45.37674958659326, 51.976686507086725, 606.017199540605, 509.7727541034386, 257.848806669779, 294.0533086094675, 418.9347828799433, 262.7033308259501, 298.88615907528384, 404.88588237723474, 272.53587557757015, 223.10378366003397, 238.18983116004992, 112.99645390337749, 290.58777105391516, 218.3144835551411, 249.60833703888486, 160.68645110225086, 400.0627862214919, 414.2599705934, 36.667695110431325, 80.20895890120904, 285.49483107199444, 335.3367901739082, 581.761730841487, 582.6095835360547, 186.66853718885673, 191.16367276496848, 592.6512011147793, 309.58202251159514, 310.8873288113018, 216.07390111268415, 567.6513633228358, 495.9208021196435, 347.8899416980413, 83.13774425147884, 189.43244373790245, 89.1216056982809, 343.99508086158, 257.0711058249878, 87.22158747033008, -27.07828173693531, 263.68901029451854, 222.51004688669818, 289.4190672175043, 249.63261171892535, 230.13111280554855, 188.58249015520505, 206.65573721957986, 191.67447813769297, 100.58112881997017, 105.27439656971495, 140.8674657183008, 83.45521585592522, 204.64542556582188, 434.92975422057657, 190.68335512931156, 123.65592245937923, 366.4585102506107, 199.32727313954382, 324.30520491547287, 135.82620998405477, 238.10668387704186, 176.97719807128738, 287.79266321304624, 252.3220931139902, 265.0073740682382, 337.41843447986867, 345.8556954708102, 275.81929533241214, 240.00630946513178, 209.18479440874484, 220.72711132072334, 333.8192603632483, 268.0759534444399, 239.85816266075517, 159.95056878280823, 123.43883674686901, 172.53462271649087, 148.9592925805527, 201.4237116778541, 299.2731141995525, 220.93371860897992, 221.10226666492036, 292.8234654716484, 206.78324019495378, 84.82869937285386, 193.95768386874016, 576.2263810954884, 577.6911105860836, 253.5718586102617, 176.3887971132391, 43.691584869197634, 180.78536035202214, 200.30847697686605, 222.5194886281534, 101.9794266181705, 121.40084727942383, 204.9556837390505, 132.20208415674665, 69.49741866740241, 15.571235790317143, 178.71643392600515, 110.85623828382612, 122.1906379963498, 161.54726553120122, 325.7768064526662, 131.71947189661034, 79.2593305662116, 17.722026091484025, 503.3699955398829, 445.09945614384935, 148.49229876284676, 191.7066331935251, 192.27352031352777, 215.360058390576, 344.94794010003596, 489.4469938366054, 302.0712971920352, 230.0210048514409, 285.3304158899379, 220.30910508925496, 139.9829505938467, 21.091271688651545, 128.13664636392963, 184.95598391786305, 148.85418155428636, 86.91483443648346, 376.3096437808841, 289.1397995821814, 95.3791676566761, 291.9522856503569, 307.2886751916282, 211.98153865727343, 283.84795195857197, 192.73973946328502, 327.3857783099835, 406.78801413883843, 386.69529912868006, 373.9635297160739, 202.16351365126934, 179.72040122430005, 350.24124442377564, 351.40775085952123, 241.37098045024874, 342.91829783302245, 158.8010121124153, 317.2113197106912, 367.1281819243739, 181.95461884415505, 152.2209070532889, 121.08555398032402, 293.57038305844065, 213.12884376140417, 102.05495125400661, 107.70145778272506, 222.62817714450216, 117.43926174984865]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.5003665942111284, "mean_inference_ms": 6.582873638648989, "mean_action_processing_ms": 1.0688811409044061, "mean_env_wait_ms": 0.920160606036816, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014306306838989258, "StateBufferConnector_ms": 0.003453373908996582, "ViewRequirementAgentConnector_ms": 0.15871286392211914}, "num_episodes": 18, "episode_return_max": 2070.2245467921443, "episode_return_min": 1255.7478118879228, "episode_return_mean": 1717.8181410439647, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 322.0581355728854, "num_env_steps_trained_throughput_per_sec": 322.0581355728854, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 96088.639, "restore_workers_time_ms": 0.02, "training_step_time_ms": 96088.578, "sample_time_ms": 3015.074, "learn_time_ms": 93048.096, "learn_throughput": 42.989, "synch_weights_time_ms": 24.273}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "479e5_00000", "date": "2024-08-16_12-22-04", "timestamp": 1723791124, "time_this_iter_s": 12.424737930297852, "time_total_s": 3315.548189640045, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a789be50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3315.548189640045, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 39.53333333333333, "ram_util_percent": 74.8388888888889}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.545238873504457, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.339806022341289, "policy_loss": -0.005003924445106239, "vf_loss": 9.343689165165815, "vf_explained_var": -0.04193768028229002, "kl": 0.009962479785595954, "entropy": 1.1832665379085239, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6905719126343097, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.723300798103292, "policy_loss": -0.002240893823247423, "vf_loss": 9.725204904748018, "vf_explained_var": -0.07201428593151153, "kl": 0.005987643791800726, "entropy": 0.5561115872765344, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 2037.662720455204, "episode_reward_min": 1255.7478118879228, "episode_reward_mean": 1697.2520239894304, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 196.27322097230146, "predator_policy": -45.37674958659326}, "policy_reward_max": {"prey_policy": 869.966235065884, "predator_policy": 606.017199540605}, "policy_reward_mean": {"prey_policy": 604.2591995733528, "predator_policy": 244.3668124213626}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2035.7583830562196, 1980.1733115045558, 1663.5130571156983, 1277.6251860740372, 2037.662720455204, 1601.2004304271888, 1904.1626203452436, 1576.6841491370408, 1563.4797395314472, 1496.580288429551, 1547.5866262722068, 1675.8997932658692, 1954.8499727883463, 1337.2132777423299, 1801.798212458211, 1926.6875481094337, 1742.4395572818098, 1953.1305864570963, 1813.9087658610927, 2015.572437352726, 1784.7938448390107, 1510.50387303797, 1631.0832227655999, 1570.070681811539, 1747.8947444557575, 1679.3983547699522, 1620.339994320469, 1595.0575588738984, 1379.054735019245, 1678.9156284304877, 1555.2534230009912, 1622.5555742321026, 1651.4018487551712, 1542.8997583732314, 1614.4317060767942, 1905.8639178621213, 1843.1352144831146, 1692.7141163763083, 1844.4964139399985, 1469.0724904856495, 1757.4680474051809, 1587.7163799566515, 1406.8219893614541, 1668.4816320749585, 1812.7002418132977, 1901.3241511394206, 1452.7438034390166, 1934.4809238038217, 1445.7062175736457, 1468.775122809962, 1603.198452086016, 1481.2912148938722, 1401.9412355316117, 1262.6848315560117, 1458.0581211926253, 1428.6434337063017, 1570.157724225395, 1646.8401343786743, 1908.0800064537427, 1255.7478118879228, 1819.6425492119183, 1922.5069469726493, 1789.5256591694683, 1745.74164908471, 1634.640394816767, 1597.863968511613, 1618.884871540745, 1820.0636334190929, 1778.5669471193817, 1697.5344957978764, 1869.6274826172255, 2020.8151200115462, 1988.7684677062477, 1714.9705550445149, 1963.8918290888803, 1764.1026162514852, 1831.0496973606146, 1693.0244057943005, 1793.7039703051344, 1565.5135241234955, 1445.9144579459605, 1590.1360420867989, 1829.9219997234181, 1872.8393142122086, 1868.0474707035278, 1763.8957266945815, 1627.438899724647, 1969.959218600813, 1930.9466379384908, 1661.2399285626748, 1841.3615332832615, 1816.324150959565, 1597.360197743103, 1869.541756213721, 1785.6624245116968, 1881.6563651416532, 1753.4560203027588, 1289.9309644013288, 1808.657442812583, 1592.7478225682867], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [400.85769180799906, 609.6475452699403, 418.31194125154326, 463.6133855514327, 593.1621931712223, 482.3137568869074, 556.5589703512179, 714.4662788023263, 695.8294025119808, 226.04336429918123, 721.0956292090109, 328.2026859389326, 498.66457927649213, 723.8599273628562, 406.88294260202326, 466.02916508250115, 515.0600320166081, 552.7800482772357, 534.187614244948, 611.2063891211762, 574.1058829946436, 464.57848866850765, 611.2306801317012, 654.3743249930369, 655.8115452569799, 484.7156707164783, 431.61436639896687, 788.7222573317233, 389.8185065217855, 791.1480846905233, 566.0430127595893, 196.27322097230146, 650.6879874359157, 713.9193598920745, 644.97436759182, 405.9229952389032, 680.7029071379618, 606.2446287991443, 519.1413833124938, 432.858888597752, 576.652252345987, 777.1139065435048, 617.9263956867127, 614.0234279150727, 446.03768912582575, 583.9793469532071, 736.7930614603898, 773.1343146177526, 712.6364921802959, 549.0591950942451, 508.60412772812737, 631.7425481053924, 547.3550943690396, 654.2712969906756, 567.9887236853671, 628.7386198312603, 639.397795834693, 533.801413794867, 778.9316723628517, 675.6612744934093, 608.9568330529356, 306.72141016165875, 670.5232445300089, 637.6930521134051, 587.6208389392459, 497.99522642577256, 543.5216921522061, 539.2466513214997, 508.9209667203785, 690.4268574080877, 622.686400842505, 743.06276069258, 642.2745967702805, 598.4348091647257, 505.2566352138205, 565.7824903592676, 713.3642680656901, 681.9410420004303, 612.3392865160152, 302.1868322856625, 455.92098992239823, 793.6129413775842, 594.6932562347595, 709.6337181922152, 569.4085201967437, 515.9195538676656, 632.2582088323251, 535.5265973652253, 621.6248843329206, 749.0393722064746, 690.7598357898663, 710.957609682954, 660.7289977457602, 513.2284224516644, 569.3619240390759, 211.20150808317072, 646.6011619933023, 369.1443998568417, 525.3885814356843, 718.9095961530587, 614.1089446645411, 566.2615418164545, 552.8021481653775, 705.1087928309, 434.8768412863436, 629.9066263494713, 629.3714404029334, 548.2447366953587, 538.265980270666, 630.2194687121284, 564.8566203198567, 580.0489098588946, 498.20141618199824, 614.4600296941226, 869.966235065884, 679.8925426550985, 584.3851615979878, 375.2253931720227, 515.803160728436, 399.7457192031149, 740.7204747186443, 671.2884957891706, 755.8805048360591, 332.2315081999482, 613.0784228511926, 644.354934274802, 586.3335361050748, 653.7685920004388, 610.9882833846109, 862.5778891496558, 675.2781740447415, 609.4931641850784, 735.7106960682003, 647.4051594817752, 594.1123991060873, 560.5017909499413, 724.4948085312751, 666.7406852810731, 585.0898073990345, 593.1744745499391, 682.9005882821162, 710.1392029132539, 788.4320454629934, 498.20928209973283, 693.9591124199433, 534.1505264415497, 601.2080262196657, 731.8786139492814, 769.929681637718, 492.31315216786624, 716.9240286217723, 462.88930934644395, 598.5573572744972, 756.4800082630123, 554.0689084095558, 589.8726966162175, 854.1679148604761, 666.2295944110477, 486.61332891459796, 572.2009683890516, 605.9379096294715, 630.2201392797571, 675.8439009315244, 574.2247022609267, 554.1315631299361, 738.2264766926378, 744.2917494407844, 657.4327196435538, 528.4103919577408, 631.599834963037, 684.6068043076042, 679.3596997167114, 673.2550665634272, 578.2594825729923, 599.3821703689123, 749.627716566384, 547.980605520183, 734.187106636203, 730.8242734443967, 585.5908523563127, 690.377266576388, 424.1336402197952, 728.9411283251345, 750.1861244568353, 547.1213863454291, 747.3283754392695, 775.4195184410552, 611.715053495524, 677.4554855032641, 654.9644671935744, 526.832605975944, 686.6831586352538, 760.3934895329612, 747.8123430674132, 468.12400451361515, 628.2284769001513, 576.027870546267, 597.3192807661094, 716.2609511775355, 768.6355382050373], "policy_predator_policy_reward": [485.6635382278351, 539.5896077504444, 538.8470772182039, 559.4009074833749, 195.97740429785077, 392.05970275971674, -45.37674958659326, 51.976686507086725, 606.017199540605, 509.7727541034386, 257.848806669779, 294.0533086094675, 418.9347828799433, 262.7033308259501, 298.88615907528384, 404.88588237723474, 272.53587557757015, 223.10378366003397, 238.18983116004992, 112.99645390337749, 290.58777105391516, 218.3144835551411, 249.60833703888486, 160.68645110225086, 400.0627862214919, 414.2599705934, 36.667695110431325, 80.20895890120904, 285.49483107199444, 335.3367901739082, 581.761730841487, 582.6095835360547, 186.66853718885673, 191.16367276496848, 592.6512011147793, 309.58202251159514, 310.8873288113018, 216.07390111268415, 567.6513633228358, 495.9208021196435, 347.8899416980413, 83.13774425147884, 189.43244373790245, 89.1216056982809, 343.99508086158, 257.0711058249878, 87.22158747033008, -27.07828173693531, 263.68901029451854, 222.51004688669818, 289.4190672175043, 249.63261171892535, 230.13111280554855, 188.58249015520505, 206.65573721957986, 191.67447813769297, 100.58112881997017, 105.27439656971495, 140.8674657183008, 83.45521585592522, 204.64542556582188, 434.92975422057657, 190.68335512931156, 123.65592245937923, 366.4585102506107, 199.32727313954382, 324.30520491547287, 135.82620998405477, 238.10668387704186, 176.97719807128738, 287.79266321304624, 252.3220931139902, 265.0073740682382, 337.41843447986867, 345.8556954708102, 275.81929533241214, 240.00630946513178, 209.18479440874484, 220.72711132072334, 333.8192603632483, 268.0759534444399, 239.85816266075517, 159.95056878280823, 123.43883674686901, 172.53462271649087, 148.9592925805527, 201.4237116778541, 299.2731141995525, 220.93371860897992, 221.10226666492036, 292.8234654716484, 206.78324019495378, 84.82869937285386, 193.95768386874016, 576.2263810954884, 577.6911105860836, 253.5718586102617, 176.3887971132391, 43.691584869197634, 180.78536035202214, 200.30847697686605, 222.5194886281534, 101.9794266181705, 121.40084727942383, 204.9556837390505, 132.20208415674665, 69.49741866740241, 15.571235790317143, 178.71643392600515, 110.85623828382612, 122.1906379963498, 161.54726553120122, 325.7768064526662, 131.71947189661034, 79.2593305662116, 17.722026091484025, 503.3699955398829, 445.09945614384935, 148.49229876284676, 191.7066331935251, 192.27352031352777, 215.360058390576, 344.94794010003596, 489.4469938366054, 302.0712971920352, 230.0210048514409, 285.3304158899379, 220.30910508925496, 139.9829505938467, 21.091271688651545, 128.13664636392963, 184.95598391786305, 148.85418155428636, 86.91483443648346, 376.3096437808841, 289.1397995821814, 95.3791676566761, 291.9522856503569, 307.2886751916282, 211.98153865727343, 283.84795195857197, 192.73973946328502, 327.3857783099835, 406.78801413883843, 386.69529912868006, 373.9635297160739, 202.16351365126934, 179.72040122430005, 350.24124442377564, 351.40775085952123, 241.37098045024874, 342.91829783302245, 158.8010121124153, 317.2113197106912, 367.1281819243739, 181.95461884415505, 152.2209070532889, 121.08555398032402, 293.57038305844065, 213.12884376140417, 102.05495125400661, 107.70145778272506, 222.62817714450216, 117.43926174984865, 300.5204178020564, 237.04354209879074, 219.40412746351, 251.71071766435924, 373.68772655634336, 334.3495172264079, 276.85450465606635, 123.0747180141951, 147.05475420995293, 228.86959637827292, 298.65162587655703, 322.29770578895864, 232.461951877576, 416.31697390453036, 101.97753690699864, 242.84726585496662, 326.7845168551475, 400.06610963193225, 241.9847545288731, 95.21214364872077, 192.05271742732242, 110.85771853108079, 297.5434901056667, 184.86369417147606, 208.8874838390303, 244.35498797582758, 338.7913711766028, 329.3492293538538, 114.10095532807424, 131.1492323743101, 148.73351495140335, 44.84496803615894, 333.1883247683884, 302.121966731816, 44.61585801809636, 63.235475167618766]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.48055969462875, "mean_inference_ms": 6.532991555125963, "mean_action_processing_ms": 1.059994998554376, "mean_env_wait_ms": 0.9125220943541846, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014762282371520996, "StateBufferConnector_ms": 0.008469462394714355, "ViewRequirementAgentConnector_ms": 0.15211951732635498}, "num_episodes": 18, "episode_return_max": 2037.662720455204, "episode_return_min": 1255.7478118879228, "episode_return_mean": 1697.2520239894304, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 324.0785943348731, "num_env_steps_trained_throughput_per_sec": 324.0785943348731, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 12650.788, "restore_workers_time_ms": 0.018, "training_step_time_ms": 12650.733, "sample_time_ms": 2097.774, "learn_time_ms": 10530.815, "learn_throughput": 379.838, "synch_weights_time_ms": 21.008}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "479e5_00000", "date": "2024-08-16_12-22-17", "timestamp": 1723791137, "time_this_iter_s": 12.34639310836792, "time_total_s": 3327.894582748413, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78b9d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3327.894582748413, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 40.194117647058825, "ram_util_percent": 74.07058823529411}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.72993517653652, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.461288539947025, "policy_loss": -0.0064443398180797145, "vf_loss": 9.466350821338633, "vf_explained_var": -0.014847229050580786, "kl": 0.012285094219473576, "entropy": 1.1806009966229636, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4749570353478982, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.825207189529662, "policy_loss": -0.002519776573079446, "vf_loss": 9.827400312978755, "vf_explained_var": -0.06858708981483702, "kl": 0.005807157809995838, "entropy": 0.5908942706843533, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 2020.8151200115462, "episode_reward_min": 1255.7478118879228, "episode_reward_mean": 1709.907183639962, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 211.20150808317072, "predator_policy": -27.07828173693531}, "policy_reward_max": {"prey_policy": 869.966235065884, "predator_policy": 577.6911105860836}, "policy_reward_mean": {"prey_policy": 635.7008166940832, "predator_policy": 219.252775125898}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1631.0832227655999, 1570.070681811539, 1747.8947444557575, 1679.3983547699522, 1620.339994320469, 1595.0575588738984, 1379.054735019245, 1678.9156284304877, 1555.2534230009912, 1622.5555742321026, 1651.4018487551712, 1542.8997583732314, 1614.4317060767942, 1905.8639178621213, 1843.1352144831146, 1692.7141163763083, 1844.4964139399985, 1469.0724904856495, 1757.4680474051809, 1587.7163799566515, 1406.8219893614541, 1668.4816320749585, 1812.7002418132977, 1901.3241511394206, 1452.7438034390166, 1934.4809238038217, 1445.7062175736457, 1468.775122809962, 1603.198452086016, 1481.2912148938722, 1401.9412355316117, 1262.6848315560117, 1458.0581211926253, 1428.6434337063017, 1570.157724225395, 1646.8401343786743, 1908.0800064537427, 1255.7478118879228, 1819.6425492119183, 1922.5069469726493, 1789.5256591694683, 1745.74164908471, 1634.640394816767, 1597.863968511613, 1618.884871540745, 1820.0636334190929, 1778.5669471193817, 1697.5344957978764, 1869.6274826172255, 2020.8151200115462, 1988.7684677062477, 1714.9705550445149, 1963.8918290888803, 1764.1026162514852, 1831.0496973606146, 1693.0244057943005, 1793.7039703051344, 1565.5135241234955, 1445.9144579459605, 1590.1360420867989, 1829.9219997234181, 1872.8393142122086, 1868.0474707035278, 1763.8957266945815, 1627.438899724647, 1969.959218600813, 1930.9466379384908, 1661.2399285626748, 1841.3615332832615, 1816.324150959565, 1597.360197743103, 1869.541756213721, 1785.6624245116968, 1881.6563651416532, 1753.4560203027588, 1289.9309644013288, 1808.657442812583, 1592.7478225682867, 1734.672995126407, 1924.7378391466082, 1790.3225005206577, 1853.0234365192755, 1702.4311046346397, 1743.6816379302463, 1772.417614399041, 1626.1369965382753, 1737.4301464071677, 1729.0950226379382, 1753.5021640459092, 1986.2786006740541, 1790.578485390099, 1791.2188655331818, 1808.446122672427, 1902.222488811392, 1768.9926853988422, 1792.2567656694725, 1807.5646855761222, 1761.4933923832407, 1976.0641518016334, 1714.1726447788355], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [446.03768912582575, 583.9793469532071, 736.7930614603898, 773.1343146177526, 712.6364921802959, 549.0591950942451, 508.60412772812737, 631.7425481053924, 547.3550943690396, 654.2712969906756, 567.9887236853671, 628.7386198312603, 639.397795834693, 533.801413794867, 778.9316723628517, 675.6612744934093, 608.9568330529356, 306.72141016165875, 670.5232445300089, 637.6930521134051, 587.6208389392459, 497.99522642577256, 543.5216921522061, 539.2466513214997, 508.9209667203785, 690.4268574080877, 622.686400842505, 743.06276069258, 642.2745967702805, 598.4348091647257, 505.2566352138205, 565.7824903592676, 713.3642680656901, 681.9410420004303, 612.3392865160152, 302.1868322856625, 455.92098992239823, 793.6129413775842, 594.6932562347595, 709.6337181922152, 569.4085201967437, 515.9195538676656, 632.2582088323251, 535.5265973652253, 621.6248843329206, 749.0393722064746, 690.7598357898663, 710.957609682954, 660.7289977457602, 513.2284224516644, 569.3619240390759, 211.20150808317072, 646.6011619933023, 369.1443998568417, 525.3885814356843, 718.9095961530587, 614.1089446645411, 566.2615418164545, 552.8021481653775, 705.1087928309, 434.8768412863436, 629.9066263494713, 629.3714404029334, 548.2447366953587, 538.265980270666, 630.2194687121284, 564.8566203198567, 580.0489098588946, 498.20141618199824, 614.4600296941226, 869.966235065884, 679.8925426550985, 584.3851615979878, 375.2253931720227, 515.803160728436, 399.7457192031149, 740.7204747186443, 671.2884957891706, 755.8805048360591, 332.2315081999482, 613.0784228511926, 644.354934274802, 586.3335361050748, 653.7685920004388, 610.9882833846109, 862.5778891496558, 675.2781740447415, 609.4931641850784, 735.7106960682003, 647.4051594817752, 594.1123991060873, 560.5017909499413, 724.4948085312751, 666.7406852810731, 585.0898073990345, 593.1744745499391, 682.9005882821162, 710.1392029132539, 788.4320454629934, 498.20928209973283, 693.9591124199433, 534.1505264415497, 601.2080262196657, 731.8786139492814, 769.929681637718, 492.31315216786624, 716.9240286217723, 462.88930934644395, 598.5573572744972, 756.4800082630123, 554.0689084095558, 589.8726966162175, 854.1679148604761, 666.2295944110477, 486.61332891459796, 572.2009683890516, 605.9379096294715, 630.2201392797571, 675.8439009315244, 574.2247022609267, 554.1315631299361, 738.2264766926378, 744.2917494407844, 657.4327196435538, 528.4103919577408, 631.599834963037, 684.6068043076042, 679.3596997167114, 673.2550665634272, 578.2594825729923, 599.3821703689123, 749.627716566384, 547.980605520183, 734.187106636203, 730.8242734443967, 585.5908523563127, 690.377266576388, 424.1336402197952, 728.9411283251345, 750.1861244568353, 547.1213863454291, 747.3283754392695, 775.4195184410552, 611.715053495524, 677.4554855032641, 654.9644671935744, 526.832605975944, 686.6831586352538, 760.3934895329612, 747.8123430674132, 468.12400451361515, 628.2284769001513, 576.027870546267, 597.3192807661094, 716.2609511775355, 768.6355382050373, 600.3635806597533, 734.8031682055223, 759.4498912535175, 685.535778520626, 717.579420817062, 735.3138546967253, 661.4929817043687, 591.7621040447284, 661.7368006208983, 680.0643808263729, 632.0735131382537, 688.4886326493744, 640.996867137397, 696.432665764351, 666.2271864725641, 778.9980314727846, 710.9296148667513, 766.6203151781887, 754.7790619804654, 540.3900414910476, 801.8828364318886, 799.7224535277304, 691.3604987365488, 733.4339467867445, 783.6309717493164, 654.577968830756, 717.9511786302689, 810.8543687151446, 622.1000159133375, 699.2647048981812, 845.6489808736635, 671.9782233222045, 735.8388410940187, 610.0838450966413, 829.3968784027039, 741.7349471116371, 598.35611299222, 735.459837293906, 546.3304208866941, 625.2613448540588, 707.8261133120595, 498.3570694616486, 744.7949532864236, 745.8171054066333], "policy_predator_policy_reward": [343.99508086158, 257.0711058249878, 87.22158747033008, -27.07828173693531, 263.68901029451854, 222.51004688669818, 289.4190672175043, 249.63261171892535, 230.13111280554855, 188.58249015520505, 206.65573721957986, 191.67447813769297, 100.58112881997017, 105.27439656971495, 140.8674657183008, 83.45521585592522, 204.64542556582188, 434.92975422057657, 190.68335512931156, 123.65592245937923, 366.4585102506107, 199.32727313954382, 324.30520491547287, 135.82620998405477, 238.10668387704186, 176.97719807128738, 287.79266321304624, 252.3220931139902, 265.0073740682382, 337.41843447986867, 345.8556954708102, 275.81929533241214, 240.00630946513178, 209.18479440874484, 220.72711132072334, 333.8192603632483, 268.0759534444399, 239.85816266075517, 159.95056878280823, 123.43883674686901, 172.53462271649087, 148.9592925805527, 201.4237116778541, 299.2731141995525, 220.93371860897992, 221.10226666492036, 292.8234654716484, 206.78324019495378, 84.82869937285386, 193.95768386874016, 576.2263810954884, 577.6911105860836, 253.5718586102617, 176.3887971132391, 43.691584869197634, 180.78536035202214, 200.30847697686605, 222.5194886281534, 101.9794266181705, 121.40084727942383, 204.9556837390505, 132.20208415674665, 69.49741866740241, 15.571235790317143, 178.71643392600515, 110.85623828382612, 122.1906379963498, 161.54726553120122, 325.7768064526662, 131.71947189661034, 79.2593305662116, 17.722026091484025, 503.3699955398829, 445.09945614384935, 148.49229876284676, 191.7066331935251, 192.27352031352777, 215.360058390576, 344.94794010003596, 489.4469938366054, 302.0712971920352, 230.0210048514409, 285.3304158899379, 220.30910508925496, 139.9829505938467, 21.091271688651545, 128.13664636392963, 184.95598391786305, 148.85418155428636, 86.91483443648346, 376.3096437808841, 289.1397995821814, 95.3791676566761, 291.9522856503569, 307.2886751916282, 211.98153865727343, 283.84795195857197, 192.73973946328502, 327.3857783099835, 406.78801413883843, 386.69529912868006, 373.9635297160739, 202.16351365126934, 179.72040122430005, 350.24124442377564, 351.40775085952123, 241.37098045024874, 342.91829783302245, 158.8010121124153, 317.2113197106912, 367.1281819243739, 181.95461884415505, 152.2209070532889, 121.08555398032402, 293.57038305844065, 213.12884376140417, 102.05495125400661, 107.70145778272506, 222.62817714450216, 117.43926174984865, 300.5204178020564, 237.04354209879074, 219.40412746351, 251.71071766435924, 373.68772655634336, 334.3495172264079, 276.85450465606635, 123.0747180141951, 147.05475420995293, 228.86959637827292, 298.65162587655703, 322.29770578895864, 232.461951877576, 416.31697390453036, 101.97753690699864, 242.84726585496662, 326.7845168551475, 400.06610963193225, 241.9847545288731, 95.21214364872077, 192.05271742732242, 110.85771853108079, 297.5434901056667, 184.86369417147606, 208.8874838390303, 244.35498797582758, 338.7913711766028, 329.3492293538538, 114.10095532807424, 131.1492323743101, 148.73351495140335, 44.84496803615894, 333.1883247683884, 302.121966731816, 44.61585801809636, 63.235475167618766, 262.1498660138417, 137.35638024728718, 222.88730863277326, 256.864860739691, 199.3203693304415, 138.1088556764308, 282.742367430101, 317.02598334007655, 176.85942701556527, 183.77049617180288, 169.49398606508677, 253.62550607753153, 230.3429250592685, 204.64515643802488, 24.563472678967536, 156.34830591396056, 138.08810052544914, 121.79211583677919, 186.37073936748175, 247.55517979894248, 132.61084392029156, 19.286030165994106, 328.6074079955366, 232.87674715522292, 193.31571954978614, 159.05382526023743, 186.1868516876373, 76.22646650013294, 214.41138079815437, 272.6700210627521, 151.6113499724819, 232.98393464304434, 117.81672798666828, 305.2532712215119, 164.74697664321235, 56.377963511921166, 288.6608316483625, 185.087903641633, 244.45185306454636, 345.44977357794164, 281.06049039331094, 488.8204786346134, 114.90367677371454, 108.65690931206511]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.456841175495216, "mean_inference_ms": 6.472706144121401, "mean_action_processing_ms": 1.0488831400939236, "mean_env_wait_ms": 0.9032255783507867, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015178084373474121, "StateBufferConnector_ms": 0.008365988731384277, "ViewRequirementAgentConnector_ms": 0.1413193941116333}, "num_episodes": 22, "episode_return_max": 2020.8151200115462, "episode_return_min": 1255.7478118879228, "episode_return_mean": 1709.907183639962, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 63.256826637515836, "num_env_steps_trained_throughput_per_sec": 63.256826637515836, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 17709.118, "restore_workers_time_ms": 0.018, "training_step_time_ms": 17709.064, "sample_time_ms": 2076.177, "learn_time_ms": 15610.806, "learn_throughput": 256.233, "synch_weights_time_ms": 20.845}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "479e5_00000", "date": "2024-08-16_12-23-20", "timestamp": 1723791200, "time_this_iter_s": 63.24816393852234, "time_total_s": 3391.1427466869354, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7891700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3391.1427466869354, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 47.421052631578945, "ram_util_percent": 74.97368421052632}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1529409085001263, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.118976285722521, "policy_loss": -0.0025290994523043827, "vf_loss": 9.120547211359417, "vf_explained_var": -0.009085821600818129, "kl": 0.008516884220064871, "entropy": 1.1717204792158944, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9643010318910004, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.71959708178485, "policy_loss": -0.0020110675744791193, "vf_loss": 9.721262363151268, "vf_explained_var": -0.03307509876432873, "kl": 0.006147602253131704, "entropy": 0.5422547486566361, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 2036.1802545739513, "episode_reward_min": 1255.7478118879228, "episode_reward_mean": 1751.828151455718, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 211.20150808317072, "predator_policy": 15.571235790317143}, "policy_reward_max": {"prey_policy": 869.966235065884, "predator_policy": 577.6911105860836}, "policy_reward_mean": {"prey_policy": 652.7273724067744, "predator_policy": 223.18670332108456}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1901.3241511394206, 1452.7438034390166, 1934.4809238038217, 1445.7062175736457, 1468.775122809962, 1603.198452086016, 1481.2912148938722, 1401.9412355316117, 1262.6848315560117, 1458.0581211926253, 1428.6434337063017, 1570.157724225395, 1646.8401343786743, 1908.0800064537427, 1255.7478118879228, 1819.6425492119183, 1922.5069469726493, 1789.5256591694683, 1745.74164908471, 1634.640394816767, 1597.863968511613, 1618.884871540745, 1820.0636334190929, 1778.5669471193817, 1697.5344957978764, 1869.6274826172255, 2020.8151200115462, 1988.7684677062477, 1714.9705550445149, 1963.8918290888803, 1764.1026162514852, 1831.0496973606146, 1693.0244057943005, 1793.7039703051344, 1565.5135241234955, 1445.9144579459605, 1590.1360420867989, 1829.9219997234181, 1872.8393142122086, 1868.0474707035278, 1763.8957266945815, 1627.438899724647, 1969.959218600813, 1930.9466379384908, 1661.2399285626748, 1841.3615332832615, 1816.324150959565, 1597.360197743103, 1869.541756213721, 1785.6624245116968, 1881.6563651416532, 1753.4560203027588, 1289.9309644013288, 1808.657442812583, 1592.7478225682867, 1734.672995126407, 1924.7378391466082, 1790.3225005206577, 1853.0234365192755, 1702.4311046346397, 1743.6816379302463, 1772.417614399041, 1626.1369965382753, 1737.4301464071677, 1729.0950226379382, 1753.5021640459092, 1986.2786006740541, 1790.578485390099, 1791.2188655331818, 1808.446122672427, 1902.222488811392, 1768.9926853988422, 1792.2567656694725, 1807.5646855761222, 1761.4933923832407, 1976.0641518016334, 1714.1726447788355, 1735.096321717798, 1910.1546181339227, 1915.7722891514115, 1998.8727187861193, 1693.437539755466, 1701.161287220114, 1834.5959721235708, 1864.7897681054026, 1744.2142338760957, 1944.9203456457515, 2036.1802545739513, 1502.8714978106352, 1825.8608281094578, 1926.4152497187667, 1679.2879752862289, 1894.636184858853, 2009.8650165619572, 1748.8743528496043, 1654.6568400996853, 1799.6833874796735, 1827.5183546500584, 1807.656368969901, 2012.4030507351063], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [690.7598357898663, 710.957609682954, 660.7289977457602, 513.2284224516644, 569.3619240390759, 211.20150808317072, 646.6011619933023, 369.1443998568417, 525.3885814356843, 718.9095961530587, 614.1089446645411, 566.2615418164545, 552.8021481653775, 705.1087928309, 434.8768412863436, 629.9066263494713, 629.3714404029334, 548.2447366953587, 538.265980270666, 630.2194687121284, 564.8566203198567, 580.0489098588946, 498.20141618199824, 614.4600296941226, 869.966235065884, 679.8925426550985, 584.3851615979878, 375.2253931720227, 515.803160728436, 399.7457192031149, 740.7204747186443, 671.2884957891706, 755.8805048360591, 332.2315081999482, 613.0784228511926, 644.354934274802, 586.3335361050748, 653.7685920004388, 610.9882833846109, 862.5778891496558, 675.2781740447415, 609.4931641850784, 735.7106960682003, 647.4051594817752, 594.1123991060873, 560.5017909499413, 724.4948085312751, 666.7406852810731, 585.0898073990345, 593.1744745499391, 682.9005882821162, 710.1392029132539, 788.4320454629934, 498.20928209973283, 693.9591124199433, 534.1505264415497, 601.2080262196657, 731.8786139492814, 769.929681637718, 492.31315216786624, 716.9240286217723, 462.88930934644395, 598.5573572744972, 756.4800082630123, 554.0689084095558, 589.8726966162175, 854.1679148604761, 666.2295944110477, 486.61332891459796, 572.2009683890516, 605.9379096294715, 630.2201392797571, 675.8439009315244, 574.2247022609267, 554.1315631299361, 738.2264766926378, 744.2917494407844, 657.4327196435538, 528.4103919577408, 631.599834963037, 684.6068043076042, 679.3596997167114, 673.2550665634272, 578.2594825729923, 599.3821703689123, 749.627716566384, 547.980605520183, 734.187106636203, 730.8242734443967, 585.5908523563127, 690.377266576388, 424.1336402197952, 728.9411283251345, 750.1861244568353, 547.1213863454291, 747.3283754392695, 775.4195184410552, 611.715053495524, 677.4554855032641, 654.9644671935744, 526.832605975944, 686.6831586352538, 760.3934895329612, 747.8123430674132, 468.12400451361515, 628.2284769001513, 576.027870546267, 597.3192807661094, 716.2609511775355, 768.6355382050373, 600.3635806597533, 734.8031682055223, 759.4498912535175, 685.535778520626, 717.579420817062, 735.3138546967253, 661.4929817043687, 591.7621040447284, 661.7368006208983, 680.0643808263729, 632.0735131382537, 688.4886326493744, 640.996867137397, 696.432665764351, 666.2271864725641, 778.9980314727846, 710.9296148667513, 766.6203151781887, 754.7790619804654, 540.3900414910476, 801.8828364318886, 799.7224535277304, 691.3604987365488, 733.4339467867445, 783.6309717493164, 654.577968830756, 717.9511786302689, 810.8543687151446, 622.1000159133375, 699.2647048981812, 845.6489808736635, 671.9782233222045, 735.8388410940187, 610.0838450966413, 829.3968784027039, 741.7349471116371, 598.35611299222, 735.459837293906, 546.3304208866941, 625.2613448540588, 707.8261133120595, 498.3570694616486, 744.7949532864236, 745.8171054066333, 588.3443055912772, 655.8414960279271, 599.5555585222025, 779.6489232026079, 728.4010930793108, 743.719946100046, 762.0175423539773, 648.7608707204093, 752.0334984826305, 788.8959706107951, 752.6793652016327, 530.8746925536693, 666.8828116326561, 645.144080076775, 794.3209583533288, 498.1297464005921, 764.0941076401921, 758.1926403223334, 575.8000934901614, 656.7735471363112, 720.2238012460269, 760.221885775094, 466.09681180297684, 769.3414669793387, 749.9235277929256, 808.872284283263, 850.2904850557637, 763.4421757989921, 678.3308237665774, 659.9452912599824, 765.5539068721665, 563.9796490575508, 504.6456009353076, 642.4468333280901, 679.9105860999008, 712.1554672953747, 654.0431184572068, 812.2261287223482, 517.2775409472816, 457.265784988534, 724.5909198232126, 698.467458113886, 439.1325640270033, 684.0281423460535, 783.6054415874804, 573.9088025689696], "policy_predator_policy_reward": [292.8234654716484, 206.78324019495378, 84.82869937285386, 193.95768386874016, 576.2263810954884, 577.6911105860836, 253.5718586102617, 176.3887971132391, 43.691584869197634, 180.78536035202214, 200.30847697686605, 222.5194886281534, 101.9794266181705, 121.40084727942383, 204.9556837390505, 132.20208415674665, 69.49741866740241, 15.571235790317143, 178.71643392600515, 110.85623828382612, 122.1906379963498, 161.54726553120122, 325.7768064526662, 131.71947189661034, 79.2593305662116, 17.722026091484025, 503.3699955398829, 445.09945614384935, 148.49229876284676, 191.7066331935251, 192.27352031352777, 215.360058390576, 344.94794010003596, 489.4469938366054, 302.0712971920352, 230.0210048514409, 285.3304158899379, 220.30910508925496, 139.9829505938467, 21.091271688651545, 128.13664636392963, 184.95598391786305, 148.85418155428636, 86.91483443648346, 376.3096437808841, 289.1397995821814, 95.3791676566761, 291.9522856503569, 307.2886751916282, 211.98153865727343, 283.84795195857197, 192.73973946328502, 327.3857783099835, 406.78801413883843, 386.69529912868006, 373.9635297160739, 202.16351365126934, 179.72040122430005, 350.24124442377564, 351.40775085952123, 241.37098045024874, 342.91829783302245, 158.8010121124153, 317.2113197106912, 367.1281819243739, 181.95461884415505, 152.2209070532889, 121.08555398032402, 293.57038305844065, 213.12884376140417, 102.05495125400661, 107.70145778272506, 222.62817714450216, 117.43926174984865, 300.5204178020564, 237.04354209879074, 219.40412746351, 251.71071766435924, 373.68772655634336, 334.3495172264079, 276.85450465606635, 123.0747180141951, 147.05475420995293, 228.86959637827292, 298.65162587655703, 322.29770578895864, 232.461951877576, 416.31697390453036, 101.97753690699864, 242.84726585496662, 326.7845168551475, 400.06610963193225, 241.9847545288731, 95.21214364872077, 192.05271742732242, 110.85771853108079, 297.5434901056667, 184.86369417147606, 208.8874838390303, 244.35498797582758, 338.7913711766028, 329.3492293538538, 114.10095532807424, 131.1492323743101, 148.73351495140335, 44.84496803615894, 333.1883247683884, 302.121966731816, 44.61585801809636, 63.235475167618766, 262.1498660138417, 137.35638024728718, 222.88730863277326, 256.864860739691, 199.3203693304415, 138.1088556764308, 282.742367430101, 317.02598334007655, 176.85942701556527, 183.77049617180288, 169.49398606508677, 253.62550607753153, 230.3429250592685, 204.64515643802488, 24.563472678967536, 156.34830591396056, 138.08810052544914, 121.79211583677919, 186.37073936748175, 247.55517979894248, 132.61084392029156, 19.286030165994106, 328.6074079955366, 232.87674715522292, 193.31571954978614, 159.05382526023743, 186.1868516876373, 76.22646650013294, 214.41138079815437, 272.6700210627521, 151.6113499724819, 232.98393464304434, 117.81672798666828, 305.2532712215119, 164.74697664321235, 56.377963511921166, 288.6608316483625, 185.087903641633, 244.45185306454636, 345.44977357794164, 281.06049039331094, 488.8204786346134, 114.90367677371454, 108.65690931206511, 189.0886495726751, 301.82187052592093, 304.3906695391044, 226.55946687000608, 237.97595804282042, 205.67529192923547, 264.88257324611084, 323.21173246562023, 61.68930676389462, 90.81876389814633, 208.89803146510718, 208.70919799970474, 284.80710575392567, 237.76197466021523, 304.2167881024957, 268.12227524898617, 61.238634983111325, 160.68885093046097, 388.60194063021214, 323.74476438906527, 265.7328933672527, 290.00167418557754, 110.90751599881827, 156.52570302950022, 55.35418160190517, 211.71083443136646, 115.01804371014701, 197.66454515386738, 149.85072185234682, 191.16113840732064, 219.07058901673895, 346.0320399124007, 391.24158886288103, 471.5309934356806, 188.79113292089048, 168.01716653343522, 102.77896027994798, 85.60863264018295, 424.11399455696915, 401.0260669868878, 170.96184024375881, 233.49813646920222, 307.7127282943716, 376.7829343024719, 219.3296268782075, 435.55917970044715]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4373139218969886, "mean_inference_ms": 6.4157752184921275, "mean_action_processing_ms": 1.039667149940518, "mean_env_wait_ms": 0.8946970078855893, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015608072280883789, "StateBufferConnector_ms": 0.008991360664367676, "ViewRequirementAgentConnector_ms": 0.15557456016540527}, "num_episodes": 23, "episode_return_max": 2036.1802545739513, "episode_return_min": 1255.7478118879228, "episode_return_mean": 1751.828151455718, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 275.29611714241287, "num_env_steps_trained_throughput_per_sec": 275.29611714241287, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 17873.53, "restore_workers_time_ms": 0.018, "training_step_time_ms": 17873.474, "sample_time_ms": 2172.723, "learn_time_ms": 15677.559, "learn_throughput": 255.142, "synch_weights_time_ms": 21.806}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "479e5_00000", "date": "2024-08-16_12-23-34", "timestamp": 1723791214, "time_this_iter_s": 14.555670976638794, "time_total_s": 3405.698417663574, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7dd7af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3405.698417663574, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 59.94761904761905, "ram_util_percent": 79.27619047619048}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.909634191996206, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.244993121535689, "policy_loss": -0.004662277292898763, "vf_loss": 9.248289422635679, "vf_explained_var": -0.03258580918665285, "kl": 0.012142132474858361, "entropy": 1.1618380594505835, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.22814807063215, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.709710593955228, "policy_loss": -0.0038403403393372343, "vf_loss": 9.713141282904084, "vf_explained_var": -0.005895158885017274, "kl": 0.007282583051356791, "entropy": 0.5639760725239598, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 2036.1802545739513, "episode_reward_min": 1289.9309644013288, "episode_reward_mean": 1794.5548079413213, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 270.7301557300413, "predator_policy": 13.174907214170773}, "policy_reward_max": {"prey_policy": 862.5778891496558, "predator_policy": 572.1366519233997}, "policy_reward_mean": {"prey_policy": 661.566042260932, "predator_policy": 235.71136170972903}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1745.74164908471, 1634.640394816767, 1597.863968511613, 1618.884871540745, 1820.0636334190929, 1778.5669471193817, 1697.5344957978764, 1869.6274826172255, 2020.8151200115462, 1988.7684677062477, 1714.9705550445149, 1963.8918290888803, 1764.1026162514852, 1831.0496973606146, 1693.0244057943005, 1793.7039703051344, 1565.5135241234955, 1445.9144579459605, 1590.1360420867989, 1829.9219997234181, 1872.8393142122086, 1868.0474707035278, 1763.8957266945815, 1627.438899724647, 1969.959218600813, 1930.9466379384908, 1661.2399285626748, 1841.3615332832615, 1816.324150959565, 1597.360197743103, 1869.541756213721, 1785.6624245116968, 1881.6563651416532, 1753.4560203027588, 1289.9309644013288, 1808.657442812583, 1592.7478225682867, 1734.672995126407, 1924.7378391466082, 1790.3225005206577, 1853.0234365192755, 1702.4311046346397, 1743.6816379302463, 1772.417614399041, 1626.1369965382753, 1737.4301464071677, 1729.0950226379382, 1753.5021640459092, 1986.2786006740541, 1790.578485390099, 1791.2188655331818, 1808.446122672427, 1902.222488811392, 1768.9926853988422, 1792.2567656694725, 1807.5646855761222, 1761.4933923832407, 1976.0641518016334, 1714.1726447788355, 1735.096321717798, 1910.1546181339227, 1915.7722891514115, 1998.8727187861193, 1693.437539755466, 1701.161287220114, 1834.5959721235708, 1864.7897681054026, 1744.2142338760957, 1944.9203456457515, 2036.1802545739513, 1502.8714978106352, 1825.8608281094578, 1926.4152497187667, 1679.2879752862289, 1894.636184858853, 2009.8650165619572, 1748.8743528496043, 1654.6568400996853, 1799.6833874796735, 1827.5183546500584, 1807.656368969901, 2012.4030507351063, 1755.214801238403, 1944.1121055803017, 1912.551440121745, 1801.219074238684, 1652.9135317544863, 1948.6108700253428, 1734.009944941892, 1914.5897427395723, 1598.5470759859604, 1969.4622022373087, 1850.4102052871701, 1814.0206377208222, 1877.5321348455118, 1512.0342856999794, 1936.5359497106185, 2027.9182454070524, 1928.2063500690049, 1846.1253909886136], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [586.3335361050748, 653.7685920004388, 610.9882833846109, 862.5778891496558, 675.2781740447415, 609.4931641850784, 735.7106960682003, 647.4051594817752, 594.1123991060873, 560.5017909499413, 724.4948085312751, 666.7406852810731, 585.0898073990345, 593.1744745499391, 682.9005882821162, 710.1392029132539, 788.4320454629934, 498.20928209973283, 693.9591124199433, 534.1505264415497, 601.2080262196657, 731.8786139492814, 769.929681637718, 492.31315216786624, 716.9240286217723, 462.88930934644395, 598.5573572744972, 756.4800082630123, 554.0689084095558, 589.8726966162175, 854.1679148604761, 666.2295944110477, 486.61332891459796, 572.2009683890516, 605.9379096294715, 630.2201392797571, 675.8439009315244, 574.2247022609267, 554.1315631299361, 738.2264766926378, 744.2917494407844, 657.4327196435538, 528.4103919577408, 631.599834963037, 684.6068043076042, 679.3596997167114, 673.2550665634272, 578.2594825729923, 599.3821703689123, 749.627716566384, 547.980605520183, 734.187106636203, 730.8242734443967, 585.5908523563127, 690.377266576388, 424.1336402197952, 728.9411283251345, 750.1861244568353, 547.1213863454291, 747.3283754392695, 775.4195184410552, 611.715053495524, 677.4554855032641, 654.9644671935744, 526.832605975944, 686.6831586352538, 760.3934895329612, 747.8123430674132, 468.12400451361515, 628.2284769001513, 576.027870546267, 597.3192807661094, 716.2609511775355, 768.6355382050373, 600.3635806597533, 734.8031682055223, 759.4498912535175, 685.535778520626, 717.579420817062, 735.3138546967253, 661.4929817043687, 591.7621040447284, 661.7368006208983, 680.0643808263729, 632.0735131382537, 688.4886326493744, 640.996867137397, 696.432665764351, 666.2271864725641, 778.9980314727846, 710.9296148667513, 766.6203151781887, 754.7790619804654, 540.3900414910476, 801.8828364318886, 799.7224535277304, 691.3604987365488, 733.4339467867445, 783.6309717493164, 654.577968830756, 717.9511786302689, 810.8543687151446, 622.1000159133375, 699.2647048981812, 845.6489808736635, 671.9782233222045, 735.8388410940187, 610.0838450966413, 829.3968784027039, 741.7349471116371, 598.35611299222, 735.459837293906, 546.3304208866941, 625.2613448540588, 707.8261133120595, 498.3570694616486, 744.7949532864236, 745.8171054066333, 588.3443055912772, 655.8414960279271, 599.5555585222025, 779.6489232026079, 728.4010930793108, 743.719946100046, 762.0175423539773, 648.7608707204093, 752.0334984826305, 788.8959706107951, 752.6793652016327, 530.8746925536693, 666.8828116326561, 645.144080076775, 794.3209583533288, 498.1297464005921, 764.0941076401921, 758.1926403223334, 575.8000934901614, 656.7735471363112, 720.2238012460269, 760.221885775094, 466.09681180297684, 769.3414669793387, 749.9235277929256, 808.872284283263, 850.2904850557637, 763.4421757989921, 678.3308237665774, 659.9452912599824, 765.5539068721665, 563.9796490575508, 504.6456009353076, 642.4468333280901, 679.9105860999008, 712.1554672953747, 654.0431184572068, 812.2261287223482, 517.2775409472816, 457.265784988534, 724.5909198232126, 698.467458113886, 439.1325640270033, 684.0281423460535, 783.6054415874804, 573.9088025689696, 602.2860418391879, 509.49308572950724, 270.7301557300413, 615.9615589819676, 597.5553138386226, 308.8026229811861, 643.0728535804099, 700.4039639361674, 470.7649860390493, 783.3884473840325, 655.3340398670866, 665.5120658611763, 619.4624977460523, 728.0456408183852, 554.7005115600588, 621.3986673949591, 842.5973274725795, 657.0404954603111, 471.4209990802641, 698.6176849416498, 633.990891803776, 709.934304815199, 822.3746131888407, 766.2577237712939, 611.2595241524241, 546.6089768284972, 734.1557125750315, 447.74158946210525, 616.2389637102434, 838.1000052132615, 618.1988242574439, 836.4572263022407, 659.2217613261059, 539.6229038987868, 634.7047228870043, 641.8653539693382], "policy_predator_policy_reward": [285.3304158899379, 220.30910508925496, 139.9829505938467, 21.091271688651545, 128.13664636392963, 184.95598391786305, 148.85418155428636, 86.91483443648346, 376.3096437808841, 289.1397995821814, 95.3791676566761, 291.9522856503569, 307.2886751916282, 211.98153865727343, 283.84795195857197, 192.73973946328502, 327.3857783099835, 406.78801413883843, 386.69529912868006, 373.9635297160739, 202.16351365126934, 179.72040122430005, 350.24124442377564, 351.40775085952123, 241.37098045024874, 342.91829783302245, 158.8010121124153, 317.2113197106912, 367.1281819243739, 181.95461884415505, 152.2209070532889, 121.08555398032402, 293.57038305844065, 213.12884376140417, 102.05495125400661, 107.70145778272506, 222.62817714450216, 117.43926174984865, 300.5204178020564, 237.04354209879074, 219.40412746351, 251.71071766435924, 373.68772655634336, 334.3495172264079, 276.85450465606635, 123.0747180141951, 147.05475420995293, 228.86959637827292, 298.65162587655703, 322.29770578895864, 232.461951877576, 416.31697390453036, 101.97753690699864, 242.84726585496662, 326.7845168551475, 400.06610963193225, 241.9847545288731, 95.21214364872077, 192.05271742732242, 110.85771853108079, 297.5434901056667, 184.86369417147606, 208.8874838390303, 244.35498797582758, 338.7913711766028, 329.3492293538538, 114.10095532807424, 131.1492323743101, 148.73351495140335, 44.84496803615894, 333.1883247683884, 302.121966731816, 44.61585801809636, 63.235475167618766, 262.1498660138417, 137.35638024728718, 222.88730863277326, 256.864860739691, 199.3203693304415, 138.1088556764308, 282.742367430101, 317.02598334007655, 176.85942701556527, 183.77049617180288, 169.49398606508677, 253.62550607753153, 230.3429250592685, 204.64515643802488, 24.563472678967536, 156.34830591396056, 138.08810052544914, 121.79211583677919, 186.37073936748175, 247.55517979894248, 132.61084392029156, 19.286030165994106, 328.6074079955366, 232.87674715522292, 193.31571954978614, 159.05382526023743, 186.1868516876373, 76.22646650013294, 214.41138079815437, 272.6700210627521, 151.6113499724819, 232.98393464304434, 117.81672798666828, 305.2532712215119, 164.74697664321235, 56.377963511921166, 288.6608316483625, 185.087903641633, 244.45185306454636, 345.44977357794164, 281.06049039331094, 488.8204786346134, 114.90367677371454, 108.65690931206511, 189.0886495726751, 301.82187052592093, 304.3906695391044, 226.55946687000608, 237.97595804282042, 205.67529192923547, 264.88257324611084, 323.21173246562023, 61.68930676389462, 90.81876389814633, 208.89803146510718, 208.70919799970474, 284.80710575392567, 237.76197466021523, 304.2167881024957, 268.12227524898617, 61.238634983111325, 160.68885093046097, 388.60194063021214, 323.74476438906527, 265.7328933672527, 290.00167418557754, 110.90751599881827, 156.52570302950022, 55.35418160190517, 211.71083443136646, 115.01804371014701, 197.66454515386738, 149.85072185234682, 191.16113840732064, 219.07058901673895, 346.0320399124007, 391.24158886288103, 471.5309934356806, 188.79113292089048, 168.01716653343522, 102.77896027994798, 85.60863264018295, 424.11399455696915, 401.0260669868878, 170.96184024375881, 233.49813646920222, 307.7127282943716, 376.7829343024719, 219.3296268782075, 435.55917970044715, 277.3524367606776, 366.0832369090313, 572.1366519233997, 485.283738944894, 526.5365279750905, 479.65697532684504, 207.7991205112767, 249.94313621083418, 183.94580398438944, 214.8142943470158, 297.1532732865442, 330.61149101053434, 268.75224304353935, 117.74956333391424, 325.9045694787297, 412.585994305825, 85.73434583890143, 13.174907214170773, 488.8185944505019, 310.6049237648954, 264.01546256023596, 242.4695461079569, 77.67195535435134, 147.71634540633903, 414.52288981115095, 305.1407440534377, 195.5407727598182, 134.59621090302474, 190.7434152552343, 291.4535655318816, 307.3800799484081, 265.88211489896156, 305.0887251989897, 424.2729596451244, 247.53874785827497, 322.0165662739959]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.417575465663485, "mean_inference_ms": 6.3702322923173185, "mean_action_processing_ms": 1.0311433907804288, "mean_env_wait_ms": 0.8884525496390562, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014013409614562988, "StateBufferConnector_ms": 0.009079217910766602, "ViewRequirementAgentConnector_ms": 0.13962292671203613}, "num_episodes": 18, "episode_return_max": 2036.1802545739513, "episode_return_min": 1289.9309644013288, "episode_return_mean": 1794.5548079413213, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 302.31320048001174, "num_env_steps_trained_throughput_per_sec": 302.31320048001174, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 17930.951, "restore_workers_time_ms": 0.018, "training_step_time_ms": 17930.893, "sample_time_ms": 2175.877, "learn_time_ms": 15734.38, "learn_throughput": 254.22, "synch_weights_time_ms": 19.282}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "479e5_00000", "date": "2024-08-16_12-23-48", "timestamp": 1723791228, "time_this_iter_s": 13.23739504814148, "time_total_s": 3418.9358127117157, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78b9d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3418.9358127117157, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 49.91578947368421, "ram_util_percent": 77.11578947368422}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.762688605463694, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.246178866694214, "policy_loss": -0.00480684670385604, "vf_loss": 9.249660821944948, "vf_explained_var": -0.0048473020079274655, "kl": 0.011776815610612954, "entropy": 1.1883052399549534, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.762376975098615, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.751865273934824, "policy_loss": -0.002874838790447308, "vf_loss": 9.754360865537452, "vf_explained_var": -0.08631360691691202, "kl": 0.006742303862474582, "entropy": 0.48253092822574434, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 2036.1802545739513, "episode_reward_min": 1289.9309644013288, "episode_reward_mean": 1796.7614988169744, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 270.7301557300413, "predator_policy": 13.174907214170773}, "policy_reward_max": {"prey_policy": 850.2904850557637, "predator_policy": 572.1366519233997}, "policy_reward_mean": {"prey_policy": 658.0972555529696, "predator_policy": 240.28349385551783}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1590.1360420867989, 1829.9219997234181, 1872.8393142122086, 1868.0474707035278, 1763.8957266945815, 1627.438899724647, 1969.959218600813, 1930.9466379384908, 1661.2399285626748, 1841.3615332832615, 1816.324150959565, 1597.360197743103, 1869.541756213721, 1785.6624245116968, 1881.6563651416532, 1753.4560203027588, 1289.9309644013288, 1808.657442812583, 1592.7478225682867, 1734.672995126407, 1924.7378391466082, 1790.3225005206577, 1853.0234365192755, 1702.4311046346397, 1743.6816379302463, 1772.417614399041, 1626.1369965382753, 1737.4301464071677, 1729.0950226379382, 1753.5021640459092, 1986.2786006740541, 1790.578485390099, 1791.2188655331818, 1808.446122672427, 1902.222488811392, 1768.9926853988422, 1792.2567656694725, 1807.5646855761222, 1761.4933923832407, 1976.0641518016334, 1714.1726447788355, 1735.096321717798, 1910.1546181339227, 1915.7722891514115, 1998.8727187861193, 1693.437539755466, 1701.161287220114, 1834.5959721235708, 1864.7897681054026, 1744.2142338760957, 1944.9203456457515, 2036.1802545739513, 1502.8714978106352, 1825.8608281094578, 1926.4152497187667, 1679.2879752862289, 1894.636184858853, 2009.8650165619572, 1748.8743528496043, 1654.6568400996853, 1799.6833874796735, 1827.5183546500584, 1807.656368969901, 2012.4030507351063, 1755.214801238403, 1944.1121055803017, 1912.551440121745, 1801.219074238684, 1652.9135317544863, 1948.6108700253428, 1734.009944941892, 1914.5897427395723, 1598.5470759859604, 1969.4622022373087, 1850.4102052871701, 1814.0206377208222, 1877.5321348455118, 1512.0342856999794, 1936.5359497106185, 2027.9182454070524, 1928.2063500690049, 1846.1253909886136, 1772.0990053819603, 1728.8658253831013, 1802.3685568375163, 1461.5043035595936, 1912.104651103637, 1871.0099854526084, 1965.834064579936, 1881.0368552010423, 1615.6388704019314, 1560.098335208475, 1765.1654074086475, 1868.7237922678783, 1742.7618484839877, 1641.9141125218416, 1754.0730159832872, 1894.0849646962583, 1793.7087865172616, 1734.3547931159105], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [675.8439009315244, 574.2247022609267, 554.1315631299361, 738.2264766926378, 744.2917494407844, 657.4327196435538, 528.4103919577408, 631.599834963037, 684.6068043076042, 679.3596997167114, 673.2550665634272, 578.2594825729923, 599.3821703689123, 749.627716566384, 547.980605520183, 734.187106636203, 730.8242734443967, 585.5908523563127, 690.377266576388, 424.1336402197952, 728.9411283251345, 750.1861244568353, 547.1213863454291, 747.3283754392695, 775.4195184410552, 611.715053495524, 677.4554855032641, 654.9644671935744, 526.832605975944, 686.6831586352538, 760.3934895329612, 747.8123430674132, 468.12400451361515, 628.2284769001513, 576.027870546267, 597.3192807661094, 716.2609511775355, 768.6355382050373, 600.3635806597533, 734.8031682055223, 759.4498912535175, 685.535778520626, 717.579420817062, 735.3138546967253, 661.4929817043687, 591.7621040447284, 661.7368006208983, 680.0643808263729, 632.0735131382537, 688.4886326493744, 640.996867137397, 696.432665764351, 666.2271864725641, 778.9980314727846, 710.9296148667513, 766.6203151781887, 754.7790619804654, 540.3900414910476, 801.8828364318886, 799.7224535277304, 691.3604987365488, 733.4339467867445, 783.6309717493164, 654.577968830756, 717.9511786302689, 810.8543687151446, 622.1000159133375, 699.2647048981812, 845.6489808736635, 671.9782233222045, 735.8388410940187, 610.0838450966413, 829.3968784027039, 741.7349471116371, 598.35611299222, 735.459837293906, 546.3304208866941, 625.2613448540588, 707.8261133120595, 498.3570694616486, 744.7949532864236, 745.8171054066333, 588.3443055912772, 655.8414960279271, 599.5555585222025, 779.6489232026079, 728.4010930793108, 743.719946100046, 762.0175423539773, 648.7608707204093, 752.0334984826305, 788.8959706107951, 752.6793652016327, 530.8746925536693, 666.8828116326561, 645.144080076775, 794.3209583533288, 498.1297464005921, 764.0941076401921, 758.1926403223334, 575.8000934901614, 656.7735471363112, 720.2238012460269, 760.221885775094, 466.09681180297684, 769.3414669793387, 749.9235277929256, 808.872284283263, 850.2904850557637, 763.4421757989921, 678.3308237665774, 659.9452912599824, 765.5539068721665, 563.9796490575508, 504.6456009353076, 642.4468333280901, 679.9105860999008, 712.1554672953747, 654.0431184572068, 812.2261287223482, 517.2775409472816, 457.265784988534, 724.5909198232126, 698.467458113886, 439.1325640270033, 684.0281423460535, 783.6054415874804, 573.9088025689696, 602.2860418391879, 509.49308572950724, 270.7301557300413, 615.9615589819676, 597.5553138386226, 308.8026229811861, 643.0728535804099, 700.4039639361674, 470.7649860390493, 783.3884473840325, 655.3340398670866, 665.5120658611763, 619.4624977460523, 728.0456408183852, 554.7005115600588, 621.3986673949591, 842.5973274725795, 657.0404954603111, 471.4209990802641, 698.6176849416498, 633.990891803776, 709.934304815199, 822.3746131888407, 766.2577237712939, 611.2595241524241, 546.6089768284972, 734.1557125750315, 447.74158946210525, 616.2389637102434, 838.1000052132615, 618.1988242574439, 836.4572263022407, 659.2217613261059, 539.6229038987868, 634.7047228870043, 641.8653539693382, 359.61236268343055, 515.8889818165703, 733.305641921543, 740.0525306859214, 585.8531342556794, 572.5486948000553, 671.1152687014924, 539.376569207449, 709.5221017714575, 585.1616104691483, 734.470244043959, 677.7273789080481, 645.3792213510711, 718.6860473253288, 529.8999826766441, 540.3238666442389, 547.3116831570841, 710.442666253328, 545.1214074465347, 706.1898253568836, 747.6105658902668, 499.4562004785969, 674.3406080131326, 754.9153312449973, 679.7780634071436, 701.0173671933775, 629.510136524886, 567.0042522098552, 632.1474706792001, 628.2361653426349, 597.4379565445383, 551.7342277035466, 528.4200972526321, 581.1073468382026, 643.5817503314286, 624.9077551241701], "policy_predator_policy_reward": [222.62817714450216, 117.43926174984865, 300.5204178020564, 237.04354209879074, 219.40412746351, 251.71071766435924, 373.68772655634336, 334.3495172264079, 276.85450465606635, 123.0747180141951, 147.05475420995293, 228.86959637827292, 298.65162587655703, 322.29770578895864, 232.461951877576, 416.31697390453036, 101.97753690699864, 242.84726585496662, 326.7845168551475, 400.06610963193225, 241.9847545288731, 95.21214364872077, 192.05271742732242, 110.85771853108079, 297.5434901056667, 184.86369417147606, 208.8874838390303, 244.35498797582758, 338.7913711766028, 329.3492293538538, 114.10095532807424, 131.1492323743101, 148.73351495140335, 44.84496803615894, 333.1883247683884, 302.121966731816, 44.61585801809636, 63.235475167618766, 262.1498660138417, 137.35638024728718, 222.88730863277326, 256.864860739691, 199.3203693304415, 138.1088556764308, 282.742367430101, 317.02598334007655, 176.85942701556527, 183.77049617180288, 169.49398606508677, 253.62550607753153, 230.3429250592685, 204.64515643802488, 24.563472678967536, 156.34830591396056, 138.08810052544914, 121.79211583677919, 186.37073936748175, 247.55517979894248, 132.61084392029156, 19.286030165994106, 328.6074079955366, 232.87674715522292, 193.31571954978614, 159.05382526023743, 186.1868516876373, 76.22646650013294, 214.41138079815437, 272.6700210627521, 151.6113499724819, 232.98393464304434, 117.81672798666828, 305.2532712215119, 164.74697664321235, 56.377963511921166, 288.6608316483625, 185.087903641633, 244.45185306454636, 345.44977357794164, 281.06049039331094, 488.8204786346134, 114.90367677371454, 108.65690931206511, 189.0886495726751, 301.82187052592093, 304.3906695391044, 226.55946687000608, 237.97595804282042, 205.67529192923547, 264.88257324611084, 323.21173246562023, 61.68930676389462, 90.81876389814633, 208.89803146510718, 208.70919799970474, 284.80710575392567, 237.76197466021523, 304.2167881024957, 268.12227524898617, 61.238634983111325, 160.68885093046097, 388.60194063021214, 323.74476438906527, 265.7328933672527, 290.00167418557754, 110.90751599881827, 156.52570302950022, 55.35418160190517, 211.71083443136646, 115.01804371014701, 197.66454515386738, 149.85072185234682, 191.16113840732064, 219.07058901673895, 346.0320399124007, 391.24158886288103, 471.5309934356806, 188.79113292089048, 168.01716653343522, 102.77896027994798, 85.60863264018295, 424.11399455696915, 401.0260669868878, 170.96184024375881, 233.49813646920222, 307.7127282943716, 376.7829343024719, 219.3296268782075, 435.55917970044715, 277.3524367606776, 366.0832369090313, 572.1366519233997, 485.283738944894, 526.5365279750905, 479.65697532684504, 207.7991205112767, 249.94313621083418, 183.94580398438944, 214.8142943470158, 297.1532732865442, 330.61149101053434, 268.75224304353935, 117.74956333391424, 325.9045694787297, 412.585994305825, 85.73434583890143, 13.174907214170773, 488.8185944505019, 310.6049237648954, 264.01546256023596, 242.4695461079569, 77.67195535435134, 147.71634540633903, 414.52288981115095, 305.1407440534377, 195.5407727598182, 134.59621090302474, 190.7434152552343, 291.4535655318816, 307.3800799484081, 265.88211489896156, 305.0887251989897, 424.2729596451244, 247.53874785827497, 322.0165662739959, 462.7736783059389, 433.82398257602006, 165.02955153550712, 90.47810124013355, 313.53329790380917, 330.43342987797445, 107.62649798381374, 143.38596766683767, 321.36684254219784, 296.0540963208357, 228.4327525764905, 230.3796099241087, 319.1778072800609, 282.5909886234778, 445.16042639455077, 365.65257948561003, 146.97360578391385, 210.9109152076066, 127.43915709917576, 181.34794530588076, 230.28837179132745, 287.8102692484548, 172.85721175982405, 266.61064124992373, 156.31649365797549, 205.6499242254947, 217.26091823534725, 228.138805551753, 227.49222546605844, 266.1971544953939, 341.9445401094852, 402.96824033868876, 397.4322128385896, 286.7491295878395, 186.51734200624287, 279.3479456540682]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3996415115418053, "mean_inference_ms": 6.3224185562268325, "mean_action_processing_ms": 1.0231817359657225, "mean_env_wait_ms": 0.8818609273783283, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005639195442199707, "StateBufferConnector_ms": 0.009013056755065918, "ViewRequirementAgentConnector_ms": 0.14116013050079346}, "num_episodes": 18, "episode_return_max": 2036.1802545739513, "episode_return_min": 1289.9309644013288, "episode_return_mean": 1796.7614988169744, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 317.72190663489755, "num_env_steps_trained_throughput_per_sec": 317.72190663489755, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 17950.425, "restore_workers_time_ms": 0.017, "training_step_time_ms": 17950.371, "sample_time_ms": 2103.432, "learn_time_ms": 15826.011, "learn_throughput": 252.748, "synch_weights_time_ms": 19.755}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "479e5_00000", "date": "2024-08-16_12-24-00", "timestamp": 1723791240, "time_this_iter_s": 12.595918893814087, "time_total_s": 3431.53173160553, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7dd7b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3431.53173160553, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 48.33888888888889, "ram_util_percent": 76.78888888888888}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2322269755696493, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.020986269895362, "policy_loss": -0.002974827280859389, "vf_loss": 9.022791340742161, "vf_explained_var": -0.04702300337887315, "kl": 0.010397585568446548, "entropy": 1.191020212791584, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9796506740113415, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.715332912263417, "policy_loss": -0.0006338598221422187, "vf_loss": 9.715711735922193, "vf_explained_var": -0.1800483317917617, "kl": 0.004534327093543775, "entropy": 0.43553506227397415, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 2036.1802545739513, "episode_reward_min": 1273.1200608393194, "episode_reward_mean": 1802.7767217668197, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 270.7301557300413, "predator_policy": -10.730329633752465}, "policy_reward_max": {"prey_policy": 850.2904850557637, "predator_policy": 572.1366519233997}, "policy_reward_mean": {"prey_policy": 655.6282366773486, "predator_policy": 245.76012420606168}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1853.0234365192755, 1702.4311046346397, 1743.6816379302463, 1772.417614399041, 1626.1369965382753, 1737.4301464071677, 1729.0950226379382, 1753.5021640459092, 1986.2786006740541, 1790.578485390099, 1791.2188655331818, 1808.446122672427, 1902.222488811392, 1768.9926853988422, 1792.2567656694725, 1807.5646855761222, 1761.4933923832407, 1976.0641518016334, 1714.1726447788355, 1735.096321717798, 1910.1546181339227, 1915.7722891514115, 1998.8727187861193, 1693.437539755466, 1701.161287220114, 1834.5959721235708, 1864.7897681054026, 1744.2142338760957, 1944.9203456457515, 2036.1802545739513, 1502.8714978106352, 1825.8608281094578, 1926.4152497187667, 1679.2879752862289, 1894.636184858853, 2009.8650165619572, 1748.8743528496043, 1654.6568400996853, 1799.6833874796735, 1827.5183546500584, 1807.656368969901, 2012.4030507351063, 1755.214801238403, 1944.1121055803017, 1912.551440121745, 1801.219074238684, 1652.9135317544863, 1948.6108700253428, 1734.009944941892, 1914.5897427395723, 1598.5470759859604, 1969.4622022373087, 1850.4102052871701, 1814.0206377208222, 1877.5321348455118, 1512.0342856999794, 1936.5359497106185, 2027.9182454070524, 1928.2063500690049, 1846.1253909886136, 1772.0990053819603, 1728.8658253831013, 1802.3685568375163, 1461.5043035595936, 1912.104651103637, 1871.0099854526084, 1965.834064579936, 1881.0368552010423, 1615.6388704019314, 1560.098335208475, 1765.1654074086475, 1868.7237922678783, 1742.7618484839877, 1641.9141125218416, 1754.0730159832872, 1894.0849646962583, 1793.7087865172616, 1734.3547931159105, 1816.9861159296581, 1715.4649957592305, 1815.813100561988, 1544.5802501609378, 1925.861534691789, 1835.3281751135607, 1753.721658066874, 1872.4581519350622, 1925.833436181418, 1866.1112356031454, 1273.1200608393194, 1808.7204978194736, 1963.746582982117, 1968.635390292148, 1671.8412338085836, 1752.4440456777913, 1973.5622893843224, 1885.6432489182982, 1514.9526831880114, 1842.9914886684876, 1848.0828285362645, 1826.4805418448364], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [661.4929817043687, 591.7621040447284, 661.7368006208983, 680.0643808263729, 632.0735131382537, 688.4886326493744, 640.996867137397, 696.432665764351, 666.2271864725641, 778.9980314727846, 710.9296148667513, 766.6203151781887, 754.7790619804654, 540.3900414910476, 801.8828364318886, 799.7224535277304, 691.3604987365488, 733.4339467867445, 783.6309717493164, 654.577968830756, 717.9511786302689, 810.8543687151446, 622.1000159133375, 699.2647048981812, 845.6489808736635, 671.9782233222045, 735.8388410940187, 610.0838450966413, 829.3968784027039, 741.7349471116371, 598.35611299222, 735.459837293906, 546.3304208866941, 625.2613448540588, 707.8261133120595, 498.3570694616486, 744.7949532864236, 745.8171054066333, 588.3443055912772, 655.8414960279271, 599.5555585222025, 779.6489232026079, 728.4010930793108, 743.719946100046, 762.0175423539773, 648.7608707204093, 752.0334984826305, 788.8959706107951, 752.6793652016327, 530.8746925536693, 666.8828116326561, 645.144080076775, 794.3209583533288, 498.1297464005921, 764.0941076401921, 758.1926403223334, 575.8000934901614, 656.7735471363112, 720.2238012460269, 760.221885775094, 466.09681180297684, 769.3414669793387, 749.9235277929256, 808.872284283263, 850.2904850557637, 763.4421757989921, 678.3308237665774, 659.9452912599824, 765.5539068721665, 563.9796490575508, 504.6456009353076, 642.4468333280901, 679.9105860999008, 712.1554672953747, 654.0431184572068, 812.2261287223482, 517.2775409472816, 457.265784988534, 724.5909198232126, 698.467458113886, 439.1325640270033, 684.0281423460535, 783.6054415874804, 573.9088025689696, 602.2860418391879, 509.49308572950724, 270.7301557300413, 615.9615589819676, 597.5553138386226, 308.8026229811861, 643.0728535804099, 700.4039639361674, 470.7649860390493, 783.3884473840325, 655.3340398670866, 665.5120658611763, 619.4624977460523, 728.0456408183852, 554.7005115600588, 621.3986673949591, 842.5973274725795, 657.0404954603111, 471.4209990802641, 698.6176849416498, 633.990891803776, 709.934304815199, 822.3746131888407, 766.2577237712939, 611.2595241524241, 546.6089768284972, 734.1557125750315, 447.74158946210525, 616.2389637102434, 838.1000052132615, 618.1988242574439, 836.4572263022407, 659.2217613261059, 539.6229038987868, 634.7047228870043, 641.8653539693382, 359.61236268343055, 515.8889818165703, 733.305641921543, 740.0525306859214, 585.8531342556794, 572.5486948000553, 671.1152687014924, 539.376569207449, 709.5221017714575, 585.1616104691483, 734.470244043959, 677.7273789080481, 645.3792213510711, 718.6860473253288, 529.8999826766441, 540.3238666442389, 547.3116831570841, 710.442666253328, 545.1214074465347, 706.1898253568836, 747.6105658902668, 499.4562004785969, 674.3406080131326, 754.9153312449973, 679.7780634071436, 701.0173671933775, 629.510136524886, 567.0042522098552, 632.1474706792001, 628.2361653426349, 597.4379565445383, 551.7342277035466, 528.4200972526321, 581.1073468382026, 643.5817503314286, 624.9077551241701, 692.6072229310257, 658.8237797500709, 675.2041957490321, 640.2074116964035, 674.1186257981103, 626.05694686169, 760.071701836982, 703.2484545252822, 631.2975628648251, 752.3265837593468, 548.1886768284251, 651.0954778183474, 701.3071238791862, 603.9467296545068, 712.5086303301631, 528.0151418121109, 667.9380034666063, 745.6244203404425, 592.3768392571734, 609.5191991341225, 572.0121991751845, 517.5628275039037, 617.5950687616382, 763.4374916325102, 813.7037259755401, 593.1460884868671, 751.6278808644829, 679.4037294054278, 546.6168967985341, 686.8431701766518, 652.9659315559907, 683.0956605539949, 598.1366883769704, 574.8407226515035, 562.3078309830938, 730.2568878182487, 547.1505889658799, 591.7704640667625, 602.0160794861279, 626.2112545479447, 578.2687419283859, 652.8400939296087, 703.5132073312652, 670.631242148439], "policy_predator_policy_reward": [282.742367430101, 317.02598334007655, 176.85942701556527, 183.77049617180288, 169.49398606508677, 253.62550607753153, 230.3429250592685, 204.64515643802488, 24.563472678967536, 156.34830591396056, 138.08810052544914, 121.79211583677919, 186.37073936748175, 247.55517979894248, 132.61084392029156, 19.286030165994106, 328.6074079955366, 232.87674715522292, 193.31571954978614, 159.05382526023743, 186.1868516876373, 76.22646650013294, 214.41138079815437, 272.6700210627521, 151.6113499724819, 232.98393464304434, 117.81672798666828, 305.2532712215119, 164.74697664321235, 56.377963511921166, 288.6608316483625, 185.087903641633, 244.45185306454636, 345.44977357794164, 281.06049039331094, 488.8204786346134, 114.90367677371454, 108.65690931206511, 189.0886495726751, 301.82187052592093, 304.3906695391044, 226.55946687000608, 237.97595804282042, 205.67529192923547, 264.88257324611084, 323.21173246562023, 61.68930676389462, 90.81876389814633, 208.89803146510718, 208.70919799970474, 284.80710575392567, 237.76197466021523, 304.2167881024957, 268.12227524898617, 61.238634983111325, 160.68885093046097, 388.60194063021214, 323.74476438906527, 265.7328933672527, 290.00167418557754, 110.90751599881827, 156.52570302950022, 55.35418160190517, 211.71083443136646, 115.01804371014701, 197.66454515386738, 149.85072185234682, 191.16113840732064, 219.07058901673895, 346.0320399124007, 391.24158886288103, 471.5309934356806, 188.79113292089048, 168.01716653343522, 102.77896027994798, 85.60863264018295, 424.11399455696915, 401.0260669868878, 170.96184024375881, 233.49813646920222, 307.7127282943716, 376.7829343024719, 219.3296268782075, 435.55917970044715, 277.3524367606776, 366.0832369090313, 572.1366519233997, 485.283738944894, 526.5365279750905, 479.65697532684504, 207.7991205112767, 249.94313621083418, 183.94580398438944, 214.8142943470158, 297.1532732865442, 330.61149101053434, 268.75224304353935, 117.74956333391424, 325.9045694787297, 412.585994305825, 85.73434583890143, 13.174907214170773, 488.8185944505019, 310.6049237648954, 264.01546256023596, 242.4695461079569, 77.67195535435134, 147.71634540633903, 414.52288981115095, 305.1407440534377, 195.5407727598182, 134.59621090302474, 190.7434152552343, 291.4535655318816, 307.3800799484081, 265.88211489896156, 305.0887251989897, 424.2729596451244, 247.53874785827497, 322.0165662739959, 462.7736783059389, 433.82398257602006, 165.02955153550712, 90.47810124013355, 313.53329790380917, 330.43342987797445, 107.62649798381374, 143.38596766683767, 321.36684254219784, 296.0540963208357, 228.4327525764905, 230.3796099241087, 319.1778072800609, 282.5909886234778, 445.16042639455077, 365.65257948561003, 146.97360578391385, 210.9109152076066, 127.43915709917576, 181.34794530588076, 230.28837179132745, 287.8102692484548, 172.85721175982405, 266.61064124992373, 156.31649365797549, 205.6499242254947, 217.26091823534725, 228.138805551753, 227.49222546605844, 266.1971544953939, 341.9445401094852, 402.96824033868876, 397.4322128385896, 286.7491295878395, 186.51734200624287, 279.3479456540682, 232.99042881704926, 232.56468443150837, 225.61567139133265, 174.43771692246236, 273.74306697419183, 241.89446092799867, 91.99042343242509, -10.730329633752465, 331.32514405886906, 210.91224400874785, 305.2352570359418, 330.8087634308476, 192.834133726336, 255.6336708068458, 375.44782640342504, 256.4865533893637, 275.27964898233506, 236.99136339203676, 289.37717014075804, 374.83802707109226, 89.94131071454659, 93.60372344568597, 252.20620716489452, 175.48173026043222, 271.54627304550405, 285.3504954742089, 263.1193231304693, 274.4844568917679, 231.67146063891911, 206.70970619448198, 184.5905984619408, 231.79185510586316, 376.5732084128205, 424.01166994302844, 318.11889848107376, 274.9596316358826, 208.99955036937388, 167.03207978599346, 244.51049874869264, 370.25365588572475, 295.56753889768686, 321.4064537805843, 242.54688443284033, 209.78920793228806]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3782020443256915, "mean_inference_ms": 6.265003962169423, "mean_action_processing_ms": 1.0136901840909387, "mean_env_wait_ms": 0.8743306745030452, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0052204132080078125, "StateBufferConnector_ms": 0.004020094871520996, "ViewRequirementAgentConnector_ms": 0.13700556755065918}, "num_episodes": 22, "episode_return_max": 2036.1802545739513, "episode_return_min": 1273.1200608393194, "episode_return_mean": 1802.7767217668197, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 352.12408242078254, "num_env_steps_trained_throughput_per_sec": 352.12408242078254, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 17813.386, "restore_workers_time_ms": 0.017, "training_step_time_ms": 17813.332, "sample_time_ms": 2033.83, "learn_time_ms": 15760.217, "learn_throughput": 253.804, "synch_weights_time_ms": 18.143}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "479e5_00000", "date": "2024-08-16_12-24-12", "timestamp": 1723791252, "time_this_iter_s": 11.36517596244812, "time_total_s": 3442.896907567978, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7f2c940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3442.896907567978, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 36.425, "ram_util_percent": 67.18124999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.162110623859224, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.157011470088252, "policy_loss": -0.007919252301916164, "vf_loss": 9.1634152730306, "vf_explained_var": -0.012902368344957867, "kl": 0.01347074093491682, "entropy": 1.1954127593645973, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5804854627876055, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.815463709957385, "policy_loss": -0.0020668945477280037, "vf_loss": 9.817409740427815, "vf_explained_var": -0.30794085882328176, "kl": 0.004297401783325508, "entropy": 0.4136830494517372, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 2036.1802545739513, "episode_reward_min": 1273.1200608393194, "episode_reward_mean": 1802.9426574032657, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 270.7301557300413, "predator_policy": -10.730329633752465}, "policy_reward_max": {"prey_policy": 850.2904850557637, "predator_policy": 572.1366519233997}, "policy_reward_mean": {"prey_policy": 645.6771270954691, "predator_policy": 255.7942016061641}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1714.1726447788355, 1735.096321717798, 1910.1546181339227, 1915.7722891514115, 1998.8727187861193, 1693.437539755466, 1701.161287220114, 1834.5959721235708, 1864.7897681054026, 1744.2142338760957, 1944.9203456457515, 2036.1802545739513, 1502.8714978106352, 1825.8608281094578, 1926.4152497187667, 1679.2879752862289, 1894.636184858853, 2009.8650165619572, 1748.8743528496043, 1654.6568400996853, 1799.6833874796735, 1827.5183546500584, 1807.656368969901, 2012.4030507351063, 1755.214801238403, 1944.1121055803017, 1912.551440121745, 1801.219074238684, 1652.9135317544863, 1948.6108700253428, 1734.009944941892, 1914.5897427395723, 1598.5470759859604, 1969.4622022373087, 1850.4102052871701, 1814.0206377208222, 1877.5321348455118, 1512.0342856999794, 1936.5359497106185, 2027.9182454070524, 1928.2063500690049, 1846.1253909886136, 1772.0990053819603, 1728.8658253831013, 1802.3685568375163, 1461.5043035595936, 1912.104651103637, 1871.0099854526084, 1965.834064579936, 1881.0368552010423, 1615.6388704019314, 1560.098335208475, 1765.1654074086475, 1868.7237922678783, 1742.7618484839877, 1641.9141125218416, 1754.0730159832872, 1894.0849646962583, 1793.7087865172616, 1734.3547931159105, 1816.9861159296581, 1715.4649957592305, 1815.813100561988, 1544.5802501609378, 1925.861534691789, 1835.3281751135607, 1753.721658066874, 1872.4581519350622, 1925.833436181418, 1866.1112356031454, 1273.1200608393194, 1808.7204978194736, 1963.746582982117, 1968.635390292148, 1671.8412338085836, 1752.4440456777913, 1973.5622893843224, 1885.6432489182982, 1514.9526831880114, 1842.9914886684876, 1848.0828285362645, 1826.4805418448364, 1816.8634816810518, 1775.5727074433967, 1844.6498839159435, 1866.9701785007358, 1978.86548840883, 1659.7134532370685, 1872.3207471709356, 1722.5579659699517, 1847.5293513395754, 1809.7931146793198, 1944.1837782914797, 1776.3546368635923, 1803.8624110827366, 1744.3249106669066, 1842.345825681966, 1805.8639408898039, 1400.718217500145, 1806.9378373441348], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [744.7949532864236, 745.8171054066333, 588.3443055912772, 655.8414960279271, 599.5555585222025, 779.6489232026079, 728.4010930793108, 743.719946100046, 762.0175423539773, 648.7608707204093, 752.0334984826305, 788.8959706107951, 752.6793652016327, 530.8746925536693, 666.8828116326561, 645.144080076775, 794.3209583533288, 498.1297464005921, 764.0941076401921, 758.1926403223334, 575.8000934901614, 656.7735471363112, 720.2238012460269, 760.221885775094, 466.09681180297684, 769.3414669793387, 749.9235277929256, 808.872284283263, 850.2904850557637, 763.4421757989921, 678.3308237665774, 659.9452912599824, 765.5539068721665, 563.9796490575508, 504.6456009353076, 642.4468333280901, 679.9105860999008, 712.1554672953747, 654.0431184572068, 812.2261287223482, 517.2775409472816, 457.265784988534, 724.5909198232126, 698.467458113886, 439.1325640270033, 684.0281423460535, 783.6054415874804, 573.9088025689696, 602.2860418391879, 509.49308572950724, 270.7301557300413, 615.9615589819676, 597.5553138386226, 308.8026229811861, 643.0728535804099, 700.4039639361674, 470.7649860390493, 783.3884473840325, 655.3340398670866, 665.5120658611763, 619.4624977460523, 728.0456408183852, 554.7005115600588, 621.3986673949591, 842.5973274725795, 657.0404954603111, 471.4209990802641, 698.6176849416498, 633.990891803776, 709.934304815199, 822.3746131888407, 766.2577237712939, 611.2595241524241, 546.6089768284972, 734.1557125750315, 447.74158946210525, 616.2389637102434, 838.1000052132615, 618.1988242574439, 836.4572263022407, 659.2217613261059, 539.6229038987868, 634.7047228870043, 641.8653539693382, 359.61236268343055, 515.8889818165703, 733.305641921543, 740.0525306859214, 585.8531342556794, 572.5486948000553, 671.1152687014924, 539.376569207449, 709.5221017714575, 585.1616104691483, 734.470244043959, 677.7273789080481, 645.3792213510711, 718.6860473253288, 529.8999826766441, 540.3238666442389, 547.3116831570841, 710.442666253328, 545.1214074465347, 706.1898253568836, 747.6105658902668, 499.4562004785969, 674.3406080131326, 754.9153312449973, 679.7780634071436, 701.0173671933775, 629.510136524886, 567.0042522098552, 632.1474706792001, 628.2361653426349, 597.4379565445383, 551.7342277035466, 528.4200972526321, 581.1073468382026, 643.5817503314286, 624.9077551241701, 692.6072229310257, 658.8237797500709, 675.2041957490321, 640.2074116964035, 674.1186257981103, 626.05694686169, 760.071701836982, 703.2484545252822, 631.2975628648251, 752.3265837593468, 548.1886768284251, 651.0954778183474, 701.3071238791862, 603.9467296545068, 712.5086303301631, 528.0151418121109, 667.9380034666063, 745.6244203404425, 592.3768392571734, 609.5191991341225, 572.0121991751845, 517.5628275039037, 617.5950687616382, 763.4374916325102, 813.7037259755401, 593.1460884868671, 751.6278808644829, 679.4037294054278, 546.6168967985341, 686.8431701766518, 652.9659315559907, 683.0956605539949, 598.1366883769704, 574.8407226515035, 562.3078309830938, 730.2568878182487, 547.1505889658799, 591.7704640667625, 602.0160794861279, 626.2112545479447, 578.2687419283859, 652.8400939296087, 703.5132073312652, 670.631242148439, 634.343720281953, 660.4500343065641, 650.3554431428448, 736.9488024213276, 570.1956581087, 607.0378496215351, 707.7842958067417, 466.3902472454563, 662.8054501941021, 688.7553644551928, 778.2156007429636, 552.3532240864246, 706.3823198696773, 717.5685835287276, 567.4696455897478, 641.5323778434973, 654.2338908975509, 684.0748581490045, 611.8405184426135, 558.3723437346615, 690.8074240107885, 687.6811392079067, 588.6871843190692, 598.1862131708957, 664.9770544086142, 567.9482809492148, 677.7267018188405, 643.9579530952143, 582.4560789223418, 684.1191374007465, 596.2666256259987, 676.4178598322533, 709.7325798264977, 442.56905434455433, 656.9373620251225, 616.2409624657092], "policy_predator_policy_reward": [114.90367677371454, 108.65690931206511, 189.0886495726751, 301.82187052592093, 304.3906695391044, 226.55946687000608, 237.97595804282042, 205.67529192923547, 264.88257324611084, 323.21173246562023, 61.68930676389462, 90.81876389814633, 208.89803146510718, 208.70919799970474, 284.80710575392567, 237.76197466021523, 304.2167881024957, 268.12227524898617, 61.238634983111325, 160.68885093046097, 388.60194063021214, 323.74476438906527, 265.7328933672527, 290.00167418557754, 110.90751599881827, 156.52570302950022, 55.35418160190517, 211.71083443136646, 115.01804371014701, 197.66454515386738, 149.85072185234682, 191.16113840732064, 219.07058901673895, 346.0320399124007, 391.24158886288103, 471.5309934356806, 188.79113292089048, 168.01716653343522, 102.77896027994798, 85.60863264018295, 424.11399455696915, 401.0260669868878, 170.96184024375881, 233.49813646920222, 307.7127282943716, 376.7829343024719, 219.3296268782075, 435.55917970044715, 277.3524367606776, 366.0832369090313, 572.1366519233997, 485.283738944894, 526.5365279750905, 479.65697532684504, 207.7991205112767, 249.94313621083418, 183.94580398438944, 214.8142943470158, 297.1532732865442, 330.61149101053434, 268.75224304353935, 117.74956333391424, 325.9045694787297, 412.585994305825, 85.73434583890143, 13.174907214170773, 488.8185944505019, 310.6049237648954, 264.01546256023596, 242.4695461079569, 77.67195535435134, 147.71634540633903, 414.52288981115095, 305.1407440534377, 195.5407727598182, 134.59621090302474, 190.7434152552343, 291.4535655318816, 307.3800799484081, 265.88211489896156, 305.0887251989897, 424.2729596451244, 247.53874785827497, 322.0165662739959, 462.7736783059389, 433.82398257602006, 165.02955153550712, 90.47810124013355, 313.53329790380917, 330.43342987797445, 107.62649798381374, 143.38596766683767, 321.36684254219784, 296.0540963208357, 228.4327525764905, 230.3796099241087, 319.1778072800609, 282.5909886234778, 445.16042639455077, 365.65257948561003, 146.97360578391385, 210.9109152076066, 127.43915709917576, 181.34794530588076, 230.28837179132745, 287.8102692484548, 172.85721175982405, 266.61064124992373, 156.31649365797549, 205.6499242254947, 217.26091823534725, 228.138805551753, 227.49222546605844, 266.1971544953939, 341.9445401094852, 402.96824033868876, 397.4322128385896, 286.7491295878395, 186.51734200624287, 279.3479456540682, 232.99042881704926, 232.56468443150837, 225.61567139133265, 174.43771692246236, 273.74306697419183, 241.89446092799867, 91.99042343242509, -10.730329633752465, 331.32514405886906, 210.91224400874785, 305.2352570359418, 330.8087634308476, 192.834133726336, 255.6336708068458, 375.44782640342504, 256.4865533893637, 275.27964898233506, 236.99136339203676, 289.37717014075804, 374.83802707109226, 89.94131071454659, 93.60372344568597, 252.20620716489452, 175.48173026043222, 271.54627304550405, 285.3504954742089, 263.1193231304693, 274.4844568917679, 231.67146063891911, 206.70970619448198, 184.5905984619408, 231.79185510586316, 376.5732084128205, 424.01166994302844, 318.11889848107376, 274.9596316358826, 208.99955036937388, 167.03207978599346, 244.51049874869264, 370.25365588572475, 295.56753889768686, 321.4064537805843, 242.54688443284033, 209.78920793228806, 180.8661526062691, 341.2035744862681, 156.61939718148423, 231.64906469773845, 396.36312119666, 271.0532549890466, 356.40611508192404, 336.3895203666138, 358.044775593734, 269.2598981658017, 184.85462580341084, 144.29000260426878, 205.22670389497878, 243.14313987755477, 246.8328457793433, 266.72309675736216, 270.2746274251939, 238.9459748678297, 315.5039925241674, 324.0762599778753, 302.82481892330185, 262.8703961494822, 260.3512781577494, 329.1299612158771, 275.9918881231352, 294.9451876017751, 168.2395517177451, 254.40070403510708, 203.32514017878236, 372.4454691800932, 187.17535507021793, 346.00410036133314, 90.67094565032478, 157.74563767876958, 240.76663898203586, 292.99287387126515]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.360105514513827, "mean_inference_ms": 6.217047085133194, "mean_action_processing_ms": 1.0057994412454923, "mean_env_wait_ms": 0.8672831688936248, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00540614128112793, "StateBufferConnector_ms": 0.004240274429321289, "ViewRequirementAgentConnector_ms": 0.14230525493621826}, "num_episodes": 18, "episode_return_max": 2036.1802545739513, "episode_return_min": 1273.1200608393194, "episode_return_mean": 1802.9426574032657, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.17148332232784, "num_env_steps_trained_throughput_per_sec": 131.17148332232784, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 19641.421, "restore_workers_time_ms": 0.015, "training_step_time_ms": 19641.37, "sample_time_ms": 1959.541, "learn_time_ms": 17657.207, "learn_throughput": 226.536, "synch_weights_time_ms": 23.518}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "479e5_00000", "date": "2024-08-16_12-24-42", "timestamp": 1723791282, "time_this_iter_s": 30.505733013153076, "time_total_s": 3473.402640581131, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78b9280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3473.402640581131, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 51.348837209302324, "ram_util_percent": 67.57209302325582}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2030205567993186, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.300383205010146, "policy_loss": -0.0025246171103346917, "vf_loss": 9.301913220541818, "vf_explained_var": -0.004894996288592223, "kl": 0.008840810852273626, "entropy": 1.189442108484803, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.807033198062705, "cur_kl_coeff": 0.014062500000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.610518586698664, "policy_loss": -0.002412942807047219, "vf_loss": 9.612895235939632, "vf_explained_var": -0.2926670951818032, "kl": 0.0025804471065364776, "entropy": 0.403597246544071, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 2027.9182454070524, "episode_reward_min": 968.3695228541845, "episode_reward_mean": 1782.7527911366678, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 270.7301557300413, "predator_policy": -10.730329633752465}, "policy_reward_max": {"prey_policy": 842.5973274725795, "predator_policy": 572.1366519233997}, "policy_reward_mean": {"prey_policy": 632.387786662674, "predator_policy": 258.98860890565993}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2012.4030507351063, 1755.214801238403, 1944.1121055803017, 1912.551440121745, 1801.219074238684, 1652.9135317544863, 1948.6108700253428, 1734.009944941892, 1914.5897427395723, 1598.5470759859604, 1969.4622022373087, 1850.4102052871701, 1814.0206377208222, 1877.5321348455118, 1512.0342856999794, 1936.5359497106185, 2027.9182454070524, 1928.2063500690049, 1846.1253909886136, 1772.0990053819603, 1728.8658253831013, 1802.3685568375163, 1461.5043035595936, 1912.104651103637, 1871.0099854526084, 1965.834064579936, 1881.0368552010423, 1615.6388704019314, 1560.098335208475, 1765.1654074086475, 1868.7237922678783, 1742.7618484839877, 1641.9141125218416, 1754.0730159832872, 1894.0849646962583, 1793.7087865172616, 1734.3547931159105, 1816.9861159296581, 1715.4649957592305, 1815.813100561988, 1544.5802501609378, 1925.861534691789, 1835.3281751135607, 1753.721658066874, 1872.4581519350622, 1925.833436181418, 1866.1112356031454, 1273.1200608393194, 1808.7204978194736, 1963.746582982117, 1968.635390292148, 1671.8412338085836, 1752.4440456777913, 1973.5622893843224, 1885.6432489182982, 1514.9526831880114, 1842.9914886684876, 1848.0828285362645, 1826.4805418448364, 1816.8634816810518, 1775.5727074433967, 1844.6498839159435, 1866.9701785007358, 1978.86548840883, 1659.7134532370685, 1872.3207471709356, 1722.5579659699517, 1847.5293513395754, 1809.7931146793198, 1944.1837782914797, 1776.3546368635923, 1803.8624110827366, 1744.3249106669066, 1842.345825681966, 1805.8639408898039, 1400.718217500145, 1806.9378373441348, 1930.2536686559936, 1862.413748926125, 1863.942529510516, 1579.696659596557, 1554.2953663903354, 1912.3931778626638, 1977.0658793998346, 1801.4030183767152, 1565.990751185801, 1394.7835235473742, 968.3695228541845, 1965.2493233713565, 1792.7699207131702, 1877.0725208655208, 1691.6780633871986, 1865.6709187720792, 1499.4990135526148, 1892.0571688487084, 1770.006001551419, 1780.7143356276836, 1625.5830088370903, 1710.9628360550757, 1869.836465715415], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [783.6054415874804, 573.9088025689696, 602.2860418391879, 509.49308572950724, 270.7301557300413, 615.9615589819676, 597.5553138386226, 308.8026229811861, 643.0728535804099, 700.4039639361674, 470.7649860390493, 783.3884473840325, 655.3340398670866, 665.5120658611763, 619.4624977460523, 728.0456408183852, 554.7005115600588, 621.3986673949591, 842.5973274725795, 657.0404954603111, 471.4209990802641, 698.6176849416498, 633.990891803776, 709.934304815199, 822.3746131888407, 766.2577237712939, 611.2595241524241, 546.6089768284972, 734.1557125750315, 447.74158946210525, 616.2389637102434, 838.1000052132615, 618.1988242574439, 836.4572263022407, 659.2217613261059, 539.6229038987868, 634.7047228870043, 641.8653539693382, 359.61236268343055, 515.8889818165703, 733.305641921543, 740.0525306859214, 585.8531342556794, 572.5486948000553, 671.1152687014924, 539.376569207449, 709.5221017714575, 585.1616104691483, 734.470244043959, 677.7273789080481, 645.3792213510711, 718.6860473253288, 529.8999826766441, 540.3238666442389, 547.3116831570841, 710.442666253328, 545.1214074465347, 706.1898253568836, 747.6105658902668, 499.4562004785969, 674.3406080131326, 754.9153312449973, 679.7780634071436, 701.0173671933775, 629.510136524886, 567.0042522098552, 632.1474706792001, 628.2361653426349, 597.4379565445383, 551.7342277035466, 528.4200972526321, 581.1073468382026, 643.5817503314286, 624.9077551241701, 692.6072229310257, 658.8237797500709, 675.2041957490321, 640.2074116964035, 674.1186257981103, 626.05694686169, 760.071701836982, 703.2484545252822, 631.2975628648251, 752.3265837593468, 548.1886768284251, 651.0954778183474, 701.3071238791862, 603.9467296545068, 712.5086303301631, 528.0151418121109, 667.9380034666063, 745.6244203404425, 592.3768392571734, 609.5191991341225, 572.0121991751845, 517.5628275039037, 617.5950687616382, 763.4374916325102, 813.7037259755401, 593.1460884868671, 751.6278808644829, 679.4037294054278, 546.6168967985341, 686.8431701766518, 652.9659315559907, 683.0956605539949, 598.1366883769704, 574.8407226515035, 562.3078309830938, 730.2568878182487, 547.1505889658799, 591.7704640667625, 602.0160794861279, 626.2112545479447, 578.2687419283859, 652.8400939296087, 703.5132073312652, 670.631242148439, 634.343720281953, 660.4500343065641, 650.3554431428448, 736.9488024213276, 570.1956581087, 607.0378496215351, 707.7842958067417, 466.3902472454563, 662.8054501941021, 688.7553644551928, 778.2156007429636, 552.3532240864246, 706.3823198696773, 717.5685835287276, 567.4696455897478, 641.5323778434973, 654.2338908975509, 684.0748581490045, 611.8405184426135, 558.3723437346615, 690.8074240107885, 687.6811392079067, 588.6871843190692, 598.1862131708957, 664.9770544086142, 567.9482809492148, 677.7267018188405, 643.9579530952143, 582.4560789223418, 684.1191374007465, 596.2666256259987, 676.4178598322533, 709.7325798264977, 442.56905434455433, 656.9373620251225, 616.2409624657092, 591.8027711462238, 580.3917567332769, 602.5768793795747, 619.0533763973928, 726.2313061863608, 616.5273837199139, 733.7373099854447, 606.6223152608474, 554.4430551655223, 729.1843037057106, 608.4283691648652, 585.1188426792627, 693.9850170696806, 664.7801453335637, 613.6741791167445, 629.7376032518537, 711.8070661593766, 582.7630530827142, 766.0203928869497, 448.3097380734964, 363.75847643553954, 551.2374159248567, 603.8256654523422, 585.8349934282131, 614.6017072340601, 590.0952159270926, 633.8966383143319, 609.3612308155522, 523.8738942139776, 651.1010574175295, 689.5495761255531, 745.395943359285, 611.5514233411694, 611.7030914214683, 635.4317331203337, 702.7772865188311, 697.4242945306679, 631.8090676865618, 598.4874428546681, 493.1020553528168, 625.5700519012519, 605.6435765445678, 688.5414163312586, 596.575260830545, 633.1919646117035, 645.7321302147816], "policy_predator_policy_reward": [219.3296268782075, 435.55917970044715, 277.3524367606776, 366.0832369090313, 572.1366519233997, 485.283738944894, 526.5365279750905, 479.65697532684504, 207.7991205112767, 249.94313621083418, 183.94580398438944, 214.8142943470158, 297.1532732865442, 330.61149101053434, 268.75224304353935, 117.74956333391424, 325.9045694787297, 412.585994305825, 85.73434583890143, 13.174907214170773, 488.8185944505019, 310.6049237648954, 264.01546256023596, 242.4695461079569, 77.67195535435134, 147.71634540633903, 414.52288981115095, 305.1407440534377, 195.5407727598182, 134.59621090302474, 190.7434152552343, 291.4535655318816, 307.3800799484081, 265.88211489896156, 305.0887251989897, 424.2729596451244, 247.53874785827497, 322.0165662739959, 462.7736783059389, 433.82398257602006, 165.02955153550712, 90.47810124013355, 313.53329790380917, 330.43342987797445, 107.62649798381374, 143.38596766683767, 321.36684254219784, 296.0540963208357, 228.4327525764905, 230.3796099241087, 319.1778072800609, 282.5909886234778, 445.16042639455077, 365.65257948561003, 146.97360578391385, 210.9109152076066, 127.43915709917576, 181.34794530588076, 230.28837179132745, 287.8102692484548, 172.85721175982405, 266.61064124992373, 156.31649365797549, 205.6499242254947, 217.26091823534725, 228.138805551753, 227.49222546605844, 266.1971544953939, 341.9445401094852, 402.96824033868876, 397.4322128385896, 286.7491295878395, 186.51734200624287, 279.3479456540682, 232.99042881704926, 232.56468443150837, 225.61567139133265, 174.43771692246236, 273.74306697419183, 241.89446092799867, 91.99042343242509, -10.730329633752465, 331.32514405886906, 210.91224400874785, 305.2352570359418, 330.8087634308476, 192.834133726336, 255.6336708068458, 375.44782640342504, 256.4865533893637, 275.27964898233506, 236.99136339203676, 289.37717014075804, 374.83802707109226, 89.94131071454659, 93.60372344568597, 252.20620716489452, 175.48173026043222, 271.54627304550405, 285.3504954742089, 263.1193231304693, 274.4844568917679, 231.67146063891911, 206.70970619448198, 184.5905984619408, 231.79185510586316, 376.5732084128205, 424.01166994302844, 318.11889848107376, 274.9596316358826, 208.99955036937388, 167.03207978599346, 244.51049874869264, 370.25365588572475, 295.56753889768686, 321.4064537805843, 242.54688443284033, 209.78920793228806, 180.8661526062691, 341.2035744862681, 156.61939718148423, 231.64906469773845, 396.36312119666, 271.0532549890466, 356.40611508192404, 336.3895203666138, 358.044775593734, 269.2598981658017, 184.85462580341084, 144.29000260426878, 205.22670389497878, 243.14313987755477, 246.8328457793433, 266.72309675736216, 270.2746274251939, 238.9459748678297, 315.5039925241674, 324.0762599778753, 302.82481892330185, 262.8703961494822, 260.3512781577494, 329.1299612158771, 275.9918881231352, 294.9451876017751, 168.2395517177451, 254.40070403510708, 203.32514017878236, 372.4454691800932, 187.17535507021793, 346.00410036133314, 90.67094565032478, 157.74563767876958, 240.76663898203586, 292.99287387126515, 357.6363167784968, 400.4228239979973, 331.34445259005133, 309.4390405591038, 254.8242585176985, 266.3595810865384, 71.89553241115472, 167.44150193910906, 118.77451361727515, 151.89349390182778, 331.53629435935187, 387.3096716591823, 334.2483390974203, 284.05237789916737, 224.1820641323075, 333.80917187580775, 116.21388133358947, 155.20675061012037, 59.094730868802216, 121.35866171812617, 59.71439163140223, -6.340761137613136, 367.6396556453786, 407.9490088454224, 256.12539965793354, 331.94759789408613, 304.6344702024898, 329.1801815331491, 243.76849041404301, 272.9346213416471, 170.98232077600537, 259.74307851123785, 159.4597684953536, 116.78473029462292, 323.4000908727471, 230.4480583367954, 163.83801156391374, 276.9346277702774, 404.8485418248313, 284.2762955953668, 212.1174099429531, 182.25197044831657, 234.69083781074627, 191.15532108252475, 262.80231282901326, 328.11005805991687]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.356298134743088, "mean_inference_ms": 6.2100134353487135, "mean_action_processing_ms": 1.0045143273877044, "mean_env_wait_ms": 0.866256828924005, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01712501049041748, "StateBufferConnector_ms": 0.012364506721496582, "ViewRequirementAgentConnector_ms": 0.5091409683227539}, "num_episodes": 23, "episode_return_max": 2027.9182454070524, "episode_return_min": 968.3695228541845, "episode_return_mean": 1782.7527911366678, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 99.8549630839877, "num_env_steps_trained_throughput_per_sec": 99.8549630839877, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 22369.942, "restore_workers_time_ms": 0.016, "training_step_time_ms": 22369.888, "sample_time_ms": 3446.648, "learn_time_ms": 18899.418, "learn_throughput": 211.647, "synch_weights_time_ms": 22.532}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "479e5_00000", "date": "2024-08-16_12-25-22", "timestamp": 1723791322, "time_this_iter_s": 40.09008479118347, "time_total_s": 3513.4927253723145, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7fe2b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3513.4927253723145, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 49.401754385964914, "ram_util_percent": 71.94912280701753}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4539913793720265, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.293305979834663, "policy_loss": -0.003538886115457567, "vf_loss": 9.295656044773324, "vf_explained_var": -0.03955019062789029, "kl": 0.010567100174571544, "entropy": 1.1585726936658223, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.790998987041453, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.597103453439379, "policy_loss": -0.001292362572778036, "vf_loss": 9.598350522379397, "vf_explained_var": -0.36324502768970673, "kl": 0.006442413136398945, "entropy": 0.38743553642558043, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 2014.0624213246174, "episode_reward_min": 968.3695228541845, "episode_reward_mean": 1780.5555666465132, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 359.61236268343055, "predator_policy": -10.730329633752465}, "policy_reward_max": {"prey_policy": 813.7037259755401, "predator_policy": 483.68436747741475}, "policy_reward_mean": {"prey_policy": 625.8480844760591, "predator_policy": 264.4296988471975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1846.1253909886136, 1772.0990053819603, 1728.8658253831013, 1802.3685568375163, 1461.5043035595936, 1912.104651103637, 1871.0099854526084, 1965.834064579936, 1881.0368552010423, 1615.6388704019314, 1560.098335208475, 1765.1654074086475, 1868.7237922678783, 1742.7618484839877, 1641.9141125218416, 1754.0730159832872, 1894.0849646962583, 1793.7087865172616, 1734.3547931159105, 1816.9861159296581, 1715.4649957592305, 1815.813100561988, 1544.5802501609378, 1925.861534691789, 1835.3281751135607, 1753.721658066874, 1872.4581519350622, 1925.833436181418, 1866.1112356031454, 1273.1200608393194, 1808.7204978194736, 1963.746582982117, 1968.635390292148, 1671.8412338085836, 1752.4440456777913, 1973.5622893843224, 1885.6432489182982, 1514.9526831880114, 1842.9914886684876, 1848.0828285362645, 1826.4805418448364, 1816.8634816810518, 1775.5727074433967, 1844.6498839159435, 1866.9701785007358, 1978.86548840883, 1659.7134532370685, 1872.3207471709356, 1722.5579659699517, 1847.5293513395754, 1809.7931146793198, 1944.1837782914797, 1776.3546368635923, 1803.8624110827366, 1744.3249106669066, 1842.345825681966, 1805.8639408898039, 1400.718217500145, 1806.9378373441348, 1930.2536686559936, 1862.413748926125, 1863.942529510516, 1579.696659596557, 1554.2953663903354, 1912.3931778626638, 1977.0658793998346, 1801.4030183767152, 1565.990751185801, 1394.7835235473742, 968.3695228541845, 1965.2493233713565, 1792.7699207131702, 1877.0725208655208, 1691.6780633871986, 1865.6709187720792, 1499.4990135526148, 1892.0571688487084, 1770.006001551419, 1780.7143356276836, 1625.5830088370903, 1710.9628360550757, 1869.836465715415, 1787.651697186598, 1838.6816229037, 1893.5237783987866, 1796.3414609027839, 1947.4413896081514, 1770.5007110870893, 1833.0448850791558, 1763.5960443501524, 1907.6685889629227, 1765.4352025669702, 1881.564176654923, 1552.3864846664205, 1953.9143332369692, 2014.0624213246174, 1995.2247216051537, 1695.784821204978, 1791.7717628129205, 1781.975096771207], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [634.7047228870043, 641.8653539693382, 359.61236268343055, 515.8889818165703, 733.305641921543, 740.0525306859214, 585.8531342556794, 572.5486948000553, 671.1152687014924, 539.376569207449, 709.5221017714575, 585.1616104691483, 734.470244043959, 677.7273789080481, 645.3792213510711, 718.6860473253288, 529.8999826766441, 540.3238666442389, 547.3116831570841, 710.442666253328, 545.1214074465347, 706.1898253568836, 747.6105658902668, 499.4562004785969, 674.3406080131326, 754.9153312449973, 679.7780634071436, 701.0173671933775, 629.510136524886, 567.0042522098552, 632.1474706792001, 628.2361653426349, 597.4379565445383, 551.7342277035466, 528.4200972526321, 581.1073468382026, 643.5817503314286, 624.9077551241701, 692.6072229310257, 658.8237797500709, 675.2041957490321, 640.2074116964035, 674.1186257981103, 626.05694686169, 760.071701836982, 703.2484545252822, 631.2975628648251, 752.3265837593468, 548.1886768284251, 651.0954778183474, 701.3071238791862, 603.9467296545068, 712.5086303301631, 528.0151418121109, 667.9380034666063, 745.6244203404425, 592.3768392571734, 609.5191991341225, 572.0121991751845, 517.5628275039037, 617.5950687616382, 763.4374916325102, 813.7037259755401, 593.1460884868671, 751.6278808644829, 679.4037294054278, 546.6168967985341, 686.8431701766518, 652.9659315559907, 683.0956605539949, 598.1366883769704, 574.8407226515035, 562.3078309830938, 730.2568878182487, 547.1505889658799, 591.7704640667625, 602.0160794861279, 626.2112545479447, 578.2687419283859, 652.8400939296087, 703.5132073312652, 670.631242148439, 634.343720281953, 660.4500343065641, 650.3554431428448, 736.9488024213276, 570.1956581087, 607.0378496215351, 707.7842958067417, 466.3902472454563, 662.8054501941021, 688.7553644551928, 778.2156007429636, 552.3532240864246, 706.3823198696773, 717.5685835287276, 567.4696455897478, 641.5323778434973, 654.2338908975509, 684.0748581490045, 611.8405184426135, 558.3723437346615, 690.8074240107885, 687.6811392079067, 588.6871843190692, 598.1862131708957, 664.9770544086142, 567.9482809492148, 677.7267018188405, 643.9579530952143, 582.4560789223418, 684.1191374007465, 596.2666256259987, 676.4178598322533, 709.7325798264977, 442.56905434455433, 656.9373620251225, 616.2409624657092, 591.8027711462238, 580.3917567332769, 602.5768793795747, 619.0533763973928, 726.2313061863608, 616.5273837199139, 733.7373099854447, 606.6223152608474, 554.4430551655223, 729.1843037057106, 608.4283691648652, 585.1188426792627, 693.9850170696806, 664.7801453335637, 613.6741791167445, 629.7376032518537, 711.8070661593766, 582.7630530827142, 766.0203928869497, 448.3097380734964, 363.75847643553954, 551.2374159248567, 603.8256654523422, 585.8349934282131, 614.6017072340601, 590.0952159270926, 633.8966383143319, 609.3612308155522, 523.8738942139776, 651.1010574175295, 689.5495761255531, 745.395943359285, 611.5514233411694, 611.7030914214683, 635.4317331203337, 702.7772865188311, 697.4242945306679, 631.8090676865618, 598.4874428546681, 493.1020553528168, 625.5700519012519, 605.6435765445678, 688.5414163312586, 596.575260830545, 633.1919646117035, 645.7321302147816, 539.0510093985826, 545.1466862769825, 432.4498452652608, 594.928944407388, 508.42060711212, 680.4857203007167, 492.06061752375103, 570.1704497214743, 604.9981425132722, 618.2956077871314, 516.5965276827988, 591.8143961599303, 586.0613696728075, 704.9520404329436, 565.8984445498078, 536.0269143993311, 563.6525107975278, 709.1473582881094, 573.588188285688, 684.4282989484203, 614.5223773362039, 573.3439466591844, 598.8180156323336, 559.1666456930847, 582.8209593335802, 631.1753286902225, 740.7922334979542, 705.1827536021988, 560.5760568203261, 605.3357561755379, 612.639225360138, 631.6282862050964, 552.5153154760492, 647.9662340035143, 590.8046069195462, 620.8643674523946], "policy_predator_policy_reward": [247.53874785827497, 322.0165662739959, 462.7736783059389, 433.82398257602006, 165.02955153550712, 90.47810124013355, 313.53329790380917, 330.43342987797445, 107.62649798381374, 143.38596766683767, 321.36684254219784, 296.0540963208357, 228.4327525764905, 230.3796099241087, 319.1778072800609, 282.5909886234778, 445.16042639455077, 365.65257948561003, 146.97360578391385, 210.9109152076066, 127.43915709917576, 181.34794530588076, 230.28837179132745, 287.8102692484548, 172.85721175982405, 266.61064124992373, 156.31649365797549, 205.6499242254947, 217.26091823534725, 228.138805551753, 227.49222546605844, 266.1971544953939, 341.9445401094852, 402.96824033868876, 397.4322128385896, 286.7491295878395, 186.51734200624287, 279.3479456540682, 232.99042881704926, 232.56468443150837, 225.61567139133265, 174.43771692246236, 273.74306697419183, 241.89446092799867, 91.99042343242509, -10.730329633752465, 331.32514405886906, 210.91224400874785, 305.2352570359418, 330.8087634308476, 192.834133726336, 255.6336708068458, 375.44782640342504, 256.4865533893637, 275.27964898233506, 236.99136339203676, 289.37717014075804, 374.83802707109226, 89.94131071454659, 93.60372344568597, 252.20620716489452, 175.48173026043222, 271.54627304550405, 285.3504954742089, 263.1193231304693, 274.4844568917679, 231.67146063891911, 206.70970619448198, 184.5905984619408, 231.79185510586316, 376.5732084128205, 424.01166994302844, 318.11889848107376, 274.9596316358826, 208.99955036937388, 167.03207978599346, 244.51049874869264, 370.25365588572475, 295.56753889768686, 321.4064537805843, 242.54688443284033, 209.78920793228806, 180.8661526062691, 341.2035744862681, 156.61939718148423, 231.64906469773845, 396.36312119666, 271.0532549890466, 356.40611508192404, 336.3895203666138, 358.044775593734, 269.2598981658017, 184.85462580341084, 144.29000260426878, 205.22670389497878, 243.14313987755477, 246.8328457793433, 266.72309675736216, 270.2746274251939, 238.9459748678297, 315.5039925241674, 324.0762599778753, 302.82481892330185, 262.8703961494822, 260.3512781577494, 329.1299612158771, 275.9918881231352, 294.9451876017751, 168.2395517177451, 254.40070403510708, 203.32514017878236, 372.4454691800932, 187.17535507021793, 346.00410036133314, 90.67094565032478, 157.74563767876958, 240.76663898203586, 292.99287387126515, 357.6363167784968, 400.4228239979973, 331.34445259005133, 309.4390405591038, 254.8242585176985, 266.3595810865384, 71.89553241115472, 167.44150193910906, 118.77451361727515, 151.89349390182778, 331.53629435935187, 387.3096716591823, 334.2483390974203, 284.05237789916737, 224.1820641323075, 333.80917187580775, 116.21388133358947, 155.20675061012037, 59.094730868802216, 121.35866171812617, 59.71439163140223, -6.340761137613136, 367.6396556453786, 407.9490088454224, 256.12539965793354, 331.94759789408613, 304.6344702024898, 329.1801815331491, 243.76849041404301, 272.9346213416471, 170.98232077600537, 259.74307851123785, 159.4597684953536, 116.78473029462292, 323.4000908727471, 230.4480583367954, 163.83801156391374, 276.9346277702774, 404.8485418248313, 284.2762955953668, 212.1174099429531, 182.25197044831657, 234.69083781074627, 191.15532108252475, 262.80231282901326, 328.11005805991687, 389.5277582885869, 313.9262432224463, 327.61846575363506, 483.68436747741475, 378.68268861919313, 325.93476236675804, 325.35420360040433, 408.75619005715356, 398.24125259758796, 325.9063867101594, 261.8447962419704, 400.24499100238904, 243.92397801150685, 298.1074969618991, 368.4894265821755, 293.1812588188406, 289.6465153856795, 345.222204491606, 290.1315406278108, 217.28717470504924, 429.026261686221, 264.67159097331245, 197.49672074812946, 196.9051025928716, 329.1670326128924, 410.75101260027265, 266.26673173070907, 301.82070249375465, 415.22623829840796, 414.08667031088135, 299.65653261292323, 151.86077702682047, 347.9017202893658, 243.38849304399227, 226.44108242689876, 343.8650399723697]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3579825870535065, "mean_inference_ms": 6.216207270342178, "mean_action_processing_ms": 1.0055694063927374, "mean_env_wait_ms": 0.8672292978625982, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018290400505065918, "StateBufferConnector_ms": 0.014050126075744629, "ViewRequirementAgentConnector_ms": 0.5607707500457764}, "num_episodes": 18, "episode_return_max": 2014.0624213246174, "episode_return_min": 968.3695228541845, "episode_return_mean": 1780.5555666465132, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 158.98002262685762, "num_env_steps_trained_throughput_per_sec": 158.98002262685762, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 23542.049, "restore_workers_time_ms": 0.014, "training_step_time_ms": 23542.002, "sample_time_ms": 3722.796, "learn_time_ms": 19794.892, "learn_throughput": 202.072, "synch_weights_time_ms": 22.985}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "479e5_00000", "date": "2024-08-16_12-25-48", "timestamp": 1723791348, "time_this_iter_s": 25.16680073738098, "time_total_s": 3538.6595261096954, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7daa940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3538.6595261096954, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 36.14722222222222, "ram_util_percent": 71.57222222222224}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5313100460029783, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.400419615690039, "policy_loss": -0.00612138124495725, "vf_loss": 9.405315308343797, "vf_explained_var": -0.07941568355080943, "kl": 0.01089499516894032, "entropy": 1.159397460985436, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9019461435852227, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.594978822980607, "policy_loss": -0.0004165484189307169, "vf_loss": 9.595347706224553, "vf_explained_var": -0.4486713188981253, "kl": 0.006780099874148613, "entropy": 0.381917452780658, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 2014.0624213246174, "episode_reward_min": 968.3695228541845, "episode_reward_mean": 1788.5431302986608, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 363.75847643553954, "predator_policy": -10.730329633752465}, "policy_reward_max": {"prey_policy": 813.7037259755401, "predator_policy": 483.68436747741475}, "policy_reward_mean": {"prey_policy": 620.4045086510542, "predator_policy": 273.8670564982761}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1544.5802501609378, 1925.861534691789, 1835.3281751135607, 1753.721658066874, 1872.4581519350622, 1925.833436181418, 1866.1112356031454, 1273.1200608393194, 1808.7204978194736, 1963.746582982117, 1968.635390292148, 1671.8412338085836, 1752.4440456777913, 1973.5622893843224, 1885.6432489182982, 1514.9526831880114, 1842.9914886684876, 1848.0828285362645, 1826.4805418448364, 1816.8634816810518, 1775.5727074433967, 1844.6498839159435, 1866.9701785007358, 1978.86548840883, 1659.7134532370685, 1872.3207471709356, 1722.5579659699517, 1847.5293513395754, 1809.7931146793198, 1944.1837782914797, 1776.3546368635923, 1803.8624110827366, 1744.3249106669066, 1842.345825681966, 1805.8639408898039, 1400.718217500145, 1806.9378373441348, 1930.2536686559936, 1862.413748926125, 1863.942529510516, 1579.696659596557, 1554.2953663903354, 1912.3931778626638, 1977.0658793998346, 1801.4030183767152, 1565.990751185801, 1394.7835235473742, 968.3695228541845, 1965.2493233713565, 1792.7699207131702, 1877.0725208655208, 1691.6780633871986, 1865.6709187720792, 1499.4990135526148, 1892.0571688487084, 1770.006001551419, 1780.7143356276836, 1625.5830088370903, 1710.9628360550757, 1869.836465715415, 1787.651697186598, 1838.6816229037, 1893.5237783987866, 1796.3414609027839, 1947.4413896081514, 1770.5007110870893, 1833.0448850791558, 1763.5960443501524, 1907.6685889629227, 1765.4352025669702, 1881.564176654923, 1552.3864846664205, 1953.9143332369692, 2014.0624213246174, 1995.2247216051537, 1695.784821204978, 1791.7717628129205, 1781.975096771207, 1776.5384502843567, 1617.7967381810997, 1961.7381563999377, 1915.2538846539783, 1884.1451925490333, 1661.9120890308288, 1912.5332335799353, 1496.5520049165705, 1770.3273672041676, 1735.8169028779405, 1866.3099945818694, 1651.3805166064403, 1875.8333423619003, 1966.833307670992, 2001.150005751651, 1831.5009759901025, 1897.3465613876842, 1884.4472555346297, 1804.2941576634505, 1496.275371148705, 1782.7712946439956, 1967.7363395398659], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [760.071701836982, 703.2484545252822, 631.2975628648251, 752.3265837593468, 548.1886768284251, 651.0954778183474, 701.3071238791862, 603.9467296545068, 712.5086303301631, 528.0151418121109, 667.9380034666063, 745.6244203404425, 592.3768392571734, 609.5191991341225, 572.0121991751845, 517.5628275039037, 617.5950687616382, 763.4374916325102, 813.7037259755401, 593.1460884868671, 751.6278808644829, 679.4037294054278, 546.6168967985341, 686.8431701766518, 652.9659315559907, 683.0956605539949, 598.1366883769704, 574.8407226515035, 562.3078309830938, 730.2568878182487, 547.1505889658799, 591.7704640667625, 602.0160794861279, 626.2112545479447, 578.2687419283859, 652.8400939296087, 703.5132073312652, 670.631242148439, 634.343720281953, 660.4500343065641, 650.3554431428448, 736.9488024213276, 570.1956581087, 607.0378496215351, 707.7842958067417, 466.3902472454563, 662.8054501941021, 688.7553644551928, 778.2156007429636, 552.3532240864246, 706.3823198696773, 717.5685835287276, 567.4696455897478, 641.5323778434973, 654.2338908975509, 684.0748581490045, 611.8405184426135, 558.3723437346615, 690.8074240107885, 687.6811392079067, 588.6871843190692, 598.1862131708957, 664.9770544086142, 567.9482809492148, 677.7267018188405, 643.9579530952143, 582.4560789223418, 684.1191374007465, 596.2666256259987, 676.4178598322533, 709.7325798264977, 442.56905434455433, 656.9373620251225, 616.2409624657092, 591.8027711462238, 580.3917567332769, 602.5768793795747, 619.0533763973928, 726.2313061863608, 616.5273837199139, 733.7373099854447, 606.6223152608474, 554.4430551655223, 729.1843037057106, 608.4283691648652, 585.1188426792627, 693.9850170696806, 664.7801453335637, 613.6741791167445, 629.7376032518537, 711.8070661593766, 582.7630530827142, 766.0203928869497, 448.3097380734964, 363.75847643553954, 551.2374159248567, 603.8256654523422, 585.8349934282131, 614.6017072340601, 590.0952159270926, 633.8966383143319, 609.3612308155522, 523.8738942139776, 651.1010574175295, 689.5495761255531, 745.395943359285, 611.5514233411694, 611.7030914214683, 635.4317331203337, 702.7772865188311, 697.4242945306679, 631.8090676865618, 598.4874428546681, 493.1020553528168, 625.5700519012519, 605.6435765445678, 688.5414163312586, 596.575260830545, 633.1919646117035, 645.7321302147816, 539.0510093985826, 545.1466862769825, 432.4498452652608, 594.928944407388, 508.42060711212, 680.4857203007167, 492.06061752375103, 570.1704497214743, 604.9981425132722, 618.2956077871314, 516.5965276827988, 591.8143961599303, 586.0613696728075, 704.9520404329436, 565.8984445498078, 536.0269143993311, 563.6525107975278, 709.1473582881094, 573.588188285688, 684.4282989484203, 614.5223773362039, 573.3439466591844, 598.8180156323336, 559.1666456930847, 582.8209593335802, 631.1753286902225, 740.7922334979542, 705.1827536021988, 560.5760568203261, 605.3357561755379, 612.639225360138, 631.6282862050964, 552.5153154760492, 647.9662340035143, 590.8046069195462, 620.8643674523946, 522.0034725677727, 640.8230711849345, 608.9267836315624, 459.45288348554186, 717.5830593859533, 549.776579697662, 664.2953305360605, 509.32298727540535, 604.6938298578241, 706.2228087855059, 488.14567100911677, 635.4267868562281, 672.1725085377122, 669.7791707969473, 600.6930221918085, 555.5202626428091, 746.1339906013081, 694.8187868946236, 505.6285026509157, 566.056985838566, 700.1689164637825, 472.30144213939207, 631.852745856134, 602.1155641833608, 496.7078381263972, 671.9111581421429, 664.8898804633158, 518.3342221547748, 633.5143436948521, 736.1052985516925, 670.044193985178, 692.4370379288176, 690.0176370289893, 696.598397546604, 591.0481527421986, 565.7915772954375, 462.94548863908557, 524.5466834569377, 468.3110394500444, 586.5355291121853, 668.2045855612814, 586.7474893820037, 594.598535110554, 520.8633574527634], "policy_predator_policy_reward": [91.99042343242509, -10.730329633752465, 331.32514405886906, 210.91224400874785, 305.2352570359418, 330.8087634308476, 192.834133726336, 255.6336708068458, 375.44782640342504, 256.4865533893637, 275.27964898233506, 236.99136339203676, 289.37717014075804, 374.83802707109226, 89.94131071454659, 93.60372344568597, 252.20620716489452, 175.48173026043222, 271.54627304550405, 285.3504954742089, 263.1193231304693, 274.4844568917679, 231.67146063891911, 206.70970619448198, 184.5905984619408, 231.79185510586316, 376.5732084128205, 424.01166994302844, 318.11889848107376, 274.9596316358826, 208.99955036937388, 167.03207978599346, 244.51049874869264, 370.25365588572475, 295.56753889768686, 321.4064537805843, 242.54688443284033, 209.78920793228806, 180.8661526062691, 341.2035744862681, 156.61939718148423, 231.64906469773845, 396.36312119666, 271.0532549890466, 356.40611508192404, 336.3895203666138, 358.044775593734, 269.2598981658017, 184.85462580341084, 144.29000260426878, 205.22670389497878, 243.14313987755477, 246.8328457793433, 266.72309675736216, 270.2746274251939, 238.9459748678297, 315.5039925241674, 324.0762599778753, 302.82481892330185, 262.8703961494822, 260.3512781577494, 329.1299612158771, 275.9918881231352, 294.9451876017751, 168.2395517177451, 254.40070403510708, 203.32514017878236, 372.4454691800932, 187.17535507021793, 346.00410036133314, 90.67094565032478, 157.74563767876958, 240.76663898203586, 292.99287387126515, 357.6363167784968, 400.4228239979973, 331.34445259005133, 309.4390405591038, 254.8242585176985, 266.3595810865384, 71.89553241115472, 167.44150193910906, 118.77451361727515, 151.89349390182778, 331.53629435935187, 387.3096716591823, 334.2483390974203, 284.05237789916737, 224.1820641323075, 333.80917187580775, 116.21388133358947, 155.20675061012037, 59.094730868802216, 121.35866171812617, 59.71439163140223, -6.340761137613136, 367.6396556453786, 407.9490088454224, 256.12539965793354, 331.94759789408613, 304.6344702024898, 329.1801815331491, 243.76849041404301, 272.9346213416471, 170.98232077600537, 259.74307851123785, 159.4597684953536, 116.78473029462292, 323.4000908727471, 230.4480583367954, 163.83801156391374, 276.9346277702774, 404.8485418248313, 284.2762955953668, 212.1174099429531, 182.25197044831657, 234.69083781074627, 191.15532108252475, 262.80231282901326, 328.11005805991687, 389.5277582885869, 313.9262432224463, 327.61846575363506, 483.68436747741475, 378.68268861919313, 325.93476236675804, 325.35420360040433, 408.75619005715356, 398.24125259758796, 325.9063867101594, 261.8447962419704, 400.24499100238904, 243.92397801150685, 298.1074969618991, 368.4894265821755, 293.1812588188406, 289.6465153856795, 345.222204491606, 290.1315406278108, 217.28717470504924, 429.026261686221, 264.67159097331245, 197.49672074812946, 196.9051025928716, 329.1670326128924, 410.75101260027265, 266.26673173070907, 301.82070249375465, 415.22623829840796, 414.08667031088135, 299.65653261292323, 151.86077702682047, 347.9017202893658, 243.38849304399227, 226.44108242689876, 343.8650399723697, 300.1541115527484, 313.55779497890217, 320.07183372851046, 229.34523733548536, 389.8256653247031, 304.5528519916187, 400.128316093543, 341.50725074896707, 244.10978703665012, 329.1187668690515, 337.6502974759714, 200.68933368951318, 285.4630166312272, 285.11853761404655, 180.03552963411207, 160.30319044783977, 55.89180391046069, 273.4827857977737, 371.3472736901264, 292.7841406983324, 247.06114514684978, 446.7784908318444, 227.63280380165418, 189.7794027652917, 326.5376481151981, 380.67669797816313, 410.09767258761116, 373.51153246528867, 337.9553094519898, 293.57505405311633, 250.12182307173484, 218.89792100437018, 254.56999990264632, 256.16052690944923, 337.3936375012649, 390.2138879957271, 433.11446536876286, 383.6875201986647, 181.29203290588498, 260.13676968059116, 323.5654575725724, 204.25376212813686, 447.82241828110847, 404.4520286954402]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3664238855041484, "mean_inference_ms": 6.2415987676325395, "mean_action_processing_ms": 1.00981982118168, "mean_env_wait_ms": 0.8711547862790023, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02017998695373535, "StateBufferConnector_ms": 0.015203595161437988, "ViewRequirementAgentConnector_ms": 0.618160605430603}, "num_episodes": 22, "episode_return_max": 2014.0624213246174, "episode_return_min": 968.3695228541845, "episode_return_mean": 1788.5431302986608, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.81265336583226, "num_env_steps_trained_throughput_per_sec": 195.81265336583226, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 24342.806, "restore_workers_time_ms": 0.014, "training_step_time_ms": 24342.757, "sample_time_ms": 4087.287, "learn_time_ms": 20230.667, "learn_throughput": 197.72, "synch_weights_time_ms": 23.449}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "479e5_00000", "date": "2024-08-16_12-26-08", "timestamp": 1723791368, "time_this_iter_s": 20.43306803703308, "time_total_s": 3559.0925941467285, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7891e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3559.0925941467285, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 34.07241379310345, "ram_util_percent": 61.886206896551734}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.357688384018247, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.34226107269368, "policy_loss": -0.004035907971953589, "vf_loss": 9.345145961721107, "vf_explained_var": -0.03290244274669223, "kl": 0.010231081503844795, "entropy": 1.1656652947582264, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6453412299749082, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.59306580881593, "policy_loss": -0.0023101249163990064, "vf_loss": 9.595332024084827, "vf_explained_var": -0.36906917498855996, "kl": 0.006241931486695735, "entropy": 0.3554540319575204, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 2014.0624213246174, "episode_reward_min": 968.3695228541845, "episode_reward_mean": 1787.766663042402, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 363.75847643553954, "predator_policy": -6.340761137613136}, "policy_reward_max": {"prey_policy": 778.2156007429636, "predator_policy": 483.68436747741475}, "policy_reward_mean": {"prey_policy": 611.7301823594338, "predator_policy": 282.15314916176686}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1826.4805418448364, 1816.8634816810518, 1775.5727074433967, 1844.6498839159435, 1866.9701785007358, 1978.86548840883, 1659.7134532370685, 1872.3207471709356, 1722.5579659699517, 1847.5293513395754, 1809.7931146793198, 1944.1837782914797, 1776.3546368635923, 1803.8624110827366, 1744.3249106669066, 1842.345825681966, 1805.8639408898039, 1400.718217500145, 1806.9378373441348, 1930.2536686559936, 1862.413748926125, 1863.942529510516, 1579.696659596557, 1554.2953663903354, 1912.3931778626638, 1977.0658793998346, 1801.4030183767152, 1565.990751185801, 1394.7835235473742, 968.3695228541845, 1965.2493233713565, 1792.7699207131702, 1877.0725208655208, 1691.6780633871986, 1865.6709187720792, 1499.4990135526148, 1892.0571688487084, 1770.006001551419, 1780.7143356276836, 1625.5830088370903, 1710.9628360550757, 1869.836465715415, 1787.651697186598, 1838.6816229037, 1893.5237783987866, 1796.3414609027839, 1947.4413896081514, 1770.5007110870893, 1833.0448850791558, 1763.5960443501524, 1907.6685889629227, 1765.4352025669702, 1881.564176654923, 1552.3864846664205, 1953.9143332369692, 2014.0624213246174, 1995.2247216051537, 1695.784821204978, 1791.7717628129205, 1781.975096771207, 1776.5384502843567, 1617.7967381810997, 1961.7381563999377, 1915.2538846539783, 1884.1451925490333, 1661.9120890308288, 1912.5332335799353, 1496.5520049165705, 1770.3273672041676, 1735.8169028779405, 1866.3099945818694, 1651.3805166064403, 1875.8333423619003, 1966.833307670992, 2001.150005751651, 1831.5009759901025, 1897.3465613876842, 1884.4472555346297, 1804.2941576634505, 1496.275371148705, 1782.7712946439956, 1967.7363395398659, 1827.2436902112916, 1929.8876859765871, 1713.2241710095864, 1702.45325901181, 1998.1198290102495, 1839.0087872366362, 1867.7864251012447, 1833.168404718611, 1693.7235442847416, 1933.0653373180157, 1371.6631705664654, 1638.1444759762549, 1682.1570588083969, 1885.1764619556807, 1552.7391598832514, 1992.0401977572283, 1860.7489459023113, 1829.6374615133252], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [703.5132073312652, 670.631242148439, 634.343720281953, 660.4500343065641, 650.3554431428448, 736.9488024213276, 570.1956581087, 607.0378496215351, 707.7842958067417, 466.3902472454563, 662.8054501941021, 688.7553644551928, 778.2156007429636, 552.3532240864246, 706.3823198696773, 717.5685835287276, 567.4696455897478, 641.5323778434973, 654.2338908975509, 684.0748581490045, 611.8405184426135, 558.3723437346615, 690.8074240107885, 687.6811392079067, 588.6871843190692, 598.1862131708957, 664.9770544086142, 567.9482809492148, 677.7267018188405, 643.9579530952143, 582.4560789223418, 684.1191374007465, 596.2666256259987, 676.4178598322533, 709.7325798264977, 442.56905434455433, 656.9373620251225, 616.2409624657092, 591.8027711462238, 580.3917567332769, 602.5768793795747, 619.0533763973928, 726.2313061863608, 616.5273837199139, 733.7373099854447, 606.6223152608474, 554.4430551655223, 729.1843037057106, 608.4283691648652, 585.1188426792627, 693.9850170696806, 664.7801453335637, 613.6741791167445, 629.7376032518537, 711.8070661593766, 582.7630530827142, 766.0203928869497, 448.3097380734964, 363.75847643553954, 551.2374159248567, 603.8256654523422, 585.8349934282131, 614.6017072340601, 590.0952159270926, 633.8966383143319, 609.3612308155522, 523.8738942139776, 651.1010574175295, 689.5495761255531, 745.395943359285, 611.5514233411694, 611.7030914214683, 635.4317331203337, 702.7772865188311, 697.4242945306679, 631.8090676865618, 598.4874428546681, 493.1020553528168, 625.5700519012519, 605.6435765445678, 688.5414163312586, 596.575260830545, 633.1919646117035, 645.7321302147816, 539.0510093985826, 545.1466862769825, 432.4498452652608, 594.928944407388, 508.42060711212, 680.4857203007167, 492.06061752375103, 570.1704497214743, 604.9981425132722, 618.2956077871314, 516.5965276827988, 591.8143961599303, 586.0613696728075, 704.9520404329436, 565.8984445498078, 536.0269143993311, 563.6525107975278, 709.1473582881094, 573.588188285688, 684.4282989484203, 614.5223773362039, 573.3439466591844, 598.8180156323336, 559.1666456930847, 582.8209593335802, 631.1753286902225, 740.7922334979542, 705.1827536021988, 560.5760568203261, 605.3357561755379, 612.639225360138, 631.6282862050964, 552.5153154760492, 647.9662340035143, 590.8046069195462, 620.8643674523946, 522.0034725677727, 640.8230711849345, 608.9267836315624, 459.45288348554186, 717.5830593859533, 549.776579697662, 664.2953305360605, 509.32298727540535, 604.6938298578241, 706.2228087855059, 488.14567100911677, 635.4267868562281, 672.1725085377122, 669.7791707969473, 600.6930221918085, 555.5202626428091, 746.1339906013081, 694.8187868946236, 505.6285026509157, 566.056985838566, 700.1689164637825, 472.30144213939207, 631.852745856134, 602.1155641833608, 496.7078381263972, 671.9111581421429, 664.8898804633158, 518.3342221547748, 633.5143436948521, 736.1052985516925, 670.044193985178, 692.4370379288176, 690.0176370289893, 696.598397546604, 591.0481527421986, 565.7915772954375, 462.94548863908557, 524.5466834569377, 468.3110394500444, 586.5355291121853, 668.2045855612814, 586.7474893820037, 594.598535110554, 520.8633574527634, 608.053069243498, 625.6013891446527, 535.2220314697186, 754.774977001237, 580.790656627662, 648.6992742421875, 666.6043384596095, 509.81010571667196, 627.495241421286, 564.1453183276315, 474.4811101645613, 595.8052630368528, 519.7774100607159, 564.3045114843353, 496.3485067426613, 646.2556238814195, 586.848763984629, 452.58487337297976, 574.9403939082482, 580.3994586032186, 640.1302661803957, 579.1045815431615, 576.3071853412818, 598.5207040540822, 719.1023318035776, 676.5046558366485, 637.4824207277297, 586.7085395858588, 462.53497260779477, 730.0025833954012, 638.3447767109803, 544.3080342651156, 623.5550371731729, 606.7988348360434, 562.0393347991117, 620.0227350745577], "policy_predator_policy_reward": [242.54688443284033, 209.78920793228806, 180.8661526062691, 341.2035744862681, 156.61939718148423, 231.64906469773845, 396.36312119666, 271.0532549890466, 356.40611508192404, 336.3895203666138, 358.044775593734, 269.2598981658017, 184.85462580341084, 144.29000260426878, 205.22670389497878, 243.14313987755477, 246.8328457793433, 266.72309675736216, 270.2746274251939, 238.9459748678297, 315.5039925241674, 324.0762599778753, 302.82481892330185, 262.8703961494822, 260.3512781577494, 329.1299612158771, 275.9918881231352, 294.9451876017751, 168.2395517177451, 254.40070403510708, 203.32514017878236, 372.4454691800932, 187.17535507021793, 346.00410036133314, 90.67094565032478, 157.74563767876958, 240.76663898203586, 292.99287387126515, 357.6363167784968, 400.4228239979973, 331.34445259005133, 309.4390405591038, 254.8242585176985, 266.3595810865384, 71.89553241115472, 167.44150193910906, 118.77451361727515, 151.89349390182778, 331.53629435935187, 387.3096716591823, 334.2483390974203, 284.05237789916737, 224.1820641323075, 333.80917187580775, 116.21388133358947, 155.20675061012037, 59.094730868802216, 121.35866171812617, 59.71439163140223, -6.340761137613136, 367.6396556453786, 407.9490088454224, 256.12539965793354, 331.94759789408613, 304.6344702024898, 329.1801815331491, 243.76849041404301, 272.9346213416471, 170.98232077600537, 259.74307851123785, 159.4597684953536, 116.78473029462292, 323.4000908727471, 230.4480583367954, 163.83801156391374, 276.9346277702774, 404.8485418248313, 284.2762955953668, 212.1174099429531, 182.25197044831657, 234.69083781074627, 191.15532108252475, 262.80231282901326, 328.11005805991687, 389.5277582885869, 313.9262432224463, 327.61846575363506, 483.68436747741475, 378.68268861919313, 325.93476236675804, 325.35420360040433, 408.75619005715356, 398.24125259758796, 325.9063867101594, 261.8447962419704, 400.24499100238904, 243.92397801150685, 298.1074969618991, 368.4894265821755, 293.1812588188406, 289.6465153856795, 345.222204491606, 290.1315406278108, 217.28717470504924, 429.026261686221, 264.67159097331245, 197.49672074812946, 196.9051025928716, 329.1670326128924, 410.75101260027265, 266.26673173070907, 301.82070249375465, 415.22623829840796, 414.08667031088135, 299.65653261292323, 151.86077702682047, 347.9017202893658, 243.38849304399227, 226.44108242689876, 343.8650399723697, 300.1541115527484, 313.55779497890217, 320.07183372851046, 229.34523733548536, 389.8256653247031, 304.5528519916187, 400.128316093543, 341.50725074896707, 244.10978703665012, 329.1187668690515, 337.6502974759714, 200.68933368951318, 285.4630166312272, 285.11853761404655, 180.03552963411207, 160.30319044783977, 55.89180391046069, 273.4827857977737, 371.3472736901264, 292.7841406983324, 247.06114514684978, 446.7784908318444, 227.63280380165418, 189.7794027652917, 326.5376481151981, 380.67669797816313, 410.09767258761116, 373.51153246528867, 337.9553094519898, 293.57505405311633, 250.12182307173484, 218.89792100437018, 254.56999990264632, 256.16052690944923, 337.3936375012649, 390.2138879957271, 433.11446536876286, 383.6875201986647, 181.29203290588498, 260.13676968059116, 323.5654575725724, 204.25376212813686, 447.82241828110847, 404.4520286954402, 354.5676310910769, 239.0216007320629, 248.90364714932366, 390.98703035631206, 236.77778020951084, 246.9564599302283, 93.73347361857145, 432.3053412169554, 376.2192941905352, 430.25997507079916, 348.2465719804042, 420.4758420548192, 353.03301920772157, 430.67148434847144, 380.516324166982, 310.0479499275469, 470.51553613213224, 183.77437079499956, 375.57676691999296, 402.1487178865566, 100.2636352987041, 52.164687544200774, 308.8009637179785, 154.51562286291005, 142.818517679361, 143.73155348881147, 316.9202710895617, 344.0652305525304, 200.04067814971228, 160.16092573034447, 415.8183846097512, 393.5690021713823, 313.97016478629996, 316.4249091067957, 272.43708808891114, 375.1383035507446]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.376454855883182, "mean_inference_ms": 6.269583601822324, "mean_action_processing_ms": 1.0144004982399495, "mean_env_wait_ms": 0.8745530827096626, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.024808526039123535, "StateBufferConnector_ms": 0.021158933639526367, "ViewRequirementAgentConnector_ms": 0.665803074836731}, "num_episodes": 18, "episode_return_max": 2014.0624213246174, "episode_return_min": 968.3695228541845, "episode_return_mean": 1787.766663042402, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 191.13826859120994, "num_env_steps_trained_throughput_per_sec": 191.13826859120994, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 25201.264, "restore_workers_time_ms": 0.015, "training_step_time_ms": 25201.214, "sample_time_ms": 4282.337, "learn_time_ms": 20893.682, "learn_throughput": 191.445, "synch_weights_time_ms": 23.844}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "479e5_00000", "date": "2024-08-16_12-26-29", "timestamp": 1723791389, "time_this_iter_s": 20.931885719299316, "time_total_s": 3580.024479866028, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a789be50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3580.024479866028, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 36.83793103448276, "ram_util_percent": 62.98620689655173}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2563265054629595, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.40280177555387, "policy_loss": -0.002850033371418557, "vf_loss": 9.404923036867979, "vf_explained_var": -0.011303127726549825, "kl": 0.006477890687551696, "entropy": 1.1693844173951125, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.144693154498698, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.427821663952379, "policy_loss": -0.0021061411864129165, "vf_loss": 9.429892884612714, "vf_explained_var": -0.48057808191687973, "kl": 0.004962405216346324, "entropy": 0.33392386482190833, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 2020.36391326778, "episode_reward_min": 968.3695228541845, "episode_reward_mean": 1794.8841261409655, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 363.75847643553954, "predator_policy": -6.340761137613136}, "policy_reward_max": {"prey_policy": 766.0203928869497, "predator_policy": 540.0598293359242}, "policy_reward_mean": {"prey_policy": 598.0326113567156, "predator_policy": 299.40945171376706}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1554.2953663903354, 1912.3931778626638, 1977.0658793998346, 1801.4030183767152, 1565.990751185801, 1394.7835235473742, 968.3695228541845, 1965.2493233713565, 1792.7699207131702, 1877.0725208655208, 1691.6780633871986, 1865.6709187720792, 1499.4990135526148, 1892.0571688487084, 1770.006001551419, 1780.7143356276836, 1625.5830088370903, 1710.9628360550757, 1869.836465715415, 1787.651697186598, 1838.6816229037, 1893.5237783987866, 1796.3414609027839, 1947.4413896081514, 1770.5007110870893, 1833.0448850791558, 1763.5960443501524, 1907.6685889629227, 1765.4352025669702, 1881.564176654923, 1552.3864846664205, 1953.9143332369692, 2014.0624213246174, 1995.2247216051537, 1695.784821204978, 1791.7717628129205, 1781.975096771207, 1776.5384502843567, 1617.7967381810997, 1961.7381563999377, 1915.2538846539783, 1884.1451925490333, 1661.9120890308288, 1912.5332335799353, 1496.5520049165705, 1770.3273672041676, 1735.8169028779405, 1866.3099945818694, 1651.3805166064403, 1875.8333423619003, 1966.833307670992, 2001.150005751651, 1831.5009759901025, 1897.3465613876842, 1884.4472555346297, 1804.2941576634505, 1496.275371148705, 1782.7712946439956, 1967.7363395398659, 1827.2436902112916, 1929.8876859765871, 1713.2241710095864, 1702.45325901181, 1998.1198290102495, 1839.0087872366362, 1867.7864251012447, 1833.168404718611, 1693.7235442847416, 1933.0653373180157, 1371.6631705664654, 1638.1444759762549, 1682.1570588083969, 1885.1764619556807, 1552.7391598832514, 1992.0401977572283, 1860.7489459023113, 1829.6374615133252, 1993.9657970993028, 1942.050507400357, 1807.0499502753628, 1813.9353378848448, 1953.784382404492, 1865.3968716248837, 1731.1731459729717, 1740.1059978850571, 1885.6154124508653, 1594.2220683961743, 1955.5006358994992, 1567.6584904894592, 1673.992687751124, 1868.57150905551, 1890.6602628768726, 2020.36391326778, 1860.9176458446389, 1704.6778974168005, 1717.3652371660633, 1785.3441702737773, 1851.7103869753553, 1917.1605484993784, 1952.7385321474012], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [554.4430551655223, 729.1843037057106, 608.4283691648652, 585.1188426792627, 693.9850170696806, 664.7801453335637, 613.6741791167445, 629.7376032518537, 711.8070661593766, 582.7630530827142, 766.0203928869497, 448.3097380734964, 363.75847643553954, 551.2374159248567, 603.8256654523422, 585.8349934282131, 614.6017072340601, 590.0952159270926, 633.8966383143319, 609.3612308155522, 523.8738942139776, 651.1010574175295, 689.5495761255531, 745.395943359285, 611.5514233411694, 611.7030914214683, 635.4317331203337, 702.7772865188311, 697.4242945306679, 631.8090676865618, 598.4874428546681, 493.1020553528168, 625.5700519012519, 605.6435765445678, 688.5414163312586, 596.575260830545, 633.1919646117035, 645.7321302147816, 539.0510093985826, 545.1466862769825, 432.4498452652608, 594.928944407388, 508.42060711212, 680.4857203007167, 492.06061752375103, 570.1704497214743, 604.9981425132722, 618.2956077871314, 516.5965276827988, 591.8143961599303, 586.0613696728075, 704.9520404329436, 565.8984445498078, 536.0269143993311, 563.6525107975278, 709.1473582881094, 573.588188285688, 684.4282989484203, 614.5223773362039, 573.3439466591844, 598.8180156323336, 559.1666456930847, 582.8209593335802, 631.1753286902225, 740.7922334979542, 705.1827536021988, 560.5760568203261, 605.3357561755379, 612.639225360138, 631.6282862050964, 552.5153154760492, 647.9662340035143, 590.8046069195462, 620.8643674523946, 522.0034725677727, 640.8230711849345, 608.9267836315624, 459.45288348554186, 717.5830593859533, 549.776579697662, 664.2953305360605, 509.32298727540535, 604.6938298578241, 706.2228087855059, 488.14567100911677, 635.4267868562281, 672.1725085377122, 669.7791707969473, 600.6930221918085, 555.5202626428091, 746.1339906013081, 694.8187868946236, 505.6285026509157, 566.056985838566, 700.1689164637825, 472.30144213939207, 631.852745856134, 602.1155641833608, 496.7078381263972, 671.9111581421429, 664.8898804633158, 518.3342221547748, 633.5143436948521, 736.1052985516925, 670.044193985178, 692.4370379288176, 690.0176370289893, 696.598397546604, 591.0481527421986, 565.7915772954375, 462.94548863908557, 524.5466834569377, 468.3110394500444, 586.5355291121853, 668.2045855612814, 586.7474893820037, 594.598535110554, 520.8633574527634, 608.053069243498, 625.6013891446527, 535.2220314697186, 754.774977001237, 580.790656627662, 648.6992742421875, 666.6043384596095, 509.81010571667196, 627.495241421286, 564.1453183276315, 474.4811101645613, 595.8052630368528, 519.7774100607159, 564.3045114843353, 496.3485067426613, 646.2556238814195, 586.848763984629, 452.58487337297976, 574.9403939082482, 580.3994586032186, 640.1302661803957, 579.1045815431615, 576.3071853412818, 598.5207040540822, 719.1023318035776, 676.5046558366485, 637.4824207277297, 586.7085395858588, 462.53497260779477, 730.0025833954012, 638.3447767109803, 544.3080342651156, 623.5550371731729, 606.7988348360434, 562.0393347991117, 620.0227350745577, 460.7093483000145, 564.4874421614236, 691.9919660273604, 645.283939448407, 533.872352500158, 657.9667222315231, 549.9225551903909, 565.7779095657373, 582.183683569177, 635.2265427119337, 430.98910407158587, 552.7145599149482, 508.08869721161506, 608.1844395963391, 500.69718750986726, 587.8960684273229, 663.3429542532328, 583.0890132359536, 580.0233675755314, 548.8382542870215, 499.76461011756487, 410.16295677046884, 541.6280224608116, 739.7224523561866, 505.1813918949164, 504.1699772331109, 510.99981591357994, 510.3225156175554, 662.5903686918032, 764.5311709166007, 572.6166838532702, 697.9817125994552, 551.0786072933007, 604.6315391670911, 663.4535056192636, 636.8490743045205, 726.2493836282971, 629.5844064027802, 517.000491106024, 453.3205777815038, 660.4878997064503, 693.9136871492319, 497.3473236845715, 504.42482846621203, 589.2473184276673, 554.8487586863555], "policy_predator_policy_reward": [118.77451361727515, 151.89349390182778, 331.53629435935187, 387.3096716591823, 334.2483390974203, 284.05237789916737, 224.1820641323075, 333.80917187580775, 116.21388133358947, 155.20675061012037, 59.094730868802216, 121.35866171812617, 59.71439163140223, -6.340761137613136, 367.6396556453786, 407.9490088454224, 256.12539965793354, 331.94759789408613, 304.6344702024898, 329.1801815331491, 243.76849041404301, 272.9346213416471, 170.98232077600537, 259.74307851123785, 159.4597684953536, 116.78473029462292, 323.4000908727471, 230.4480583367954, 163.83801156391374, 276.9346277702774, 404.8485418248313, 284.2762955953668, 212.1174099429531, 182.25197044831657, 234.69083781074627, 191.15532108252475, 262.80231282901326, 328.11005805991687, 389.5277582885869, 313.9262432224463, 327.61846575363506, 483.68436747741475, 378.68268861919313, 325.93476236675804, 325.35420360040433, 408.75619005715356, 398.24125259758796, 325.9063867101594, 261.8447962419704, 400.24499100238904, 243.92397801150685, 298.1074969618991, 368.4894265821755, 293.1812588188406, 289.6465153856795, 345.222204491606, 290.1315406278108, 217.28717470504924, 429.026261686221, 264.67159097331245, 197.49672074812946, 196.9051025928716, 329.1670326128924, 410.75101260027265, 266.26673173070907, 301.82070249375465, 415.22623829840796, 414.08667031088135, 299.65653261292323, 151.86077702682047, 347.9017202893658, 243.38849304399227, 226.44108242689876, 343.8650399723697, 300.1541115527484, 313.55779497890217, 320.07183372851046, 229.34523733548536, 389.8256653247031, 304.5528519916187, 400.128316093543, 341.50725074896707, 244.10978703665012, 329.1187668690515, 337.6502974759714, 200.68933368951318, 285.4630166312272, 285.11853761404655, 180.03552963411207, 160.30319044783977, 55.89180391046069, 273.4827857977737, 371.3472736901264, 292.7841406983324, 247.06114514684978, 446.7784908318444, 227.63280380165418, 189.7794027652917, 326.5376481151981, 380.67669797816313, 410.09767258761116, 373.51153246528867, 337.9553094519898, 293.57505405311633, 250.12182307173484, 218.89792100437018, 254.56999990264632, 256.16052690944923, 337.3936375012649, 390.2138879957271, 433.11446536876286, 383.6875201986647, 181.29203290588498, 260.13676968059116, 323.5654575725724, 204.25376212813686, 447.82241828110847, 404.4520286954402, 354.5676310910769, 239.0216007320629, 248.90364714932366, 390.98703035631206, 236.77778020951084, 246.9564599302283, 93.73347361857145, 432.3053412169554, 376.2192941905352, 430.25997507079916, 348.2465719804042, 420.4758420548192, 353.03301920772157, 430.67148434847144, 380.516324166982, 310.0479499275469, 470.51553613213224, 183.77437079499956, 375.57676691999296, 402.1487178865566, 100.2636352987041, 52.164687544200774, 308.8009637179785, 154.51562286291005, 142.818517679361, 143.73155348881147, 316.9202710895617, 344.0652305525304, 200.04067814971228, 160.16092573034447, 415.8183846097512, 393.5690021713823, 313.97016478629996, 316.4249091067957, 272.43708808891114, 375.1383035507446, 479.2273712859697, 489.54163535189514, 336.2261994015388, 268.5484025230485, 398.57280443639615, 216.63807110728615, 423.82868622469266, 274.4061869040223, 367.39764697555745, 368.97650914782434, 341.63337830242676, 540.0598293359242, 271.8821908761788, 343.01781828883827, 370.1775310120141, 281.3352109358534, 276.6188165643507, 362.5646283973284, 207.56736379732783, 257.7930827362934, 536.7075079959533, 508.86556101551145, 127.01168944597377, 159.2963262264878, 384.8917448885023, 279.7495737345998, 451.7199310456191, 395.52924647875506, 236.5150509083014, 227.02367236016715, 383.41118131184436, 366.35433550320886, 286.39546037340097, 418.81203901084626, 184.34673590553206, 220.02858158748265, 227.80671888964375, 133.7247282453434, 306.1951449794804, 508.8279564067678, 224.47890791426445, 272.82989220540424, 439.60043673637233, 475.78795961222187, 442.1758118656464, 366.46664316773126]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3927507520660187, "mean_inference_ms": 6.309058731780127, "mean_action_processing_ms": 1.0217260801479495, "mean_env_wait_ms": 0.8794566480576035, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.023342490196228027, "StateBufferConnector_ms": 0.021599531173706055, "ViewRequirementAgentConnector_ms": 0.5728424787521362}, "num_episodes": 23, "episode_return_max": 2020.36391326778, "episode_return_min": 968.3695228541845, "episode_return_mean": 1794.8841261409655, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 229.0071955408531, "num_env_steps_trained_throughput_per_sec": 229.0071955408531, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 20624.506, "restore_workers_time_ms": 0.015, "training_step_time_ms": 20624.456, "sample_time_ms": 4608.885, "learn_time_ms": 15989.946, "learn_throughput": 250.157, "synch_weights_time_ms": 24.357}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "479e5_00000", "date": "2024-08-16_12-26-47", "timestamp": 1723791407, "time_this_iter_s": 17.472965002059937, "time_total_s": 3597.4974448680878, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7dd1280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3597.4974448680878, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 31.112, "ram_util_percent": 63.61600000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1750545959308663, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.320475295233349, "policy_loss": -0.007071495377803566, "vf_loss": 9.32578797920671, "vf_explained_var": -0.008583243561800194, "kl": 0.015633940055803645, "entropy": 1.1778883964296372, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.948212910581518, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.510981762598432, "policy_loss": 0.0006555029449777471, "vf_loss": 9.510306898752848, "vf_explained_var": -0.39797963906848244, "kl": 0.005498760900303962, "entropy": 0.34399601467072016, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 2079.422724023285, "episode_reward_min": 1371.6631705664654, "episode_reward_mean": 1816.2935847306235, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 389.5713098508599, "predator_policy": 52.164687544200774}, "policy_reward_max": {"prey_policy": 764.5311709166007, "predator_policy": 540.0598293359242}, "policy_reward_mean": {"prey_policy": 593.9352857487992, "predator_policy": 314.2115066165125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1869.836465715415, 1787.651697186598, 1838.6816229037, 1893.5237783987866, 1796.3414609027839, 1947.4413896081514, 1770.5007110870893, 1833.0448850791558, 1763.5960443501524, 1907.6685889629227, 1765.4352025669702, 1881.564176654923, 1552.3864846664205, 1953.9143332369692, 2014.0624213246174, 1995.2247216051537, 1695.784821204978, 1791.7717628129205, 1781.975096771207, 1776.5384502843567, 1617.7967381810997, 1961.7381563999377, 1915.2538846539783, 1884.1451925490333, 1661.9120890308288, 1912.5332335799353, 1496.5520049165705, 1770.3273672041676, 1735.8169028779405, 1866.3099945818694, 1651.3805166064403, 1875.8333423619003, 1966.833307670992, 2001.150005751651, 1831.5009759901025, 1897.3465613876842, 1884.4472555346297, 1804.2941576634505, 1496.275371148705, 1782.7712946439956, 1967.7363395398659, 1827.2436902112916, 1929.8876859765871, 1713.2241710095864, 1702.45325901181, 1998.1198290102495, 1839.0087872366362, 1867.7864251012447, 1833.168404718611, 1693.7235442847416, 1933.0653373180157, 1371.6631705664654, 1638.1444759762549, 1682.1570588083969, 1885.1764619556807, 1552.7391598832514, 1992.0401977572283, 1860.7489459023113, 1829.6374615133252, 1993.9657970993028, 1942.050507400357, 1807.0499502753628, 1813.9353378848448, 1953.784382404492, 1865.3968716248837, 1731.1731459729717, 1740.1059978850571, 1885.6154124508653, 1594.2220683961743, 1955.5006358994992, 1567.6584904894592, 1673.992687751124, 1868.57150905551, 1890.6602628768726, 2020.36391326778, 1860.9176458446389, 1704.6778974168005, 1717.3652371660633, 1785.3441702737773, 1851.7103869753553, 1917.1605484993784, 1952.7385321474012, 1473.1826966423314, 1944.2513287724696, 1840.9844567043003, 1688.3744106477686, 1954.2958869816468, 1823.949073266181, 1782.079869135002, 1852.1191030113569, 1780.1234991995489, 2015.8674919411528, 2079.422724023285, 1824.6567694627927, 1882.882032498985, 1927.3031654682065, 1663.75809864564, 1748.0934259402463, 1743.8048193959444, 1761.3613584277855], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [633.1919646117035, 645.7321302147816, 539.0510093985826, 545.1466862769825, 432.4498452652608, 594.928944407388, 508.42060711212, 680.4857203007167, 492.06061752375103, 570.1704497214743, 604.9981425132722, 618.2956077871314, 516.5965276827988, 591.8143961599303, 586.0613696728075, 704.9520404329436, 565.8984445498078, 536.0269143993311, 563.6525107975278, 709.1473582881094, 573.588188285688, 684.4282989484203, 614.5223773362039, 573.3439466591844, 598.8180156323336, 559.1666456930847, 582.8209593335802, 631.1753286902225, 740.7922334979542, 705.1827536021988, 560.5760568203261, 605.3357561755379, 612.639225360138, 631.6282862050964, 552.5153154760492, 647.9662340035143, 590.8046069195462, 620.8643674523946, 522.0034725677727, 640.8230711849345, 608.9267836315624, 459.45288348554186, 717.5830593859533, 549.776579697662, 664.2953305360605, 509.32298727540535, 604.6938298578241, 706.2228087855059, 488.14567100911677, 635.4267868562281, 672.1725085377122, 669.7791707969473, 600.6930221918085, 555.5202626428091, 746.1339906013081, 694.8187868946236, 505.6285026509157, 566.056985838566, 700.1689164637825, 472.30144213939207, 631.852745856134, 602.1155641833608, 496.7078381263972, 671.9111581421429, 664.8898804633158, 518.3342221547748, 633.5143436948521, 736.1052985516925, 670.044193985178, 692.4370379288176, 690.0176370289893, 696.598397546604, 591.0481527421986, 565.7915772954375, 462.94548863908557, 524.5466834569377, 468.3110394500444, 586.5355291121853, 668.2045855612814, 586.7474893820037, 594.598535110554, 520.8633574527634, 608.053069243498, 625.6013891446527, 535.2220314697186, 754.774977001237, 580.790656627662, 648.6992742421875, 666.6043384596095, 509.81010571667196, 627.495241421286, 564.1453183276315, 474.4811101645613, 595.8052630368528, 519.7774100607159, 564.3045114843353, 496.3485067426613, 646.2556238814195, 586.848763984629, 452.58487337297976, 574.9403939082482, 580.3994586032186, 640.1302661803957, 579.1045815431615, 576.3071853412818, 598.5207040540822, 719.1023318035776, 676.5046558366485, 637.4824207277297, 586.7085395858588, 462.53497260779477, 730.0025833954012, 638.3447767109803, 544.3080342651156, 623.5550371731729, 606.7988348360434, 562.0393347991117, 620.0227350745577, 460.7093483000145, 564.4874421614236, 691.9919660273604, 645.283939448407, 533.872352500158, 657.9667222315231, 549.9225551903909, 565.7779095657373, 582.183683569177, 635.2265427119337, 430.98910407158587, 552.7145599149482, 508.08869721161506, 608.1844395963391, 500.69718750986726, 587.8960684273229, 663.3429542532328, 583.0890132359536, 580.0233675755314, 548.8382542870215, 499.76461011756487, 410.16295677046884, 541.6280224608116, 739.7224523561866, 505.1813918949164, 504.1699772331109, 510.99981591357994, 510.3225156175554, 662.5903686918032, 764.5311709166007, 572.6166838532702, 697.9817125994552, 551.0786072933007, 604.6315391670911, 663.4535056192636, 636.8490743045205, 726.2493836282971, 629.5844064027802, 517.000491106024, 453.3205777815038, 660.4878997064503, 693.9136871492319, 497.3473236845715, 504.42482846621203, 589.2473184276673, 554.8487586863555, 565.2169599061484, 524.7645649368712, 725.817946980912, 389.5713098508599, 580.4326826386849, 666.9413519741485, 511.482510097939, 476.81379059987694, 571.3879100759717, 571.3536980927173, 560.3571837789033, 474.2362880670746, 569.9883897651608, 591.810674568992, 575.0554411784178, 557.8679664054962, 613.6601530831107, 638.9626260176027, 664.0067561690843, 682.6686443944658, 659.347362591319, 559.5807987766674, 593.6951295332155, 636.4687308234437, 634.2278692545336, 470.8716575772861, 667.540528386824, 649.9200019455434, 703.7572966200464, 588.4037587491244, 643.4961634830532, 566.8931252710802, 685.0283827222232, 614.8693799308534, 699.6241202592236, 543.8140046820704], "policy_predator_policy_reward": [262.80231282901326, 328.11005805991687, 389.5277582885869, 313.9262432224463, 327.61846575363506, 483.68436747741475, 378.68268861919313, 325.93476236675804, 325.35420360040433, 408.75619005715356, 398.24125259758796, 325.9063867101594, 261.8447962419704, 400.24499100238904, 243.92397801150685, 298.1074969618991, 368.4894265821755, 293.1812588188406, 289.6465153856795, 345.222204491606, 290.1315406278108, 217.28717470504924, 429.026261686221, 264.67159097331245, 197.49672074812946, 196.9051025928716, 329.1670326128924, 410.75101260027265, 266.26673173070907, 301.82070249375465, 415.22623829840796, 414.08667031088135, 299.65653261292323, 151.86077702682047, 347.9017202893658, 243.38849304399227, 226.44108242689876, 343.8650399723697, 300.1541115527484, 313.55779497890217, 320.07183372851046, 229.34523733548536, 389.8256653247031, 304.5528519916187, 400.128316093543, 341.50725074896707, 244.10978703665012, 329.1187668690515, 337.6502974759714, 200.68933368951318, 285.4630166312272, 285.11853761404655, 180.03552963411207, 160.30319044783977, 55.89180391046069, 273.4827857977737, 371.3472736901264, 292.7841406983324, 247.06114514684978, 446.7784908318444, 227.63280380165418, 189.7794027652917, 326.5376481151981, 380.67669797816313, 410.09767258761116, 373.51153246528867, 337.9553094519898, 293.57505405311633, 250.12182307173484, 218.89792100437018, 254.56999990264632, 256.16052690944923, 337.3936375012649, 390.2138879957271, 433.11446536876286, 383.6875201986647, 181.29203290588498, 260.13676968059116, 323.5654575725724, 204.25376212813686, 447.82241828110847, 404.4520286954402, 354.5676310910769, 239.0216007320629, 248.90364714932366, 390.98703035631206, 236.77778020951084, 246.9564599302283, 93.73347361857145, 432.3053412169554, 376.2192941905352, 430.25997507079916, 348.2465719804042, 420.4758420548192, 353.03301920772157, 430.67148434847144, 380.516324166982, 310.0479499275469, 470.51553613213224, 183.77437079499956, 375.57676691999296, 402.1487178865566, 100.2636352987041, 52.164687544200774, 308.8009637179785, 154.51562286291005, 142.818517679361, 143.73155348881147, 316.9202710895617, 344.0652305525304, 200.04067814971228, 160.16092573034447, 415.8183846097512, 393.5690021713823, 313.97016478629996, 316.4249091067957, 272.43708808891114, 375.1383035507446, 479.2273712859697, 489.54163535189514, 336.2261994015388, 268.5484025230485, 398.57280443639615, 216.63807110728615, 423.82868622469266, 274.4061869040223, 367.39764697555745, 368.97650914782434, 341.63337830242676, 540.0598293359242, 271.8821908761788, 343.01781828883827, 370.1775310120141, 281.3352109358534, 276.6188165643507, 362.5646283973284, 207.56736379732783, 257.7930827362934, 536.7075079959533, 508.86556101551145, 127.01168944597377, 159.2963262264878, 384.8917448885023, 279.7495737345998, 451.7199310456191, 395.52924647875506, 236.5150509083014, 227.02367236016715, 383.41118131184436, 366.35433550320886, 286.39546037340097, 418.81203901084626, 184.34673590553206, 220.02858158748265, 227.80671888964375, 133.7247282453434, 306.1951449794804, 508.8279564067678, 224.47890791426445, 272.82989220540424, 439.60043673637233, 475.78795961222187, 442.1758118656464, 366.46664316773126, 167.93547177538113, 215.2657000239323, 420.8773048129506, 407.9847671277433, 278.43509174022984, 315.1753303512371, 471.2245685149486, 228.85354143500606, 443.63280581599815, 367.92147299696194, 399.3035496263478, 390.0520517938547, 291.99363570397435, 328.2871690968729, 346.9942744806438, 372.2014209467985, 296.68801458860787, 230.81270551022948, 365.02314496522536, 304.1689464123784, 403.8930794557382, 456.6014831995592, 351.0775192232262, 243.41538988290648, 388.59029083469153, 389.19221483247304, 332.8189303628664, 277.0237047729729, 238.41168993849027, 133.18535333798175, 224.75802457838992, 312.9461126077208, 278.04782422298, 165.8592325198926, 308.17566305675666, 209.74757042973206]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.395000984604418, "mean_inference_ms": 6.32049392748981, "mean_action_processing_ms": 1.0224389061643209, "mean_env_wait_ms": 0.8809759737669282, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.025368571281433105, "StateBufferConnector_ms": 0.016228318214416504, "ViewRequirementAgentConnector_ms": 0.4161869287490845}, "num_episodes": 18, "episode_return_max": 2079.422724023285, "episode_return_min": 1371.6631705664654, "episode_return_mean": 1816.2935847306235, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 212.09355348066615, "num_env_steps_trained_throughput_per_sec": 212.09355348066615, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 21057.484, "restore_workers_time_ms": 0.015, "training_step_time_ms": 21057.436, "sample_time_ms": 5040.558, "learn_time_ms": 15992.147, "learn_throughput": 250.123, "synch_weights_time_ms": 23.611}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "479e5_00000", "date": "2024-08-16_12-27-05", "timestamp": 1723791425, "time_this_iter_s": 18.864777088165283, "time_total_s": 3616.362221956253, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7dd1e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3616.362221956253, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 34.02222222222222, "ram_util_percent": 63.029629629629625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8872460088717244, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.412844248171206, "policy_loss": -0.00414316597463632, "vf_loss": 9.415652057607337, "vf_explained_var": -0.0124907635191761, "kl": 0.011870134739625168, "entropy": 1.182746283717887, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.292076040725544, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.472844493704498, "policy_loss": -0.0008061312957021294, "vf_loss": 9.473634417094882, "vf_explained_var": -0.4751019210411758, "kl": 0.004611398271301202, "entropy": 0.38782559287926505, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 2079.422724023285, "episode_reward_min": 1371.6631705664654, "episode_reward_mean": 1810.5862267286977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 319.7752482322737, "predator_policy": 52.164687544200774}, "policy_reward_max": {"prey_policy": 764.5311709166007, "predator_policy": 540.0598293359242}, "policy_reward_mean": {"prey_policy": 590.9291376175299, "predator_policy": 314.3639757468191}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1781.975096771207, 1776.5384502843567, 1617.7967381810997, 1961.7381563999377, 1915.2538846539783, 1884.1451925490333, 1661.9120890308288, 1912.5332335799353, 1496.5520049165705, 1770.3273672041676, 1735.8169028779405, 1866.3099945818694, 1651.3805166064403, 1875.8333423619003, 1966.833307670992, 2001.150005751651, 1831.5009759901025, 1897.3465613876842, 1884.4472555346297, 1804.2941576634505, 1496.275371148705, 1782.7712946439956, 1967.7363395398659, 1827.2436902112916, 1929.8876859765871, 1713.2241710095864, 1702.45325901181, 1998.1198290102495, 1839.0087872366362, 1867.7864251012447, 1833.168404718611, 1693.7235442847416, 1933.0653373180157, 1371.6631705664654, 1638.1444759762549, 1682.1570588083969, 1885.1764619556807, 1552.7391598832514, 1992.0401977572283, 1860.7489459023113, 1829.6374615133252, 1993.9657970993028, 1942.050507400357, 1807.0499502753628, 1813.9353378848448, 1953.784382404492, 1865.3968716248837, 1731.1731459729717, 1740.1059978850571, 1885.6154124508653, 1594.2220683961743, 1955.5006358994992, 1567.6584904894592, 1673.992687751124, 1868.57150905551, 1890.6602628768726, 2020.36391326778, 1860.9176458446389, 1704.6778974168005, 1717.3652371660633, 1785.3441702737773, 1851.7103869753553, 1917.1605484993784, 1952.7385321474012, 1473.1826966423314, 1944.2513287724696, 1840.9844567043003, 1688.3744106477686, 1954.2958869816468, 1823.949073266181, 1782.079869135002, 1852.1191030113569, 1780.1234991995489, 2015.8674919411528, 2079.422724023285, 1824.6567694627927, 1882.882032498985, 1927.3031654682065, 1663.75809864564, 1748.0934259402463, 1743.8048193959444, 1761.3613584277855, 1891.3985462268017, 1754.2243334822754, 1557.9099265054936, 1884.76781134394, 1743.8655446101898, 1876.3356257423006, 1797.4309838191873, 1567.324820861338, 1668.1153159341068, 1542.1555013230388, 1955.223873139573, 2014.3349010472086, 1786.9597646083375, 1956.5423934819805, 1841.8161348694146, 1913.6575381043767, 1882.8643618094177, 1852.7673911661636], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [590.8046069195462, 620.8643674523946, 522.0034725677727, 640.8230711849345, 608.9267836315624, 459.45288348554186, 717.5830593859533, 549.776579697662, 664.2953305360605, 509.32298727540535, 604.6938298578241, 706.2228087855059, 488.14567100911677, 635.4267868562281, 672.1725085377122, 669.7791707969473, 600.6930221918085, 555.5202626428091, 746.1339906013081, 694.8187868946236, 505.6285026509157, 566.056985838566, 700.1689164637825, 472.30144213939207, 631.852745856134, 602.1155641833608, 496.7078381263972, 671.9111581421429, 664.8898804633158, 518.3342221547748, 633.5143436948521, 736.1052985516925, 670.044193985178, 692.4370379288176, 690.0176370289893, 696.598397546604, 591.0481527421986, 565.7915772954375, 462.94548863908557, 524.5466834569377, 468.3110394500444, 586.5355291121853, 668.2045855612814, 586.7474893820037, 594.598535110554, 520.8633574527634, 608.053069243498, 625.6013891446527, 535.2220314697186, 754.774977001237, 580.790656627662, 648.6992742421875, 666.6043384596095, 509.81010571667196, 627.495241421286, 564.1453183276315, 474.4811101645613, 595.8052630368528, 519.7774100607159, 564.3045114843353, 496.3485067426613, 646.2556238814195, 586.848763984629, 452.58487337297976, 574.9403939082482, 580.3994586032186, 640.1302661803957, 579.1045815431615, 576.3071853412818, 598.5207040540822, 719.1023318035776, 676.5046558366485, 637.4824207277297, 586.7085395858588, 462.53497260779477, 730.0025833954012, 638.3447767109803, 544.3080342651156, 623.5550371731729, 606.7988348360434, 562.0393347991117, 620.0227350745577, 460.7093483000145, 564.4874421614236, 691.9919660273604, 645.283939448407, 533.872352500158, 657.9667222315231, 549.9225551903909, 565.7779095657373, 582.183683569177, 635.2265427119337, 430.98910407158587, 552.7145599149482, 508.08869721161506, 608.1844395963391, 500.69718750986726, 587.8960684273229, 663.3429542532328, 583.0890132359536, 580.0233675755314, 548.8382542870215, 499.76461011756487, 410.16295677046884, 541.6280224608116, 739.7224523561866, 505.1813918949164, 504.1699772331109, 510.99981591357994, 510.3225156175554, 662.5903686918032, 764.5311709166007, 572.6166838532702, 697.9817125994552, 551.0786072933007, 604.6315391670911, 663.4535056192636, 636.8490743045205, 726.2493836282971, 629.5844064027802, 517.000491106024, 453.3205777815038, 660.4878997064503, 693.9136871492319, 497.3473236845715, 504.42482846621203, 589.2473184276673, 554.8487586863555, 565.2169599061484, 524.7645649368712, 725.817946980912, 389.5713098508599, 580.4326826386849, 666.9413519741485, 511.482510097939, 476.81379059987694, 571.3879100759717, 571.3536980927173, 560.3571837789033, 474.2362880670746, 569.9883897651608, 591.810674568992, 575.0554411784178, 557.8679664054962, 613.6601530831107, 638.9626260176027, 664.0067561690843, 682.6686443944658, 659.347362591319, 559.5807987766674, 593.6951295332155, 636.4687308234437, 634.2278692545336, 470.8716575772861, 667.540528386824, 649.9200019455434, 703.7572966200464, 588.4037587491244, 643.4961634830532, 566.8931252710802, 685.0283827222232, 614.8693799308534, 699.6241202592236, 543.8140046820704, 664.658806499909, 635.0626473015689, 627.3247232500125, 563.282350690876, 627.0915554507155, 510.2891230804574, 670.0271839303264, 621.5515506686276, 575.826693059308, 509.2607913983254, 607.4566888799666, 402.23291373606463, 612.9556869171589, 547.3550939493327, 590.0275294598965, 319.7752482322737, 528.1663406175023, 554.8660310760863, 698.0227794003647, 575.6425142690229, 551.5628729071059, 581.8926043451978, 557.0968247034202, 658.8928683977659, 612.3218293153542, 680.5233817538438, 656.2284337274199, 576.9206010177612, 628.663908480629, 646.7175492326172, 623.0836877183965, 691.5875536791348, 373.9513114665588, 513.3980554640646, 546.0752239029953, 572.5583246020248], "policy_predator_policy_reward": [226.44108242689876, 343.8650399723697, 300.1541115527484, 313.55779497890217, 320.07183372851046, 229.34523733548536, 389.8256653247031, 304.5528519916187, 400.128316093543, 341.50725074896707, 244.10978703665012, 329.1187668690515, 337.6502974759714, 200.68933368951318, 285.4630166312272, 285.11853761404655, 180.03552963411207, 160.30319044783977, 55.89180391046069, 273.4827857977737, 371.3472736901264, 292.7841406983324, 247.06114514684978, 446.7784908318444, 227.63280380165418, 189.7794027652917, 326.5376481151981, 380.67669797816313, 410.09767258761116, 373.51153246528867, 337.9553094519898, 293.57505405311633, 250.12182307173484, 218.89792100437018, 254.56999990264632, 256.16052690944923, 337.3936375012649, 390.2138879957271, 433.11446536876286, 383.6875201986647, 181.29203290588498, 260.13676968059116, 323.5654575725724, 204.25376212813686, 447.82241828110847, 404.4520286954402, 354.5676310910769, 239.0216007320629, 248.90364714932366, 390.98703035631206, 236.77778020951084, 246.9564599302283, 93.73347361857145, 432.3053412169554, 376.2192941905352, 430.25997507079916, 348.2465719804042, 420.4758420548192, 353.03301920772157, 430.67148434847144, 380.516324166982, 310.0479499275469, 470.51553613213224, 183.77437079499956, 375.57676691999296, 402.1487178865566, 100.2636352987041, 52.164687544200774, 308.8009637179785, 154.51562286291005, 142.818517679361, 143.73155348881147, 316.9202710895617, 344.0652305525304, 200.04067814971228, 160.16092573034447, 415.8183846097512, 393.5690021713823, 313.97016478629996, 316.4249091067957, 272.43708808891114, 375.1383035507446, 479.2273712859697, 489.54163535189514, 336.2261994015388, 268.5484025230485, 398.57280443639615, 216.63807110728615, 423.82868622469266, 274.4061869040223, 367.39764697555745, 368.97650914782434, 341.63337830242676, 540.0598293359242, 271.8821908761788, 343.01781828883827, 370.1775310120141, 281.3352109358534, 276.6188165643507, 362.5646283973284, 207.56736379732783, 257.7930827362934, 536.7075079959533, 508.86556101551145, 127.01168944597377, 159.2963262264878, 384.8917448885023, 279.7495737345998, 451.7199310456191, 395.52924647875506, 236.5150509083014, 227.02367236016715, 383.41118131184436, 366.35433550320886, 286.39546037340097, 418.81203901084626, 184.34673590553206, 220.02858158748265, 227.80671888964375, 133.7247282453434, 306.1951449794804, 508.8279564067678, 224.47890791426445, 272.82989220540424, 439.60043673637233, 475.78795961222187, 442.1758118656464, 366.46664316773126, 167.93547177538113, 215.2657000239323, 420.8773048129506, 407.9847671277433, 278.43509174022984, 315.1753303512371, 471.2245685149486, 228.85354143500606, 443.63280581599815, 367.92147299696194, 399.3035496263478, 390.0520517938547, 291.99363570397435, 328.2871690968729, 346.9942744806438, 372.2014209467985, 296.68801458860787, 230.81270551022948, 365.02314496522536, 304.1689464123784, 403.8930794557382, 456.6014831995592, 351.0775192232262, 243.41538988290648, 388.59029083469153, 389.19221483247304, 332.8189303628664, 277.0237047729729, 238.41168993849027, 133.18535333798175, 224.75802457838992, 312.9461126077208, 278.04782422298, 165.8592325198926, 308.17566305675666, 209.74757042973206, 354.61467223190544, 237.06242019341815, 222.42585245886698, 341.19140708252, 261.4804272356214, 159.04882073870033, 308.3318903794, 284.8571863655889, 232.1703450826176, 426.60771506994115, 422.72851175003365, 443.9175113762369, 171.9525004337339, 465.16770251896094, 339.8789945183149, 317.6430486508536, 199.8595086943488, 385.2234355461704, 53.41132054107582, 215.07888711257624, 408.1293404072689, 413.6390554799988, 492.6412357329314, 305.70397221308883, 295.49928951605676, 198.61526402308252, 412.37233942211054, 311.0210193146894, 337.86215597349536, 228.57252118267553, 279.60042327375464, 319.38587343308745, 495.035687552488, 500.4793073263061, 284.63723515195164, 449.49660750919355]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.397009339078556, "mean_inference_ms": 6.325544020922989, "mean_action_processing_ms": 1.023172862513948, "mean_env_wait_ms": 0.8810585379181911, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02039504051208496, "StateBufferConnector_ms": 0.01509702205657959, "ViewRequirementAgentConnector_ms": 0.3812600374221802}, "num_episodes": 18, "episode_return_max": 2079.422724023285, "episode_return_min": 1371.6631705664654, "episode_return_mean": 1810.5862267286977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 233.45948267313776, "num_env_steps_trained_throughput_per_sec": 233.45948267313776, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 21447.712, "restore_workers_time_ms": 0.015, "training_step_time_ms": 21447.665, "sample_time_ms": 5240.658, "learn_time_ms": 16182.063, "learn_throughput": 247.187, "synch_weights_time_ms": 23.808}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "479e5_00000", "date": "2024-08-16_12-27-23", "timestamp": 1723791443, "time_this_iter_s": 17.13749074935913, "time_total_s": 3633.499712705612, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7fe2b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3633.499712705612, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 30.84166666666667, "ram_util_percent": 63.020833333333336}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8978252320377913, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.348735186662623, "policy_loss": -0.0035275270022875655, "vf_loss": 9.350470760890415, "vf_explained_var": -0.06588837315165808, "kl": 0.015928558517377976, "entropy": 1.190368817470692, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.453470533849701, "cur_kl_coeff": 0.0017578125000000005, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.026282871084868, "policy_loss": 0.01641657521292843, "vf_loss": 9.009741583324614, "vf_explained_var": -0.3204964952178733, "kl": 0.07094446492528214, "entropy": 0.46939115418643546, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 2095.809179868487, "episode_reward_min": 1371.6631705664654, "episode_reward_mean": 1833.053016587993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 319.7752482322737, "predator_policy": 52.164687544200774}, "policy_reward_max": {"prey_policy": 764.5311709166007, "predator_policy": 540.0598293359242}, "policy_reward_mean": {"prey_policy": 582.323485754676, "predator_policy": 334.2030225393204}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1967.7363395398659, 1827.2436902112916, 1929.8876859765871, 1713.2241710095864, 1702.45325901181, 1998.1198290102495, 1839.0087872366362, 1867.7864251012447, 1833.168404718611, 1693.7235442847416, 1933.0653373180157, 1371.6631705664654, 1638.1444759762549, 1682.1570588083969, 1885.1764619556807, 1552.7391598832514, 1992.0401977572283, 1860.7489459023113, 1829.6374615133252, 1993.9657970993028, 1942.050507400357, 1807.0499502753628, 1813.9353378848448, 1953.784382404492, 1865.3968716248837, 1731.1731459729717, 1740.1059978850571, 1885.6154124508653, 1594.2220683961743, 1955.5006358994992, 1567.6584904894592, 1673.992687751124, 1868.57150905551, 1890.6602628768726, 2020.36391326778, 1860.9176458446389, 1704.6778974168005, 1717.3652371660633, 1785.3441702737773, 1851.7103869753553, 1917.1605484993784, 1952.7385321474012, 1473.1826966423314, 1944.2513287724696, 1840.9844567043003, 1688.3744106477686, 1954.2958869816468, 1823.949073266181, 1782.079869135002, 1852.1191030113569, 1780.1234991995489, 2015.8674919411528, 2079.422724023285, 1824.6567694627927, 1882.882032498985, 1927.3031654682065, 1663.75809864564, 1748.0934259402463, 1743.8048193959444, 1761.3613584277855, 1891.3985462268017, 1754.2243334822754, 1557.9099265054936, 1884.76781134394, 1743.8655446101898, 1876.3356257423006, 1797.4309838191873, 1567.324820861338, 1668.1153159341068, 1542.1555013230388, 1955.223873139573, 2014.3349010472086, 1786.9597646083375, 1956.5423934819805, 1841.8161348694146, 1913.6575381043767, 1882.8643618094177, 1852.7673911661636, 1793.390511786882, 1956.7128137713303, 1947.9331093768142, 1894.5282568945138, 1890.5023321497195, 1976.962763115114, 1803.1223327868324, 1877.16665146145, 2095.809179868487, 1947.6823814718168, 1894.2553665308226, 1786.6528551280378, 1822.3652761462095, 1944.797394843364, 1857.4074783981828, 1860.947944119888, 1987.2291109675555, 1837.2348287541363, 1785.348500247514, 2052.5610105523224, 1859.428688020085, 1947.3720993288714], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [594.598535110554, 520.8633574527634, 608.053069243498, 625.6013891446527, 535.2220314697186, 754.774977001237, 580.790656627662, 648.6992742421875, 666.6043384596095, 509.81010571667196, 627.495241421286, 564.1453183276315, 474.4811101645613, 595.8052630368528, 519.7774100607159, 564.3045114843353, 496.3485067426613, 646.2556238814195, 586.848763984629, 452.58487337297976, 574.9403939082482, 580.3994586032186, 640.1302661803957, 579.1045815431615, 576.3071853412818, 598.5207040540822, 719.1023318035776, 676.5046558366485, 637.4824207277297, 586.7085395858588, 462.53497260779477, 730.0025833954012, 638.3447767109803, 544.3080342651156, 623.5550371731729, 606.7988348360434, 562.0393347991117, 620.0227350745577, 460.7093483000145, 564.4874421614236, 691.9919660273604, 645.283939448407, 533.872352500158, 657.9667222315231, 549.9225551903909, 565.7779095657373, 582.183683569177, 635.2265427119337, 430.98910407158587, 552.7145599149482, 508.08869721161506, 608.1844395963391, 500.69718750986726, 587.8960684273229, 663.3429542532328, 583.0890132359536, 580.0233675755314, 548.8382542870215, 499.76461011756487, 410.16295677046884, 541.6280224608116, 739.7224523561866, 505.1813918949164, 504.1699772331109, 510.99981591357994, 510.3225156175554, 662.5903686918032, 764.5311709166007, 572.6166838532702, 697.9817125994552, 551.0786072933007, 604.6315391670911, 663.4535056192636, 636.8490743045205, 726.2493836282971, 629.5844064027802, 517.000491106024, 453.3205777815038, 660.4878997064503, 693.9136871492319, 497.3473236845715, 504.42482846621203, 589.2473184276673, 554.8487586863555, 565.2169599061484, 524.7645649368712, 725.817946980912, 389.5713098508599, 580.4326826386849, 666.9413519741485, 511.482510097939, 476.81379059987694, 571.3879100759717, 571.3536980927173, 560.3571837789033, 474.2362880670746, 569.9883897651608, 591.810674568992, 575.0554411784178, 557.8679664054962, 613.6601530831107, 638.9626260176027, 664.0067561690843, 682.6686443944658, 659.347362591319, 559.5807987766674, 593.6951295332155, 636.4687308234437, 634.2278692545336, 470.8716575772861, 667.540528386824, 649.9200019455434, 703.7572966200464, 588.4037587491244, 643.4961634830532, 566.8931252710802, 685.0283827222232, 614.8693799308534, 699.6241202592236, 543.8140046820704, 664.658806499909, 635.0626473015689, 627.3247232500125, 563.282350690876, 627.0915554507155, 510.2891230804574, 670.0271839303264, 621.5515506686276, 575.826693059308, 509.2607913983254, 607.4566888799666, 402.23291373606463, 612.9556869171589, 547.3550939493327, 590.0275294598965, 319.7752482322737, 528.1663406175023, 554.8660310760863, 698.0227794003647, 575.6425142690229, 551.5628729071059, 581.8926043451978, 557.0968247034202, 658.8928683977659, 612.3218293153542, 680.5233817538438, 656.2284337274199, 576.9206010177612, 628.663908480629, 646.7175492326172, 623.0836877183965, 691.5875536791348, 373.9513114665588, 513.3980554640646, 546.0752239029953, 572.5583246020248, 607.9523084581805, 614.2466167615613, 706.8847732769467, 508.2101904368913, 421.8612429372106, 593.7571359304825, 519.0566205666657, 527.889486992417, 511.9196703842919, 493.7696526448319, 607.7674840384561, 576.958354374463, 432.4892911919693, 578.6271800428414, 548.382231847885, 452.2023693302352, 531.8511460862832, 705.9243969045318, 652.5569524241929, 616.5225264103734, 470.4117765135691, 589.2362152235381, 518.7667979380826, 510.0039384884816, 482.16981753570445, 435.6542331387444, 584.1293059283792, 631.2162719192215, 617.2602776967713, 694.2843288913834, 633.2796489351567, 641.7716521138027, 636.7840135774516, 582.0483281436497, 490.2721378534157, 568.3120736963548, 567.341034870905, 615.8253565933811, 699.3123451328954, 460.0965076735131, 639.8751683395568, 490.10871738933486, 512.1363489734293, 660.018390526596], "policy_predator_policy_reward": [447.82241828110847, 404.4520286954402, 354.5676310910769, 239.0216007320629, 248.90364714932366, 390.98703035631206, 236.77778020951084, 246.9564599302283, 93.73347361857145, 432.3053412169554, 376.2192941905352, 430.25997507079916, 348.2465719804042, 420.4758420548192, 353.03301920772157, 430.67148434847144, 380.516324166982, 310.0479499275469, 470.51553613213224, 183.77437079499956, 375.57676691999296, 402.1487178865566, 100.2636352987041, 52.164687544200774, 308.8009637179785, 154.51562286291005, 142.818517679361, 143.73155348881147, 316.9202710895617, 344.0652305525304, 200.04067814971228, 160.16092573034447, 415.8183846097512, 393.5690021713823, 313.97016478629996, 316.4249091067957, 272.43708808891114, 375.1383035507446, 479.2273712859697, 489.54163535189514, 336.2261994015388, 268.5484025230485, 398.57280443639615, 216.63807110728615, 423.82868622469266, 274.4061869040223, 367.39764697555745, 368.97650914782434, 341.63337830242676, 540.0598293359242, 271.8821908761788, 343.01781828883827, 370.1775310120141, 281.3352109358534, 276.6188165643507, 362.5646283973284, 207.56736379732783, 257.7930827362934, 536.7075079959533, 508.86556101551145, 127.01168944597377, 159.2963262264878, 384.8917448885023, 279.7495737345998, 451.7199310456191, 395.52924647875506, 236.5150509083014, 227.02367236016715, 383.41118131184436, 366.35433550320886, 286.39546037340097, 418.81203901084626, 184.34673590553206, 220.02858158748265, 227.80671888964375, 133.7247282453434, 306.1951449794804, 508.8279564067678, 224.47890791426445, 272.82989220540424, 439.60043673637233, 475.78795961222187, 442.1758118656464, 366.46664316773126, 167.93547177538113, 215.2657000239323, 420.8773048129506, 407.9847671277433, 278.43509174022984, 315.1753303512371, 471.2245685149486, 228.85354143500606, 443.63280581599815, 367.92147299696194, 399.3035496263478, 390.0520517938547, 291.99363570397435, 328.2871690968729, 346.9942744806438, 372.2014209467985, 296.68801458860787, 230.81270551022948, 365.02314496522536, 304.1689464123784, 403.8930794557382, 456.6014831995592, 351.0775192232262, 243.41538988290648, 388.59029083469153, 389.19221483247304, 332.8189303628664, 277.0237047729729, 238.41168993849027, 133.18535333798175, 224.75802457838992, 312.9461126077208, 278.04782422298, 165.8592325198926, 308.17566305675666, 209.74757042973206, 354.61467223190544, 237.06242019341815, 222.42585245886698, 341.19140708252, 261.4804272356214, 159.04882073870033, 308.3318903794, 284.8571863655889, 232.1703450826176, 426.60771506994115, 422.72851175003365, 443.9175113762369, 171.9525004337339, 465.16770251896094, 339.8789945183149, 317.6430486508536, 199.8595086943488, 385.2234355461704, 53.41132054107582, 215.07888711257624, 408.1293404072689, 413.6390554799988, 492.6412357329314, 305.70397221308883, 295.49928951605676, 198.61526402308252, 412.37233942211054, 311.0210193146894, 337.86215597349536, 228.57252118267553, 279.60042327375464, 319.38587343308745, 495.035687552488, 500.4793073263061, 284.63723515195164, 449.49660750919355, 280.93463266839615, 290.2569538987438, 351.77676600048056, 389.84108405701016, 464.80248307652175, 467.51224743259786, 466.23336393044457, 381.34878540498795, 462.04275885479785, 422.7702502657985, 366.9958759860373, 425.24104871615856, 321.56141435226584, 470.44444719975394, 484.09064577262114, 392.49140451071065, 466.8259124617957, 391.2077244158762, 346.2619886593348, 332.3409139779166, 433.0698202221514, 401.53755457156353, 264.0474998816744, 493.83461881979935, 487.88961428485777, 416.65161118690247, 418.1672335200961, 311.2845834756713, 189.28740042201133, 356.5754713880187, 221.68711472137636, 364.2095283495519, 409.70754031922644, 358.68922892722793, 395.41473488308566, 383.23588232127884, 298.1519951657054, 304.0301136175208, 431.01477405975197, 462.13738368616265, 369.7549382792602, 359.6898640119317, 347.0683876142279, 428.14897221461996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3984079056315086, "mean_inference_ms": 6.327456239361355, "mean_action_processing_ms": 1.0234586749815988, "mean_env_wait_ms": 0.8806853586466958, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01953279972076416, "StateBufferConnector_ms": 0.014919877052307129, "ViewRequirementAgentConnector_ms": 0.35393691062927246}, "num_episodes": 22, "episode_return_max": 2095.809179868487, "episode_return_min": 1371.6631705664654, "episode_return_mean": 1833.053016587993, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 238.74504911372253, "num_env_steps_trained_throughput_per_sec": 238.74504911372253, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 21864.176, "restore_workers_time_ms": 0.015, "training_step_time_ms": 21864.13, "sample_time_ms": 5558.433, "learn_time_ms": 16280.945, "learn_throughput": 245.686, "synch_weights_time_ms": 23.614}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "479e5_00000", "date": "2024-08-16_12-27-39", "timestamp": 1723791459, "time_this_iter_s": 16.7609703540802, "time_total_s": 3650.2606830596924, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7dd19d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3650.2606830596924, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 28.899999999999995, "ram_util_percent": 63.737500000000004}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.264570113306954, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.55495175810718, "policy_loss": -0.00438853449855867, "vf_loss": 9.557918486519466, "vf_explained_var": -0.006364046108155023, "kl": 0.01263810052394532, "entropy": 1.1445084154290497, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.606405794131693, "cur_kl_coeff": 0.00263671875, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.302253720621584, "policy_loss": 0.002653134653527073, "vf_loss": 9.299527062310112, "vf_explained_var": -0.28351798612604695, "kl": 0.027883142561377673, "entropy": 0.6004583884483923, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 2114.812675181854, "episode_reward_min": 1287.1611665222192, "episode_reward_mean": 1840.0356474993578, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 194.3360272150961, "predator_policy": 53.41132054107582}, "policy_reward_max": {"prey_policy": 842.677036736719, "predator_policy": 603.5472138177494}, "policy_reward_mean": {"prey_policy": 573.0968337025065, "predator_policy": 346.9209900471724}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1829.6374615133252, 1993.9657970993028, 1942.050507400357, 1807.0499502753628, 1813.9353378848448, 1953.784382404492, 1865.3968716248837, 1731.1731459729717, 1740.1059978850571, 1885.6154124508653, 1594.2220683961743, 1955.5006358994992, 1567.6584904894592, 1673.992687751124, 1868.57150905551, 1890.6602628768726, 2020.36391326778, 1860.9176458446389, 1704.6778974168005, 1717.3652371660633, 1785.3441702737773, 1851.7103869753553, 1917.1605484993784, 1952.7385321474012, 1473.1826966423314, 1944.2513287724696, 1840.9844567043003, 1688.3744106477686, 1954.2958869816468, 1823.949073266181, 1782.079869135002, 1852.1191030113569, 1780.1234991995489, 2015.8674919411528, 2079.422724023285, 1824.6567694627927, 1882.882032498985, 1927.3031654682065, 1663.75809864564, 1748.0934259402463, 1743.8048193959444, 1761.3613584277855, 1891.3985462268017, 1754.2243334822754, 1557.9099265054936, 1884.76781134394, 1743.8655446101898, 1876.3356257423006, 1797.4309838191873, 1567.324820861338, 1668.1153159341068, 1542.1555013230388, 1955.223873139573, 2014.3349010472086, 1786.9597646083375, 1956.5423934819805, 1841.8161348694146, 1913.6575381043767, 1882.8643618094177, 1852.7673911661636, 1793.390511786882, 1956.7128137713303, 1947.9331093768142, 1894.5282568945138, 1890.5023321497195, 1976.962763115114, 1803.1223327868324, 1877.16665146145, 2095.809179868487, 1947.6823814718168, 1894.2553665308226, 1786.6528551280378, 1822.3652761462095, 1944.797394843364, 1857.4074783981828, 1860.947944119888, 1987.2291109675555, 1837.2348287541363, 1785.348500247514, 2052.5610105523224, 1859.428688020085, 1947.3720993288714, 1944.7882222708824, 1481.7707589298298, 1287.1611665222192, 1886.2821943561516, 1554.073394234524, 1937.4997339850322, 1934.380173085513, 1895.3844422782315, 1994.3569334489375, 1963.2241610555006, 1900.4065239132296, 1578.3898009726793, 2086.9940249542205, 1921.8047210550874, 1792.5135101201863, 1897.284219670803, 1815.2233793698633, 2114.812675181854], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [562.0393347991117, 620.0227350745577, 460.7093483000145, 564.4874421614236, 691.9919660273604, 645.283939448407, 533.872352500158, 657.9667222315231, 549.9225551903909, 565.7779095657373, 582.183683569177, 635.2265427119337, 430.98910407158587, 552.7145599149482, 508.08869721161506, 608.1844395963391, 500.69718750986726, 587.8960684273229, 663.3429542532328, 583.0890132359536, 580.0233675755314, 548.8382542870215, 499.76461011756487, 410.16295677046884, 541.6280224608116, 739.7224523561866, 505.1813918949164, 504.1699772331109, 510.99981591357994, 510.3225156175554, 662.5903686918032, 764.5311709166007, 572.6166838532702, 697.9817125994552, 551.0786072933007, 604.6315391670911, 663.4535056192636, 636.8490743045205, 726.2493836282971, 629.5844064027802, 517.000491106024, 453.3205777815038, 660.4878997064503, 693.9136871492319, 497.3473236845715, 504.42482846621203, 589.2473184276673, 554.8487586863555, 565.2169599061484, 524.7645649368712, 725.817946980912, 389.5713098508599, 580.4326826386849, 666.9413519741485, 511.482510097939, 476.81379059987694, 571.3879100759717, 571.3536980927173, 560.3571837789033, 474.2362880670746, 569.9883897651608, 591.810674568992, 575.0554411784178, 557.8679664054962, 613.6601530831107, 638.9626260176027, 664.0067561690843, 682.6686443944658, 659.347362591319, 559.5807987766674, 593.6951295332155, 636.4687308234437, 634.2278692545336, 470.8716575772861, 667.540528386824, 649.9200019455434, 703.7572966200464, 588.4037587491244, 643.4961634830532, 566.8931252710802, 685.0283827222232, 614.8693799308534, 699.6241202592236, 543.8140046820704, 664.658806499909, 635.0626473015689, 627.3247232500125, 563.282350690876, 627.0915554507155, 510.2891230804574, 670.0271839303264, 621.5515506686276, 575.826693059308, 509.2607913983254, 607.4566888799666, 402.23291373606463, 612.9556869171589, 547.3550939493327, 590.0275294598965, 319.7752482322737, 528.1663406175023, 554.8660310760863, 698.0227794003647, 575.6425142690229, 551.5628729071059, 581.8926043451978, 557.0968247034202, 658.8928683977659, 612.3218293153542, 680.5233817538438, 656.2284337274199, 576.9206010177612, 628.663908480629, 646.7175492326172, 623.0836877183965, 691.5875536791348, 373.9513114665588, 513.3980554640646, 546.0752239029953, 572.5583246020248, 607.9523084581805, 614.2466167615613, 706.8847732769467, 508.2101904368913, 421.8612429372106, 593.7571359304825, 519.0566205666657, 527.889486992417, 511.9196703842919, 493.7696526448319, 607.7674840384561, 576.958354374463, 432.4892911919693, 578.6271800428414, 548.382231847885, 452.2023693302352, 531.8511460862832, 705.9243969045318, 652.5569524241929, 616.5225264103734, 470.4117765135691, 589.2362152235381, 518.7667979380826, 510.0039384884816, 482.16981753570445, 435.6542331387444, 584.1293059283792, 631.2162719192215, 617.2602776967713, 694.2843288913834, 633.2796489351567, 641.7716521138027, 636.7840135774516, 582.0483281436497, 490.2721378534157, 568.3120736963548, 567.341034870905, 615.8253565933811, 699.3123451328954, 460.0965076735131, 639.8751683395568, 490.10871738933486, 512.1363489734293, 660.018390526596, 753.2116549975707, 271.8412394261091, 508.5261293460067, 474.4986028977489, 438.2098810080192, 504.8135651674622, 194.3360272150961, 525.5547689869688, 451.72972897907925, 465.42123234509455, 575.4174960330271, 532.7720479716405, 538.4752797198124, 535.0572129661069, 563.839316576284, 466.63003742585335, 483.67600823062753, 681.391271237605, 672.0638790764872, 518.1025769805316, 639.4866133514938, 430.95997173943374, 655.0225415712121, 577.1966121845093, 842.677036736719, 479.0984863902705, 613.2182564692157, 604.0788698141403, 537.6891312765044, 436.67562493692924, 595.3896530886511, 560.8909582474018, 530.3788070018377, 582.1978912206919, 515.2711073185975, 746.6792051497026], "policy_predator_policy_reward": [272.43708808891114, 375.1383035507446, 479.2273712859697, 489.54163535189514, 336.2261994015388, 268.5484025230485, 398.57280443639615, 216.63807110728615, 423.82868622469266, 274.4061869040223, 367.39764697555745, 368.97650914782434, 341.63337830242676, 540.0598293359242, 271.8821908761788, 343.01781828883827, 370.1775310120141, 281.3352109358534, 276.6188165643507, 362.5646283973284, 207.56736379732783, 257.7930827362934, 536.7075079959533, 508.86556101551145, 127.01168944597377, 159.2963262264878, 384.8917448885023, 279.7495737345998, 451.7199310456191, 395.52924647875506, 236.5150509083014, 227.02367236016715, 383.41118131184436, 366.35433550320886, 286.39546037340097, 418.81203901084626, 184.34673590553206, 220.02858158748265, 227.80671888964375, 133.7247282453434, 306.1951449794804, 508.8279564067678, 224.47890791426445, 272.82989220540424, 439.60043673637233, 475.78795961222187, 442.1758118656464, 366.46664316773126, 167.93547177538113, 215.2657000239323, 420.8773048129506, 407.9847671277433, 278.43509174022984, 315.1753303512371, 471.2245685149486, 228.85354143500606, 443.63280581599815, 367.92147299696194, 399.3035496263478, 390.0520517938547, 291.99363570397435, 328.2871690968729, 346.9942744806438, 372.2014209467985, 296.68801458860787, 230.81270551022948, 365.02314496522536, 304.1689464123784, 403.8930794557382, 456.6014831995592, 351.0775192232262, 243.41538988290648, 388.59029083469153, 389.19221483247304, 332.8189303628664, 277.0237047729729, 238.41168993849027, 133.18535333798175, 224.75802457838992, 312.9461126077208, 278.04782422298, 165.8592325198926, 308.17566305675666, 209.74757042973206, 354.61467223190544, 237.06242019341815, 222.42585245886698, 341.19140708252, 261.4804272356214, 159.04882073870033, 308.3318903794, 284.8571863655889, 232.1703450826176, 426.60771506994115, 422.72851175003365, 443.9175113762369, 171.9525004337339, 465.16770251896094, 339.8789945183149, 317.6430486508536, 199.8595086943488, 385.2234355461704, 53.41132054107582, 215.07888711257624, 408.1293404072689, 413.6390554799988, 492.6412357329314, 305.70397221308883, 295.49928951605676, 198.61526402308252, 412.37233942211054, 311.0210193146894, 337.86215597349536, 228.57252118267553, 279.60042327375464, 319.38587343308745, 495.035687552488, 500.4793073263061, 284.63723515195164, 449.49660750919355, 280.93463266839615, 290.2569538987438, 351.77676600048056, 389.84108405701016, 464.80248307652175, 467.51224743259786, 466.23336393044457, 381.34878540498795, 462.04275885479785, 422.7702502657985, 366.9958759860373, 425.24104871615856, 321.56141435226584, 470.44444719975394, 484.09064577262114, 392.49140451071065, 466.8259124617957, 391.2077244158762, 346.2619886593348, 332.3409139779166, 433.0698202221514, 401.53755457156353, 264.0474998816744, 493.83461881979935, 487.88961428485777, 416.65161118690247, 418.1672335200961, 311.2845834756713, 189.28740042201133, 356.5754713880187, 221.68711472137636, 364.2095283495519, 409.70754031922644, 358.68922892722793, 395.41473488308566, 383.23588232127884, 298.1519951657054, 304.0301136175208, 431.01477405975197, 462.13738368616265, 369.7549382792602, 359.6898640119317, 347.0683876142279, 428.14897221461996, 477.7333842994396, 442.0019435477653, 244.46446115324395, 254.2815655328299, 190.8956027489595, 153.242117597778, 603.5472138177494, 562.8441843363378, 224.84249684269128, 412.07993606765757, 404.66427698785185, 424.64591299251265, 444.67247367899745, 416.17520672059493, 448.99837945023734, 415.9167088258561, 383.6314936178805, 445.6581603628269, 284.3487672138868, 488.70893778459657, 385.7921395887402, 444.1677992335614, 157.3885535801378, 188.7820936368187, 372.37773792474394, 392.840763902486, 299.75570246306785, 404.7518923086641, 352.6276191513545, 465.521134755396, 353.5827622958997, 387.4208460388483, 383.3497665644707, 319.29691458286123, 456.19374494329935, 396.6686177702549]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.400019400740208, "mean_inference_ms": 6.3303273180423165, "mean_action_processing_ms": 1.0240265831728752, "mean_env_wait_ms": 0.8806080637041, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015534400939941406, "StateBufferConnector_ms": 0.009739041328430176, "ViewRequirementAgentConnector_ms": 0.34123384952545166}, "num_episodes": 18, "episode_return_max": 2114.812675181854, "episode_return_min": 1287.1611665222192, "episode_return_mean": 1840.0356474993578, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 241.36596212316618, "num_env_steps_trained_throughput_per_sec": 241.36596212316618, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 22385.448, "restore_workers_time_ms": 0.015, "training_step_time_ms": 22385.401, "sample_time_ms": 5881.396, "learn_time_ms": 16478.824, "learn_throughput": 242.736, "synch_weights_time_ms": 24.04}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "479e5_00000", "date": "2024-08-16_12-27-56", "timestamp": 1723791476, "time_this_iter_s": 16.575939178466797, "time_total_s": 3666.836622238159, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7f2cca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3666.836622238159, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 29.15833333333333, "ram_util_percent": 64.19166666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.237211513771582, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.401915155642877, "policy_loss": -0.0021143350384331175, "vf_loss": 9.403227838385043, "vf_explained_var": -0.0023495888583874576, "kl": 0.007125850751315298, "entropy": 1.1163609336292932, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.514959036799335, "cur_kl_coeff": 0.003955078124999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.59744871886319, "policy_loss": -0.002771715794951118, "vf_loss": 9.600155926255322, "vf_explained_var": -0.14907576129550026, "kl": 0.016308382911605555, "entropy": 0.5843709277255195, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 2114.812675181854, "episode_reward_min": 1173.4482445853957, "episode_reward_mean": 1804.0470712618362, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 194.3360272150961, "predator_policy": 53.41132054107582}, "policy_reward_max": {"prey_policy": 842.677036736719, "predator_policy": 603.5472138177494}, "policy_reward_mean": {"prey_policy": 563.6204750696834, "predator_policy": 338.4030605612346}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1952.7385321474012, 1473.1826966423314, 1944.2513287724696, 1840.9844567043003, 1688.3744106477686, 1954.2958869816468, 1823.949073266181, 1782.079869135002, 1852.1191030113569, 1780.1234991995489, 2015.8674919411528, 2079.422724023285, 1824.6567694627927, 1882.882032498985, 1927.3031654682065, 1663.75809864564, 1748.0934259402463, 1743.8048193959444, 1761.3613584277855, 1891.3985462268017, 1754.2243334822754, 1557.9099265054936, 1884.76781134394, 1743.8655446101898, 1876.3356257423006, 1797.4309838191873, 1567.324820861338, 1668.1153159341068, 1542.1555013230388, 1955.223873139573, 2014.3349010472086, 1786.9597646083375, 1956.5423934819805, 1841.8161348694146, 1913.6575381043767, 1882.8643618094177, 1852.7673911661636, 1793.390511786882, 1956.7128137713303, 1947.9331093768142, 1894.5282568945138, 1890.5023321497195, 1976.962763115114, 1803.1223327868324, 1877.16665146145, 2095.809179868487, 1947.6823814718168, 1894.2553665308226, 1786.6528551280378, 1822.3652761462095, 1944.797394843364, 1857.4074783981828, 1860.947944119888, 1987.2291109675555, 1837.2348287541363, 1785.348500247514, 2052.5610105523224, 1859.428688020085, 1947.3720993288714, 1944.7882222708824, 1481.7707589298298, 1287.1611665222192, 1886.2821943561516, 1554.073394234524, 1937.4997339850322, 1934.380173085513, 1895.3844422782315, 1994.3569334489375, 1963.2241610555006, 1900.4065239132296, 1578.3898009726793, 2086.9940249542205, 1921.8047210550874, 1792.5135101201863, 1897.284219670803, 1815.2233793698633, 2114.812675181854, 1761.1791869325666, 1720.3071661629083, 1776.8629975257986, 1841.7210186003604, 1794.3677472171787, 1720.1907976893185, 1846.8821892599753, 1626.3275645676463, 1817.5601569056066, 1307.8886421952259, 1896.179845281749, 2030.0079426944849, 1641.2806267101748, 1173.4482445853957, 1989.25413612417, 1180.8945995472177, 1603.023765066986, 1694.3905404485402, 1559.6138555182067, 1345.6518479339788, 1937.839349491057, 1577.8351441655443, 1529.2953300476224], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [589.2473184276673, 554.8487586863555, 565.2169599061484, 524.7645649368712, 725.817946980912, 389.5713098508599, 580.4326826386849, 666.9413519741485, 511.482510097939, 476.81379059987694, 571.3879100759717, 571.3536980927173, 560.3571837789033, 474.2362880670746, 569.9883897651608, 591.810674568992, 575.0554411784178, 557.8679664054962, 613.6601530831107, 638.9626260176027, 664.0067561690843, 682.6686443944658, 659.347362591319, 559.5807987766674, 593.6951295332155, 636.4687308234437, 634.2278692545336, 470.8716575772861, 667.540528386824, 649.9200019455434, 703.7572966200464, 588.4037587491244, 643.4961634830532, 566.8931252710802, 685.0283827222232, 614.8693799308534, 699.6241202592236, 543.8140046820704, 664.658806499909, 635.0626473015689, 627.3247232500125, 563.282350690876, 627.0915554507155, 510.2891230804574, 670.0271839303264, 621.5515506686276, 575.826693059308, 509.2607913983254, 607.4566888799666, 402.23291373606463, 612.9556869171589, 547.3550939493327, 590.0275294598965, 319.7752482322737, 528.1663406175023, 554.8660310760863, 698.0227794003647, 575.6425142690229, 551.5628729071059, 581.8926043451978, 557.0968247034202, 658.8928683977659, 612.3218293153542, 680.5233817538438, 656.2284337274199, 576.9206010177612, 628.663908480629, 646.7175492326172, 623.0836877183965, 691.5875536791348, 373.9513114665588, 513.3980554640646, 546.0752239029953, 572.5583246020248, 607.9523084581805, 614.2466167615613, 706.8847732769467, 508.2101904368913, 421.8612429372106, 593.7571359304825, 519.0566205666657, 527.889486992417, 511.9196703842919, 493.7696526448319, 607.7674840384561, 576.958354374463, 432.4892911919693, 578.6271800428414, 548.382231847885, 452.2023693302352, 531.8511460862832, 705.9243969045318, 652.5569524241929, 616.5225264103734, 470.4117765135691, 589.2362152235381, 518.7667979380826, 510.0039384884816, 482.16981753570445, 435.6542331387444, 584.1293059283792, 631.2162719192215, 617.2602776967713, 694.2843288913834, 633.2796489351567, 641.7716521138027, 636.7840135774516, 582.0483281436497, 490.2721378534157, 568.3120736963548, 567.341034870905, 615.8253565933811, 699.3123451328954, 460.0965076735131, 639.8751683395568, 490.10871738933486, 512.1363489734293, 660.018390526596, 753.2116549975707, 271.8412394261091, 508.5261293460067, 474.4986028977489, 438.2098810080192, 504.8135651674622, 194.3360272150961, 525.5547689869688, 451.72972897907925, 465.42123234509455, 575.4174960330271, 532.7720479716405, 538.4752797198124, 535.0572129661069, 563.839316576284, 466.63003742585335, 483.67600823062753, 681.391271237605, 672.0638790764872, 518.1025769805316, 639.4866133514938, 430.95997173943374, 655.0225415712121, 577.1966121845093, 842.677036736719, 479.0984863902705, 613.2182564692157, 604.0788698141403, 537.6891312765044, 436.67562493692924, 595.3896530886511, 560.8909582474018, 530.3788070018377, 582.1978912206919, 515.2711073185975, 746.6792051497026, 621.3902630160252, 616.4465918940384, 637.2859651301279, 632.4402823144011, 338.49717256174614, 463.82388200545034, 464.6303592103326, 586.4913237970709, 679.9965352545591, 521.0819464736268, 539.0815158611626, 598.594643488752, 491.81171844120826, 457.42439297362955, 706.3054630698085, 451.7442014450077, 561.7082323103434, 570.3161821893078, 639.7358793815131, 305.1976255375527, 695.5630216555588, 455.5040642281833, 542.7292776167725, 770.2990140411162, 569.0028757268547, 655.4646516217572, 303.4433485713041, 648.5807616521291, 454.5454900444613, 535.3206746209999, 259.8417794407047, 624.6945528851434, 490.5917166195821, 555.6014346488851, 582.8762173037245, 485.56667360714795, 432.3778401612842, 504.69711321445965, 573.2015528036937, 199.01, 572.9954605656364, 632.4803090595503, 464.8188886436167, 638.6254057070419, 677.6008213284839, 586.6523317094016], "policy_predator_policy_reward": [442.1758118656464, 366.46664316773126, 167.93547177538113, 215.2657000239323, 420.8773048129506, 407.9847671277433, 278.43509174022984, 315.1753303512371, 471.2245685149486, 228.85354143500606, 443.63280581599815, 367.92147299696194, 399.3035496263478, 390.0520517938547, 291.99363570397435, 328.2871690968729, 346.9942744806438, 372.2014209467985, 296.68801458860787, 230.81270551022948, 365.02314496522536, 304.1689464123784, 403.8930794557382, 456.6014831995592, 351.0775192232262, 243.41538988290648, 388.59029083469153, 389.19221483247304, 332.8189303628664, 277.0237047729729, 238.41168993849027, 133.18535333798175, 224.75802457838992, 312.9461126077208, 278.04782422298, 165.8592325198926, 308.17566305675666, 209.74757042973206, 354.61467223190544, 237.06242019341815, 222.42585245886698, 341.19140708252, 261.4804272356214, 159.04882073870033, 308.3318903794, 284.8571863655889, 232.1703450826176, 426.60771506994115, 422.72851175003365, 443.9175113762369, 171.9525004337339, 465.16770251896094, 339.8789945183149, 317.6430486508536, 199.8595086943488, 385.2234355461704, 53.41132054107582, 215.07888711257624, 408.1293404072689, 413.6390554799988, 492.6412357329314, 305.70397221308883, 295.49928951605676, 198.61526402308252, 412.37233942211054, 311.0210193146894, 337.86215597349536, 228.57252118267553, 279.60042327375464, 319.38587343308745, 495.035687552488, 500.4793073263061, 284.63723515195164, 449.49660750919355, 280.93463266839615, 290.2569538987438, 351.77676600048056, 389.84108405701016, 464.80248307652175, 467.51224743259786, 466.23336393044457, 381.34878540498795, 462.04275885479785, 422.7702502657985, 366.9958759860373, 425.24104871615856, 321.56141435226584, 470.44444719975394, 484.09064577262114, 392.49140451071065, 466.8259124617957, 391.2077244158762, 346.2619886593348, 332.3409139779166, 433.0698202221514, 401.53755457156353, 264.0474998816744, 493.83461881979935, 487.88961428485777, 416.65161118690247, 418.1672335200961, 311.2845834756713, 189.28740042201133, 356.5754713880187, 221.68711472137636, 364.2095283495519, 409.70754031922644, 358.68922892722793, 395.41473488308566, 383.23588232127884, 298.1519951657054, 304.0301136175208, 431.01477405975197, 462.13738368616265, 369.7549382792602, 359.6898640119317, 347.0683876142279, 428.14897221461996, 477.7333842994396, 442.0019435477653, 244.46446115324395, 254.2815655328299, 190.8956027489595, 153.242117597778, 603.5472138177494, 562.8441843363378, 224.84249684269128, 412.07993606765757, 404.66427698785185, 424.64591299251265, 444.67247367899745, 416.17520672059493, 448.99837945023734, 415.9167088258561, 383.6314936178805, 445.6581603628269, 284.3487672138868, 488.70893778459657, 385.7921395887402, 444.1677992335614, 157.3885535801378, 188.7820936368187, 372.37773792474394, 392.840763902486, 299.75570246306785, 404.7518923086641, 352.6276191513545, 465.521134755396, 353.5827622958997, 387.4208460388483, 383.3497665644707, 319.29691458286123, 456.19374494329935, 396.6686177702549, 220.13875928845556, 303.2035727340477, 265.8419874851482, 184.73893123323063, 494.42203641070665, 480.119906547893, 400.4337782803685, 390.1655573125883, 273.76989518909136, 319.51937029989745, 189.18872230351434, 393.3259160358908, 424.61026642004055, 473.0358114250966, 174.64560951178385, 293.6322905410468, 330.6350254888318, 354.90071691712296, 213.64669797581382, 149.3084393003467, 387.9790580516327, 357.13370134637705, 301.18082435079737, 415.7988266858019, 269.761764944089, 147.0513344174764, 133.6763194521073, 87.74781490985588, 441.72419967297645, 557.6637717857312, 146.74829871085754, 149.60996851051243, 266.3586927976499, 290.4719210008688, 390.3145265909277, 235.6331229467395, 263.046640337494, 359.49226180496777, 211.30867556414947, 362.13161956613607, 437.23252867826915, 295.131051187599, 89.63954006465232, 384.7513097502324, 142.41887630226407, 122.62330070747177]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4008574640882534, "mean_inference_ms": 6.330873923618034, "mean_action_processing_ms": 1.0245133547117202, "mean_env_wait_ms": 0.8800799040561397, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013064742088317871, "StateBufferConnector_ms": 0.009911775588989258, "ViewRequirementAgentConnector_ms": 0.35823535919189453}, "num_episodes": 23, "episode_return_max": 2114.812675181854, "episode_return_min": 1173.4482445853957, "episode_return_mean": 1804.0470712618362, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 261.78087720071295, "num_env_steps_trained_throughput_per_sec": 261.78087720071295, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 20864.0, "restore_workers_time_ms": 0.014, "training_step_time_ms": 20863.953, "sample_time_ms": 6152.703, "learn_time_ms": 14691.079, "learn_throughput": 272.274, "synch_weights_time_ms": 19.062}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "479e5_00000", "date": "2024-08-16_12-28-11", "timestamp": 1723791491, "time_this_iter_s": 15.285880088806152, "time_total_s": 3682.1225023269653, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7fe2b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3682.1225023269653, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 27.62380952380952, "ram_util_percent": 64.55238095238094}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3123319673159766, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.460373812377767, "policy_loss": -0.0013843946105913905, "vf_loss": 9.460977702166037, "vf_explained_var": 0.02425274574567401, "kl": 0.006937708528116384, "entropy": 1.1537927431404276, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.21306458342643, "cur_kl_coeff": 0.003955078124999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.399305887575503, "policy_loss": 0.0042937011306454975, "vf_loss": 9.394948775679977, "vf_explained_var": -0.1397695797776419, "kl": 0.016038847293886993, "entropy": 0.5789802987424154, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 2114.812675181854, "episode_reward_min": 1173.4482445853957, "episode_reward_mean": 1788.5566414465761, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 194.3360272150961, "predator_policy": -18.907716712548563}, "policy_reward_max": {"prey_policy": 842.677036736719, "predator_policy": 631.2664460790745}, "policy_reward_mean": {"prey_policy": 557.1369372300567, "predator_policy": 337.1413834932315}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1761.3613584277855, 1891.3985462268017, 1754.2243334822754, 1557.9099265054936, 1884.76781134394, 1743.8655446101898, 1876.3356257423006, 1797.4309838191873, 1567.324820861338, 1668.1153159341068, 1542.1555013230388, 1955.223873139573, 2014.3349010472086, 1786.9597646083375, 1956.5423934819805, 1841.8161348694146, 1913.6575381043767, 1882.8643618094177, 1852.7673911661636, 1793.390511786882, 1956.7128137713303, 1947.9331093768142, 1894.5282568945138, 1890.5023321497195, 1976.962763115114, 1803.1223327868324, 1877.16665146145, 2095.809179868487, 1947.6823814718168, 1894.2553665308226, 1786.6528551280378, 1822.3652761462095, 1944.797394843364, 1857.4074783981828, 1860.947944119888, 1987.2291109675555, 1837.2348287541363, 1785.348500247514, 2052.5610105523224, 1859.428688020085, 1947.3720993288714, 1944.7882222708824, 1481.7707589298298, 1287.1611665222192, 1886.2821943561516, 1554.073394234524, 1937.4997339850322, 1934.380173085513, 1895.3844422782315, 1994.3569334489375, 1963.2241610555006, 1900.4065239132296, 1578.3898009726793, 2086.9940249542205, 1921.8047210550874, 1792.5135101201863, 1897.284219670803, 1815.2233793698633, 2114.812675181854, 1761.1791869325666, 1720.3071661629083, 1776.8629975257986, 1841.7210186003604, 1794.3677472171787, 1720.1907976893185, 1846.8821892599753, 1626.3275645676463, 1817.5601569056066, 1307.8886421952259, 1896.179845281749, 2030.0079426944849, 1641.2806267101748, 1173.4482445853957, 1989.25413612417, 1180.8945995472177, 1603.023765066986, 1694.3905404485402, 1559.6138555182067, 1345.6518479339788, 1937.839349491057, 1577.8351441655443, 1529.2953300476224, 1624.7603785878246, 1708.0138724227747, 2059.7004664271963, 1637.6055197340743, 1322.6359306271906, 1615.1851350452366, 1947.2394433037482, 1817.0143309304156, 1348.9448515753536, 1476.8422779651078, 2082.0343448937415, 1826.1177685530436, 1650.5515484249613, 1883.64449083161, 1949.4125897025513, 1979.9128020829023, 1492.8414649773454, 2006.387186273219], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [699.6241202592236, 543.8140046820704, 664.658806499909, 635.0626473015689, 627.3247232500125, 563.282350690876, 627.0915554507155, 510.2891230804574, 670.0271839303264, 621.5515506686276, 575.826693059308, 509.2607913983254, 607.4566888799666, 402.23291373606463, 612.9556869171589, 547.3550939493327, 590.0275294598965, 319.7752482322737, 528.1663406175023, 554.8660310760863, 698.0227794003647, 575.6425142690229, 551.5628729071059, 581.8926043451978, 557.0968247034202, 658.8928683977659, 612.3218293153542, 680.5233817538438, 656.2284337274199, 576.9206010177612, 628.663908480629, 646.7175492326172, 623.0836877183965, 691.5875536791348, 373.9513114665588, 513.3980554640646, 546.0752239029953, 572.5583246020248, 607.9523084581805, 614.2466167615613, 706.8847732769467, 508.2101904368913, 421.8612429372106, 593.7571359304825, 519.0566205666657, 527.889486992417, 511.9196703842919, 493.7696526448319, 607.7674840384561, 576.958354374463, 432.4892911919693, 578.6271800428414, 548.382231847885, 452.2023693302352, 531.8511460862832, 705.9243969045318, 652.5569524241929, 616.5225264103734, 470.4117765135691, 589.2362152235381, 518.7667979380826, 510.0039384884816, 482.16981753570445, 435.6542331387444, 584.1293059283792, 631.2162719192215, 617.2602776967713, 694.2843288913834, 633.2796489351567, 641.7716521138027, 636.7840135774516, 582.0483281436497, 490.2721378534157, 568.3120736963548, 567.341034870905, 615.8253565933811, 699.3123451328954, 460.0965076735131, 639.8751683395568, 490.10871738933486, 512.1363489734293, 660.018390526596, 753.2116549975707, 271.8412394261091, 508.5261293460067, 474.4986028977489, 438.2098810080192, 504.8135651674622, 194.3360272150961, 525.5547689869688, 451.72972897907925, 465.42123234509455, 575.4174960330271, 532.7720479716405, 538.4752797198124, 535.0572129661069, 563.839316576284, 466.63003742585335, 483.67600823062753, 681.391271237605, 672.0638790764872, 518.1025769805316, 639.4866133514938, 430.95997173943374, 655.0225415712121, 577.1966121845093, 842.677036736719, 479.0984863902705, 613.2182564692157, 604.0788698141403, 537.6891312765044, 436.67562493692924, 595.3896530886511, 560.8909582474018, 530.3788070018377, 582.1978912206919, 515.2711073185975, 746.6792051497026, 621.3902630160252, 616.4465918940384, 637.2859651301279, 632.4402823144011, 338.49717256174614, 463.82388200545034, 464.6303592103326, 586.4913237970709, 679.9965352545591, 521.0819464736268, 539.0815158611626, 598.594643488752, 491.81171844120826, 457.42439297362955, 706.3054630698085, 451.7442014450077, 561.7082323103434, 570.3161821893078, 639.7358793815131, 305.1976255375527, 695.5630216555588, 455.5040642281833, 542.7292776167725, 770.2990140411162, 569.0028757268547, 655.4646516217572, 303.4433485713041, 648.5807616521291, 454.5454900444613, 535.3206746209999, 259.8417794407047, 624.6945528851434, 490.5917166195821, 555.6014346488851, 582.8762173037245, 485.56667360714795, 432.3778401612842, 504.69711321445965, 573.2015528036937, 199.01, 572.9954605656364, 632.4803090595503, 464.8188886436167, 638.6254057070419, 677.6008213284839, 586.6523317094016, 406.57142260933153, 715.3306933857415, 703.7799986657561, 639.4969585958636, 573.9596058013032, 610.1810570401352, 450.26847769726527, 484.0197288167618, 375.5388496415173, 821.8379468631523, 575.1351585102834, 409.497357160285, 640.7231527278668, 677.2374703801457, 628.9364900634049, 450.9011766215631, 586.8933949893511, 470.2708200000917, 679.6089367913952, 506.3718201757729, 440.71428328621664, 706.5566198610791, 240.93551253512527, 328.15015754380437, 530.8146783386561, 493.50887264749525, 566.3236548130877, 570.4916287279465, 526.0216888145325, 476.55767722183816, 584.4681368221679, 536.1952002000043, 713.1085568814543, 744.2652420694699, 667.9892278476628, 501.2238892888017], "policy_predator_policy_reward": [308.17566305675666, 209.74757042973206, 354.61467223190544, 237.06242019341815, 222.42585245886698, 341.19140708252, 261.4804272356214, 159.04882073870033, 308.3318903794, 284.8571863655889, 232.1703450826176, 426.60771506994115, 422.72851175003365, 443.9175113762369, 171.9525004337339, 465.16770251896094, 339.8789945183149, 317.6430486508536, 199.8595086943488, 385.2234355461704, 53.41132054107582, 215.07888711257624, 408.1293404072689, 413.6390554799988, 492.6412357329314, 305.70397221308883, 295.49928951605676, 198.61526402308252, 412.37233942211054, 311.0210193146894, 337.86215597349536, 228.57252118267553, 279.60042327375464, 319.38587343308745, 495.035687552488, 500.4793073263061, 284.63723515195164, 449.49660750919355, 280.93463266839615, 290.2569538987438, 351.77676600048056, 389.84108405701016, 464.80248307652175, 467.51224743259786, 466.23336393044457, 381.34878540498795, 462.04275885479785, 422.7702502657985, 366.9958759860373, 425.24104871615856, 321.56141435226584, 470.44444719975394, 484.09064577262114, 392.49140451071065, 466.8259124617957, 391.2077244158762, 346.2619886593348, 332.3409139779166, 433.0698202221514, 401.53755457156353, 264.0474998816744, 493.83461881979935, 487.88961428485777, 416.65161118690247, 418.1672335200961, 311.2845834756713, 189.28740042201133, 356.5754713880187, 221.68711472137636, 364.2095283495519, 409.70754031922644, 358.68922892722793, 395.41473488308566, 383.23588232127884, 298.1519951657054, 304.0301136175208, 431.01477405975197, 462.13738368616265, 369.7549382792602, 359.6898640119317, 347.0683876142279, 428.14897221461996, 477.7333842994396, 442.0019435477653, 244.46446115324395, 254.2815655328299, 190.8956027489595, 153.242117597778, 603.5472138177494, 562.8441843363378, 224.84249684269128, 412.07993606765757, 404.66427698785185, 424.64591299251265, 444.67247367899745, 416.17520672059493, 448.99837945023734, 415.9167088258561, 383.6314936178805, 445.6581603628269, 284.3487672138868, 488.70893778459657, 385.7921395887402, 444.1677992335614, 157.3885535801378, 188.7820936368187, 372.37773792474394, 392.840763902486, 299.75570246306785, 404.7518923086641, 352.6276191513545, 465.521134755396, 353.5827622958997, 387.4208460388483, 383.3497665644707, 319.29691458286123, 456.19374494329935, 396.6686177702549, 220.13875928845556, 303.2035727340477, 265.8419874851482, 184.73893123323063, 494.42203641070665, 480.119906547893, 400.4337782803685, 390.1655573125883, 273.76989518909136, 319.51937029989745, 189.18872230351434, 393.3259160358908, 424.61026642004055, 473.0358114250966, 174.64560951178385, 293.6322905410468, 330.6350254888318, 354.90071691712296, 213.64669797581382, 149.3084393003467, 387.9790580516327, 357.13370134637705, 301.18082435079737, 415.7988266858019, 269.761764944089, 147.0513344174764, 133.6763194521073, 87.74781490985588, 441.72419967297645, 557.6637717857312, 146.74829871085754, 149.60996851051243, 266.3586927976499, 290.4719210008688, 390.3145265909277, 235.6331229467395, 263.046640337494, 359.49226180496777, 211.30867556414947, 362.13161956613607, 437.23252867826915, 295.131051187599, 89.63954006465232, 384.7513097502324, 142.41887630226407, 122.62330070747177, 243.59671810279124, 259.26154448996095, 29.74972366241937, 334.9871914987354, 474.26143125215526, 401.29837233360576, 204.1712463456174, 499.14606687442887, 53.36103721742389, 71.89809690509782, 297.24423918474986, 333.3083801899209, 295.12098527287367, 334.15783492286187, 463.8342071954498, 273.3424570499968, 62.364100255138354, 229.416536330773, 309.76923771048894, -18.907716712548563, 480.8954387995469, 453.8680029469008, 625.7656523950398, 631.2664460790745, 276.1022514905099, 350.12574594829607, 349.3889480153151, 397.44025927525826, 494.04408466033516, 452.78913900584826, 395.97426587704973, 463.2751991836804, 52.99565329094832, -17.5279872645294, 421.22484324064516, 415.9492258961106]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3984415429058448, "mean_inference_ms": 6.321401203503097, "mean_action_processing_ms": 1.0234823200245975, "mean_env_wait_ms": 0.8784716044004532, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011068463325500488, "StateBufferConnector_ms": 0.0085984468460083, "ViewRequirementAgentConnector_ms": 0.35660791397094727}, "num_episodes": 18, "episode_return_max": 2114.812675181854, "episode_return_min": 1173.4482445853957, "episode_return_mean": 1788.5566414465761, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 261.1501157057412, "num_env_steps_trained_throughput_per_sec": 261.1501157057412, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 18389.876, "restore_workers_time_ms": 0.014, "training_step_time_ms": 18389.832, "sample_time_ms": 4885.267, "learn_time_ms": 13485.48, "learn_throughput": 296.615, "synch_weights_time_ms": 18.131}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "479e5_00000", "date": "2024-08-16_12-28-27", "timestamp": 1723791507, "time_this_iter_s": 15.32232403755188, "time_total_s": 3697.444826364517, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7f958b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3697.444826364517, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 27.59090909090909, "ram_util_percent": 64.59545454545456}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9212057060350185, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.441192149106788, "policy_loss": -0.004582089330587122, "vf_loss": 9.4447359569489, "vf_explained_var": 0.0020179283051263716, "kl": 0.009229058416941459, "entropy": 1.117033807247404, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7559639024671423, "cur_kl_coeff": 0.003955078124999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.420794358833756, "policy_loss": 0.0005648205779916632, "vf_loss": 9.420143469553144, "vf_explained_var": -0.18378069227334684, "kl": 0.021758938982413975, "entropy": 0.5159014966752794, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 2132.178424556338, "episode_reward_min": 1173.4482445853957, "episode_reward_mean": 1799.112936189411, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 58.998919027283165, "predator_policy": -18.907716712548563}, "policy_reward_max": {"prey_policy": 842.677036736719, "predator_policy": 680.225885803304}, "policy_reward_mean": {"prey_policy": 550.5047714063202, "predator_policy": 349.05169668838533}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1894.5282568945138, 1890.5023321497195, 1976.962763115114, 1803.1223327868324, 1877.16665146145, 2095.809179868487, 1947.6823814718168, 1894.2553665308226, 1786.6528551280378, 1822.3652761462095, 1944.797394843364, 1857.4074783981828, 1860.947944119888, 1987.2291109675555, 1837.2348287541363, 1785.348500247514, 2052.5610105523224, 1859.428688020085, 1947.3720993288714, 1944.7882222708824, 1481.7707589298298, 1287.1611665222192, 1886.2821943561516, 1554.073394234524, 1937.4997339850322, 1934.380173085513, 1895.3844422782315, 1994.3569334489375, 1963.2241610555006, 1900.4065239132296, 1578.3898009726793, 2086.9940249542205, 1921.8047210550874, 1792.5135101201863, 1897.284219670803, 1815.2233793698633, 2114.812675181854, 1761.1791869325666, 1720.3071661629083, 1776.8629975257986, 1841.7210186003604, 1794.3677472171787, 1720.1907976893185, 1846.8821892599753, 1626.3275645676463, 1817.5601569056066, 1307.8886421952259, 1896.179845281749, 2030.0079426944849, 1641.2806267101748, 1173.4482445853957, 1989.25413612417, 1180.8945995472177, 1603.023765066986, 1694.3905404485402, 1559.6138555182067, 1345.6518479339788, 1937.839349491057, 1577.8351441655443, 1529.2953300476224, 1624.7603785878246, 1708.0138724227747, 2059.7004664271963, 1637.6055197340743, 1322.6359306271906, 1615.1851350452366, 1947.2394433037482, 1817.0143309304156, 1348.9448515753536, 1476.8422779651078, 2082.0343448937415, 1826.1177685530436, 1650.5515484249613, 1883.64449083161, 1949.4125897025513, 1979.9128020829023, 1492.8414649773454, 2006.387186273219, 2073.741111165786, 1360.2523812614352, 1929.9457303767592, 2056.8140871992755, 1828.417496012033, 1662.3979578341973, 1725.2690575970892, 2127.0583132594393, 2132.178424556338, 1739.9278603984915, 1782.5080983666924, 1940.9318923360333, 1628.1641349891167, 1742.5755142165747, 1914.2228352708805, 1931.9589492928947, 1917.561468995754, 1854.6260803268185, 1788.7324807116458, 1911.8389897373268, 2040.8621255738858, 1912.737046242948], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [519.0566205666657, 527.889486992417, 511.9196703842919, 493.7696526448319, 607.7674840384561, 576.958354374463, 432.4892911919693, 578.6271800428414, 548.382231847885, 452.2023693302352, 531.8511460862832, 705.9243969045318, 652.5569524241929, 616.5225264103734, 470.4117765135691, 589.2362152235381, 518.7667979380826, 510.0039384884816, 482.16981753570445, 435.6542331387444, 584.1293059283792, 631.2162719192215, 617.2602776967713, 694.2843288913834, 633.2796489351567, 641.7716521138027, 636.7840135774516, 582.0483281436497, 490.2721378534157, 568.3120736963548, 567.341034870905, 615.8253565933811, 699.3123451328954, 460.0965076735131, 639.8751683395568, 490.10871738933486, 512.1363489734293, 660.018390526596, 753.2116549975707, 271.8412394261091, 508.5261293460067, 474.4986028977489, 438.2098810080192, 504.8135651674622, 194.3360272150961, 525.5547689869688, 451.72972897907925, 465.42123234509455, 575.4174960330271, 532.7720479716405, 538.4752797198124, 535.0572129661069, 563.839316576284, 466.63003742585335, 483.67600823062753, 681.391271237605, 672.0638790764872, 518.1025769805316, 639.4866133514938, 430.95997173943374, 655.0225415712121, 577.1966121845093, 842.677036736719, 479.0984863902705, 613.2182564692157, 604.0788698141403, 537.6891312765044, 436.67562493692924, 595.3896530886511, 560.8909582474018, 530.3788070018377, 582.1978912206919, 515.2711073185975, 746.6792051497026, 621.3902630160252, 616.4465918940384, 637.2859651301279, 632.4402823144011, 338.49717256174614, 463.82388200545034, 464.6303592103326, 586.4913237970709, 679.9965352545591, 521.0819464736268, 539.0815158611626, 598.594643488752, 491.81171844120826, 457.42439297362955, 706.3054630698085, 451.7442014450077, 561.7082323103434, 570.3161821893078, 639.7358793815131, 305.1976255375527, 695.5630216555588, 455.5040642281833, 542.7292776167725, 770.2990140411162, 569.0028757268547, 655.4646516217572, 303.4433485713041, 648.5807616521291, 454.5454900444613, 535.3206746209999, 259.8417794407047, 624.6945528851434, 490.5917166195821, 555.6014346488851, 582.8762173037245, 485.56667360714795, 432.3778401612842, 504.69711321445965, 573.2015528036937, 199.01, 572.9954605656364, 632.4803090595503, 464.8188886436167, 638.6254057070419, 677.6008213284839, 586.6523317094016, 406.57142260933153, 715.3306933857415, 703.7799986657561, 639.4969585958636, 573.9596058013032, 610.1810570401352, 450.26847769726527, 484.0197288167618, 375.5388496415173, 821.8379468631523, 575.1351585102834, 409.497357160285, 640.7231527278668, 677.2374703801457, 628.9364900634049, 450.9011766215631, 586.8933949893511, 470.2708200000917, 679.6089367913952, 506.3718201757729, 440.71428328621664, 706.5566198610791, 240.93551253512527, 328.15015754380437, 530.8146783386561, 493.50887264749525, 566.3236548130877, 570.4916287279465, 526.0216888145325, 476.55767722183816, 584.4681368221679, 536.1952002000043, 713.1085568814543, 744.2652420694699, 667.9892278476628, 501.2238892888017, 584.9431279845129, 702.1671890752323, 589.5728934738537, 443.2041138617302, 469.46942901265186, 412.46912926370635, 640.5994123594189, 585.898647801959, 545.027774895503, 491.70630540129315, 482.23512972857395, 647.6766173936663, 732.2691406150443, 532.1147736996136, 768.2710071074331, 418.819734024596, 821.1889273469386, 420.4775069001856, 543.5261988989569, 534.8015071785437, 401.0890316709919, 546.9193488968247, 458.2723790122267, 577.5406838281339, 680.0728930730902, 744.3874774288856, 391.9798603498346, 557.7132801935819, 430.43620457579186, 520.4705371881687, 515.9730052248453, 489.851759862282, 563.8795862906676, 58.998919027283165, 588.4318482958516, 516.9102749397027, 674.4908261934397, 577.855884997512, 453.7931643202226, 495.6415149971277, 690.0453702346423, 666.1761931777515, 527.2145677340834, 787.6853330409931], "policy_predator_policy_reward": [466.23336393044457, 381.34878540498795, 462.04275885479785, 422.7702502657985, 366.9958759860373, 425.24104871615856, 321.56141435226584, 470.44444719975394, 484.09064577262114, 392.49140451071065, 466.8259124617957, 391.2077244158762, 346.2619886593348, 332.3409139779166, 433.0698202221514, 401.53755457156353, 264.0474998816744, 493.83461881979935, 487.88961428485777, 416.65161118690247, 418.1672335200961, 311.2845834756713, 189.28740042201133, 356.5754713880187, 221.68711472137636, 364.2095283495519, 409.70754031922644, 358.68922892722793, 395.41473488308566, 383.23588232127884, 298.1519951657054, 304.0301136175208, 431.01477405975197, 462.13738368616265, 369.7549382792602, 359.6898640119317, 347.0683876142279, 428.14897221461996, 477.7333842994396, 442.0019435477653, 244.46446115324395, 254.2815655328299, 190.8956027489595, 153.242117597778, 603.5472138177494, 562.8441843363378, 224.84249684269128, 412.07993606765757, 404.66427698785185, 424.64591299251265, 444.67247367899745, 416.17520672059493, 448.99837945023734, 415.9167088258561, 383.6314936178805, 445.6581603628269, 284.3487672138868, 488.70893778459657, 385.7921395887402, 444.1677992335614, 157.3885535801378, 188.7820936368187, 372.37773792474394, 392.840763902486, 299.75570246306785, 404.7518923086641, 352.6276191513545, 465.521134755396, 353.5827622958997, 387.4208460388483, 383.3497665644707, 319.29691458286123, 456.19374494329935, 396.6686177702549, 220.13875928845556, 303.2035727340477, 265.8419874851482, 184.73893123323063, 494.42203641070665, 480.119906547893, 400.4337782803685, 390.1655573125883, 273.76989518909136, 319.51937029989745, 189.18872230351434, 393.3259160358908, 424.61026642004055, 473.0358114250966, 174.64560951178385, 293.6322905410468, 330.6350254888318, 354.90071691712296, 213.64669797581382, 149.3084393003467, 387.9790580516327, 357.13370134637705, 301.18082435079737, 415.7988266858019, 269.761764944089, 147.0513344174764, 133.6763194521073, 87.74781490985588, 441.72419967297645, 557.6637717857312, 146.74829871085754, 149.60996851051243, 266.3586927976499, 290.4719210008688, 390.3145265909277, 235.6331229467395, 263.046640337494, 359.49226180496777, 211.30867556414947, 362.13161956613607, 437.23252867826915, 295.131051187599, 89.63954006465232, 384.7513097502324, 142.41887630226407, 122.62330070747177, 243.59671810279124, 259.26154448996095, 29.74972366241937, 334.9871914987354, 474.26143125215526, 401.29837233360576, 204.1712463456174, 499.14606687442887, 53.36103721742389, 71.89809690509782, 297.24423918474986, 333.3083801899209, 295.12098527287367, 334.15783492286187, 463.8342071954498, 273.3424570499968, 62.364100255138354, 229.416536330773, 309.76923771048894, -18.907716712548563, 480.8954387995469, 453.8680029469008, 625.7656523950398, 631.2664460790745, 276.1022514905099, 350.12574594829607, 349.3889480153151, 397.44025927525826, 494.04408466033516, 452.78913900584826, 395.97426587704973, 463.2751991836804, 52.99565329094832, -17.5279872645294, 421.22484324064516, 415.9492258961106, 395.4092183542724, 391.2215757517694, 279.8650262038554, 47.61034772199465, 596.0917049370752, 451.91546716332545, 409.0763871685628, 421.2396398693359, 416.66829013290726, 375.01512558232946, 239.56054861447683, 292.9256620974788, 247.4483459952368, 213.43679728719744, 452.4710061998573, 487.4965659275526, 398.959601085469, 491.55238922374457, 331.59386031321253, 330.00629400778064, 499.8813491966687, 334.61836860220615, 393.71357297856565, 511.40525651710914, 102.39439141644034, 101.30937307069988, 365.02169591222656, 427.8606777609288, 476.7813740888231, 486.5347194180992, 472.796211091959, 453.33797311380704, 680.225885803304, 614.4570778744977, 390.53958753155797, 358.74436955970725, 240.00030421603978, 296.3854653046537, 474.63592604004873, 487.76838437992785, 353.32765995708934, 331.3129022044043, 317.93443449666756, 279.9027109712041]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.395356075630373, "mean_inference_ms": 6.3097020544218205, "mean_action_processing_ms": 1.0218699164978857, "mean_env_wait_ms": 0.8766824220145039, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01094973087310791, "StateBufferConnector_ms": 0.008575439453125, "ViewRequirementAgentConnector_ms": 0.36016178131103516}, "num_episodes": 22, "episode_return_max": 2132.178424556338, "episode_return_min": 1173.4482445853957, "episode_return_mean": 1799.112936189411, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 268.456034765801, "num_env_steps_trained_throughput_per_sec": 268.456034765801, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 17363.838, "restore_workers_time_ms": 0.013, "training_step_time_ms": 17363.795, "sample_time_ms": 4700.95, "learn_time_ms": 12643.793, "learn_throughput": 316.361, "synch_weights_time_ms": 18.254}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "479e5_00000", "date": "2024-08-16_12-28-42", "timestamp": 1723791522, "time_this_iter_s": 14.905495166778564, "time_total_s": 3712.350321531296, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7dce8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3712.350321531296, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 27.214285714285715, "ram_util_percent": 64.14285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3288125270888917, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.625421048219872, "policy_loss": -0.003124269221727022, "vf_loss": 9.627772987708843, "vf_explained_var": 0.01976330911040937, "kl": 0.0068651563608761335, "entropy": 1.1109896893854494, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0838360342872204, "cur_kl_coeff": 0.005932617187500002, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.455283699842989, "policy_loss": 0.0007925007611798941, "vf_loss": 9.454459731288688, "vf_explained_var": -0.07834692698307139, "kl": 0.005302462088727634, "entropy": 0.4732098647999385, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 2132.178424556338, "episode_reward_min": 659.6716151906504, "episode_reward_mean": 1725.8517737023749, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 58.998919027283165, "predator_policy": -18.907716712548563}, "policy_reward_max": {"prey_policy": 842.677036736719, "predator_policy": 680.225885803304}, "policy_reward_mean": {"prey_policy": 531.525493668605, "predator_policy": 331.4003931825827}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1947.3720993288714, 1944.7882222708824, 1481.7707589298298, 1287.1611665222192, 1886.2821943561516, 1554.073394234524, 1937.4997339850322, 1934.380173085513, 1895.3844422782315, 1994.3569334489375, 1963.2241610555006, 1900.4065239132296, 1578.3898009726793, 2086.9940249542205, 1921.8047210550874, 1792.5135101201863, 1897.284219670803, 1815.2233793698633, 2114.812675181854, 1761.1791869325666, 1720.3071661629083, 1776.8629975257986, 1841.7210186003604, 1794.3677472171787, 1720.1907976893185, 1846.8821892599753, 1626.3275645676463, 1817.5601569056066, 1307.8886421952259, 1896.179845281749, 2030.0079426944849, 1641.2806267101748, 1173.4482445853957, 1989.25413612417, 1180.8945995472177, 1603.023765066986, 1694.3905404485402, 1559.6138555182067, 1345.6518479339788, 1937.839349491057, 1577.8351441655443, 1529.2953300476224, 1624.7603785878246, 1708.0138724227747, 2059.7004664271963, 1637.6055197340743, 1322.6359306271906, 1615.1851350452366, 1947.2394433037482, 1817.0143309304156, 1348.9448515753536, 1476.8422779651078, 2082.0343448937415, 1826.1177685530436, 1650.5515484249613, 1883.64449083161, 1949.4125897025513, 1979.9128020829023, 1492.8414649773454, 2006.387186273219, 2073.741111165786, 1360.2523812614352, 1929.9457303767592, 2056.8140871992755, 1828.417496012033, 1662.3979578341973, 1725.2690575970892, 2127.0583132594393, 2132.178424556338, 1739.9278603984915, 1782.5080983666924, 1940.9318923360333, 1628.1641349891167, 1742.5755142165747, 1914.2228352708805, 1931.9589492928947, 1917.561468995754, 1854.6260803268185, 1788.7324807116458, 1911.8389897373268, 2040.8621255738858, 1912.737046242948, 801.8748780853603, 1525.7708701293886, 1862.2378172674437, 1113.225108255583, 957.6466665773992, 659.6716151906504, 1187.9163451156132, 1243.294731966063, 1831.6697720906845, 1965.0883775496131, 1640.5467909205643, 1917.7052460962598, 1488.0853048226948, 1583.4818341323303, 1677.0724731438215, 1489.4080275882375, 1949.9299461268026, 1953.2602976939656], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [512.1363489734293, 660.018390526596, 753.2116549975707, 271.8412394261091, 508.5261293460067, 474.4986028977489, 438.2098810080192, 504.8135651674622, 194.3360272150961, 525.5547689869688, 451.72972897907925, 465.42123234509455, 575.4174960330271, 532.7720479716405, 538.4752797198124, 535.0572129661069, 563.839316576284, 466.63003742585335, 483.67600823062753, 681.391271237605, 672.0638790764872, 518.1025769805316, 639.4866133514938, 430.95997173943374, 655.0225415712121, 577.1966121845093, 842.677036736719, 479.0984863902705, 613.2182564692157, 604.0788698141403, 537.6891312765044, 436.67562493692924, 595.3896530886511, 560.8909582474018, 530.3788070018377, 582.1978912206919, 515.2711073185975, 746.6792051497026, 621.3902630160252, 616.4465918940384, 637.2859651301279, 632.4402823144011, 338.49717256174614, 463.82388200545034, 464.6303592103326, 586.4913237970709, 679.9965352545591, 521.0819464736268, 539.0815158611626, 598.594643488752, 491.81171844120826, 457.42439297362955, 706.3054630698085, 451.7442014450077, 561.7082323103434, 570.3161821893078, 639.7358793815131, 305.1976255375527, 695.5630216555588, 455.5040642281833, 542.7292776167725, 770.2990140411162, 569.0028757268547, 655.4646516217572, 303.4433485713041, 648.5807616521291, 454.5454900444613, 535.3206746209999, 259.8417794407047, 624.6945528851434, 490.5917166195821, 555.6014346488851, 582.8762173037245, 485.56667360714795, 432.3778401612842, 504.69711321445965, 573.2015528036937, 199.01, 572.9954605656364, 632.4803090595503, 464.8188886436167, 638.6254057070419, 677.6008213284839, 586.6523317094016, 406.57142260933153, 715.3306933857415, 703.7799986657561, 639.4969585958636, 573.9596058013032, 610.1810570401352, 450.26847769726527, 484.0197288167618, 375.5388496415173, 821.8379468631523, 575.1351585102834, 409.497357160285, 640.7231527278668, 677.2374703801457, 628.9364900634049, 450.9011766215631, 586.8933949893511, 470.2708200000917, 679.6089367913952, 506.3718201757729, 440.71428328621664, 706.5566198610791, 240.93551253512527, 328.15015754380437, 530.8146783386561, 493.50887264749525, 566.3236548130877, 570.4916287279465, 526.0216888145325, 476.55767722183816, 584.4681368221679, 536.1952002000043, 713.1085568814543, 744.2652420694699, 667.9892278476628, 501.2238892888017, 584.9431279845129, 702.1671890752323, 589.5728934738537, 443.2041138617302, 469.46942901265186, 412.46912926370635, 640.5994123594189, 585.898647801959, 545.027774895503, 491.70630540129315, 482.23512972857395, 647.6766173936663, 732.2691406150443, 532.1147736996136, 768.2710071074331, 418.819734024596, 821.1889273469386, 420.4775069001856, 543.5261988989569, 534.8015071785437, 401.0890316709919, 546.9193488968247, 458.2723790122267, 577.5406838281339, 680.0728930730902, 744.3874774288856, 391.9798603498346, 557.7132801935819, 430.43620457579186, 520.4705371881687, 515.9730052248453, 489.851759862282, 563.8795862906676, 58.998919027283165, 588.4318482958516, 516.9102749397027, 674.4908261934397, 577.855884997512, 453.7931643202226, 495.6415149971277, 690.0453702346423, 666.1761931777515, 527.2145677340834, 787.6853330409931, 468.10257199329925, 342.7521128541145, 648.0630734070741, 380.49839033812566, 423.53150066695395, 382.36590410580726, 172.7453400115709, 641.2474940364766, 250.09186306841443, 477.40832196402584, 339.7766988124614, 220.66723267730305, 293.88048267499335, 685.2071642577245, 497.4409055279729, 241.41156406210365, 674.5069151255417, 642.1199239992153, 555.2513002906844, 434.8021078110633, 611.0689310750039, 444.8739258521477, 493.2309880069827, 357.3978376297427, 485.56586003497284, 590.8123982374478, 383.75127301883595, 575.1002104054375, 434.1604994052644, 591.7674810920773, 651.551451632553, 436.83321226140407, 411.1918463552139, 403.42413704900935, 426.8406133645265, 448.780230184139], "policy_predator_policy_reward": [347.0683876142279, 428.14897221461996, 477.7333842994396, 442.0019435477653, 244.46446115324395, 254.2815655328299, 190.8956027489595, 153.242117597778, 603.5472138177494, 562.8441843363378, 224.84249684269128, 412.07993606765757, 404.66427698785185, 424.64591299251265, 444.67247367899745, 416.17520672059493, 448.99837945023734, 415.9167088258561, 383.6314936178805, 445.6581603628269, 284.3487672138868, 488.70893778459657, 385.7921395887402, 444.1677992335614, 157.3885535801378, 188.7820936368187, 372.37773792474394, 392.840763902486, 299.75570246306785, 404.7518923086641, 352.6276191513545, 465.521134755396, 353.5827622958997, 387.4208460388483, 383.3497665644707, 319.29691458286123, 456.19374494329935, 396.6686177702549, 220.13875928845556, 303.2035727340477, 265.8419874851482, 184.73893123323063, 494.42203641070665, 480.119906547893, 400.4337782803685, 390.1655573125883, 273.76989518909136, 319.51937029989745, 189.18872230351434, 393.3259160358908, 424.61026642004055, 473.0358114250966, 174.64560951178385, 293.6322905410468, 330.6350254888318, 354.90071691712296, 213.64669797581382, 149.3084393003467, 387.9790580516327, 357.13370134637705, 301.18082435079737, 415.7988266858019, 269.761764944089, 147.0513344174764, 133.6763194521073, 87.74781490985588, 441.72419967297645, 557.6637717857312, 146.74829871085754, 149.60996851051243, 266.3586927976499, 290.4719210008688, 390.3145265909277, 235.6331229467395, 263.046640337494, 359.49226180496777, 211.30867556414947, 362.13161956613607, 437.23252867826915, 295.131051187599, 89.63954006465232, 384.7513097502324, 142.41887630226407, 122.62330070747177, 243.59671810279124, 259.26154448996095, 29.74972366241937, 334.9871914987354, 474.26143125215526, 401.29837233360576, 204.1712463456174, 499.14606687442887, 53.36103721742389, 71.89809690509782, 297.24423918474986, 333.3083801899209, 295.12098527287367, 334.15783492286187, 463.8342071954498, 273.3424570499968, 62.364100255138354, 229.416536330773, 309.76923771048894, -18.907716712548563, 480.8954387995469, 453.8680029469008, 625.7656523950398, 631.2664460790745, 276.1022514905099, 350.12574594829607, 349.3889480153151, 397.44025927525826, 494.04408466033516, 452.78913900584826, 395.97426587704973, 463.2751991836804, 52.99565329094832, -17.5279872645294, 421.22484324064516, 415.9492258961106, 395.4092183542724, 391.2215757517694, 279.8650262038554, 47.61034772199465, 596.0917049370752, 451.91546716332545, 409.0763871685628, 421.2396398693359, 416.66829013290726, 375.01512558232946, 239.56054861447683, 292.9256620974788, 247.4483459952368, 213.43679728719744, 452.4710061998573, 487.4965659275526, 398.959601085469, 491.55238922374457, 331.59386031321253, 330.00629400778064, 499.8813491966687, 334.61836860220615, 393.71357297856565, 511.40525651710914, 102.39439141644034, 101.30937307069988, 365.02169591222656, 427.8606777609288, 476.7813740888231, 486.5347194180992, 472.796211091959, 453.33797311380704, 680.225885803304, 614.4570778744977, 390.53958753155797, 358.74436955970725, 240.00030421603978, 296.3854653046537, 474.63592604004873, 487.76838437992785, 353.32765995708934, 331.3129022044043, 317.93443449666756, 279.9027109712041, -6.014109352458542, -2.9656974095950517, 230.40493325818431, 266.8044731260062, 517.9972251367918, 538.3431873578884, 147.05647593684006, 152.17579827069795, 132.2975895823946, 97.84889196256452, 106.78317799953042, -7.555494298644217, 142.93680699442706, 65.89189118846757, 234.60598515971026, 269.83627721627715, 290.8847583132759, 224.15817465265198, 523.0747836461512, 451.9601858017153, 203.1831156730967, 381.4208183203136, 572.3281489368401, 494.74827152269546, 318.5616535543609, 93.14539299591412, 341.5959163210415, 283.0344343870141, 361.3694497222055, 289.7750429242767, 198.65702930903248, 202.36633438525072, 585.2119850198119, 550.1019777027659, 544.6559129221394, 532.98354122316]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3929681633440585, "mean_inference_ms": 6.299344946863634, "mean_action_processing_ms": 1.020615511510714, "mean_env_wait_ms": 0.8749044561125373, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010887980461120605, "StateBufferConnector_ms": 0.00863194465637207, "ViewRequirementAgentConnector_ms": 0.36289262771606445}, "num_episodes": 18, "episode_return_max": 2132.178424556338, "episode_return_min": 659.6716151906504, "episode_return_mean": 1725.8517737023749, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 253.94903296266565, "num_env_steps_trained_throughput_per_sec": 253.94903296266565, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 16896.188, "restore_workers_time_ms": 0.013, "training_step_time_ms": 16896.145, "sample_time_ms": 4588.477, "learn_time_ms": 12288.832, "learn_throughput": 325.499, "synch_weights_time_ms": 17.964}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "479e5_00000", "date": "2024-08-16_12-28-57", "timestamp": 1723791537, "time_this_iter_s": 15.756101131439209, "time_total_s": 3728.106422662735, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7fe2af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3728.106422662735, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 28.021739130434778, "ram_util_percent": 64.03478260869566}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8108595931971516, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.545526749242551, "policy_loss": -0.002259026803618307, "vf_loss": 9.547325107534096, "vf_explained_var": 0.01439536176030598, "kl": 0.004094656102900619, "entropy": 1.1095870459521258, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5488474806938224, "cur_kl_coeff": 0.005932617187500002, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.570941607157389, "policy_loss": -0.001941673335910001, "vf_loss": 9.572830663913141, "vf_explained_var": -0.04670087837037586, "kl": 0.00886674611022899, "entropy": 0.47810929780283934, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 2169.568396436172, "episode_reward_min": 575.5880990054563, "episode_reward_mean": 1646.7551419914184, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 58.998919027283165, "predator_policy": -18.907716712548563}, "policy_reward_max": {"prey_policy": 901.6254074821358, "predator_policy": 680.225885803304}, "policy_reward_mean": {"prey_policy": 521.0576956465503, "predator_policy": 302.31987534915913}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1794.3677472171787, 1720.1907976893185, 1846.8821892599753, 1626.3275645676463, 1817.5601569056066, 1307.8886421952259, 1896.179845281749, 2030.0079426944849, 1641.2806267101748, 1173.4482445853957, 1989.25413612417, 1180.8945995472177, 1603.023765066986, 1694.3905404485402, 1559.6138555182067, 1345.6518479339788, 1937.839349491057, 1577.8351441655443, 1529.2953300476224, 1624.7603785878246, 1708.0138724227747, 2059.7004664271963, 1637.6055197340743, 1322.6359306271906, 1615.1851350452366, 1947.2394433037482, 1817.0143309304156, 1348.9448515753536, 1476.8422779651078, 2082.0343448937415, 1826.1177685530436, 1650.5515484249613, 1883.64449083161, 1949.4125897025513, 1979.9128020829023, 1492.8414649773454, 2006.387186273219, 2073.741111165786, 1360.2523812614352, 1929.9457303767592, 2056.8140871992755, 1828.417496012033, 1662.3979578341973, 1725.2690575970892, 2127.0583132594393, 2132.178424556338, 1739.9278603984915, 1782.5080983666924, 1940.9318923360333, 1628.1641349891167, 1742.5755142165747, 1914.2228352708805, 1931.9589492928947, 1917.561468995754, 1854.6260803268185, 1788.7324807116458, 1911.8389897373268, 2040.8621255738858, 1912.737046242948, 801.8748780853603, 1525.7708701293886, 1862.2378172674437, 1113.225108255583, 957.6466665773992, 659.6716151906504, 1187.9163451156132, 1243.294731966063, 1831.6697720906845, 1965.0883775496131, 1640.5467909205643, 1917.7052460962598, 1488.0853048226948, 1583.4818341323303, 1677.0724731438215, 1489.4080275882375, 1949.9299461268026, 1953.2602976939656, 575.5880990054563, 1946.3617884794965, 2169.568396436172, 1232.324972682681, 1152.590319341466, 1744.6241448091175, 1477.7364293004737, 1633.5566523074851, 855.3115041116912, 922.7940839803608, 1735.389106278269, 1946.436279337724, 674.4468545528713, 1921.4248548359224, 2001.013775390919, 1546.882791055653, 877.0359837118413, 1467.3917920208287, 1192.6965042100096, 1256.3747622495098, 1880.7983882256572, 1904.673256302626, 2009.1085942333616], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [679.9965352545591, 521.0819464736268, 539.0815158611626, 598.594643488752, 491.81171844120826, 457.42439297362955, 706.3054630698085, 451.7442014450077, 561.7082323103434, 570.3161821893078, 639.7358793815131, 305.1976255375527, 695.5630216555588, 455.5040642281833, 542.7292776167725, 770.2990140411162, 569.0028757268547, 655.4646516217572, 303.4433485713041, 648.5807616521291, 454.5454900444613, 535.3206746209999, 259.8417794407047, 624.6945528851434, 490.5917166195821, 555.6014346488851, 582.8762173037245, 485.56667360714795, 432.3778401612842, 504.69711321445965, 573.2015528036937, 199.01, 572.9954605656364, 632.4803090595503, 464.8188886436167, 638.6254057070419, 677.6008213284839, 586.6523317094016, 406.57142260933153, 715.3306933857415, 703.7799986657561, 639.4969585958636, 573.9596058013032, 610.1810570401352, 450.26847769726527, 484.0197288167618, 375.5388496415173, 821.8379468631523, 575.1351585102834, 409.497357160285, 640.7231527278668, 677.2374703801457, 628.9364900634049, 450.9011766215631, 586.8933949893511, 470.2708200000917, 679.6089367913952, 506.3718201757729, 440.71428328621664, 706.5566198610791, 240.93551253512527, 328.15015754380437, 530.8146783386561, 493.50887264749525, 566.3236548130877, 570.4916287279465, 526.0216888145325, 476.55767722183816, 584.4681368221679, 536.1952002000043, 713.1085568814543, 744.2652420694699, 667.9892278476628, 501.2238892888017, 584.9431279845129, 702.1671890752323, 589.5728934738537, 443.2041138617302, 469.46942901265186, 412.46912926370635, 640.5994123594189, 585.898647801959, 545.027774895503, 491.70630540129315, 482.23512972857395, 647.6766173936663, 732.2691406150443, 532.1147736996136, 768.2710071074331, 418.819734024596, 821.1889273469386, 420.4775069001856, 543.5261988989569, 534.8015071785437, 401.0890316709919, 546.9193488968247, 458.2723790122267, 577.5406838281339, 680.0728930730902, 744.3874774288856, 391.9798603498346, 557.7132801935819, 430.43620457579186, 520.4705371881687, 515.9730052248453, 489.851759862282, 563.8795862906676, 58.998919027283165, 588.4318482958516, 516.9102749397027, 674.4908261934397, 577.855884997512, 453.7931643202226, 495.6415149971277, 690.0453702346423, 666.1761931777515, 527.2145677340834, 787.6853330409931, 468.10257199329925, 342.7521128541145, 648.0630734070741, 380.49839033812566, 423.53150066695395, 382.36590410580726, 172.7453400115709, 641.2474940364766, 250.09186306841443, 477.40832196402584, 339.7766988124614, 220.66723267730305, 293.88048267499335, 685.2071642577245, 497.4409055279729, 241.41156406210365, 674.5069151255417, 642.1199239992153, 555.2513002906844, 434.8021078110633, 611.0689310750039, 444.8739258521477, 493.2309880069827, 357.3978376297427, 485.56586003497284, 590.8123982374478, 383.75127301883595, 575.1002104054375, 434.1604994052644, 591.7674810920773, 651.551451632553, 436.83321226140407, 411.1918463552139, 403.42413704900935, 426.8406133645265, 448.780230184139, 238.82568430128944, 331.64310484447327, 497.09601918409476, 556.0434136643611, 901.6254074821358, 460.2613395170457, 339.7420515389651, 628.4840017913451, 193.28583509549324, 658.393967942492, 498.16050608014245, 665.8613200225802, 676.2219685903467, 391.2839952722894, 610.7677596741482, 449.51500322498947, 237.98206235156076, 581.3839598391542, 237.512231820086, 623.7150035241787, 535.5859740389263, 614.9021562882866, 644.9215049053612, 488.57105853219065, 312.516460098096, 308.7859743343085, 566.5328737529715, 635.5236753494855, 505.32883947834245, 552.5080592535858, 432.3720470468273, 689.9229535365148, 315.41651656656165, 501.75663187865734, 489.1155174637967, 473.4241649752431, 221.9973594473235, 591.6944203855068, 612.1388560806801, 246.16348426830717, 565.0585809499305, 599.2880571334938, 707.9856864148009, 663.6771485228859, 441.81423327032337, 447.2728283691437], "policy_predator_policy_reward": [273.76989518909136, 319.51937029989745, 189.18872230351434, 393.3259160358908, 424.61026642004055, 473.0358114250966, 174.64560951178385, 293.6322905410468, 330.6350254888318, 354.90071691712296, 213.64669797581382, 149.3084393003467, 387.9790580516327, 357.13370134637705, 301.18082435079737, 415.7988266858019, 269.761764944089, 147.0513344174764, 133.6763194521073, 87.74781490985588, 441.72419967297645, 557.6637717857312, 146.74829871085754, 149.60996851051243, 266.3586927976499, 290.4719210008688, 390.3145265909277, 235.6331229467395, 263.046640337494, 359.49226180496777, 211.30867556414947, 362.13161956613607, 437.23252867826915, 295.131051187599, 89.63954006465232, 384.7513097502324, 142.41887630226407, 122.62330070747177, 243.59671810279124, 259.26154448996095, 29.74972366241937, 334.9871914987354, 474.26143125215526, 401.29837233360576, 204.1712463456174, 499.14606687442887, 53.36103721742389, 71.89809690509782, 297.24423918474986, 333.3083801899209, 295.12098527287367, 334.15783492286187, 463.8342071954498, 273.3424570499968, 62.364100255138354, 229.416536330773, 309.76923771048894, -18.907716712548563, 480.8954387995469, 453.8680029469008, 625.7656523950398, 631.2664460790745, 276.1022514905099, 350.12574594829607, 349.3889480153151, 397.44025927525826, 494.04408466033516, 452.78913900584826, 395.97426587704973, 463.2751991836804, 52.99565329094832, -17.5279872645294, 421.22484324064516, 415.9492258961106, 395.4092183542724, 391.2215757517694, 279.8650262038554, 47.61034772199465, 596.0917049370752, 451.91546716332545, 409.0763871685628, 421.2396398693359, 416.66829013290726, 375.01512558232946, 239.56054861447683, 292.9256620974788, 247.4483459952368, 213.43679728719744, 452.4710061998573, 487.4965659275526, 398.959601085469, 491.55238922374457, 331.59386031321253, 330.00629400778064, 499.8813491966687, 334.61836860220615, 393.71357297856565, 511.40525651710914, 102.39439141644034, 101.30937307069988, 365.02169591222656, 427.8606777609288, 476.7813740888231, 486.5347194180992, 472.796211091959, 453.33797311380704, 680.225885803304, 614.4570778744977, 390.53958753155797, 358.74436955970725, 240.00030421603978, 296.3854653046537, 474.63592604004873, 487.76838437992785, 353.32765995708934, 331.3129022044043, 317.93443449666756, 279.9027109712041, -6.014109352458542, -2.9656974095950517, 230.40493325818431, 266.8044731260062, 517.9972251367918, 538.3431873578884, 147.05647593684006, 152.17579827069795, 132.2975895823946, 97.84889196256452, 106.78317799953042, -7.555494298644217, 142.93680699442706, 65.89189118846757, 234.60598515971026, 269.83627721627715, 290.8847583132759, 224.15817465265198, 523.0747836461512, 451.9601858017153, 203.1831156730967, 381.4208183203136, 572.3281489368401, 494.74827152269546, 318.5616535543609, 93.14539299591412, 341.5959163210415, 283.0344343870141, 361.3694497222055, 289.7750429242767, 198.65702930903248, 202.36633438525072, 585.2119850198119, 550.1019777027659, 544.6559129221394, 532.98354122316, -2.2700356885272743, 7.389345548220824, 377.9309064820224, 515.2914491490175, 388.5200847005402, 419.16156473644986, 245.48592228943707, 18.612997062932795, 184.56334519755103, 116.34717110592874, 287.8875044140842, 292.71481429231045, 275.5384419202697, 134.6920235175691, 285.85175361434915, 287.4221357940006, 4.25884430633159, 31.686637614644198, 52.516633846937474, 9.05021478915845, 281.1804521322686, 303.72052381878694, 392.79752361700093, 420.1461922831702, 52.5991274052779, 0.5452927151884293, 402.68791891707997, 316.68038681638734, 478.3144386722128, 464.8624379867813, 210.08654118738286, 214.5012492849285, -3.494145733805884, 63.35698100042828, 215.3444331996671, 289.50767638212403, 235.30093165485397, 143.70379272232526, 154.85288530265768, 243.21953659786445, 396.24073218596, 320.21101795627266, 308.3537081851216, 224.6567131798228, 558.8127049963099, 561.2088275975831]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3896720946912025, "mean_inference_ms": 6.2855752978243915, "mean_action_processing_ms": 1.019210570736049, "mean_env_wait_ms": 0.8722263880064668, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011854052543640137, "StateBufferConnector_ms": 0.008412837982177734, "ViewRequirementAgentConnector_ms": 0.33777689933776855}, "num_episodes": 23, "episode_return_max": 2169.568396436172, "episode_return_min": 575.5880990054563, "episode_return_mean": 1646.7551419914184, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 267.1631226194471, "num_env_steps_trained_throughput_per_sec": 267.1631226194471, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 16300.674, "restore_workers_time_ms": 0.013, "training_step_time_ms": 16300.632, "sample_time_ms": 4579.775, "learn_time_ms": 11702.224, "learn_throughput": 341.815, "synch_weights_time_ms": 17.744}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "479e5_00000", "date": "2024-08-16_12-29-12", "timestamp": 1723791552, "time_this_iter_s": 14.977710723876953, "time_total_s": 3743.084133386612, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78e5dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3743.084133386612, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 28.233333333333338, "ram_util_percent": 64.13809523809522}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4566852534889545, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.537378870242486, "policy_loss": -0.005095795787644213, "vf_loss": 9.541785963250216, "vf_explained_var": 0.0029628583363124302, "kl": 0.012243723257528791, "entropy": 1.0729218367546325, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.842532733950035, "cur_kl_coeff": 0.005932617187500002, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.359726503160264, "policy_loss": 0.006924885474687452, "vf_loss": 9.352731072965753, "vf_explained_var": -0.05408209224857351, "kl": 0.011888815942510775, "entropy": 0.44817194380457437, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 2169.568396436172, "episode_reward_min": 575.5880990054563, "episode_reward_mean": 1630.6875088362608, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 58.998919027283165, "predator_policy": -18.907716712548563}, "policy_reward_max": {"prey_policy": 901.6254074821358, "predator_policy": 680.225885803304}, "policy_reward_mean": {"prey_policy": 517.4928697016644, "predator_policy": 297.8508847164661}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1529.2953300476224, 1624.7603785878246, 1708.0138724227747, 2059.7004664271963, 1637.6055197340743, 1322.6359306271906, 1615.1851350452366, 1947.2394433037482, 1817.0143309304156, 1348.9448515753536, 1476.8422779651078, 2082.0343448937415, 1826.1177685530436, 1650.5515484249613, 1883.64449083161, 1949.4125897025513, 1979.9128020829023, 1492.8414649773454, 2006.387186273219, 2073.741111165786, 1360.2523812614352, 1929.9457303767592, 2056.8140871992755, 1828.417496012033, 1662.3979578341973, 1725.2690575970892, 2127.0583132594393, 2132.178424556338, 1739.9278603984915, 1782.5080983666924, 1940.9318923360333, 1628.1641349891167, 1742.5755142165747, 1914.2228352708805, 1931.9589492928947, 1917.561468995754, 1854.6260803268185, 1788.7324807116458, 1911.8389897373268, 2040.8621255738858, 1912.737046242948, 801.8748780853603, 1525.7708701293886, 1862.2378172674437, 1113.225108255583, 957.6466665773992, 659.6716151906504, 1187.9163451156132, 1243.294731966063, 1831.6697720906845, 1965.0883775496131, 1640.5467909205643, 1917.7052460962598, 1488.0853048226948, 1583.4818341323303, 1677.0724731438215, 1489.4080275882375, 1949.9299461268026, 1953.2602976939656, 575.5880990054563, 1946.3617884794965, 2169.568396436172, 1232.324972682681, 1152.590319341466, 1744.6241448091175, 1477.7364293004737, 1633.5566523074851, 855.3115041116912, 922.7940839803608, 1735.389106278269, 1946.436279337724, 674.4468545528713, 1921.4248548359224, 2001.013775390919, 1546.882791055653, 877.0359837118413, 1467.3917920208287, 1192.6965042100096, 1256.3747622495098, 1880.7983882256572, 1904.673256302626, 2009.1085942333616, 1335.7623645946903, 2074.0252260180146, 1388.205041691025, 1926.485427941585, 1352.1548665137352, 1613.8018334287585, 1026.2254539493724, 1438.064838148711, 1527.636909752783, 1816.2196130863867, 1988.1211401332678, 1392.0893949598553, 1692.1234610650072, 1185.492236387, 1302.5126516962462, 1660.9343784626203, 1610.7251370145907, 1805.293705043038], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [677.6008213284839, 586.6523317094016, 406.57142260933153, 715.3306933857415, 703.7799986657561, 639.4969585958636, 573.9596058013032, 610.1810570401352, 450.26847769726527, 484.0197288167618, 375.5388496415173, 821.8379468631523, 575.1351585102834, 409.497357160285, 640.7231527278668, 677.2374703801457, 628.9364900634049, 450.9011766215631, 586.8933949893511, 470.2708200000917, 679.6089367913952, 506.3718201757729, 440.71428328621664, 706.5566198610791, 240.93551253512527, 328.15015754380437, 530.8146783386561, 493.50887264749525, 566.3236548130877, 570.4916287279465, 526.0216888145325, 476.55767722183816, 584.4681368221679, 536.1952002000043, 713.1085568814543, 744.2652420694699, 667.9892278476628, 501.2238892888017, 584.9431279845129, 702.1671890752323, 589.5728934738537, 443.2041138617302, 469.46942901265186, 412.46912926370635, 640.5994123594189, 585.898647801959, 545.027774895503, 491.70630540129315, 482.23512972857395, 647.6766173936663, 732.2691406150443, 532.1147736996136, 768.2710071074331, 418.819734024596, 821.1889273469386, 420.4775069001856, 543.5261988989569, 534.8015071785437, 401.0890316709919, 546.9193488968247, 458.2723790122267, 577.5406838281339, 680.0728930730902, 744.3874774288856, 391.9798603498346, 557.7132801935819, 430.43620457579186, 520.4705371881687, 515.9730052248453, 489.851759862282, 563.8795862906676, 58.998919027283165, 588.4318482958516, 516.9102749397027, 674.4908261934397, 577.855884997512, 453.7931643202226, 495.6415149971277, 690.0453702346423, 666.1761931777515, 527.2145677340834, 787.6853330409931, 468.10257199329925, 342.7521128541145, 648.0630734070741, 380.49839033812566, 423.53150066695395, 382.36590410580726, 172.7453400115709, 641.2474940364766, 250.09186306841443, 477.40832196402584, 339.7766988124614, 220.66723267730305, 293.88048267499335, 685.2071642577245, 497.4409055279729, 241.41156406210365, 674.5069151255417, 642.1199239992153, 555.2513002906844, 434.8021078110633, 611.0689310750039, 444.8739258521477, 493.2309880069827, 357.3978376297427, 485.56586003497284, 590.8123982374478, 383.75127301883595, 575.1002104054375, 434.1604994052644, 591.7674810920773, 651.551451632553, 436.83321226140407, 411.1918463552139, 403.42413704900935, 426.8406133645265, 448.780230184139, 238.82568430128944, 331.64310484447327, 497.09601918409476, 556.0434136643611, 901.6254074821358, 460.2613395170457, 339.7420515389651, 628.4840017913451, 193.28583509549324, 658.393967942492, 498.16050608014245, 665.8613200225802, 676.2219685903467, 391.2839952722894, 610.7677596741482, 449.51500322498947, 237.98206235156076, 581.3839598391542, 237.512231820086, 623.7150035241787, 535.5859740389263, 614.9021562882866, 644.9215049053612, 488.57105853219065, 312.516460098096, 308.7859743343085, 566.5328737529715, 635.5236753494855, 505.32883947834245, 552.5080592535858, 432.3720470468273, 689.9229535365148, 315.41651656656165, 501.75663187865734, 489.1155174637967, 473.4241649752431, 221.9973594473235, 591.6944203855068, 612.1388560806801, 246.16348426830717, 565.0585809499305, 599.2880571334938, 707.9856864148009, 663.6771485228859, 441.81423327032337, 447.2728283691437, 632.2782842472875, 406.131435438186, 776.1914700566675, 543.5352879041359, 526.6911039331047, 374.8780878846629, 605.0797615106034, 445.7960525224342, 305.8193514523898, 198.02498975862537, 293.22825802806, 516.3208796784935, 634.9918489115405, 220.50360607844524, 631.8977790308684, 391.27451977776235, 599.397246247656, 453.65707354112266, 595.3816368227676, 604.5406427555762, 675.7842065593659, 576.1609064613626, 390.2824434036898, 577.0948888689849, 702.9662921559094, 653.4702648089736, 510.9423834148388, 214.79201144188505, 532.9363757005019, 472.4825396587852, 529.950350885811, 572.1830060871777, 464.11165844754635, 526.9072955644117, 644.4093024244745, 657.7720304248078], "policy_predator_policy_reward": [142.41887630226407, 122.62330070747177, 243.59671810279124, 259.26154448996095, 29.74972366241937, 334.9871914987354, 474.26143125215526, 401.29837233360576, 204.1712463456174, 499.14606687442887, 53.36103721742389, 71.89809690509782, 297.24423918474986, 333.3083801899209, 295.12098527287367, 334.15783492286187, 463.8342071954498, 273.3424570499968, 62.364100255138354, 229.416536330773, 309.76923771048894, -18.907716712548563, 480.8954387995469, 453.8680029469008, 625.7656523950398, 631.2664460790745, 276.1022514905099, 350.12574594829607, 349.3889480153151, 397.44025927525826, 494.04408466033516, 452.78913900584826, 395.97426587704973, 463.2751991836804, 52.99565329094832, -17.5279872645294, 421.22484324064516, 415.9492258961106, 395.4092183542724, 391.2215757517694, 279.8650262038554, 47.61034772199465, 596.0917049370752, 451.91546716332545, 409.0763871685628, 421.2396398693359, 416.66829013290726, 375.01512558232946, 239.56054861447683, 292.9256620974788, 247.4483459952368, 213.43679728719744, 452.4710061998573, 487.4965659275526, 398.959601085469, 491.55238922374457, 331.59386031321253, 330.00629400778064, 499.8813491966687, 334.61836860220615, 393.71357297856565, 511.40525651710914, 102.39439141644034, 101.30937307069988, 365.02169591222656, 427.8606777609288, 476.7813740888231, 486.5347194180992, 472.796211091959, 453.33797311380704, 680.225885803304, 614.4570778744977, 390.53958753155797, 358.74436955970725, 240.00030421603978, 296.3854653046537, 474.63592604004873, 487.76838437992785, 353.32765995708934, 331.3129022044043, 317.93443449666756, 279.9027109712041, -6.014109352458542, -2.9656974095950517, 230.40493325818431, 266.8044731260062, 517.9972251367918, 538.3431873578884, 147.05647593684006, 152.17579827069795, 132.2975895823946, 97.84889196256452, 106.78317799953042, -7.555494298644217, 142.93680699442706, 65.89189118846757, 234.60598515971026, 269.83627721627715, 290.8847583132759, 224.15817465265198, 523.0747836461512, 451.9601858017153, 203.1831156730967, 381.4208183203136, 572.3281489368401, 494.74827152269546, 318.5616535543609, 93.14539299591412, 341.5959163210415, 283.0344343870141, 361.3694497222055, 289.7750429242767, 198.65702930903248, 202.36633438525072, 585.2119850198119, 550.1019777027659, 544.6559129221394, 532.98354122316, -2.2700356885272743, 7.389345548220824, 377.9309064820224, 515.2914491490175, 388.5200847005402, 419.16156473644986, 245.48592228943707, 18.612997062932795, 184.56334519755103, 116.34717110592874, 287.8875044140842, 292.71481429231045, 275.5384419202697, 134.6920235175691, 285.85175361434915, 287.4221357940006, 4.25884430633159, 31.686637614644198, 52.516633846937474, 9.05021478915845, 281.1804521322686, 303.72052381878694, 392.79752361700093, 420.1461922831702, 52.5991274052779, 0.5452927151884293, 402.68791891707997, 316.68038681638734, 478.3144386722128, 464.8624379867813, 210.08654118738286, 214.5012492849285, -3.494145733805884, 63.35698100042828, 215.3444331996671, 289.50767638212403, 235.30093165485397, 143.70379272232526, 154.85288530265768, 243.21953659786445, 396.24073218596, 320.21101795627266, 308.3537081851216, 224.6567131798228, 558.8127049963099, 561.2088275975831, 36.96793845376605, 260.3847064554509, 392.96696004258996, 361.33150801461977, 242.79174805805502, 243.84410181520096, 548.7663332581271, 326.84328065041876, 454.4480615757026, 393.8624637270156, 537.4236945531416, 266.8290011690635, 164.5031903314955, 6.226808627891258, 170.09239648068697, 244.80014285939265, 360.02025959723784, 114.56233036676883, 237.55329682806047, 378.74403667998195, 491.07338523813274, 245.1026418744086, 241.79740940537818, 182.91465328180402, 182.2873632460733, 153.3995408540496, 406.8215263808747, 52.93631514940201, 156.36491131035822, 140.7288250266012, 262.2597114682189, 296.54131002141236, 224.79366156268406, 394.9125214399473, 212.68776248479628, 290.4246097089605]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3860956438060033, "mean_inference_ms": 6.275130229325268, "mean_action_processing_ms": 1.0167371840068835, "mean_env_wait_ms": 0.8709793830884114, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014783382415771484, "StateBufferConnector_ms": 0.008510351181030273, "ViewRequirementAgentConnector_ms": 0.36502504348754883}, "num_episodes": 18, "episode_return_max": 2169.568396436172, "episode_return_min": 575.5880990054563, "episode_return_mean": 1630.6875088362608, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 235.11386619602084, "num_env_steps_trained_throughput_per_sec": 235.11386619602084, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 16255.308, "restore_workers_time_ms": 0.013, "training_step_time_ms": 16255.265, "sample_time_ms": 4488.057, "learn_time_ms": 11748.52, "learn_throughput": 340.468, "synch_weights_time_ms": 17.807}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "479e5_00000", "date": "2024-08-16_12-29-29", "timestamp": 1723791569, "time_this_iter_s": 17.020164728164673, "time_total_s": 3760.1042981147766, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7dd15e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3760.1042981147766, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 29.791666666666668, "ram_util_percent": 63.92916666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.939964002465445, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.516298503472061, "policy_loss": -0.0025755488648813553, "vf_loss": 9.518258461624226, "vf_explained_var": -0.00996834427591354, "kl": 0.010943954931127627, "entropy": 1.0875693120969037, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6919488122223547, "cur_kl_coeff": 0.005932617187500002, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.492943706209697, "policy_loss": 0.0005563038514641227, "vf_loss": 9.492346551178624, "vf_explained_var": -0.07957561987417716, "kl": 0.006892889453050675, "entropy": 0.40799257783662707, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 2169.568396436172, "episode_reward_min": 575.5880990054563, "episode_reward_mean": 1594.4292871692094, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 58.998919027283165, "predator_policy": -24.714583740151596}, "policy_reward_max": {"prey_policy": 901.6254074821358, "predator_policy": 680.225885803304}, "policy_reward_mean": {"prey_policy": 501.89704546283394, "predator_policy": 295.3175981217709}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2006.387186273219, 2073.741111165786, 1360.2523812614352, 1929.9457303767592, 2056.8140871992755, 1828.417496012033, 1662.3979578341973, 1725.2690575970892, 2127.0583132594393, 2132.178424556338, 1739.9278603984915, 1782.5080983666924, 1940.9318923360333, 1628.1641349891167, 1742.5755142165747, 1914.2228352708805, 1931.9589492928947, 1917.561468995754, 1854.6260803268185, 1788.7324807116458, 1911.8389897373268, 2040.8621255738858, 1912.737046242948, 801.8748780853603, 1525.7708701293886, 1862.2378172674437, 1113.225108255583, 957.6466665773992, 659.6716151906504, 1187.9163451156132, 1243.294731966063, 1831.6697720906845, 1965.0883775496131, 1640.5467909205643, 1917.7052460962598, 1488.0853048226948, 1583.4818341323303, 1677.0724731438215, 1489.4080275882375, 1949.9299461268026, 1953.2602976939656, 575.5880990054563, 1946.3617884794965, 2169.568396436172, 1232.324972682681, 1152.590319341466, 1744.6241448091175, 1477.7364293004737, 1633.5566523074851, 855.3115041116912, 922.7940839803608, 1735.389106278269, 1946.436279337724, 674.4468545528713, 1921.4248548359224, 2001.013775390919, 1546.882791055653, 877.0359837118413, 1467.3917920208287, 1192.6965042100096, 1256.3747622495098, 1880.7983882256572, 1904.673256302626, 2009.1085942333616, 1335.7623645946903, 2074.0252260180146, 1388.205041691025, 1926.485427941585, 1352.1548665137352, 1613.8018334287585, 1026.2254539493724, 1438.064838148711, 1527.636909752783, 1816.2196130863867, 1988.1211401332678, 1392.0893949598553, 1692.1234610650072, 1185.492236387, 1302.5126516962462, 1660.9343784626203, 1610.7251370145907, 1805.293705043038, 1890.2312582947688, 1315.9189517250445, 1424.5098778760519, 1375.391984445165, 1493.6433528924063, 1337.628407277703, 1686.9262837156164, 1422.8365728220078, 1195.1387122864219, 1904.1448409783764, 1122.5312171167982, 2107.2214733554, 1604.310832613463, 1404.9006008764295, 1864.8719736899384, 1307.1367597597512, 1105.4817486644986, 1763.105531037722], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [667.9892278476628, 501.2238892888017, 584.9431279845129, 702.1671890752323, 589.5728934738537, 443.2041138617302, 469.46942901265186, 412.46912926370635, 640.5994123594189, 585.898647801959, 545.027774895503, 491.70630540129315, 482.23512972857395, 647.6766173936663, 732.2691406150443, 532.1147736996136, 768.2710071074331, 418.819734024596, 821.1889273469386, 420.4775069001856, 543.5261988989569, 534.8015071785437, 401.0890316709919, 546.9193488968247, 458.2723790122267, 577.5406838281339, 680.0728930730902, 744.3874774288856, 391.9798603498346, 557.7132801935819, 430.43620457579186, 520.4705371881687, 515.9730052248453, 489.851759862282, 563.8795862906676, 58.998919027283165, 588.4318482958516, 516.9102749397027, 674.4908261934397, 577.855884997512, 453.7931643202226, 495.6415149971277, 690.0453702346423, 666.1761931777515, 527.2145677340834, 787.6853330409931, 468.10257199329925, 342.7521128541145, 648.0630734070741, 380.49839033812566, 423.53150066695395, 382.36590410580726, 172.7453400115709, 641.2474940364766, 250.09186306841443, 477.40832196402584, 339.7766988124614, 220.66723267730305, 293.88048267499335, 685.2071642577245, 497.4409055279729, 241.41156406210365, 674.5069151255417, 642.1199239992153, 555.2513002906844, 434.8021078110633, 611.0689310750039, 444.8739258521477, 493.2309880069827, 357.3978376297427, 485.56586003497284, 590.8123982374478, 383.75127301883595, 575.1002104054375, 434.1604994052644, 591.7674810920773, 651.551451632553, 436.83321226140407, 411.1918463552139, 403.42413704900935, 426.8406133645265, 448.780230184139, 238.82568430128944, 331.64310484447327, 497.09601918409476, 556.0434136643611, 901.6254074821358, 460.2613395170457, 339.7420515389651, 628.4840017913451, 193.28583509549324, 658.393967942492, 498.16050608014245, 665.8613200225802, 676.2219685903467, 391.2839952722894, 610.7677596741482, 449.51500322498947, 237.98206235156076, 581.3839598391542, 237.512231820086, 623.7150035241787, 535.5859740389263, 614.9021562882866, 644.9215049053612, 488.57105853219065, 312.516460098096, 308.7859743343085, 566.5328737529715, 635.5236753494855, 505.32883947834245, 552.5080592535858, 432.3720470468273, 689.9229535365148, 315.41651656656165, 501.75663187865734, 489.1155174637967, 473.4241649752431, 221.9973594473235, 591.6944203855068, 612.1388560806801, 246.16348426830717, 565.0585809499305, 599.2880571334938, 707.9856864148009, 663.6771485228859, 441.81423327032337, 447.2728283691437, 632.2782842472875, 406.131435438186, 776.1914700566675, 543.5352879041359, 526.6911039331047, 374.8780878846629, 605.0797615106034, 445.7960525224342, 305.8193514523898, 198.02498975862537, 293.22825802806, 516.3208796784935, 634.9918489115405, 220.50360607844524, 631.8977790308684, 391.27451977776235, 599.397246247656, 453.65707354112266, 595.3816368227676, 604.5406427555762, 675.7842065593659, 576.1609064613626, 390.2824434036898, 577.0948888689849, 702.9662921559094, 653.4702648089736, 510.9423834148388, 214.79201144188505, 532.9363757005019, 472.4825396587852, 529.950350885811, 572.1830060871777, 464.11165844754635, 526.9072955644117, 644.4093024244745, 657.7720304248078, 464.13234228372096, 576.7384335450611, 654.6275377664265, 207.0304377284191, 406.8161687228778, 506.1832789964852, 248.2284705722789, 489.8462568681003, 544.7616503654679, 380.41375570933457, 613.2545464468551, 403.733810858525, 578.1740337511987, 629.2198341760907, 268.2851976545439, 531.3945510473271, 351.71105485378735, 428.7422173574272, 535.4695487560065, 399.0652034108258, 374.7252750552332, 646.1835397041217, 392.07246202100487, 851.409908661632, 628.9923756145158, 336.68031853942193, 540.5714583806309, 287.95253848622593, 285.9441630882145, 380.81145652942166, 762.2502518182589, 301.1677118631269, 243.8560489967299, 721.875849399724, 599.7840034403291, 437.65503910230535], "policy_predator_policy_reward": [421.22484324064516, 415.9492258961106, 395.4092183542724, 391.2215757517694, 279.8650262038554, 47.61034772199465, 596.0917049370752, 451.91546716332545, 409.0763871685628, 421.2396398693359, 416.66829013290726, 375.01512558232946, 239.56054861447683, 292.9256620974788, 247.4483459952368, 213.43679728719744, 452.4710061998573, 487.4965659275526, 398.959601085469, 491.55238922374457, 331.59386031321253, 330.00629400778064, 499.8813491966687, 334.61836860220615, 393.71357297856565, 511.40525651710914, 102.39439141644034, 101.30937307069988, 365.02169591222656, 427.8606777609288, 476.7813740888231, 486.5347194180992, 472.796211091959, 453.33797311380704, 680.225885803304, 614.4570778744977, 390.53958753155797, 358.74436955970725, 240.00030421603978, 296.3854653046537, 474.63592604004873, 487.76838437992785, 353.32765995708934, 331.3129022044043, 317.93443449666756, 279.9027109712041, -6.014109352458542, -2.9656974095950517, 230.40493325818431, 266.8044731260062, 517.9972251367918, 538.3431873578884, 147.05647593684006, 152.17579827069795, 132.2975895823946, 97.84889196256452, 106.78317799953042, -7.555494298644217, 142.93680699442706, 65.89189118846757, 234.60598515971026, 269.83627721627715, 290.8847583132759, 224.15817465265198, 523.0747836461512, 451.9601858017153, 203.1831156730967, 381.4208183203136, 572.3281489368401, 494.74827152269546, 318.5616535543609, 93.14539299591412, 341.5959163210415, 283.0344343870141, 361.3694497222055, 289.7750429242767, 198.65702930903248, 202.36633438525072, 585.2119850198119, 550.1019777027659, 544.6559129221394, 532.98354122316, -2.2700356885272743, 7.389345548220824, 377.9309064820224, 515.2914491490175, 388.5200847005402, 419.16156473644986, 245.48592228943707, 18.612997062932795, 184.56334519755103, 116.34717110592874, 287.8875044140842, 292.71481429231045, 275.5384419202697, 134.6920235175691, 285.85175361434915, 287.4221357940006, 4.25884430633159, 31.686637614644198, 52.516633846937474, 9.05021478915845, 281.1804521322686, 303.72052381878694, 392.79752361700093, 420.1461922831702, 52.5991274052779, 0.5452927151884293, 402.68791891707997, 316.68038681638734, 478.3144386722128, 464.8624379867813, 210.08654118738286, 214.5012492849285, -3.494145733805884, 63.35698100042828, 215.3444331996671, 289.50767638212403, 235.30093165485397, 143.70379272232526, 154.85288530265768, 243.21953659786445, 396.24073218596, 320.21101795627266, 308.3537081851216, 224.6567131798228, 558.8127049963099, 561.2088275975831, 36.96793845376605, 260.3847064554509, 392.96696004258996, 361.33150801461977, 242.79174805805502, 243.84410181520096, 548.7663332581271, 326.84328065041876, 454.4480615757026, 393.8624637270156, 537.4236945531416, 266.8290011690635, 164.5031903314955, 6.226808627891258, 170.09239648068697, 244.80014285939265, 360.02025959723784, 114.56233036676883, 237.55329682806047, 378.74403667998195, 491.07338523813274, 245.1026418744086, 241.79740940537818, 182.91465328180402, 182.2873632460733, 153.3995408540496, 406.8215263808747, 52.93631514940201, 156.36491131035822, 140.7288250266012, 262.2597114682189, 296.54131002141236, 224.79366156268406, 394.9125214399473, 212.68776248479628, 290.4246097089605, 481.81137274422093, 367.54910972176634, 223.7905175908585, 230.47045863933982, 188.9750135504192, 322.53541660627167, 433.8966934357463, 203.42056356903905, 357.4523770525124, 211.01556976509258, 142.99794771858996, 177.6421022537325, 226.41723542442125, 253.11518036390663, 371.4007902854668, 251.75603383467072, -24.714583740151596, 439.4000238153583, 478.60526607454614, 491.00482273700106, -10.308992995248015, 111.93139535269145, 444.4354542043902, 419.3036484683686, 216.3225527187835, 422.31558574074427, 358.89596233101656, 217.48064167855765, 577.0654896641005, 621.0508644082029, 96.04147554538976, 147.67732053297516, 55.53475355296491, 84.21509671507985, 399.23871892502393, 326.42776957006515]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.382914649051367, "mean_inference_ms": 6.264418995410502, "mean_action_processing_ms": 1.0149605908506627, "mean_env_wait_ms": 0.8693064562510956, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013466715812683105, "StateBufferConnector_ms": 0.007850050926208496, "ViewRequirementAgentConnector_ms": 0.3509953022003174}, "num_episodes": 18, "episode_return_max": 2169.568396436172, "episode_return_min": 575.5880990054563, "episode_return_mean": 1594.4292871692094, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 251.631945719832, "num_env_steps_trained_throughput_per_sec": 251.631945719832, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 15958.971, "restore_workers_time_ms": 0.013, "training_step_time_ms": 15958.928, "sample_time_ms": 4138.081, "learn_time_ms": 11802.43, "learn_throughput": 338.913, "synch_weights_time_ms": 17.509}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "479e5_00000", "date": "2024-08-16_12-29-45", "timestamp": 1723791585, "time_this_iter_s": 15.900878190994263, "time_total_s": 3776.005176305771, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7fb0700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3776.005176305771, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 28.217391304347824, "ram_util_percent": 64.34347826086955}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0225361416894923, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.269531271192763, "policy_loss": -0.0016250068812123525, "vf_loss": 9.270509336360547, "vf_explained_var": -0.015674569335564104, "kl": 0.011501771756103679, "entropy": 1.0597654555840468, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5724595354663, "cur_kl_coeff": 0.005932617187500002, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.269928540123834, "policy_loss": -0.0029867828833481306, "vf_loss": 9.272868697857731, "vf_explained_var": -0.05044693007040276, "kl": 0.007860815272446206, "entropy": 0.43206419449634653, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 2169.568396436172, "episode_reward_min": 575.5880990054563, "episode_reward_mean": 1555.8509834564495, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 172.7453400115709, "predator_policy": -24.714583740151596}, "policy_reward_max": {"prey_policy": 901.6254074821358, "predator_policy": 621.0508644082029}, "policy_reward_mean": {"prey_policy": 493.5203510664432, "predator_policy": 284.4051406617818}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1912.737046242948, 801.8748780853603, 1525.7708701293886, 1862.2378172674437, 1113.225108255583, 957.6466665773992, 659.6716151906504, 1187.9163451156132, 1243.294731966063, 1831.6697720906845, 1965.0883775496131, 1640.5467909205643, 1917.7052460962598, 1488.0853048226948, 1583.4818341323303, 1677.0724731438215, 1489.4080275882375, 1949.9299461268026, 1953.2602976939656, 575.5880990054563, 1946.3617884794965, 2169.568396436172, 1232.324972682681, 1152.590319341466, 1744.6241448091175, 1477.7364293004737, 1633.5566523074851, 855.3115041116912, 922.7940839803608, 1735.389106278269, 1946.436279337724, 674.4468545528713, 1921.4248548359224, 2001.013775390919, 1546.882791055653, 877.0359837118413, 1467.3917920208287, 1192.6965042100096, 1256.3747622495098, 1880.7983882256572, 1904.673256302626, 2009.1085942333616, 1335.7623645946903, 2074.0252260180146, 1388.205041691025, 1926.485427941585, 1352.1548665137352, 1613.8018334287585, 1026.2254539493724, 1438.064838148711, 1527.636909752783, 1816.2196130863867, 1988.1211401332678, 1392.0893949598553, 1692.1234610650072, 1185.492236387, 1302.5126516962462, 1660.9343784626203, 1610.7251370145907, 1805.293705043038, 1890.2312582947688, 1315.9189517250445, 1424.5098778760519, 1375.391984445165, 1493.6433528924063, 1337.628407277703, 1686.9262837156164, 1422.8365728220078, 1195.1387122864219, 1904.1448409783764, 1122.5312171167982, 2107.2214733554, 1604.310832613463, 1404.9006008764295, 1864.8719736899384, 1307.1367597597512, 1105.4817486644986, 1763.105531037722, 1523.259072060163, 2047.6231879867762, 1516.943753064671, 1879.2905013369696, 1594.306783678255, 1939.3852155933123, 1380.7435693371083, 1986.5223567426135, 1813.4885892788295, 1190.9229005037978, 1780.2695945913117, 1839.621891565712, 1087.7446562408159, 1645.8443427816994, 1791.257710755731, 1610.89282943981, 1965.859610499114, 1666.9413862580193, 1774.920047375328, 1919.1715281595605, 1651.837882310778, 1631.6943949153156], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [527.2145677340834, 787.6853330409931, 468.10257199329925, 342.7521128541145, 648.0630734070741, 380.49839033812566, 423.53150066695395, 382.36590410580726, 172.7453400115709, 641.2474940364766, 250.09186306841443, 477.40832196402584, 339.7766988124614, 220.66723267730305, 293.88048267499335, 685.2071642577245, 497.4409055279729, 241.41156406210365, 674.5069151255417, 642.1199239992153, 555.2513002906844, 434.8021078110633, 611.0689310750039, 444.8739258521477, 493.2309880069827, 357.3978376297427, 485.56586003497284, 590.8123982374478, 383.75127301883595, 575.1002104054375, 434.1604994052644, 591.7674810920773, 651.551451632553, 436.83321226140407, 411.1918463552139, 403.42413704900935, 426.8406133645265, 448.780230184139, 238.82568430128944, 331.64310484447327, 497.09601918409476, 556.0434136643611, 901.6254074821358, 460.2613395170457, 339.7420515389651, 628.4840017913451, 193.28583509549324, 658.393967942492, 498.16050608014245, 665.8613200225802, 676.2219685903467, 391.2839952722894, 610.7677596741482, 449.51500322498947, 237.98206235156076, 581.3839598391542, 237.512231820086, 623.7150035241787, 535.5859740389263, 614.9021562882866, 644.9215049053612, 488.57105853219065, 312.516460098096, 308.7859743343085, 566.5328737529715, 635.5236753494855, 505.32883947834245, 552.5080592535858, 432.3720470468273, 689.9229535365148, 315.41651656656165, 501.75663187865734, 489.1155174637967, 473.4241649752431, 221.9973594473235, 591.6944203855068, 612.1388560806801, 246.16348426830717, 565.0585809499305, 599.2880571334938, 707.9856864148009, 663.6771485228859, 441.81423327032337, 447.2728283691437, 632.2782842472875, 406.131435438186, 776.1914700566675, 543.5352879041359, 526.6911039331047, 374.8780878846629, 605.0797615106034, 445.7960525224342, 305.8193514523898, 198.02498975862537, 293.22825802806, 516.3208796784935, 634.9918489115405, 220.50360607844524, 631.8977790308684, 391.27451977776235, 599.397246247656, 453.65707354112266, 595.3816368227676, 604.5406427555762, 675.7842065593659, 576.1609064613626, 390.2824434036898, 577.0948888689849, 702.9662921559094, 653.4702648089736, 510.9423834148388, 214.79201144188505, 532.9363757005019, 472.4825396587852, 529.950350885811, 572.1830060871777, 464.11165844754635, 526.9072955644117, 644.4093024244745, 657.7720304248078, 464.13234228372096, 576.7384335450611, 654.6275377664265, 207.0304377284191, 406.8161687228778, 506.1832789964852, 248.2284705722789, 489.8462568681003, 544.7616503654679, 380.41375570933457, 613.2545464468551, 403.733810858525, 578.1740337511987, 629.2198341760907, 268.2851976545439, 531.3945510473271, 351.71105485378735, 428.7422173574272, 535.4695487560065, 399.0652034108258, 374.7252750552332, 646.1835397041217, 392.07246202100487, 851.409908661632, 628.9923756145158, 336.68031853942193, 540.5714583806309, 287.95253848622593, 285.9441630882145, 380.81145652942166, 762.2502518182589, 301.1677118631269, 243.8560489967299, 721.875849399724, 599.7840034403291, 437.65503910230535, 464.0971340123607, 293.73533455348854, 341.2411907448068, 790.1670499962232, 402.0399948136308, 243.455123788184, 506.39670993428695, 491.8361305141937, 360.2807363489309, 486.2870156045869, 540.5144861672658, 722.7944347538017, 482.726510818728, 673.1420976994931, 524.2928643890035, 682.658583679091, 347.63047286936205, 545.6275449509856, 651.6150526535848, 205.44769073252252, 578.1497962353136, 530.7624004285116, 542.9223499199403, 549.0812411458421, 646.6252541443331, 345.14084732077373, 782.4010704650561, 679.5479402386871, 556.4009464664645, 552.0275065255784, 574.3716330561301, 629.2499184401091, 627.8130327571278, 652.6238987133418, 451.00721029430116, 550.9062098194868, 434.9523903523045, 693.9170603708938, 393.51449699443185, 571.254209161879, 344.09449836612634, 275.3316692791353, 419.7631684937533, 323.39793964652023], "policy_predator_policy_reward": [317.93443449666756, 279.9027109712041, -6.014109352458542, -2.9656974095950517, 230.40493325818431, 266.8044731260062, 517.9972251367918, 538.3431873578884, 147.05647593684006, 152.17579827069795, 132.2975895823946, 97.84889196256452, 106.78317799953042, -7.555494298644217, 142.93680699442706, 65.89189118846757, 234.60598515971026, 269.83627721627715, 290.8847583132759, 224.15817465265198, 523.0747836461512, 451.9601858017153, 203.1831156730967, 381.4208183203136, 572.3281489368401, 494.74827152269546, 318.5616535543609, 93.14539299591412, 341.5959163210415, 283.0344343870141, 361.3694497222055, 289.7750429242767, 198.65702930903248, 202.36633438525072, 585.2119850198119, 550.1019777027659, 544.6559129221394, 532.98354122316, -2.2700356885272743, 7.389345548220824, 377.9309064820224, 515.2914491490175, 388.5200847005402, 419.16156473644986, 245.48592228943707, 18.612997062932795, 184.56334519755103, 116.34717110592874, 287.8875044140842, 292.71481429231045, 275.5384419202697, 134.6920235175691, 285.85175361434915, 287.4221357940006, 4.25884430633159, 31.686637614644198, 52.516633846937474, 9.05021478915845, 281.1804521322686, 303.72052381878694, 392.79752361700093, 420.1461922831702, 52.5991274052779, 0.5452927151884293, 402.68791891707997, 316.68038681638734, 478.3144386722128, 464.8624379867813, 210.08654118738286, 214.5012492849285, -3.494145733805884, 63.35698100042828, 215.3444331996671, 289.50767638212403, 235.30093165485397, 143.70379272232526, 154.85288530265768, 243.21953659786445, 396.24073218596, 320.21101795627266, 308.3537081851216, 224.6567131798228, 558.8127049963099, 561.2088275975831, 36.96793845376605, 260.3847064554509, 392.96696004258996, 361.33150801461977, 242.79174805805502, 243.84410181520096, 548.7663332581271, 326.84328065041876, 454.4480615757026, 393.8624637270156, 537.4236945531416, 266.8290011690635, 164.5031903314955, 6.226808627891258, 170.09239648068697, 244.80014285939265, 360.02025959723784, 114.56233036676883, 237.55329682806047, 378.74403667998195, 491.07338523813274, 245.1026418744086, 241.79740940537818, 182.91465328180402, 182.2873632460733, 153.3995408540496, 406.8215263808747, 52.93631514940201, 156.36491131035822, 140.7288250266012, 262.2597114682189, 296.54131002141236, 224.79366156268406, 394.9125214399473, 212.68776248479628, 290.4246097089605, 481.81137274422093, 367.54910972176634, 223.7905175908585, 230.47045863933982, 188.9750135504192, 322.53541660627167, 433.8966934357463, 203.42056356903905, 357.4523770525124, 211.01556976509258, 142.99794771858996, 177.6421022537325, 226.41723542442125, 253.11518036390663, 371.4007902854668, 251.75603383467072, -24.714583740151596, 439.4000238153583, 478.60526607454614, 491.00482273700106, -10.308992995248015, 111.93139535269145, 444.4354542043902, 419.3036484683686, 216.3225527187835, 422.31558574074427, 358.89596233101656, 217.48064167855765, 577.0654896641005, 621.0508644082029, 96.04147554538976, 147.67732053297516, 55.53475355296491, 84.21509671507985, 399.23871892502393, 326.42776957006515, 341.5124010615964, 423.91420243271835, 418.06995055985055, 498.144996685892, 337.299278385486, 534.1493560773683, 474.8430645869822, 406.21459630150974, 434.4207009449221, 313.3183307798171, 290.97949548243633, 385.09679918980936, 42.404990658409574, 182.46997016047868, 392.92130986446546, 386.6495988100541, 497.30449806220986, 422.926073396274, 159.436195096317, 174.42396202137274, 171.0363547911317, 500.3210431363558, 332.2286132027145, 415.38968729721535, 12.43303997616163, 83.54551479954655, 26.700958052494073, 157.19437402546382, 373.9204837182006, 308.90877404548866, 297.44346246104067, 109.82781548253264, 241.8796839350112, 443.54299509363386, 419.5013457434976, 245.5266204007325, 443.38340872902194, 202.66718792310695, 540.08606050957, 414.3167614936783, 490.6442561761622, 541.7674584893546, 549.0906200772877, 339.44266669775544]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.379177314549612, "mean_inference_ms": 6.2517573177545795, "mean_action_processing_ms": 1.0130535999221306, "mean_env_wait_ms": 0.8674409114698765, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01746511459350586, "StateBufferConnector_ms": 0.007850170135498047, "ViewRequirementAgentConnector_ms": 0.32978665828704834}, "num_episodes": 22, "episode_return_max": 2169.568396436172, "episode_return_min": 575.5880990054563, "episode_return_mean": 1555.8509834564495, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 258.12576429367056, "num_env_steps_trained_throughput_per_sec": 258.12576429367056, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 15795.244, "restore_workers_time_ms": 0.013, "training_step_time_ms": 15795.201, "sample_time_ms": 4145.715, "learn_time_ms": 11630.925, "learn_throughput": 343.911, "synch_weights_time_ms": 17.663}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "479e5_00000", "date": "2024-08-16_12-30-01", "timestamp": 1723791601, "time_this_iter_s": 15.50156021118164, "time_total_s": 3791.5067365169525, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78e5dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3791.5067365169525, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 28.077272727272724, "ram_util_percent": 63.86363636363637}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2241384686300996, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.494897001256387, "policy_loss": -0.003432237052127088, "vf_loss": 9.49775619456377, "vf_explained_var": -0.023746228628057652, "kl": 0.010187835439923318, "entropy": 1.0347353636903107, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.335955877515374, "cur_kl_coeff": 0.005932617187500002, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.491457665155805, "policy_loss": 0.0011914680123072926, "vf_loss": 9.490217540377662, "vf_explained_var": -0.01968001436304163, "kl": 0.008200917191479964, "entropy": 0.4342777639312088, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 2169.568396436172, "episode_reward_min": 575.5880990054563, "episode_reward_mean": 1572.1719340690202, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 193.28583509549324, "predator_policy": -24.714583740151596}, "policy_reward_max": {"prey_policy": 901.6254074821358, "predator_policy": 621.0508644082029}, "policy_reward_mean": {"prey_policy": 492.5786388649419, "predator_policy": 293.50732816956815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1953.2602976939656, 575.5880990054563, 1946.3617884794965, 2169.568396436172, 1232.324972682681, 1152.590319341466, 1744.6241448091175, 1477.7364293004737, 1633.5566523074851, 855.3115041116912, 922.7940839803608, 1735.389106278269, 1946.436279337724, 674.4468545528713, 1921.4248548359224, 2001.013775390919, 1546.882791055653, 877.0359837118413, 1467.3917920208287, 1192.6965042100096, 1256.3747622495098, 1880.7983882256572, 1904.673256302626, 2009.1085942333616, 1335.7623645946903, 2074.0252260180146, 1388.205041691025, 1926.485427941585, 1352.1548665137352, 1613.8018334287585, 1026.2254539493724, 1438.064838148711, 1527.636909752783, 1816.2196130863867, 1988.1211401332678, 1392.0893949598553, 1692.1234610650072, 1185.492236387, 1302.5126516962462, 1660.9343784626203, 1610.7251370145907, 1805.293705043038, 1890.2312582947688, 1315.9189517250445, 1424.5098778760519, 1375.391984445165, 1493.6433528924063, 1337.628407277703, 1686.9262837156164, 1422.8365728220078, 1195.1387122864219, 1904.1448409783764, 1122.5312171167982, 2107.2214733554, 1604.310832613463, 1404.9006008764295, 1864.8719736899384, 1307.1367597597512, 1105.4817486644986, 1763.105531037722, 1523.259072060163, 2047.6231879867762, 1516.943753064671, 1879.2905013369696, 1594.306783678255, 1939.3852155933123, 1380.7435693371083, 1986.5223567426135, 1813.4885892788295, 1190.9229005037978, 1780.2695945913117, 1839.621891565712, 1087.7446562408159, 1645.8443427816994, 1791.257710755731, 1610.89282943981, 1965.859610499114, 1666.9413862580193, 1774.920047375328, 1919.1715281595605, 1651.837882310778, 1631.6943949153156, 780.0141659434763, 1772.7653694073035, 1736.342500127794, 1347.8982233560985, 1428.1058182209617, 1336.073213219833, 1399.2406437138404, 2045.670163370983, 1780.3556075969816, 1437.7072149834235, 1747.3587544575976, 1129.8194745378826, 2041.7194944572373, 2038.1996689041318, 1600.706366182816, 1112.411394133787, 1959.6074959778048, 1745.462343966526], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [426.8406133645265, 448.780230184139, 238.82568430128944, 331.64310484447327, 497.09601918409476, 556.0434136643611, 901.6254074821358, 460.2613395170457, 339.7420515389651, 628.4840017913451, 193.28583509549324, 658.393967942492, 498.16050608014245, 665.8613200225802, 676.2219685903467, 391.2839952722894, 610.7677596741482, 449.51500322498947, 237.98206235156076, 581.3839598391542, 237.512231820086, 623.7150035241787, 535.5859740389263, 614.9021562882866, 644.9215049053612, 488.57105853219065, 312.516460098096, 308.7859743343085, 566.5328737529715, 635.5236753494855, 505.32883947834245, 552.5080592535858, 432.3720470468273, 689.9229535365148, 315.41651656656165, 501.75663187865734, 489.1155174637967, 473.4241649752431, 221.9973594473235, 591.6944203855068, 612.1388560806801, 246.16348426830717, 565.0585809499305, 599.2880571334938, 707.9856864148009, 663.6771485228859, 441.81423327032337, 447.2728283691437, 632.2782842472875, 406.131435438186, 776.1914700566675, 543.5352879041359, 526.6911039331047, 374.8780878846629, 605.0797615106034, 445.7960525224342, 305.8193514523898, 198.02498975862537, 293.22825802806, 516.3208796784935, 634.9918489115405, 220.50360607844524, 631.8977790308684, 391.27451977776235, 599.397246247656, 453.65707354112266, 595.3816368227676, 604.5406427555762, 675.7842065593659, 576.1609064613626, 390.2824434036898, 577.0948888689849, 702.9662921559094, 653.4702648089736, 510.9423834148388, 214.79201144188505, 532.9363757005019, 472.4825396587852, 529.950350885811, 572.1830060871777, 464.11165844754635, 526.9072955644117, 644.4093024244745, 657.7720304248078, 464.13234228372096, 576.7384335450611, 654.6275377664265, 207.0304377284191, 406.8161687228778, 506.1832789964852, 248.2284705722789, 489.8462568681003, 544.7616503654679, 380.41375570933457, 613.2545464468551, 403.733810858525, 578.1740337511987, 629.2198341760907, 268.2851976545439, 531.3945510473271, 351.71105485378735, 428.7422173574272, 535.4695487560065, 399.0652034108258, 374.7252750552332, 646.1835397041217, 392.07246202100487, 851.409908661632, 628.9923756145158, 336.68031853942193, 540.5714583806309, 287.95253848622593, 285.9441630882145, 380.81145652942166, 762.2502518182589, 301.1677118631269, 243.8560489967299, 721.875849399724, 599.7840034403291, 437.65503910230535, 464.0971340123607, 293.73533455348854, 341.2411907448068, 790.1670499962232, 402.0399948136308, 243.455123788184, 506.39670993428695, 491.8361305141937, 360.2807363489309, 486.2870156045869, 540.5144861672658, 722.7944347538017, 482.726510818728, 673.1420976994931, 524.2928643890035, 682.658583679091, 347.63047286936205, 545.6275449509856, 651.6150526535848, 205.44769073252252, 578.1497962353136, 530.7624004285116, 542.9223499199403, 549.0812411458421, 646.6252541443331, 345.14084732077373, 782.4010704650561, 679.5479402386871, 556.4009464664645, 552.0275065255784, 574.3716330561301, 629.2499184401091, 627.8130327571278, 652.6238987133418, 451.00721029430116, 550.9062098194868, 434.9523903523045, 693.9170603708938, 393.51449699443185, 571.254209161879, 344.09449836612634, 275.3316692791353, 419.7631684937533, 323.39793964652023, 233.52841540320603, 376.7450217855635, 404.32509156466705, 348.31095234551833, 408.47602585077294, 384.77664850348646, 236.00827648723666, 614.9318041054718, 282.775081024704, 538.293528643607, 265.21415658648493, 624.2572771068626, 561.5312139893553, 274.34782100197293, 682.8954025879247, 461.1901005371046, 529.1767177959406, 490.4783277139979, 282.41163308727306, 542.6291964457452, 747.679418340005, 536.9007155458987, 200.0, 624.1754671381043, 449.83515972605613, 621.1900371805804, 603.4925401477062, 566.1785994535915, 565.2766107208872, 402.46416558664697, 212.22977298541116, 684.6721844645245, 303.33280662163804, 554.2864480570555, 662.0550400744634, 493.0867216063738], "policy_predator_policy_reward": [544.6559129221394, 532.98354122316, -2.2700356885272743, 7.389345548220824, 377.9309064820224, 515.2914491490175, 388.5200847005402, 419.16156473644986, 245.48592228943707, 18.612997062932795, 184.56334519755103, 116.34717110592874, 287.8875044140842, 292.71481429231045, 275.5384419202697, 134.6920235175691, 285.85175361434915, 287.4221357940006, 4.25884430633159, 31.686637614644198, 52.516633846937474, 9.05021478915845, 281.1804521322686, 303.72052381878694, 392.79752361700093, 420.1461922831702, 52.5991274052779, 0.5452927151884293, 402.68791891707997, 316.68038681638734, 478.3144386722128, 464.8624379867813, 210.08654118738286, 214.5012492849285, -3.494145733805884, 63.35698100042828, 215.3444331996671, 289.50767638212403, 235.30093165485397, 143.70379272232526, 154.85288530265768, 243.21953659786445, 396.24073218596, 320.21101795627266, 308.3537081851216, 224.6567131798228, 558.8127049963099, 561.2088275975831, 36.96793845376605, 260.3847064554509, 392.96696004258996, 361.33150801461977, 242.79174805805502, 243.84410181520096, 548.7663332581271, 326.84328065041876, 454.4480615757026, 393.8624637270156, 537.4236945531416, 266.8290011690635, 164.5031903314955, 6.226808627891258, 170.09239648068697, 244.80014285939265, 360.02025959723784, 114.56233036676883, 237.55329682806047, 378.74403667998195, 491.07338523813274, 245.1026418744086, 241.79740940537818, 182.91465328180402, 182.2873632460733, 153.3995408540496, 406.8215263808747, 52.93631514940201, 156.36491131035822, 140.7288250266012, 262.2597114682189, 296.54131002141236, 224.79366156268406, 394.9125214399473, 212.68776248479628, 290.4246097089605, 481.81137274422093, 367.54910972176634, 223.7905175908585, 230.47045863933982, 188.9750135504192, 322.53541660627167, 433.8966934357463, 203.42056356903905, 357.4523770525124, 211.01556976509258, 142.99794771858996, 177.6421022537325, 226.41723542442125, 253.11518036390663, 371.4007902854668, 251.75603383467072, -24.714583740151596, 439.4000238153583, 478.60526607454614, 491.00482273700106, -10.308992995248015, 111.93139535269145, 444.4354542043902, 419.3036484683686, 216.3225527187835, 422.31558574074427, 358.89596233101656, 217.48064167855765, 577.0654896641005, 621.0508644082029, 96.04147554538976, 147.67732053297516, 55.53475355296491, 84.21509671507985, 399.23871892502393, 326.42776957006515, 341.5124010615964, 423.91420243271835, 418.06995055985055, 498.144996685892, 337.299278385486, 534.1493560773683, 474.8430645869822, 406.21459630150974, 434.4207009449221, 313.3183307798171, 290.97949548243633, 385.09679918980936, 42.404990658409574, 182.46997016047868, 392.92130986446546, 386.6495988100541, 497.30449806220986, 422.926073396274, 159.436195096317, 174.42396202137274, 171.0363547911317, 500.3210431363558, 332.2286132027145, 415.38968729721535, 12.43303997616163, 83.54551479954655, 26.700958052494073, 157.19437402546382, 373.9204837182006, 308.90877404548866, 297.44346246104067, 109.82781548253264, 241.8796839350112, 443.54299509363386, 419.5013457434976, 245.5266204007325, 443.38340872902194, 202.66718792310695, 540.08606050957, 414.3167614936783, 490.6442561761622, 541.7674584893546, 549.0906200772877, 339.44266669775544, 67.89062432625019, 101.8501044284567, 518.0102699328434, 502.119055564275, 467.40600517065707, 475.6838206028816, 181.56867000771211, 315.3894727556791, 282.5320465284039, 324.50516202424626, 319.31807147784093, 127.28370804864485, 271.8169928375803, 291.54461588492825, 439.7170407098896, 461.86761953606657, 420.81595610413467, 339.88460598290584, 309.29523277993513, 303.371152670469, 241.98404244976885, 220.79457812192678, 126.06873919255698, 179.57526820722114, 488.3956820675737, 482.29861548302875, 439.53267333979545, 428.99585596303984, 309.9594184916115, 323.0061713836686, 121.37622882235205, 94.1332078615001, 556.9523566067136, 545.0358846923964, 128.0830741664614, 462.2375081192304]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3759139561364178, "mean_inference_ms": 6.2411818579711635, "mean_action_processing_ms": 1.011468443735443, "mean_env_wait_ms": 0.8657737750004919, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01824653148651123, "StateBufferConnector_ms": 0.007772326469421387, "ViewRequirementAgentConnector_ms": 0.32232987880706787}, "num_episodes": 18, "episode_return_max": 2169.568396436172, "episode_return_min": 575.5880990054563, "episode_return_mean": 1572.1719340690202, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 228.10577782851263, "num_env_steps_trained_throughput_per_sec": 228.10577782851263, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 15873.389, "restore_workers_time_ms": 0.013, "training_step_time_ms": 15873.346, "sample_time_ms": 4120.223, "learn_time_ms": 11733.23, "learn_throughput": 340.912, "synch_weights_time_ms": 18.979}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "479e5_00000", "date": "2024-08-16_12-30-18", "timestamp": 1723791618, "time_this_iter_s": 17.541731119155884, "time_total_s": 3809.0484676361084, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7fe2f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3809.0484676361084, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 29.727999999999998, "ram_util_percent": 63.900000000000006}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2112061814656334, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.519754867452793, "policy_loss": -0.0004231105999597324, "vf_loss": 9.519770775144062, "vf_explained_var": -0.011079899690769337, "kl": 0.007239356799841907, "entropy": 1.0363115145731225, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7772027721323034, "cur_kl_coeff": 0.005932617187500002, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.5814293578819, "policy_loss": 0.0006196588381297059, "vf_loss": 9.58076042901902, "vf_explained_var": -0.046998448851247314, "kl": 0.008305081397382279, "entropy": 0.4135375508871028, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 2107.2214733554, "episode_reward_min": 532.1510170699203, "episode_reward_mean": 1552.7723361928167, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 62.74358624907433, "predator_policy": -24.714583740151596}, "policy_reward_max": {"prey_policy": 851.409908661632, "predator_policy": 668.6847163844506}, "policy_reward_mean": {"prey_policy": 470.74760848673776, "predator_policy": 305.6385596096706}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2009.1085942333616, 1335.7623645946903, 2074.0252260180146, 1388.205041691025, 1926.485427941585, 1352.1548665137352, 1613.8018334287585, 1026.2254539493724, 1438.064838148711, 1527.636909752783, 1816.2196130863867, 1988.1211401332678, 1392.0893949598553, 1692.1234610650072, 1185.492236387, 1302.5126516962462, 1660.9343784626203, 1610.7251370145907, 1805.293705043038, 1890.2312582947688, 1315.9189517250445, 1424.5098778760519, 1375.391984445165, 1493.6433528924063, 1337.628407277703, 1686.9262837156164, 1422.8365728220078, 1195.1387122864219, 1904.1448409783764, 1122.5312171167982, 2107.2214733554, 1604.310832613463, 1404.9006008764295, 1864.8719736899384, 1307.1367597597512, 1105.4817486644986, 1763.105531037722, 1523.259072060163, 2047.6231879867762, 1516.943753064671, 1879.2905013369696, 1594.306783678255, 1939.3852155933123, 1380.7435693371083, 1986.5223567426135, 1813.4885892788295, 1190.9229005037978, 1780.2695945913117, 1839.621891565712, 1087.7446562408159, 1645.8443427816994, 1791.257710755731, 1610.89282943981, 1965.859610499114, 1666.9413862580193, 1774.920047375328, 1919.1715281595605, 1651.837882310778, 1631.6943949153156, 780.0141659434763, 1772.7653694073035, 1736.342500127794, 1347.8982233560985, 1428.1058182209617, 1336.073213219833, 1399.2406437138404, 2045.670163370983, 1780.3556075969816, 1437.7072149834235, 1747.3587544575976, 1129.8194745378826, 2041.7194944572373, 2038.1996689041318, 1600.706366182816, 1112.411394133787, 1959.6074959778048, 1745.462343966526, 1363.5398465948583, 920.7406503522332, 1542.782770338146, 532.1510170699203, 1262.932525232204, 1222.5094347124327, 868.248421302898, 1755.5478887023253, 1900.2119651629205, 1879.3055425507744, 710.1474928644905, 1728.9246376998753, 1158.4072974343671, 966.2337402448677, 2090.2173443479855, 1767.9252038636143, 1593.8430638936522, 1700.9690162513282, 1748.9461523061293, 856.1326873880738, 1857.4784474858227, 1338.029725478549, 1363.0963774224197], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [441.81423327032337, 447.2728283691437, 632.2782842472875, 406.131435438186, 776.1914700566675, 543.5352879041359, 526.6911039331047, 374.8780878846629, 605.0797615106034, 445.7960525224342, 305.8193514523898, 198.02498975862537, 293.22825802806, 516.3208796784935, 634.9918489115405, 220.50360607844524, 631.8977790308684, 391.27451977776235, 599.397246247656, 453.65707354112266, 595.3816368227676, 604.5406427555762, 675.7842065593659, 576.1609064613626, 390.2824434036898, 577.0948888689849, 702.9662921559094, 653.4702648089736, 510.9423834148388, 214.79201144188505, 532.9363757005019, 472.4825396587852, 529.950350885811, 572.1830060871777, 464.11165844754635, 526.9072955644117, 644.4093024244745, 657.7720304248078, 464.13234228372096, 576.7384335450611, 654.6275377664265, 207.0304377284191, 406.8161687228778, 506.1832789964852, 248.2284705722789, 489.8462568681003, 544.7616503654679, 380.41375570933457, 613.2545464468551, 403.733810858525, 578.1740337511987, 629.2198341760907, 268.2851976545439, 531.3945510473271, 351.71105485378735, 428.7422173574272, 535.4695487560065, 399.0652034108258, 374.7252750552332, 646.1835397041217, 392.07246202100487, 851.409908661632, 628.9923756145158, 336.68031853942193, 540.5714583806309, 287.95253848622593, 285.9441630882145, 380.81145652942166, 762.2502518182589, 301.1677118631269, 243.8560489967299, 721.875849399724, 599.7840034403291, 437.65503910230535, 464.0971340123607, 293.73533455348854, 341.2411907448068, 790.1670499962232, 402.0399948136308, 243.455123788184, 506.39670993428695, 491.8361305141937, 360.2807363489309, 486.2870156045869, 540.5144861672658, 722.7944347538017, 482.726510818728, 673.1420976994931, 524.2928643890035, 682.658583679091, 347.63047286936205, 545.6275449509856, 651.6150526535848, 205.44769073252252, 578.1497962353136, 530.7624004285116, 542.9223499199403, 549.0812411458421, 646.6252541443331, 345.14084732077373, 782.4010704650561, 679.5479402386871, 556.4009464664645, 552.0275065255784, 574.3716330561301, 629.2499184401091, 627.8130327571278, 652.6238987133418, 451.00721029430116, 550.9062098194868, 434.9523903523045, 693.9170603708938, 393.51449699443185, 571.254209161879, 344.09449836612634, 275.3316692791353, 419.7631684937533, 323.39793964652023, 233.52841540320603, 376.7450217855635, 404.32509156466705, 348.31095234551833, 408.47602585077294, 384.77664850348646, 236.00827648723666, 614.9318041054718, 282.775081024704, 538.293528643607, 265.21415658648493, 624.2572771068626, 561.5312139893553, 274.34782100197293, 682.8954025879247, 461.1901005371046, 529.1767177959406, 490.4783277139979, 282.41163308727306, 542.6291964457452, 747.679418340005, 536.9007155458987, 200.0, 624.1754671381043, 449.83515972605613, 621.1900371805804, 603.4925401477062, 566.1785994535915, 565.2766107208872, 402.46416558664697, 212.22977298541116, 684.6721844645245, 303.33280662163804, 554.2864480570555, 662.0550400744634, 493.0867216063738, 304.2039947439023, 486.0024519024232, 207.40349968161672, 482.9274153917397, 535.8873979961442, 364.98841112752336, 225.0309291814061, 219.85547171039642, 680.3626352403796, 194.06, 688.4960136985964, 257.95111771413735, 338.8719952279605, 200.0, 360.1366085731501, 62.74358624907433, 268.1613178308926, 509.22628806344005, 306.3776344596858, 557.2498574141231, 242.30655513672414, 362.4998528520568, 408.14270080026665, 363.97230956990995, 219.56559034548746, 548.3913329315105, 347.3789614851975, 449.5017235666455, 534.1994080228551, 418.7756778814808, 406.5216963950792, 532.6930320651936, 352.6336410288529, 537.854437278671, 528.459108154395, 705.4404490888334, 709.3513942766064, 477.2959714069542, 463.3375053301931, 246.91716392876538, 532.9486866454778, 313.41773677715355, 503.68387804930734, 302.24019949175374, 196.04, 608.9017656551382], "policy_predator_policy_reward": [558.8127049963099, 561.2088275975831, 36.96793845376605, 260.3847064554509, 392.96696004258996, 361.33150801461977, 242.79174805805502, 243.84410181520096, 548.7663332581271, 326.84328065041876, 454.4480615757026, 393.8624637270156, 537.4236945531416, 266.8290011690635, 164.5031903314955, 6.226808627891258, 170.09239648068697, 244.80014285939265, 360.02025959723784, 114.56233036676883, 237.55329682806047, 378.74403667998195, 491.07338523813274, 245.1026418744086, 241.79740940537818, 182.91465328180402, 182.2873632460733, 153.3995408540496, 406.8215263808747, 52.93631514940201, 156.36491131035822, 140.7288250266012, 262.2597114682189, 296.54131002141236, 224.79366156268406, 394.9125214399473, 212.68776248479628, 290.4246097089605, 481.81137274422093, 367.54910972176634, 223.7905175908585, 230.47045863933982, 188.9750135504192, 322.53541660627167, 433.8966934357463, 203.42056356903905, 357.4523770525124, 211.01556976509258, 142.99794771858996, 177.6421022537325, 226.41723542442125, 253.11518036390663, 371.4007902854668, 251.75603383467072, -24.714583740151596, 439.4000238153583, 478.60526607454614, 491.00482273700106, -10.308992995248015, 111.93139535269145, 444.4354542043902, 419.3036484683686, 216.3225527187835, 422.31558574074427, 358.89596233101656, 217.48064167855765, 577.0654896641005, 621.0508644082029, 96.04147554538976, 147.67732053297516, 55.53475355296491, 84.21509671507985, 399.23871892502393, 326.42776957006515, 341.5124010615964, 423.91420243271835, 418.06995055985055, 498.144996685892, 337.299278385486, 534.1493560773683, 474.8430645869822, 406.21459630150974, 434.4207009449221, 313.3183307798171, 290.97949548243633, 385.09679918980936, 42.404990658409574, 182.46997016047868, 392.92130986446546, 386.6495988100541, 497.30449806220986, 422.926073396274, 159.436195096317, 174.42396202137274, 171.0363547911317, 500.3210431363558, 332.2286132027145, 415.38968729721535, 12.43303997616163, 83.54551479954655, 26.700958052494073, 157.19437402546382, 373.9204837182006, 308.90877404548866, 297.44346246104067, 109.82781548253264, 241.8796839350112, 443.54299509363386, 419.5013457434976, 245.5266204007325, 443.38340872902194, 202.66718792310695, 540.08606050957, 414.3167614936783, 490.6442561761622, 541.7674584893546, 549.0906200772877, 339.44266669775544, 67.89062432625019, 101.8501044284567, 518.0102699328434, 502.119055564275, 467.40600517065707, 475.6838206028816, 181.56867000771211, 315.3894727556791, 282.5320465284039, 324.50516202424626, 319.31807147784093, 127.28370804864485, 271.8169928375803, 291.54461588492825, 439.7170407098896, 461.86761953606657, 420.81595610413467, 339.88460598290584, 309.29523277993513, 303.371152670469, 241.98404244976885, 220.79457812192678, 126.06873919255698, 179.57526820722114, 488.3956820675737, 482.29861548302875, 439.53267333979545, 428.99585596303984, 309.9594184916115, 323.0061713836686, 121.37622882235205, 94.1332078615001, 556.9523566067136, 545.0358846923964, 128.0830741664614, 462.2375081192304, 292.35981841147117, 280.9735815370623, 105.97744278031415, 124.43229249856344, 365.8999234064922, 276.00703780798625, 41.46658237711002, 45.798033801007655, 188.1516840505241, 200.3582059412991, 137.32995438744405, 138.7323489122555, 186.99110747242358, 142.38531860251405, 668.6847163844506, 663.9829774956509, 614.7847585339027, 508.0396007346793, 583.9408611785628, 431.737189498403, 39.12672341205636, 66.21436146365345, 532.4160566509579, 424.3935706787411, 190.75052807891143, 199.69984607845777, 157.17776529714067, 12.175289895883854, 601.5680364804002, 535.6742219632495, 569.4719073592973, 259.23856804404704, 348.20042157112954, 355.154564015001, 218.01828602323016, 249.05117298486633, 264.1084861391036, 298.19030048346445, 37.48588448669622, 108.39213364241941, 575.5712554892859, 435.5407685739022, 399.937470771281, 132.1681771662049, 283.83278333804935, 274.3218284292319]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.372993363413122, "mean_inference_ms": 6.232239131977699, "mean_action_processing_ms": 1.0101417896789382, "mean_env_wait_ms": 0.864158056738511, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01724696159362793, "StateBufferConnector_ms": 0.007854104042053223, "ViewRequirementAgentConnector_ms": 0.3454761505126953}, "num_episodes": 23, "episode_return_max": 2107.2214733554, "episode_return_min": 532.1510170699203, "episode_return_mean": 1552.7723361928167, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 241.54064349503443, "num_env_steps_trained_throughput_per_sec": 241.54064349503443, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 15872.19, "restore_workers_time_ms": 0.013, "training_step_time_ms": 15872.147, "sample_time_ms": 4177.397, "learn_time_ms": 11674.771, "learn_throughput": 342.619, "synch_weights_time_ms": 19.044}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "479e5_00000", "date": "2024-08-16_12-30-35", "timestamp": 1723791635, "time_this_iter_s": 16.566692113876343, "time_total_s": 3825.6151597499847, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7dcea60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3825.6151597499847, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 30.752173913043475, "ram_util_percent": 64.58695652173913}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6170555445567643, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.429927762854037, "policy_loss": -0.0028070855240224213, "vf_loss": 9.432227761404855, "vf_explained_var": 0.006130810105611407, "kl": 0.00901523397712533, "entropy": 1.0157475144459458, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.347272715445549, "cur_kl_coeff": 0.005932617187500002, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.62723750210313, "policy_loss": -0.00012371299330085988, "vf_loss": 9.627331394619413, "vf_explained_var": -0.061324895437432345, "kl": 0.005023660109391949, "entropy": 0.33399584058415954, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 2114.943873948009, "episode_reward_min": 456.94516353830517, "episode_reward_mean": 1529.753794388823, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 62.74358624907433, "predator_policy": -24.714583740151596}, "policy_reward_max": {"prey_policy": 851.409908661632, "predator_policy": 668.6847163844506}, "policy_reward_mean": {"prey_policy": 468.9990332966049, "predator_policy": 295.87786389780666}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1805.293705043038, 1890.2312582947688, 1315.9189517250445, 1424.5098778760519, 1375.391984445165, 1493.6433528924063, 1337.628407277703, 1686.9262837156164, 1422.8365728220078, 1195.1387122864219, 1904.1448409783764, 1122.5312171167982, 2107.2214733554, 1604.310832613463, 1404.9006008764295, 1864.8719736899384, 1307.1367597597512, 1105.4817486644986, 1763.105531037722, 1523.259072060163, 2047.6231879867762, 1516.943753064671, 1879.2905013369696, 1594.306783678255, 1939.3852155933123, 1380.7435693371083, 1986.5223567426135, 1813.4885892788295, 1190.9229005037978, 1780.2695945913117, 1839.621891565712, 1087.7446562408159, 1645.8443427816994, 1791.257710755731, 1610.89282943981, 1965.859610499114, 1666.9413862580193, 1774.920047375328, 1919.1715281595605, 1651.837882310778, 1631.6943949153156, 780.0141659434763, 1772.7653694073035, 1736.342500127794, 1347.8982233560985, 1428.1058182209617, 1336.073213219833, 1399.2406437138404, 2045.670163370983, 1780.3556075969816, 1437.7072149834235, 1747.3587544575976, 1129.8194745378826, 2041.7194944572373, 2038.1996689041318, 1600.706366182816, 1112.411394133787, 1959.6074959778048, 1745.462343966526, 1363.5398465948583, 920.7406503522332, 1542.782770338146, 532.1510170699203, 1262.932525232204, 1222.5094347124327, 868.248421302898, 1755.5478887023253, 1900.2119651629205, 1879.3055425507744, 710.1474928644905, 1728.9246376998753, 1158.4072974343671, 966.2337402448677, 2090.2173443479855, 1767.9252038636143, 1593.8430638936522, 1700.9690162513282, 1748.9461523061293, 856.1326873880738, 1857.4784474858227, 1338.029725478549, 1363.0963774224197, 1240.786509164541, 456.94516353830517, 2114.943873948009, 1698.0888623085996, 1257.634975625678, 1749.638013980307, 1613.3185405899314, 1624.2221912612818, 1494.765236669122, 1279.1339212364298, 1185.0968963304572, 1225.177992614753, 537.2475349259154, 1849.3649196325898, 1584.088242615443, 1837.5006879611367, 1320.8790518946419, 1969.001774380474], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [644.4093024244745, 657.7720304248078, 464.13234228372096, 576.7384335450611, 654.6275377664265, 207.0304377284191, 406.8161687228778, 506.1832789964852, 248.2284705722789, 489.8462568681003, 544.7616503654679, 380.41375570933457, 613.2545464468551, 403.733810858525, 578.1740337511987, 629.2198341760907, 268.2851976545439, 531.3945510473271, 351.71105485378735, 428.7422173574272, 535.4695487560065, 399.0652034108258, 374.7252750552332, 646.1835397041217, 392.07246202100487, 851.409908661632, 628.9923756145158, 336.68031853942193, 540.5714583806309, 287.95253848622593, 285.9441630882145, 380.81145652942166, 762.2502518182589, 301.1677118631269, 243.8560489967299, 721.875849399724, 599.7840034403291, 437.65503910230535, 464.0971340123607, 293.73533455348854, 341.2411907448068, 790.1670499962232, 402.0399948136308, 243.455123788184, 506.39670993428695, 491.8361305141937, 360.2807363489309, 486.2870156045869, 540.5144861672658, 722.7944347538017, 482.726510818728, 673.1420976994931, 524.2928643890035, 682.658583679091, 347.63047286936205, 545.6275449509856, 651.6150526535848, 205.44769073252252, 578.1497962353136, 530.7624004285116, 542.9223499199403, 549.0812411458421, 646.6252541443331, 345.14084732077373, 782.4010704650561, 679.5479402386871, 556.4009464664645, 552.0275065255784, 574.3716330561301, 629.2499184401091, 627.8130327571278, 652.6238987133418, 451.00721029430116, 550.9062098194868, 434.9523903523045, 693.9170603708938, 393.51449699443185, 571.254209161879, 344.09449836612634, 275.3316692791353, 419.7631684937533, 323.39793964652023, 233.52841540320603, 376.7450217855635, 404.32509156466705, 348.31095234551833, 408.47602585077294, 384.77664850348646, 236.00827648723666, 614.9318041054718, 282.775081024704, 538.293528643607, 265.21415658648493, 624.2572771068626, 561.5312139893553, 274.34782100197293, 682.8954025879247, 461.1901005371046, 529.1767177959406, 490.4783277139979, 282.41163308727306, 542.6291964457452, 747.679418340005, 536.9007155458987, 200.0, 624.1754671381043, 449.83515972605613, 621.1900371805804, 603.4925401477062, 566.1785994535915, 565.2766107208872, 402.46416558664697, 212.22977298541116, 684.6721844645245, 303.33280662163804, 554.2864480570555, 662.0550400744634, 493.0867216063738, 304.2039947439023, 486.0024519024232, 207.40349968161672, 482.9274153917397, 535.8873979961442, 364.98841112752336, 225.0309291814061, 219.85547171039642, 680.3626352403796, 194.06, 688.4960136985964, 257.95111771413735, 338.8719952279605, 200.0, 360.1366085731501, 62.74358624907433, 268.1613178308926, 509.22628806344005, 306.3776344596858, 557.2498574141231, 242.30655513672414, 362.4998528520568, 408.14270080026665, 363.97230956990995, 219.56559034548746, 548.3913329315105, 347.3789614851975, 449.5017235666455, 534.1994080228551, 418.7756778814808, 406.5216963950792, 532.6930320651936, 352.6336410288529, 537.854437278671, 528.459108154395, 705.4404490888334, 709.3513942766064, 477.2959714069542, 463.3375053301931, 246.91716392876538, 532.9486866454778, 313.41773677715355, 503.68387804930734, 302.24019949175374, 196.04, 608.9017656551382, 658.5154196029141, 207.67439039199715, 208.2592190721444, 234.9905250311953, 573.6463252328998, 535.3684416425458, 422.04704583892976, 685.5200784210753, 673.6722611687222, 258.0324383397429, 495.47620107871325, 675.8611799242632, 479.3293373207156, 627.5887886070124, 463.1122155593512, 716.7097146127687, 398.44392440609164, 620.5898263212882, 236.1276902043177, 588.5576257282404, 250.66928430701293, 666.5570688150805, 356.0772464634595, 815.4265604033283, 216.35478686611626, 297.0267350695568, 485.4124556702767, 511.07468878272147, 519.1342180986252, 393.393650136795, 800.0057369960041, 617.9848478863188, 554.4960372143174, 195.05, 704.4310631070989, 552.4389343308823], "policy_predator_policy_reward": [212.68776248479628, 290.4246097089605, 481.81137274422093, 367.54910972176634, 223.7905175908585, 230.47045863933982, 188.9750135504192, 322.53541660627167, 433.8966934357463, 203.42056356903905, 357.4523770525124, 211.01556976509258, 142.99794771858996, 177.6421022537325, 226.41723542442125, 253.11518036390663, 371.4007902854668, 251.75603383467072, -24.714583740151596, 439.4000238153583, 478.60526607454614, 491.00482273700106, -10.308992995248015, 111.93139535269145, 444.4354542043902, 419.3036484683686, 216.3225527187835, 422.31558574074427, 358.89596233101656, 217.48064167855765, 577.0654896641005, 621.0508644082029, 96.04147554538976, 147.67732053297516, 55.53475355296491, 84.21509671507985, 399.23871892502393, 326.42776957006515, 341.5124010615964, 423.91420243271835, 418.06995055985055, 498.144996685892, 337.299278385486, 534.1493560773683, 474.8430645869822, 406.21459630150974, 434.4207009449221, 313.3183307798171, 290.97949548243633, 385.09679918980936, 42.404990658409574, 182.46997016047868, 392.92130986446546, 386.6495988100541, 497.30449806220986, 422.926073396274, 159.436195096317, 174.42396202137274, 171.0363547911317, 500.3210431363558, 332.2286132027145, 415.38968729721535, 12.43303997616163, 83.54551479954655, 26.700958052494073, 157.19437402546382, 373.9204837182006, 308.90877404548866, 297.44346246104067, 109.82781548253264, 241.8796839350112, 443.54299509363386, 419.5013457434976, 245.5266204007325, 443.38340872902194, 202.66718792310695, 540.08606050957, 414.3167614936783, 490.6442561761622, 541.7674584893546, 549.0906200772877, 339.44266669775544, 67.89062432625019, 101.8501044284567, 518.0102699328434, 502.119055564275, 467.40600517065707, 475.6838206028816, 181.56867000771211, 315.3894727556791, 282.5320465284039, 324.50516202424626, 319.31807147784093, 127.28370804864485, 271.8169928375803, 291.54461588492825, 439.7170407098896, 461.86761953606657, 420.81595610413467, 339.88460598290584, 309.29523277993513, 303.371152670469, 241.98404244976885, 220.79457812192678, 126.06873919255698, 179.57526820722114, 488.3956820675737, 482.29861548302875, 439.53267333979545, 428.99585596303984, 309.9594184916115, 323.0061713836686, 121.37622882235205, 94.1332078615001, 556.9523566067136, 545.0358846923964, 128.0830741664614, 462.2375081192304, 292.35981841147117, 280.9735815370623, 105.97744278031415, 124.43229249856344, 365.8999234064922, 276.00703780798625, 41.46658237711002, 45.798033801007655, 188.1516840505241, 200.3582059412991, 137.32995438744405, 138.7323489122555, 186.99110747242358, 142.38531860251405, 668.6847163844506, 663.9829774956509, 614.7847585339027, 508.0396007346793, 583.9408611785628, 431.737189498403, 39.12672341205636, 66.21436146365345, 532.4160566509579, 424.3935706787411, 190.75052807891143, 199.69984607845777, 157.17776529714067, 12.175289895883854, 601.5680364804002, 535.6742219632495, 569.4719073592973, 259.23856804404704, 348.20042157112954, 355.154564015001, 218.01828602323016, 249.05117298486633, 264.1084861391036, 298.19030048346445, 37.48588448669622, 108.39213364241941, 575.5712554892859, 435.5407685739022, 399.937470771281, 132.1681771662049, 283.83278333804935, 274.3218284292319, 53.52304562292721, 321.07365354670304, -0.03375686009667778, 13.729176295062206, 516.0512370938677, 489.8778699786963, 246.0627519143708, 344.45898613422116, 277.7202686888413, 48.21000742837174, 275.60997876863206, 302.6906542086993, 257.99624060936696, 248.40417405283662, 219.04155629548825, 225.35870479367725, 159.81575998218236, 315.91572595956114, 242.23049841701163, 212.21810688685986, 97.53186135120966, 170.33868185715502, 44.789155836054285, 8.885029911910422, -3.828822735615574, 27.69483572585795, 427.47887363984694, 425.39890153974443, 345.87789965337606, 325.6824747266473, 356.77036454004326, 62.73973853877766, 331.269781968157, 240.06323271216684, 343.4306780827965, 368.70109885969543]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.370648664313419, "mean_inference_ms": 6.225092135433837, "mean_action_processing_ms": 1.0090094085406442, "mean_env_wait_ms": 0.8629570520292824, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.016141057014465332, "StateBufferConnector_ms": 0.007832646369934082, "ViewRequirementAgentConnector_ms": 0.3279144763946533}, "num_episodes": 18, "episode_return_max": 2114.943873948009, "episode_return_min": 456.94516353830517, "episode_return_mean": 1529.753794388823, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 254.7850397168422, "num_env_steps_trained_throughput_per_sec": 254.7850397168422, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 15914.145, "restore_workers_time_ms": 0.013, "training_step_time_ms": 15914.104, "sample_time_ms": 4172.734, "learn_time_ms": 11721.56, "learn_throughput": 341.252, "synch_weights_time_ms": 18.891}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "479e5_00000", "date": "2024-08-16_12-30-51", "timestamp": 1723791651, "time_this_iter_s": 15.703387260437012, "time_total_s": 3841.3185470104218, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a78e5dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3841.3185470104218, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 28.20909090909091, "ram_util_percent": 64.42727272727271}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.100353750034615, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.613753803697213, "policy_loss": -0.002319523781198003, "vf_loss": 9.615552192264133, "vf_explained_var": 0.0016707396381115786, "kl": 0.009264630691338314, "entropy": 0.9475505779344569, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2152859998600825, "cur_kl_coeff": 0.005932617187500002, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.556481820565683, "policy_loss": 0.0011774289281299662, "vf_loss": 9.55527750297829, "vf_explained_var": -0.008413437749973681, "kl": 0.004530383255136454, "entropy": 0.3305394591320129, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 2114.943873948009, "episode_reward_min": 451.13, "episode_reward_mean": 1471.409252202343, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 62.74358624907433, "predator_policy": -5.780310701703625}, "policy_reward_max": {"prey_policy": 835.8308084721718, "predator_policy": 668.6847163844506}, "policy_reward_mean": {"prey_policy": 461.16448008867695, "predator_policy": 274.5401460124948}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1879.2905013369696, 1594.306783678255, 1939.3852155933123, 1380.7435693371083, 1986.5223567426135, 1813.4885892788295, 1190.9229005037978, 1780.2695945913117, 1839.621891565712, 1087.7446562408159, 1645.8443427816994, 1791.257710755731, 1610.89282943981, 1965.859610499114, 1666.9413862580193, 1774.920047375328, 1919.1715281595605, 1651.837882310778, 1631.6943949153156, 780.0141659434763, 1772.7653694073035, 1736.342500127794, 1347.8982233560985, 1428.1058182209617, 1336.073213219833, 1399.2406437138404, 2045.670163370983, 1780.3556075969816, 1437.7072149834235, 1747.3587544575976, 1129.8194745378826, 2041.7194944572373, 2038.1996689041318, 1600.706366182816, 1112.411394133787, 1959.6074959778048, 1745.462343966526, 1363.5398465948583, 920.7406503522332, 1542.782770338146, 532.1510170699203, 1262.932525232204, 1222.5094347124327, 868.248421302898, 1755.5478887023253, 1900.2119651629205, 1879.3055425507744, 710.1474928644905, 1728.9246376998753, 1158.4072974343671, 966.2337402448677, 2090.2173443479855, 1767.9252038636143, 1593.8430638936522, 1700.9690162513282, 1748.9461523061293, 856.1326873880738, 1857.4784474858227, 1338.029725478549, 1363.0963774224197, 1240.786509164541, 456.94516353830517, 2114.943873948009, 1698.0888623085996, 1257.634975625678, 1749.638013980307, 1613.3185405899314, 1624.2221912612818, 1494.765236669122, 1279.1339212364298, 1185.0968963304572, 1225.177992614753, 537.2475349259154, 1849.3649196325898, 1584.088242615443, 1837.5006879611367, 1320.8790518946419, 1969.001774380474, 912.4192593309804, 1385.1070744329247, 2062.886887260176, 1437.1346357352588, 631.9026120084116, 1041.2536967005037, 1981.2770267359729, 1185.9450887074338, 1221.7149128397189, 932.6124187226201, 1892.441681376182, 797.377243257698, 931.8105368324431, 451.13, 1793.4036688668648, 1446.147649477226, 651.4277616927418, 1319.6628278047763, 1789.646508660003, 1657.2250778733926, 1282.4896173380296, 1579.5796932809058], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [506.39670993428695, 491.8361305141937, 360.2807363489309, 486.2870156045869, 540.5144861672658, 722.7944347538017, 482.726510818728, 673.1420976994931, 524.2928643890035, 682.658583679091, 347.63047286936205, 545.6275449509856, 651.6150526535848, 205.44769073252252, 578.1497962353136, 530.7624004285116, 542.9223499199403, 549.0812411458421, 646.6252541443331, 345.14084732077373, 782.4010704650561, 679.5479402386871, 556.4009464664645, 552.0275065255784, 574.3716330561301, 629.2499184401091, 627.8130327571278, 652.6238987133418, 451.00721029430116, 550.9062098194868, 434.9523903523045, 693.9170603708938, 393.51449699443185, 571.254209161879, 344.09449836612634, 275.3316692791353, 419.7631684937533, 323.39793964652023, 233.52841540320603, 376.7450217855635, 404.32509156466705, 348.31095234551833, 408.47602585077294, 384.77664850348646, 236.00827648723666, 614.9318041054718, 282.775081024704, 538.293528643607, 265.21415658648493, 624.2572771068626, 561.5312139893553, 274.34782100197293, 682.8954025879247, 461.1901005371046, 529.1767177959406, 490.4783277139979, 282.41163308727306, 542.6291964457452, 747.679418340005, 536.9007155458987, 200.0, 624.1754671381043, 449.83515972605613, 621.1900371805804, 603.4925401477062, 566.1785994535915, 565.2766107208872, 402.46416558664697, 212.22977298541116, 684.6721844645245, 303.33280662163804, 554.2864480570555, 662.0550400744634, 493.0867216063738, 304.2039947439023, 486.0024519024232, 207.40349968161672, 482.9274153917397, 535.8873979961442, 364.98841112752336, 225.0309291814061, 219.85547171039642, 680.3626352403796, 194.06, 688.4960136985964, 257.95111771413735, 338.8719952279605, 200.0, 360.1366085731501, 62.74358624907433, 268.1613178308926, 509.22628806344005, 306.3776344596858, 557.2498574141231, 242.30655513672414, 362.4998528520568, 408.14270080026665, 363.97230956990995, 219.56559034548746, 548.3913329315105, 347.3789614851975, 449.5017235666455, 534.1994080228551, 418.7756778814808, 406.5216963950792, 532.6930320651936, 352.6336410288529, 537.854437278671, 528.459108154395, 705.4404490888334, 709.3513942766064, 477.2959714069542, 463.3375053301931, 246.91716392876538, 532.9486866454778, 313.41773677715355, 503.68387804930734, 302.24019949175374, 196.04, 608.9017656551382, 658.5154196029141, 207.67439039199715, 208.2592190721444, 234.9905250311953, 573.6463252328998, 535.3684416425458, 422.04704583892976, 685.5200784210753, 673.6722611687222, 258.0324383397429, 495.47620107871325, 675.8611799242632, 479.3293373207156, 627.5887886070124, 463.1122155593512, 716.7097146127687, 398.44392440609164, 620.5898263212882, 236.1276902043177, 588.5576257282404, 250.66928430701293, 666.5570688150805, 356.0772464634595, 815.4265604033283, 216.35478686611626, 297.0267350695568, 485.4124556702767, 511.07468878272147, 519.1342180986252, 393.393650136795, 800.0057369960041, 617.9848478863188, 554.4960372143174, 195.05, 704.4310631070989, 552.4389343308823, 575.3712140261376, 257.373281130018, 497.5460806687694, 458.2032554477556, 392.6309778605583, 546.5197969110867, 538.4662373859013, 512.499706337997, 367.54491417742173, 208.2623389912032, 394.33158451846595, 443.57599883997926, 526.0758228266384, 538.0773252077211, 319.3435825589637, 443.5897843243742, 451.23351465379534, 762.3104032891773, 225.70146100847938, 298.52683815555656, 400.57982563744616, 678.0939695544175, 472.6321768118428, 210.52662208952293, 338.2705114269261, 218.9213750953965, 202.11353561380517, 252.31885615010702, 491.70930809091476, 766.5685401487481, 212.82169101007872, 396.9991679976537, 250.66881501320375, 320.75209112190936, 254.29367252834237, 583.9856358675066, 835.8308084721718, 644.0150458115422, 536.5413140696284, 639.5887044088255, 545.1211553573809, 232.22371331484695, 396.812119781338, 641.194477050499], "policy_predator_policy_reward": [474.8430645869822, 406.21459630150974, 434.4207009449221, 313.3183307798171, 290.97949548243633, 385.09679918980936, 42.404990658409574, 182.46997016047868, 392.92130986446546, 386.6495988100541, 497.30449806220986, 422.926073396274, 159.436195096317, 174.42396202137274, 171.0363547911317, 500.3210431363558, 332.2286132027145, 415.38968729721535, 12.43303997616163, 83.54551479954655, 26.700958052494073, 157.19437402546382, 373.9204837182006, 308.90877404548866, 297.44346246104067, 109.82781548253264, 241.8796839350112, 443.54299509363386, 419.5013457434976, 245.5266204007325, 443.38340872902194, 202.66718792310695, 540.08606050957, 414.3167614936783, 490.6442561761622, 541.7674584893546, 549.0906200772877, 339.44266669775544, 67.89062432625019, 101.8501044284567, 518.0102699328434, 502.119055564275, 467.40600517065707, 475.6838206028816, 181.56867000771211, 315.3894727556791, 282.5320465284039, 324.50516202424626, 319.31807147784093, 127.28370804864485, 271.8169928375803, 291.54461588492825, 439.7170407098896, 461.86761953606657, 420.81595610413467, 339.88460598290584, 309.29523277993513, 303.371152670469, 241.98404244976885, 220.79457812192678, 126.06873919255698, 179.57526820722114, 488.3956820675737, 482.29861548302875, 439.53267333979545, 428.99585596303984, 309.9594184916115, 323.0061713836686, 121.37622882235205, 94.1332078615001, 556.9523566067136, 545.0358846923964, 128.0830741664614, 462.2375081192304, 292.35981841147117, 280.9735815370623, 105.97744278031415, 124.43229249856344, 365.8999234064922, 276.00703780798625, 41.46658237711002, 45.798033801007655, 188.1516840505241, 200.3582059412991, 137.32995438744405, 138.7323489122555, 186.99110747242358, 142.38531860251405, 668.6847163844506, 663.9829774956509, 614.7847585339027, 508.0396007346793, 583.9408611785628, 431.737189498403, 39.12672341205636, 66.21436146365345, 532.4160566509579, 424.3935706787411, 190.75052807891143, 199.69984607845777, 157.17776529714067, 12.175289895883854, 601.5680364804002, 535.6742219632495, 569.4719073592973, 259.23856804404704, 348.20042157112954, 355.154564015001, 218.01828602323016, 249.05117298486633, 264.1084861391036, 298.19030048346445, 37.48588448669622, 108.39213364241941, 575.5712554892859, 435.5407685739022, 399.937470771281, 132.1681771662049, 283.83278333804935, 274.3218284292319, 53.52304562292721, 321.07365354670304, -0.03375686009667778, 13.729176295062206, 516.0512370938677, 489.8778699786963, 246.0627519143708, 344.45898613422116, 277.7202686888413, 48.21000742837174, 275.60997876863206, 302.6906542086993, 257.99624060936696, 248.40417405283662, 219.04155629548825, 225.35870479367725, 159.81575998218236, 315.91572595956114, 242.23049841701163, 212.21810688685986, 97.53186135120966, 170.33868185715502, 44.789155836054285, 8.885029911910422, -3.828822735615574, 27.69483572585795, 427.47887363984694, 425.39890153974443, 345.87789965337606, 325.6824747266473, 356.77036454004326, 62.73973853877766, 331.269781968157, 240.06323271216684, 343.4306780827965, 368.70109885969543, 43.3503945849695, 36.3243695898556, 219.4845569217187, 209.8731813946819, 572.2338651013224, 551.5022473872085, 196.67823037005206, 189.49046164130706, 36.464853095682585, 19.63050574410377, 95.4226931467582, 107.92342019530118, 431.890374459053, 485.23350424255733, 297.7999523891123, 125.21176943498334, 13.951305598448162, -5.780310701703625, 177.52059323820424, 230.86352632038, 379.3806787888162, 434.3872073955029, 61.294877406422096, 52.923566949911006, 119.5486227695863, 255.0700275405345, -3.8562335811064212, 0.553841817194261, 316.30035306999775, 218.8254675572021, 494.97834434082506, 341.34844612867033, 44.504712532389036, 35.502143025239754, 261.4196256516744, 219.96389375725198, 128.17097062687924, 181.62968374940925, 263.0827260439837, 218.0123333509575, 59.5536351327957, 445.59111353300375, 248.60164021408863, 292.97145623498324]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3678731855716073, "mean_inference_ms": 6.217662351373989, "mean_action_processing_ms": 1.007723106324213, "mean_env_wait_ms": 0.8616375165101451, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014644622802734375, "StateBufferConnector_ms": 0.007534384727478027, "ViewRequirementAgentConnector_ms": 0.3034994602203369}, "num_episodes": 22, "episode_return_max": 2114.943873948009, "episode_return_min": 451.13, "episode_return_mean": 1471.409252202343, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 256.16340110503836, "num_env_steps_trained_throughput_per_sec": 256.16340110503836, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 15943.963, "restore_workers_time_ms": 0.013, "training_step_time_ms": 15943.921, "sample_time_ms": 4166.191, "learn_time_ms": 11757.433, "learn_throughput": 340.21, "synch_weights_time_ms": 19.391}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "479e5_00000", "date": "2024-08-16_12-31-06", "timestamp": 1723791666, "time_this_iter_s": 15.621618032455444, "time_total_s": 3856.940165042877, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab270700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3856.940165042877, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 27.839130434782607, "ram_util_percent": 63.5695652173913}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.112564505597271, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.380422475602892, "policy_loss": -0.00373018068993198, "vf_loss": 9.383583524492051, "vf_explained_var": 0.047033461218788514, "kl": 0.01011812196963048, "entropy": 0.9682507814238311, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8839191815840506, "cur_kl_coeff": 0.002966308593750001, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.336112694513231, "policy_loss": 0.006453295225873786, "vf_loss": 9.329588258834113, "vf_explained_var": 0.0195562827524054, "kl": 0.02398273004024187, "entropy": 0.31913954666051914, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 2136.5051540966147, "episode_reward_min": 451.13, "episode_reward_mean": 1441.7835100609645, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 62.74358624907433, "predator_policy": -12.453881181990045}, "policy_reward_max": {"prey_policy": 835.8308084721718, "predator_policy": 668.6847163844506}, "policy_reward_mean": {"prey_policy": 450.9159460325095, "predator_policy": 269.975808997973}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1631.6943949153156, 780.0141659434763, 1772.7653694073035, 1736.342500127794, 1347.8982233560985, 1428.1058182209617, 1336.073213219833, 1399.2406437138404, 2045.670163370983, 1780.3556075969816, 1437.7072149834235, 1747.3587544575976, 1129.8194745378826, 2041.7194944572373, 2038.1996689041318, 1600.706366182816, 1112.411394133787, 1959.6074959778048, 1745.462343966526, 1363.5398465948583, 920.7406503522332, 1542.782770338146, 532.1510170699203, 1262.932525232204, 1222.5094347124327, 868.248421302898, 1755.5478887023253, 1900.2119651629205, 1879.3055425507744, 710.1474928644905, 1728.9246376998753, 1158.4072974343671, 966.2337402448677, 2090.2173443479855, 1767.9252038636143, 1593.8430638936522, 1700.9690162513282, 1748.9461523061293, 856.1326873880738, 1857.4784474858227, 1338.029725478549, 1363.0963774224197, 1240.786509164541, 456.94516353830517, 2114.943873948009, 1698.0888623085996, 1257.634975625678, 1749.638013980307, 1613.3185405899314, 1624.2221912612818, 1494.765236669122, 1279.1339212364298, 1185.0968963304572, 1225.177992614753, 537.2475349259154, 1849.3649196325898, 1584.088242615443, 1837.5006879611367, 1320.8790518946419, 1969.001774380474, 912.4192593309804, 1385.1070744329247, 2062.886887260176, 1437.1346357352588, 631.9026120084116, 1041.2536967005037, 1981.2770267359729, 1185.9450887074338, 1221.7149128397189, 932.6124187226201, 1892.441681376182, 797.377243257698, 931.8105368324431, 451.13, 1793.4036688668648, 1446.147649477226, 651.4277616927418, 1319.6628278047763, 1789.646508660003, 1657.2250778733926, 1282.4896173380296, 1579.5796932809058, 1837.7942200890154, 1256.5753572853962, 1144.4471444004685, 1955.346871526047, 1970.4399473540693, 2136.5051540966147, 1258.3516671780142, 1264.0606639683115, 1448.57754042528, 1340.9014089025382, 1275.8340052566375, 1358.4277707521774, 1848.1919701775819, 1327.5597447638343, 1497.74153923291, 1928.2000405323624, 800.9375327577623, 1906.5546036119065], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [419.7631684937533, 323.39793964652023, 233.52841540320603, 376.7450217855635, 404.32509156466705, 348.31095234551833, 408.47602585077294, 384.77664850348646, 236.00827648723666, 614.9318041054718, 282.775081024704, 538.293528643607, 265.21415658648493, 624.2572771068626, 561.5312139893553, 274.34782100197293, 682.8954025879247, 461.1901005371046, 529.1767177959406, 490.4783277139979, 282.41163308727306, 542.6291964457452, 747.679418340005, 536.9007155458987, 200.0, 624.1754671381043, 449.83515972605613, 621.1900371805804, 603.4925401477062, 566.1785994535915, 565.2766107208872, 402.46416558664697, 212.22977298541116, 684.6721844645245, 303.33280662163804, 554.2864480570555, 662.0550400744634, 493.0867216063738, 304.2039947439023, 486.0024519024232, 207.40349968161672, 482.9274153917397, 535.8873979961442, 364.98841112752336, 225.0309291814061, 219.85547171039642, 680.3626352403796, 194.06, 688.4960136985964, 257.95111771413735, 338.8719952279605, 200.0, 360.1366085731501, 62.74358624907433, 268.1613178308926, 509.22628806344005, 306.3776344596858, 557.2498574141231, 242.30655513672414, 362.4998528520568, 408.14270080026665, 363.97230956990995, 219.56559034548746, 548.3913329315105, 347.3789614851975, 449.5017235666455, 534.1994080228551, 418.7756778814808, 406.5216963950792, 532.6930320651936, 352.6336410288529, 537.854437278671, 528.459108154395, 705.4404490888334, 709.3513942766064, 477.2959714069542, 463.3375053301931, 246.91716392876538, 532.9486866454778, 313.41773677715355, 503.68387804930734, 302.24019949175374, 196.04, 608.9017656551382, 658.5154196029141, 207.67439039199715, 208.2592190721444, 234.9905250311953, 573.6463252328998, 535.3684416425458, 422.04704583892976, 685.5200784210753, 673.6722611687222, 258.0324383397429, 495.47620107871325, 675.8611799242632, 479.3293373207156, 627.5887886070124, 463.1122155593512, 716.7097146127687, 398.44392440609164, 620.5898263212882, 236.1276902043177, 588.5576257282404, 250.66928430701293, 666.5570688150805, 356.0772464634595, 815.4265604033283, 216.35478686611626, 297.0267350695568, 485.4124556702767, 511.07468878272147, 519.1342180986252, 393.393650136795, 800.0057369960041, 617.9848478863188, 554.4960372143174, 195.05, 704.4310631070989, 552.4389343308823, 575.3712140261376, 257.373281130018, 497.5460806687694, 458.2032554477556, 392.6309778605583, 546.5197969110867, 538.4662373859013, 512.499706337997, 367.54491417742173, 208.2623389912032, 394.33158451846595, 443.57599883997926, 526.0758228266384, 538.0773252077211, 319.3435825589637, 443.5897843243742, 451.23351465379534, 762.3104032891773, 225.70146100847938, 298.52683815555656, 400.57982563744616, 678.0939695544175, 472.6321768118428, 210.52662208952293, 338.2705114269261, 218.9213750953965, 202.11353561380517, 252.31885615010702, 491.70930809091476, 766.5685401487481, 212.82169101007872, 396.9991679976537, 250.66881501320375, 320.75209112190936, 254.29367252834237, 583.9856358675066, 835.8308084721718, 644.0150458115422, 536.5413140696284, 639.5887044088255, 545.1211553573809, 232.22371331484695, 396.812119781338, 641.194477050499, 733.7423666202202, 675.1766406326618, 718.8845835348997, 275.4717531993415, 260.97908537771434, 717.1757849795866, 708.4859037947424, 592.4133496549896, 472.8430754523161, 622.6501409228616, 449.6148275426731, 693.716818803165, 218.95083292762595, 613.8322391174529, 436.5639960118233, 366.1858753859105, 521.3024334079072, 337.1629955312235, 357.15165697140975, 600.3391140779507, 198.1403520309646, 585.2354364540645, 610.9931210985465, 236.63503571173834, 573.690916217225, 513.0655574748026, 444.7064497999607, 233.60277798129692, 203.04585164225517, 562.0536352150195, 524.8632165933702, 456.73658553120123, 258.7422508034535, 484.35930763558287, 428.1975010383799, 446.9276312037838], "policy_predator_policy_reward": [549.0906200772877, 339.44266669775544, 67.89062432625019, 101.8501044284567, 518.0102699328434, 502.119055564275, 467.40600517065707, 475.6838206028816, 181.56867000771211, 315.3894727556791, 282.5320465284039, 324.50516202424626, 319.31807147784093, 127.28370804864485, 271.8169928375803, 291.54461588492825, 439.7170407098896, 461.86761953606657, 420.81595610413467, 339.88460598290584, 309.29523277993513, 303.371152670469, 241.98404244976885, 220.79457812192678, 126.06873919255698, 179.57526820722114, 488.3956820675737, 482.29861548302875, 439.53267333979545, 428.99585596303984, 309.9594184916115, 323.0061713836686, 121.37622882235205, 94.1332078615001, 556.9523566067136, 545.0358846923964, 128.0830741664614, 462.2375081192304, 292.35981841147117, 280.9735815370623, 105.97744278031415, 124.43229249856344, 365.8999234064922, 276.00703780798625, 41.46658237711002, 45.798033801007655, 188.1516840505241, 200.3582059412991, 137.32995438744405, 138.7323489122555, 186.99110747242358, 142.38531860251405, 668.6847163844506, 663.9829774956509, 614.7847585339027, 508.0396007346793, 583.9408611785628, 431.737189498403, 39.12672341205636, 66.21436146365345, 532.4160566509579, 424.3935706787411, 190.75052807891143, 199.69984607845777, 157.17776529714067, 12.175289895883854, 601.5680364804002, 535.6742219632495, 569.4719073592973, 259.23856804404704, 348.20042157112954, 355.154564015001, 218.01828602323016, 249.05117298486633, 264.1084861391036, 298.19030048346445, 37.48588448669622, 108.39213364241941, 575.5712554892859, 435.5407685739022, 399.937470771281, 132.1681771662049, 283.83278333804935, 274.3218284292319, 53.52304562292721, 321.07365354670304, -0.03375686009667778, 13.729176295062206, 516.0512370938677, 489.8778699786963, 246.0627519143708, 344.45898613422116, 277.7202686888413, 48.21000742837174, 275.60997876863206, 302.6906542086993, 257.99624060936696, 248.40417405283662, 219.04155629548825, 225.35870479367725, 159.81575998218236, 315.91572595956114, 242.23049841701163, 212.21810688685986, 97.53186135120966, 170.33868185715502, 44.789155836054285, 8.885029911910422, -3.828822735615574, 27.69483572585795, 427.47887363984694, 425.39890153974443, 345.87789965337606, 325.6824747266473, 356.77036454004326, 62.73973853877766, 331.269781968157, 240.06323271216684, 343.4306780827965, 368.70109885969543, 43.3503945849695, 36.3243695898556, 219.4845569217187, 209.8731813946819, 572.2338651013224, 551.5022473872085, 196.67823037005206, 189.49046164130706, 36.464853095682585, 19.63050574410377, 95.4226931467582, 107.92342019530118, 431.890374459053, 485.23350424255733, 297.7999523891123, 125.21176943498334, 13.951305598448162, -5.780310701703625, 177.52059323820424, 230.86352632038, 379.3806787888162, 434.3872073955029, 61.294877406422096, 52.923566949911006, 119.5486227695863, 255.0700275405345, -3.8562335811064212, 0.553841817194261, 316.30035306999775, 218.8254675572021, 494.97834434082506, 341.34844612867033, 44.504712532389036, 35.502143025239754, 261.4196256516744, 219.96389375725198, 128.17097062687924, 181.62968374940925, 263.0827260439837, 218.0123333509575, 59.5536351327957, 445.59111353300375, 248.60164021408863, 292.97145623498324, 91.31055018473057, 337.56466265140324, 195.53217742412426, 66.68684312703357, 24.440706562074716, 141.85156748109333, 331.3913709518939, 323.05624712442193, 455.4084714735259, 419.5382595053678, 480.3515556234259, 512.8219521273494, 287.0643401909464, 138.5042549419906, 239.44899209166726, 221.86180047890986, 225.75583329086734, 364.3562781952824, -12.453881181990045, 395.8645190351677, 234.4421672273992, 258.01604954420844, 263.94218298160314, 246.85743096029157, 371.2337509199344, 390.20174556561966, 442.9970116940097, 206.2535052885665, 372.55645450036144, 360.08559787527406, 525.678459269041, 420.92177913875037, 20.305288502145878, 37.53068581658011, 573.0336611931948, 458.395810176548]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.365879170242203, "mean_inference_ms": 6.210831921588879, "mean_action_processing_ms": 1.0066870172445543, "mean_env_wait_ms": 0.8601090315692761, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010953545570373535, "StateBufferConnector_ms": 0.00995171070098877, "ViewRequirementAgentConnector_ms": 0.3160775899887085}, "num_episodes": 18, "episode_return_max": 2136.5051540966147, "episode_return_min": 451.13, "episode_return_mean": 1441.7835100609645, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 244.42870853616174, "num_env_steps_trained_throughput_per_sec": 244.42870853616174, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 16090.43, "restore_workers_time_ms": 0.013, "training_step_time_ms": 16090.389, "sample_time_ms": 4161.776, "learn_time_ms": 11908.637, "learn_throughput": 335.891, "synch_weights_time_ms": 19.072}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "479e5_00000", "date": "2024-08-16_12-31-23", "timestamp": 1723791683, "time_this_iter_s": 16.36864423751831, "time_total_s": 3873.3088092803955, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7fb0430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3873.3088092803955, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 30.23913043478262, "ram_util_percent": 63.939130434782626}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4823048783042445, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.610160658094618, "policy_loss": 0.00018957672251398286, "vf_loss": 9.609640408066845, "vf_explained_var": 0.031746976053903975, "kl": 0.0058785788190696756, "entropy": 0.9542875014284932, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5397638974839416, "cur_kl_coeff": 0.004449462890624998, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.474707265379568, "policy_loss": 0.0014855930975899495, "vf_loss": 9.473188228203506, "vf_explained_var": 0.025181879000688988, "kl": 0.007512698385990571, "entropy": 0.33272987525299114, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 2138.4363677341416, "episode_reward_min": 451.13, "episode_reward_mean": 1441.9972762873801, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 62.74358624907433, "predator_policy": -12.453881181990045}, "policy_reward_max": {"prey_policy": 835.8308084721718, "predator_policy": 668.6847163844506}, "policy_reward_mean": {"prey_policy": 458.15527213660187, "predator_policy": 262.8433660070882}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1262.932525232204, 1222.5094347124327, 868.248421302898, 1755.5478887023253, 1900.2119651629205, 1879.3055425507744, 710.1474928644905, 1728.9246376998753, 1158.4072974343671, 966.2337402448677, 2090.2173443479855, 1767.9252038636143, 1593.8430638936522, 1700.9690162513282, 1748.9461523061293, 856.1326873880738, 1857.4784474858227, 1338.029725478549, 1363.0963774224197, 1240.786509164541, 456.94516353830517, 2114.943873948009, 1698.0888623085996, 1257.634975625678, 1749.638013980307, 1613.3185405899314, 1624.2221912612818, 1494.765236669122, 1279.1339212364298, 1185.0968963304572, 1225.177992614753, 537.2475349259154, 1849.3649196325898, 1584.088242615443, 1837.5006879611367, 1320.8790518946419, 1969.001774380474, 912.4192593309804, 1385.1070744329247, 2062.886887260176, 1437.1346357352588, 631.9026120084116, 1041.2536967005037, 1981.2770267359729, 1185.9450887074338, 1221.7149128397189, 932.6124187226201, 1892.441681376182, 797.377243257698, 931.8105368324431, 451.13, 1793.4036688668648, 1446.147649477226, 651.4277616927418, 1319.6628278047763, 1789.646508660003, 1657.2250778733926, 1282.4896173380296, 1579.5796932809058, 1837.7942200890154, 1256.5753572853962, 1144.4471444004685, 1955.346871526047, 1970.4399473540693, 2136.5051540966147, 1258.3516671780142, 1264.0606639683115, 1448.57754042528, 1340.9014089025382, 1275.8340052566375, 1358.4277707521774, 1848.1919701775819, 1327.5597447638343, 1497.74153923291, 1928.2000405323624, 800.9375327577623, 1906.5546036119065, 2138.4363677341416, 2050.567484382431, 1889.927313017242, 1241.0645364671932, 1092.0192191493015, 1428.4288859361202, 836.253286668014, 1697.9434257338874, 1461.0510954986464, 1373.265141222725, 1482.7142906849056, 1657.916381839765, 1523.2443528605143, 1715.9845571199348, 1645.3484551858044, 1948.4444451157024, 1508.1370798072378, 1627.8029745964711, 1220.324260073727, 865.4903963019212, 1355.086728476698, 1193.685702094861, 1498.606834503222], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [680.3626352403796, 194.06, 688.4960136985964, 257.95111771413735, 338.8719952279605, 200.0, 360.1366085731501, 62.74358624907433, 268.1613178308926, 509.22628806344005, 306.3776344596858, 557.2498574141231, 242.30655513672414, 362.4998528520568, 408.14270080026665, 363.97230956990995, 219.56559034548746, 548.3913329315105, 347.3789614851975, 449.5017235666455, 534.1994080228551, 418.7756778814808, 406.5216963950792, 532.6930320651936, 352.6336410288529, 537.854437278671, 528.459108154395, 705.4404490888334, 709.3513942766064, 477.2959714069542, 463.3375053301931, 246.91716392876538, 532.9486866454778, 313.41773677715355, 503.68387804930734, 302.24019949175374, 196.04, 608.9017656551382, 658.5154196029141, 207.67439039199715, 208.2592190721444, 234.9905250311953, 573.6463252328998, 535.3684416425458, 422.04704583892976, 685.5200784210753, 673.6722611687222, 258.0324383397429, 495.47620107871325, 675.8611799242632, 479.3293373207156, 627.5887886070124, 463.1122155593512, 716.7097146127687, 398.44392440609164, 620.5898263212882, 236.1276902043177, 588.5576257282404, 250.66928430701293, 666.5570688150805, 356.0772464634595, 815.4265604033283, 216.35478686611626, 297.0267350695568, 485.4124556702767, 511.07468878272147, 519.1342180986252, 393.393650136795, 800.0057369960041, 617.9848478863188, 554.4960372143174, 195.05, 704.4310631070989, 552.4389343308823, 575.3712140261376, 257.373281130018, 497.5460806687694, 458.2032554477556, 392.6309778605583, 546.5197969110867, 538.4662373859013, 512.499706337997, 367.54491417742173, 208.2623389912032, 394.33158451846595, 443.57599883997926, 526.0758228266384, 538.0773252077211, 319.3435825589637, 443.5897843243742, 451.23351465379534, 762.3104032891773, 225.70146100847938, 298.52683815555656, 400.57982563744616, 678.0939695544175, 472.6321768118428, 210.52662208952293, 338.2705114269261, 218.9213750953965, 202.11353561380517, 252.31885615010702, 491.70930809091476, 766.5685401487481, 212.82169101007872, 396.9991679976537, 250.66881501320375, 320.75209112190936, 254.29367252834237, 583.9856358675066, 835.8308084721718, 644.0150458115422, 536.5413140696284, 639.5887044088255, 545.1211553573809, 232.22371331484695, 396.812119781338, 641.194477050499, 733.7423666202202, 675.1766406326618, 718.8845835348997, 275.4717531993415, 260.97908537771434, 717.1757849795866, 708.4859037947424, 592.4133496549896, 472.8430754523161, 622.6501409228616, 449.6148275426731, 693.716818803165, 218.95083292762595, 613.8322391174529, 436.5639960118233, 366.1858753859105, 521.3024334079072, 337.1629955312235, 357.15165697140975, 600.3391140779507, 198.1403520309646, 585.2354364540645, 610.9931210985465, 236.63503571173834, 573.690916217225, 513.0655574748026, 444.7064497999607, 233.60277798129692, 203.04585164225517, 562.0536352150195, 524.8632165933702, 456.73658553120123, 258.7422508034535, 484.35930763558287, 428.1975010383799, 446.9276312037838, 511.8381803555176, 781.2167145381326, 495.518591526443, 693.3837176524635, 667.7983489932869, 378.930153827648, 642.7982672278132, 196.04, 298.5397627122255, 610.330466382131, 603.7463736443956, 233.5719455928666, 570.722625850155, 221.11057463973373, 449.9513522603817, 458.34468907691223, 591.3267575547164, 239.07759429543498, 475.74476677697714, 224.67986973025918, 668.9062420010108, 577.4216866947594, 301.2831475959446, 522.4632215387113, 500.8189869533726, 696.5999846700131, 554.9069899541411, 528.9172802292463, 629.0323971121971, 569.2627492163067, 595.156830557766, 626.5458938912308, 637.5968451703036, 369.56661275549664, 459.5604679462228, 178.0070999841742, 714.9987539788968, 256.7116090677432, 465.940734307436, 202.85588016289074, 197.03, 517.7408349749901, 791.9524775777844, 235.73777692686218, 425.88511688588227, 216.91390811884312], "policy_predator_policy_reward": [188.1516840505241, 200.3582059412991, 137.32995438744405, 138.7323489122555, 186.99110747242358, 142.38531860251405, 668.6847163844506, 663.9829774956509, 614.7847585339027, 508.0396007346793, 583.9408611785628, 431.737189498403, 39.12672341205636, 66.21436146365345, 532.4160566509579, 424.3935706787411, 190.75052807891143, 199.69984607845777, 157.17776529714067, 12.175289895883854, 601.5680364804002, 535.6742219632495, 569.4719073592973, 259.23856804404704, 348.20042157112954, 355.154564015001, 218.01828602323016, 249.05117298486633, 264.1084861391036, 298.19030048346445, 37.48588448669622, 108.39213364241941, 575.5712554892859, 435.5407685739022, 399.937470771281, 132.1681771662049, 283.83278333804935, 274.3218284292319, 53.52304562292721, 321.07365354670304, -0.03375686009667778, 13.729176295062206, 516.0512370938677, 489.8778699786963, 246.0627519143708, 344.45898613422116, 277.7202686888413, 48.21000742837174, 275.60997876863206, 302.6906542086993, 257.99624060936696, 248.40417405283662, 219.04155629548825, 225.35870479367725, 159.81575998218236, 315.91572595956114, 242.23049841701163, 212.21810688685986, 97.53186135120966, 170.33868185715502, 44.789155836054285, 8.885029911910422, -3.828822735615574, 27.69483572585795, 427.47887363984694, 425.39890153974443, 345.87789965337606, 325.6824747266473, 356.77036454004326, 62.73973853877766, 331.269781968157, 240.06323271216684, 343.4306780827965, 368.70109885969543, 43.3503945849695, 36.3243695898556, 219.4845569217187, 209.8731813946819, 572.2338651013224, 551.5022473872085, 196.67823037005206, 189.49046164130706, 36.464853095682585, 19.63050574410377, 95.4226931467582, 107.92342019530118, 431.890374459053, 485.23350424255733, 297.7999523891123, 125.21176943498334, 13.951305598448162, -5.780310701703625, 177.52059323820424, 230.86352632038, 379.3806787888162, 434.3872073955029, 61.294877406422096, 52.923566949911006, 119.5486227695863, 255.0700275405345, -3.8562335811064212, 0.553841817194261, 316.30035306999775, 218.8254675572021, 494.97834434082506, 341.34844612867033, 44.504712532389036, 35.502143025239754, 261.4196256516744, 219.96389375725198, 128.17097062687924, 181.62968374940925, 263.0827260439837, 218.0123333509575, 59.5536351327957, 445.59111353300375, 248.60164021408863, 292.97145623498324, 91.31055018473057, 337.56466265140324, 195.53217742412426, 66.68684312703357, 24.440706562074716, 141.85156748109333, 331.3913709518939, 323.05624712442193, 455.4084714735259, 419.5382595053678, 480.3515556234259, 512.8219521273494, 287.0643401909464, 138.5042549419906, 239.44899209166726, 221.86180047890986, 225.75583329086734, 364.3562781952824, -12.453881181990045, 395.8645190351677, 234.4421672273992, 258.01604954420844, 263.94218298160314, 246.85743096029157, 371.2337509199344, 390.20174556561966, 442.9970116940097, 206.2535052885665, 372.55645450036144, 360.08559787527406, 525.678459269041, 420.92177913875037, 20.305288502145878, 37.53068581658011, 573.0336611931948, 458.395810176548, 407.6537420584135, 437.72773078207535, 426.24725661402425, 435.4179185895012, 401.31509981323853, 441.88371038306843, 311.62942500439135, 90.59684423498905, 102.62506929033707, 80.52392076460815, 268.3024490385479, 322.80811766030854, -9.045437384704453, 53.46552356283027, 203.1635965083866, 586.4837878882114, 314.82964116912746, 315.8171024793657, 473.12779372597345, 199.71271098951357, 114.092635008096, 122.29372698104378, 175.02918591311922, 659.1408267919885, 99.74061524135195, 226.08476599577722, 211.47070291313426, 420.6895840234144, 230.0934426462959, 216.95986621100414, 279.7550801677606, 446.9866404989453, 265.47817629504203, 235.4954455863951, 452.685180330824, 537.5502263352512, 28.482651005983996, 220.13124602110324, 76.90902268117483, 119.78475915042057, 272.8383283369046, 367.4775651648035, 143.6587990978016, 22.336648492412024, 451.6928640216922, 404.11494547679996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.363022117874842, "mean_inference_ms": 6.202704993152886, "mean_action_processing_ms": 1.0057582533013776, "mean_env_wait_ms": 0.8578656045679675, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010127902030944824, "StateBufferConnector_ms": 0.012055158615112305, "ViewRequirementAgentConnector_ms": 0.33118247985839844}, "num_episodes": 23, "episode_return_max": 2138.4363677341416, "episode_return_min": 451.13, "episode_return_mean": 1441.9972762873801, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 259.9095857191831, "num_env_steps_trained_throughput_per_sec": 259.9095857191831, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 16054.307, "restore_workers_time_ms": 0.013, "training_step_time_ms": 16054.266, "sample_time_ms": 4139.112, "learn_time_ms": 11895.343, "learn_throughput": 336.266, "synch_weights_time_ms": 18.944}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": true, "training_iteration": 100, "trial_id": "479e5_00000", "date": "2024-08-16_12-31-38", "timestamp": 1723791698, "time_this_iter_s": 15.395893812179565, "time_total_s": 3888.704703092575, "pid": 29582, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a7fe23a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3888.704703092575, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 27.74545454545455, "ram_util_percent": 64.49999999999999}}
