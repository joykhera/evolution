{"num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 137.74403931982167, "num_env_steps_trained_throughput_per_sec": 137.74403931982167, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "training_iteration": 100, "timestamp": 1724313493, "time_this_iter_s": 29.082139015197754, "time_total_s": 2851.6235399246216, "time_since_restore": 2851.6235399246216, "iterations_since_restore": 100, "info/num_env_steps_sampled": 400000, "info/num_env_steps_trained": 400000, "info/num_agent_steps_sampled": 1600000, "info/num_agent_steps_trained": 1600000, "env_runners/episode_reward_max": 920.9710588120797, "env_runners/episode_reward_min": -199.8915541431219, "env_runners/episode_reward_mean": 173.52493963499856, "env_runners/episode_len_mean": 400.0, "env_runners/episodes_timesteps_total": 40000, "env_runners/num_faulty_episodes": 0, "env_runners/num_episodes": 7, "env_runners/episode_return_max": 920.9710588120797, "env_runners/episode_return_min": -199.8915541431219, "env_runners/episode_return_mean": 173.52493963499856, "env_runners/episodes_this_iter": 7, "timers/training_iteration_time_ms": 29554.081, "timers/restore_workers_time_ms": 0.135, "timers/training_step_time_ms": 29553.68, "timers/sample_time_ms": 3921.447, "timers/learn_time_ms": 25589.362, "timers/learn_throughput": 156.315, "timers/synch_weights_time_ms": 37.389, "counters/num_env_steps_sampled": 400000, "counters/num_env_steps_trained": 400000, "counters/num_agent_steps_sampled": 1600000, "counters/num_agent_steps_trained": 1600000, "perf/cpu_util_percent": 45.27560975609756, "perf/ram_util_percent": 83.14390243902439, "info/learner/prey_policy/num_agent_steps_trained": 126.98412698412699, "info/learner/prey_policy/num_grad_updates_lifetime": 94028.0, "info/learner/prey_policy/diff_num_grad_updates_vs_sampler_policy": 482.3950000000041, "info/learner/predator_policy/num_agent_steps_trained": 126.98412698412699, "info/learner/predator_policy/num_grad_updates_lifetime": 94028.0, "info/learner/predator_policy/diff_num_grad_updates_vs_sampler_policy": 482.3950000000041, "info/learner/prey_policy/learner_stats/allreduce_latency": 0.0, "info/learner/prey_policy/learner_stats/grad_gnorm": 31.045182310336482, "info/learner/prey_policy/learner_stats/cur_kl_coeff": 0.14999999999999997, "info/learner/prey_policy/learner_stats/cur_lr": 0.00010000000000000003, "info/learner/prey_policy/learner_stats/total_loss": 6.110952478237253, "info/learner/prey_policy/learner_stats/policy_loss": -0.008465230571864931, "info/learner/prey_policy/learner_stats/vf_loss": 6.118179486289857, "info/learner/prey_policy/learner_stats/vf_explained_var": 0.46979324729354294, "info/learner/prey_policy/learner_stats/kl": 0.008254694894803738, "info/learner/prey_policy/learner_stats/entropy": 0.5831502323428159, "info/learner/prey_policy/learner_stats/entropy_coeff": 0.0, "info/learner/predator_policy/learner_stats/allreduce_latency": 0.0, "info/learner/predator_policy/learner_stats/grad_gnorm": 25.856191210267404, "info/learner/predator_policy/learner_stats/cur_kl_coeff": 0.025, "info/learner/predator_policy/learner_stats/cur_lr": 0.00010000000000000003, "info/learner/predator_policy/learner_stats/total_loss": 6.297121504122618, "info/learner/predator_policy/learner_stats/policy_loss": -0.01004399551256072, "info/learner/predator_policy/learner_stats/vf_loss": 6.30693201186165, "info/learner/predator_policy/learner_stats/vf_explained_var": 0.40224476529176906, "info/learner/predator_policy/learner_stats/kl": 0.009339428690838671, "info/learner/predator_policy/learner_stats/entropy": 0.1549141616259933, "info/learner/predator_policy/learner_stats/entropy_coeff": 0.0, "_timestamp": 1724313493.5537431, "_runtime": 2847.313358068466, "_step": 99, "env_runners/policy_reward_min/prey_policy": -878.0505982962081, "env_runners/policy_reward_min/predator_policy": 0.0, "env_runners/policy_reward_max/prey_policy": 361.0496312532229, "env_runners/policy_reward_max/predator_policy": 1133.7571123334228, "env_runners/policy_reward_mean/prey_policy": -387.969083202238, "env_runners/policy_reward_mean/predator_policy": 474.7315530197382, "env_runners/sampler_perf/mean_raw_obs_processing_ms": 7.8558641919731755, "env_runners/sampler_perf/mean_inference_ms": 7.025941166821977, "env_runners/sampler_perf/mean_action_processing_ms": 2.479124016883518, "env_runners/sampler_perf/mean_env_wait_ms": 14.186617965750704, "env_runners/sampler_perf/mean_env_render_ms": 0.0, "env_runners/connector_metrics/ObsPreprocessorConnector_ms": 0.014721155166625977, "env_runners/connector_metrics/StateBufferConnector_ms": 0.004843473434448242, "env_runners/connector_metrics/ViewRequirementAgentConnector_ms": 0.24166333675384521}